<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8">
<meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/">

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>1. Introduction â€” PTX ISA 9.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css">
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css">
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css">
      <link rel="stylesheet" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" type="text/css">
      <link rel="stylesheet" href="../_static/omni-style.css" type="text/css">
      <link rel="stylesheet" href="../_static/api-styles.css" type="text/css">
      <link rel="stylesheet" href="../_static/ptx.css" type="text/css">
    <link rel="shortcut icon" href="../_static/favicon.ico">
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/mermaid-init.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script src="../_static/version.js"></script>
        <script src="../_static/social-media.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html">
    <link rel="search" title="Search" href="search.html">
    <link rel="prev" title="Contents" href="contents.html">
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">


<a href="contents.html">
  <img src="../_static/Logo_and_CUDA.png" class="logo" alt="Logo">
</a>

<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs">
    <input type="hidden" name="check_keywords" value="yes">
    <input type="hidden" name="area" value="default">
  </form>
</div>
        </div>
<div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current">
<a class="current reference internal" href="#">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#scalable-data-parallel-computing-using-gpus">1.1. Scalable Data-Parallel Computing using GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goals-of-ptx">1.2. Goals of PTX</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ptx-isa-version-9-1">1.3. PTX ISA Version 9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#document-structure">1.4. Document Structure</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#programming-model">2. Programming Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#highly-multithreaded-coprocessor">2.1. A Highly Multithreaded Coprocessor</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#thread-hierarchy">2.2. Thread Hierarchy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cooperative-thread-arrays">2.2.1. Cooperative Thread Arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cluster-of-cooperative-thread-arrays">2.2.2. Cluster of Cooperative Thread Arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="#grid-of-clusters">2.2.3. Grid of Clusters</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#memory-hierarchy">2.3. Memory Hierarchy</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#ptx-machine-model">3. PTX Machine Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#set-of-simt-multiprocessors">3.1. A Set of SIMT Multiprocessors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#independent-thread-scheduling">3.2. Independent Thread Scheduling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#on-chip-shared-memory">3.3. On-chip Shared Memory</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#syntax">4. Syntax</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#source-format">4.1. Source Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="#comments">4.2. Comments</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#statements">4.3. Statements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#directive-statements">4.3.1. Directive Statements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#instruction-statements">4.3.2. Instruction Statements</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#identifiers">4.4. Identifiers</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#constants">4.5. Constants</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#integer-constants">4.5.1. Integer Constants</a></li>
<li class="toctree-l3"><a class="reference internal" href="#floating-point-constants">4.5.2. Floating-Point Constants</a></li>
<li class="toctree-l3"><a class="reference internal" href="#predicate-constants">4.5.3. Predicate Constants</a></li>
<li class="toctree-l3"><a class="reference internal" href="#constant-expressions">4.5.4. Constant Expressions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#integer-constant-expression-evaluation">4.5.5. Integer Constant Expression Evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary-of-constant-expression-evaluation-rules">4.5.6. Summary of Constant Expression Evaluation Rules</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#state-spaces-types-and-variables">5. State Spaces, Types, and Variables</a><ul>
<li class="toctree-l2">
<a class="reference internal" href="#state-spaces">5.1. State Spaces</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#register-state-space">5.1.1. Register State Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#special-register-state-space">5.1.2. Special Register State Space</a></li>
<li class="toctree-l3">
<a class="reference internal" href="#constant-state-space">5.1.3. Constant State Space</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#banked-constant-state-space-deprecated">5.1.3.1. Banked Constant State Space (deprecated)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#global-state-space">5.1.4. Global State Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#local-state-space">5.1.5. Local State Space</a></li>
<li class="toctree-l3">
<a class="reference internal" href="#parameter-state-space">5.1.6. Parameter State Space</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#kernel-function-parameters">5.1.6.1. Kernel Function Parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kernel-function-parameter-attributes">5.1.6.2. Kernel Function Parameter Attributes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#kernel-parameter-attribute-ptr">5.1.6.3. Kernel Parameter Attribute: <code class="docutils literal notranslate"><span class="pre">.ptr</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#device-function-parameters">5.1.6.4. Device Function Parameters</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#shared-state-space">5.1.7. Shared State Space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#texture-state-space-deprecated">5.1.8. Texture State Space (deprecated)</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#types">5.2. Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#fundamental-types">5.2.1. Fundamental Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#restricted-use-of-sub-word-sizes">5.2.2. Restricted Use of Sub-Word Sizes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#alternate-floating-point-data-formats">5.2.3. Alternate Floating-Point Data Formats</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fixed-point-data-formats">5.2.4. Fixed-point Data format</a></li>
<li class="toctree-l3">
<a class="reference internal" href="#packed-data-types">5.2.5. Packed Data Types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#packed-floating-point-data-types">5.2.5.1. Packed Floating Point Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packed-integer-data-types">5.2.5.2. Packed Integer Data Types</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packed-fixed-point-data-types">5.2.5.3. Packed Fixed-Point Data Types</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#texture-sampler-and-surface-types">5.3. Texture Sampler and Surface Types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#texture-surface-properties">5.3.1. Texture and Surface Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sampler-properties">5.3.2. Sampler Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#channel-data-type-and-channel-order-fields">5.3.3. Channel Data Type and Channel Order Fields</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#variables">5.4. Variables</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#variable-declarations">5.4.1. Variable Declarations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#vectors">5.4.2. Vectors</a></li>
<li class="toctree-l3"><a class="reference internal" href="#array-declarations">5.4.3. Array Declarations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#initializers">5.4.4. Initializers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#alignment">5.4.5. Alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#parameterized-variable-names">5.4.6. Parameterized Variable Names</a></li>
<li class="toctree-l3"><a class="reference internal" href="#variable-attributes">5.4.7. Variable Attributes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#variable-and-function-attribute-directive-attribute">5.4.8. Variable and Function Attribute Directive: <code class="docutils literal notranslate"><span class="pre">.attribute</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#tensors">5.5. Tensors</a><ul>
<li class="toctree-l3">
<a class="reference internal" href="#tensor-dimension-size-format">5.5.1. Tensor Dimension, size and format</a><ul>
<li class="toctree-l4">
<a class="reference internal" href="#tensor-dimension-size-format-sub-bytes">5.5.1.1. Sub-byte Types</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tensor-dimension-size-format-sub-bytes-padding-align">5.5.1.1.1. Padding and alignment of the sub-byte types</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensor-access-modes">5.5.2. Tensor Access Modes</a></li>
<li class="toctree-l3">
<a class="reference internal" href="#tensor-tiled-mode">5.5.3. Tiled Mode</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tensor-tiled-mode-bounding-box">5.5.3.1. Bounding Box</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-tiled-mode-traversal-stride">5.5.3.2. Traversal-Stride</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-tiled-mode-oob-access">5.5.3.3. Out of Boundary Access</a></li>
<li class="toctree-l4">
<a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes">5.5.3.4. <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> modes</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes-bounding-box">5.5.3.4.1. Bounding Box</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#tensor-im2col-mode">5.5.4. <code class="docutils literal notranslate"><span class="pre">im2col</span></code> mode</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-mode-bounding-box">5.5.4.1. Bounding Box</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-mode-traversal-stride">5.5.4.2. Traversal Stride</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-mode-oob-access">5.5.4.3. Out of Boundary Access</a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#tensor-im2col-w-w128-modes">5.5.5. <code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> modes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-w-w128-modes-bounding-box">5.5.5.1. Bounding Box</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-w-w128-modes-traversal-stride">5.5.5.2. Traversal Stride</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-w-w128-modes-whalo">5.5.5.3. <code class="docutils literal notranslate"><span class="pre">wHalo</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tensor-im2col-w-w128-modes-woffset">5.5.5.4. <code class="docutils literal notranslate"><span class="pre">wOffset</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tensor-interleaved-layout">5.5.6. Interleave layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensor-swizzling-modes">5.5.7. Swizzling Modes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tensor-tensormap">5.5.8. Tensor-map</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#instruction-operands">6. Instruction Operands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#operand-type-information">6.1. Operand Type Information</a></li>
<li class="toctree-l2"><a class="reference internal" href="#source-operands">6.2. Source Operands</a></li>
<li class="toctree-l2"><a class="reference internal" href="#destination-operands">6.3. Destination Operands</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#using-addresses-arrays-and-vectors">6.4. Using Addresses, Arrays, and Vectors</a><ul>
<li class="toctree-l3">
<a class="reference internal" href="#addresses-as-operands">6.4.1. Addresses as Operands</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#generic-addressing">6.4.1.1. Generic Addressing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#arrays-as-operands">6.4.2. Arrays as Operands</a></li>
<li class="toctree-l3"><a class="reference internal" href="#vectors-as-operands">6.4.3. Vectors as Operands</a></li>
<li class="toctree-l3"><a class="reference internal" href="#labels-and-function-names-as-operands">6.4.4. Labels and Function Names as Operands</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#type-conversion">6.5. Type Conversion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#scalar-conversions">6.5.1. Scalar Conversions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rounding-modifiers">6.5.2. Rounding Modifiers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#operand-costs">6.6. Operand Costs</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#abstracting-abi">7. Abstracting the ABI</a><ul>
<li class="toctree-l2">
<a class="reference internal" href="#function-declarations-and-definitions">7.1. Function Declarations and Definitions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#changes-from-ptx-isa-version-1-x">7.1.1. Changes from PTX ISA Version 1.x</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#variadic-functions">7.2. Variadic Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#alloca">7.3. Alloca</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#memory-consistency-model">8. Memory Consistency Model</a><ul>
<li class="toctree-l2">
<a class="reference internal" href="#scope-and-applicability">8.1. Scope and applicability of the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#limitations-system-scope-atomicity">8.1.1. Limitations on atomicity at system scope</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#memory-operations">8.2. Memory operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overlap">8.2.1. Overlap</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aliases">8.2.2. Aliases</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multimem-addresses">8.2.3. Multimem Addresses</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-operations-on-vector-data-types">8.2.4. Memory Operations on Vector Data Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-operations-on-packed-data-types">8.2.5. Memory Operations on Packed Data Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="#initialization">8.2.6. Initialization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#memory-consistency-state-spaces">8.3. State spaces</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#operation-types">8.4. Operation types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#mmio-operation">8.4.1. mmio Operation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#volatile-operation">8.4.2. volatile Operation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#scope">8.5. Scope</a></li>
<li class="toctree-l2"><a class="reference internal" href="#proxies">8.6. Proxies</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#morally-strong-operations">8.7. Morally strong operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#conflict-and-data-races">8.7.1. Conflict and Data-races</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mixed-size-limitations">8.7.2. Limitations on Mixed-size Data-races</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#release-acquire-patterns">8.8. Release and Acquire Patterns</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#ordering-memory-operations">8.9. Ordering of memory operations</a><ul>
<li class="toctree-l3">
<a class="reference internal" href="#program-order">8.9.1. Program Order</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#program-order-async-operations">8.9.1.1. Asynchronous Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#observation-order">8.9.2. Observation Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fence-sc-order">8.9.3. Fence-SC Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="#memory-synchronization">8.9.4. Memory synchronization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#causality-order">8.9.5. Causality Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="#coherence-order">8.9.6. Coherence Order</a></li>
<li class="toctree-l3"><a class="reference internal" href="#communication-order">8.9.7. Communication Order</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#axioms">8.10. Axioms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#coherence-axiom">8.10.1. Coherence</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fence-sc-axiom">8.10.2. Fence-SC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#atomicity-axiom">8.10.3. Atomicity</a></li>
<li class="toctree-l3"><a class="reference internal" href="#no-thin-air-axiom">8.10.4. No Thin Air</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sc-per-loc-axiom">8.10.5. Sequential Consistency Per Location</a></li>
<li class="toctree-l3"><a class="reference internal" href="#causality-axiom">8.10.6. Causality</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#special-cases">8.11. Special Cases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#red-read">8.11.1. Reductions do not form Acquire Patterns</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#instruction-set">9. Instruction Set</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#format-and-semantics-of-instruction-descriptions">9.1. Format and Semantics of Instruction Descriptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ptx-instructions">9.2. PTX Instructions</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#predicated-execution">9.3. Predicated Execution</a><ul>
<li class="toctree-l3">
<a class="reference internal" href="#comparisons">9.3.1. Comparisons</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#integer-and-bit-size-comparisons">9.3.1.1. Integer and Bit-Size Comparisons</a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-comparisons">9.3.1.2. Floating Point Comparisons</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#manipulating-predicates">9.3.2. Manipulating Predicates</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#type-information-for-instructions-and-operands">9.4. Type Information for Instructions and Operands</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#operand-size-exceeding-instruction-type-size">9.4.1. Operand Size Exceeding Instruction-Type Size</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#divergence-of-threads-in-control-constructs">9.5. Divergence of Threads in Control Constructs</a></li>
<li class="toctree-l2">
<a class="reference internal" href="#semantics">9.6. Semantics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#machine-specific-semantics-of-16-bit-code">9.6.1. Machine-Specific Semantics of 16-bit Code</a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#instructions">9.7. Instructions</a><ul>
<li class="toctree-l3">
<a class="reference internal" href="#integer-arithmetic-instructions">9.7.1. Integer Arithmetic Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-add">9.7.1.1. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-sub">9.7.1.2. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-mul">9.7.1.3. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-mad">9.7.1.4. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-mul24">9.7.1.5. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mul24</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-mad24">9.7.1.6. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad24</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-sad">9.7.1.7. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-div">9.7.1.8. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">div</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-rem">9.7.1.9. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">rem</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-abs">9.7.1.10. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-neg">9.7.1.11. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-min">9.7.1.12. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-max">9.7.1.13. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-popc">9.7.1.14. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">popc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-clz">9.7.1.15. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">clz</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-bfind">9.7.1.16. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfind</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-fns">9.7.1.17. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">fns</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-brev">9.7.1.18. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">brev</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-bfe">9.7.1.19. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfe</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-bfi">9.7.1.20. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfi</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-szext">9.7.1.21. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">szext</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-bmsk">9.7.1.22. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bmsk</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-dp4a">9.7.1.23. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">dp4a</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#integer-arithmetic-instructions-dp2a">9.7.1.24. Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">dp2a</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#extended-precision-integer-arithmetic-instructions">9.7.2. Extended-Precision Integer Arithmetic Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-add-cc">9.7.2.1. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">add.cc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-addc">9.7.2.2. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">addc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-sub-cc">9.7.2.3. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-subc">9.7.2.4. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">subc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-mad-cc">9.7.2.5. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#extended-precision-arithmetic-instructions-madc">9.7.2.6. Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">madc</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#floating-point-instructions">9.7.3. Floating-Point Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-testp">9.7.3.1. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">testp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-copysign">9.7.3.2. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">copysign</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-add">9.7.3.3. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-sub">9.7.3.4. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-mul">9.7.3.5. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-fma">9.7.3.6. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-mad">9.7.3.7. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-div">9.7.3.8. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">div</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-abs">9.7.3.9. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-neg">9.7.3.10. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-min">9.7.3.11. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-max">9.7.3.12. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-rcp">9.7.3.13. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rcp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-rcp-approx-ftz-f64">9.7.3.14. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-sqrt">9.7.3.15. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sqrt</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-rsqrt">9.7.3.16. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rsqrt</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-rsqrt-approx-ftz-f64">9.7.3.17. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-sin">9.7.3.18. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sin</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-cos">9.7.3.19. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">cos</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-lg2">9.7.3.20. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">lg2</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-ex2">9.7.3.21. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">ex2</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#floating-point-instructions-tanh">9.7.3.22. Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">tanh</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#half-precision-floating-point-instructions">9.7.4. Half Precision Floating-Point Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-add">9.7.4.1. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-sub">9.7.4.2. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-mul">9.7.4.3. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-fma">9.7.4.4. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-neg">9.7.4.5. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-abs">9.7.4.6. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-min">9.7.4.7. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-max">9.7.4.8. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-tanh">9.7.4.9. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">tanh</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-floating-point-instructions-ex2">9.7.4.10. Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">ex2</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#mixed-precision-floating-point-instructions">9.7.5. Mixed Precision Floating-Point Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#mixed-precision-floating-point-instructions-add">9.7.5.1. Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#mixed-precision-floating-point-instructions-sub">9.7.5.2. Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#mixed-precision-floating-point-instructions-fma">9.7.5.3. Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#comparison-and-selection-instructions">9.7.6. Comparison and Selection Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#comparison-and-selection-instructions-set">9.7.6.1. Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">set</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#comparison-and-selection-instructions-setp">9.7.6.2. Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">setp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#comparison-and-selection-instructions-selp">9.7.6.3. Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">selp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#comparison-and-selection-instructions-slct">9.7.6.4. Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">slct</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#half-precision-comparison-instructions">9.7.7. Half Precision Comparison Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-comparison-instructions-set">9.7.7.1. Half Precision Comparison Instructions: <code class="docutils literal notranslate"><span class="pre">set</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#half-precision-comparison-instructions-setp">9.7.7.2. Half Precision Comparison Instructions: <code class="docutils literal notranslate"><span class="pre">setp</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#logic-and-shift-instructions">9.7.8. Logic and Shift Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-and">9.7.8.1. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">and</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-or">9.7.8.2. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">or</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-xor">9.7.8.3. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">xor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-not">9.7.8.4. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">not</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-cnot">9.7.8.5. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">cnot</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-lop3">9.7.8.6. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">lop3</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-shf">9.7.8.7. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shf</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-shl">9.7.8.8. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shl</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#logic-and-shift-instructions-shr">9.7.8.9. Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shr</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#data-movement-and-conversion-instructions">9.7.9. Data Movement and Conversion Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cache-operators">9.7.9.1. Cache Operators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#cache-eviction-priority-hints">9.7.9.2. Cache Eviction Priority Hints</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-mov">9.7.9.3. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mov</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-mov-2">9.7.9.4. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mov</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-shfl">9.7.9.5. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">shfl</span></code> (deprecated)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-shfl-sync">9.7.9.6. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-prmt">9.7.9.7. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">prmt</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-ld">9.7.9.8. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ld</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-ld-global-nc">9.7.9.9. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-ldu">9.7.9.10. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ldu</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-st">9.7.9.11. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-st-async">9.7.9.12. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st.async</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-st-bulk">9.7.9.13. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st.bulk</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-multimem">9.7.9.14. Data Movement and Conversion Instructions:
<code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-prefetch-prefetchu">9.7.9.15. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-applypriority">9.7.9.16. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">applypriority</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-discard">9.7.9.17. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">discard</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-createpolicy">9.7.9.18. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">createpolicy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-isspacep">9.7.9.19. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">isspacep</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-cvta">9.7.9.20. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvta</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-cvt">9.7.9.21. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvt</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-cvt-pack">9.7.9.22. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-mapa">9.7.9.23. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mapa</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-getctarank">9.7.9.24. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">getctarank</span></code></a></li>
<li class="toctree-l4">
<a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy">9.7.9.25. Data Movement and Conversion Instructions: Asynchronous copy</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms">9.7.9.25.1. Completion Mechanisms for Asynchronous Copy Operations</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-async-group">9.7.9.25.1.1. Async-group mechanism</a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-mbarrier">9.7.9.25.1.2. Mbarrier-based mechanism</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#async-proxy">9.7.9.25.2. Async Proxy</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#data-movement-and-conversion-instructions-non-bulk-copy">9.7.9.25.3. Data Movement and Conversion Instructions: Non-bulk copy</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async">9.7.9.25.3.1. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-commit-group">9.7.9.25.3.2. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-wait-group">9.7.9.25.3.3. Data Movement and Conversion Instructions:
<code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> / <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code></a></li>
</ul>
</li>
<li class="toctree-l5">
<a class="reference internal" href="#data-movement-and-conversion-instructions-bulk-copy">9.7.9.25.4. Data Movement and Conversion Instructions: Bulk copy</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk">9.7.9.25.4.1. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk">9.7.9.25.4.2. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch">9.7.9.25.4.3. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-multimem-cp-async-bulk">9.7.9.26. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code></a></li>
<li class="toctree-l4">
<a class="reference internal" href="#data-movement-and-conversion-instructions-multimem-cp-reduce-async-bulk">9.7.9.27. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code></a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#data-movement-and-conversion-instructions-tensor-copy">9.7.9.27.1. Data Movement and Conversion Instructions: Tensor copy</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions">9.7.9.27.1.1. Restriction on Tensor Copy instructions</a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-tensor">9.7.9.27.1.2. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor">9.7.9.27.1.3. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch-tensor">9.7.9.27.1.4. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code></a></li>
</ul>
</li>
<li class="toctree-l5">
<a class="reference internal" href="#data-movement-and-conversion-instructions-bulk-tensor-copy-completion">9.7.9.27.2. Data Movement and Conversion Instructions: Bulk and Tensor copy completion instructions</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-commit-group">9.7.9.27.2.1. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-wait-group">9.7.9.27.2.2. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#data-movement-and-conversion-instructions-tensormap-replace">9.7.9.28. Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#texture-instructions">9.7.10. Texture Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#texturing-modes">9.7.10.1. Texturing Modes</a></li>
<li class="toctree-l4"><a class="reference internal" href="#mipmaps">9.7.10.2. Mipmaps</a></li>
<li class="toctree-l4"><a class="reference internal" href="#texture-instructions-tex">9.7.10.3. Texture Instructions: <code class="docutils literal notranslate"><span class="pre">tex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#texture-instructions-tld4">9.7.10.4. Texture Instructions: <code class="docutils literal notranslate"><span class="pre">tld4</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#texture-instructions-txq">9.7.10.5. Texture Instructions: <code class="docutils literal notranslate"><span class="pre">txq</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#texture-instructions-istypep">9.7.10.6. Texture Instructions: <code class="docutils literal notranslate"><span class="pre">istypep</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#surface-instructions">9.7.11. Surface Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#surface-instructions-suld">9.7.11.1. Surface Instructions: <code class="docutils literal notranslate"><span class="pre">suld</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surface-instructions-sust">9.7.11.2. Surface Instructions: <code class="docutils literal notranslate"><span class="pre">sust</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surface-instructions-sured">9.7.11.3. Surface Instructions: <code class="docutils literal notranslate"><span class="pre">sured</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#surface-instructions-suq">9.7.11.4. Surface Instructions: <code class="docutils literal notranslate"><span class="pre">suq</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#control-flow-instructions">9.7.12. Control Flow Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-curly-braces">9.7.12.1. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">{}</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-at">9.7.12.2. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">@</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-bra">9.7.12.3. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">bra</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-brx-idx">9.7.12.4. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-call">9.7.12.5. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">call</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-ret">9.7.12.6. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">ret</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#control-flow-instructions-exit">9.7.12.7. Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">exit</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions">9.7.13. Parallel Synchronization and Communication Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-bar">9.7.13.1. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">bar</span></code>, <code class="docutils literal notranslate"><span class="pre">barrier</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-bar-warp-sync">9.7.13.2. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-barrier-cluster">9.7.13.3. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-membar">9.7.13.4. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">membar</span></code> / <code class="docutils literal notranslate"><span class="pre">fence</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-atom">9.7.13.5. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">atom</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-red">9.7.13.6. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">red</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-red-async">9.7.13.7. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">red.async</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-vote">9.7.13.8. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">vote</span></code> (deprecated)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-vote-sync">9.7.13.9. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-match-sync">9.7.13.10. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">match.sync</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-activemask">9.7.13.11. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">activemask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-redux-sync">9.7.13.12. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-griddepcontrol">9.7.13.13. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-elect-sync">9.7.13.14. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">elect.sync</span></code></a></li>
<li class="toctree-l4">
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier">9.7.13.15. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code></a><ul>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment">9.7.13.15.1. Size and alignment of mbarrier object</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents">9.7.13.15.2. Contents of the mbarrier object</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-lifecycle">9.7.13.15.3. Lifecycle of the mbarrier object</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase">9.7.13.15.4. Phase of the mbarrier object</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations">9.7.13.15.5. Tracking asynchronous operations by the mbarrier object</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation">9.7.13.15.5.1. expect-tx operation</a></li>
<li class="toctree-l6"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation">9.7.13.15.5.2. complete-tx operation</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion">9.7.13.15.6. Phase Completion of the mbarrier object</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on">9.7.13.15.7. Arrive-on operation on mbarrier object</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-smem">9.7.13.15.8. mbarrier support with shared memory</a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-init">9.7.13.15.9. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-inval">9.7.13.15.10. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx">9.7.13.15.11. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx">9.7.13.15.12. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive">9.7.13.15.13. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop">9.7.13.15.14. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive">9.7.13.15.15. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait">9.7.13.15.16. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> / <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-pending-count">9.7.13.15.17. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code></a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy">9.7.13.16. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel">9.7.13.17. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel">9.7.13.18. Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#warp-level-matrix-instructions">9.7.14. Warp Level Matrix Multiply-Accumulate Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#warp-level-matrix-shape">9.7.14.1. Matrix Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#warp-level-matrix-data-types">9.7.14.2. Matrix Data-types</a></li>
<li class="toctree-l4"><a class="reference internal" href="#warp-level-block-scaling">9.7.14.3. Block Scaling for <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code></a></li>
<li class="toctree-l4">
<a class="reference internal" href="#warp-level-matrix-instructions-wmma">9.7.14.4. Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment">9.7.14.4.1. Matrix Fragments for WMMA</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-storage">9.7.14.4.2. Matrix Storage for WMMA</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-wmma-ld">9.7.14.4.3. Warp-level Matrix Load Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-wmma-st">9.7.14.4.4. Warp-level Matrix Store Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-wmma-mma">9.7.14.4.5. Warp-level Matrix Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#warp-level-matrix-instructions-for-mma">9.7.14.5. Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-884-f16">9.7.14.5.1. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-884-f64">9.7.14.5.2. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-8816">9.7.14.5.3. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k16</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-8832">9.7.14.5.4. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k32</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-88128">9.7.14.5.5. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k128</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-1684">9.7.14.5.6. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k4</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-1688">9.7.14.5.7. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-float">9.7.14.5.8. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with floating point type</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-i8-f8">9.7.14.5.9. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with integer type</a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-16832">9.7.14.5.10. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-16864">9.7.14.5.11. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-168128">9.7.14.5.12. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-fragment-mma-168256">9.7.14.5.13. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k256</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-mma">9.7.14.5.14. Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">mma</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-ldmatrix">9.7.14.5.15. Warp-level matrix load instruction: <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-stmatrix">9.7.14.5.16. Warp-level matrix store instruction: <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-movmatrix">9.7.14.5.17. Warp-level matrix transpose instruction: <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#warp-level-matrix-instructions-for-sparse-mma">9.7.14.6. Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instruction with sparse matrix A</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-sparse-matrix-storage">9.7.14.6.1. Sparse matrix storage</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#warp-level-matrix-fragments-for-sparse-mma">9.7.14.6.2. Matrix fragments for multiply-accumulate operation with sparse matrix A</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16816-f16bf16">9.7.14.6.2.1. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16832-f16bf16">9.7.14.6.2.2. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16816-tf32">9.7.14.6.2.3. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-1688-tf32">9.7.14.6.2.4. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16832-u8s8">9.7.14.6.2.5. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> integer type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8">9.7.14.6.2.6. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16864-u4s4">9.7.14.6.2.7. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> integer type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-168128-u4s4">9.7.14.6.2.8. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> integer type</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#warp-level-matrix-instructions-sparse-mma">9.7.14.6.3. Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> / <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions">9.7.15. Asynchronous Warpgroup Level Matrix Multiply-Accumulate Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-warpgroup">9.7.15.1. Warpgroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape">9.7.15.2. Matrix Shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-data-types">9.7.15.3. Matrix Data-types</a></li>
<li class="toctree-l4"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-async-proxy">9.7.15.4. Async Proxy</a></li>
<li class="toctree-l4">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-operation-wgmma-mma-async">9.7.15.5. Asynchronous Warpgroup Level Matrix Multiply-Accumulate Operation using <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment">9.7.15.5.1. Register Fragments and Shared Memory Matrix Layouts</a><ul>
<li class="toctree-l6">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment">9.7.15.5.1.1. Register Fragments</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n16">9.7.15.5.1.1.1. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n8">9.7.15.5.1.1.2. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk8</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32">9.7.15.5.1.1.3. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n256">9.7.15.5.1.1.4. Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk256</span></code></a></li>
</ul>
</li>
<li class="toctree-l6">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout">9.7.15.5.1.2. Shared Memory Matrix Layout</a><ul>
<li class="toctree-l7">
<a class="reference internal" href="#asynchronous-warpgroup-level-majorness-supported-by-strides">9.7.15.5.1.2.1. Major-ness supported by Strides</a><ul>
<li class="toctree-l8"><a class="reference internal" href="#asynchronous-warpgroup-level-leading-dimension-byte-offset">9.7.15.5.1.2.1.1. Leading Dimension Byte Offset</a></li>
<li class="toctree-l8"><a class="reference internal" href="#asynchronous-warpgroup-level-stride-dimension-byte-offset">9.7.15.5.1.2.1.2. Stride Dimension Byte Offset</a></li>
<li class="toctree-l8"><a class="reference internal" href="#asynchronous-warpgroup-level-canonical-layouts">9.7.15.5.1.2.1.3. Canonical Layouts</a></li>
</ul>
</li>
<li class="toctree-l7"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor">9.7.15.5.1.2.2. Matrix Descriptor Format</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma">9.7.15.5.2. Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-for-sparse-wgmma">9.7.15.6. Asynchronous Warpgroup Level Multiply-and-Accumulate Operation using <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> instruction</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage">9.7.15.6.1. Sparse matrix storage</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragments-for-sparse-wgmma">9.7.15.6.2. Matrix fragments for warpgroup-level multiply-accumulate operation with sparse matrix A</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n32">9.7.15.6.2.1. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n16">9.7.15.6.2.2. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64">9.7.15.6.2.3. Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk64</span></code></a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma-sp">9.7.15.6.3. Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#asynchronous-wgmma-proxy-operations">9.7.15.7. Asynchronous <code class="docutils literal notranslate"><span class="pre">wgmma</span></code> Proxy Operations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-fence">9.7.15.7.1. Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group">9.7.15.7.2. Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group">9.7.15.7.3. Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#tensorcore-5th-generation-instructions">9.7.16. TensorCore 5th Generation Family Instructions</a><ul>
<li class="toctree-l4">
<a class="reference internal" href="#tensor-memory">9.7.16.1. Tensor Memory</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tensor-memory-addressing">9.7.16.1.1. Tensor Memory Addressing</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tensor-memory-allocation">9.7.16.1.2. Tensor Memory Allocation</a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-matrix-data-movement-shape">9.7.16.2. Matrix and Data Movement Shape</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-matrix-shape">9.7.16.2.1. Matrix Shape</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-matrix-shape-target-isa-note">9.7.16.2.1.1. Target ISA Note</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-specify-matrix-shape">9.7.16.2.2. Specifying Matrix Shape</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-data-movement-shape">9.7.16.2.3. Data Movement Shape</a><ul>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-memory-layout">9.7.16.2.3.1. Memory Layout</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-matrix-fragments-shape-3232b">9.7.16.2.3.1.1. Matrix fragments for shape .32x32b</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-matrix-fragments-shape-6464b">9.7.16.2.3.1.2. Matrix fragments for shape .16x64b</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-matrix-fragments-shape-16128b">9.7.16.2.3.1.3. Matrix fragments for shape .16x128b</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-matrix-fragments-shape-16256b">9.7.16.2.3.1.4. Matrix fragments for shape .16x256b</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-matrix-fragments-shape-1632b2">9.7.16.2.3.1.5. Matrix fragments for shape .16x32bx2</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-majorness-supported-by-strides">9.7.16.3. Major-ness supported by Strides</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-leading-dimension-byte-offset">9.7.16.3.1. Leading Dimension Stride: relative offset or absolute address</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-relative-offset">9.7.16.3.1.1. Relative offset mode</a></li>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-absolute-address">9.7.16.3.1.2. Absolute address mode for K dimension being 48B</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-absolute-address-restriction">9.7.16.3.1.2.1. Restrictions on the Leading Dimension Absolute Address Stride</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-stride-dimension-byte-offset">9.7.16.3.2. Stride Dimension Byte Offset</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-canonical-layouts">9.7.16.3.3. Canonical Layouts</a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-matrix-descriptors">9.7.16.4. Matrix Descriptors</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-shared-memory-descriptor">9.7.16.4.1. Shared memory descriptor</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-shared-memory-descriptor-target-isa-note">9.7.16.4.1.1. Target ISA Note</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instruction-descriptor">9.7.16.4.2. Instruction descriptor</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-zero-column-mask-descriptor">9.7.16.4.3. Zero-Column Mask Descriptor</a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-issue-granularity">9.7.16.5. Issue Granularity</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-cta-pair">9.7.16.5.1. CTA Pair</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-peer-cta">9.7.16.5.2. Peer CTA</a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-memory-consistency-model">9.7.16.6. Memory Consistency Model for 5th generation of TensorCore operations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-memory-consistency-model-async-operations">9.7.16.6.1. Asynchronous Operations</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-memory-consistency-model-pipelined-instructions">9.7.16.6.2. Pipelined tcgen05 Instructions</a><ul>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-memory-consistency-model-pipelined-instructions-implicit">9.7.16.6.2.1. Implicitly pipelined tcgen05 Instructions</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-memory-consistency-model-mbarrier-completion">9.7.16.6.2.1.1. mbarrier based completion mechanism</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-memory-consistency-model-wait-completion">9.7.16.6.2.1.2. <code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code> instruction based completion mechanism</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-memory-consistency-model-inter-thread-sync">9.7.16.6.3. Specialized Inter-thread Synchronization for tcgen05 instructions</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns">9.7.16.6.4. Canonical synchronization patterns</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-same-thread">9.7.16.6.4.1. Pipelined instructions, same thread</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-same-thread">9.7.16.6.4.2. Non-pipelined instructions, same thread</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-diff-thread">9.7.16.6.4.3. Pipelined instructions, different thread</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-diff-thread">9.7.16.6.4.4. Non-pipelined instructions, different thread</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-reg-dependency-same-thread">9.7.16.6.4.5. Register dependencies, same thread</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-memory-consistency-model-smem-access">9.7.16.6.5. Shared Memory Accesses</a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-memory-alloc-manage-instructions">9.7.16.7. Tensor Memory Allocation and Management Instructions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-alloc-dealloc-relinquish-alloc-permit">9.7.16.7.1. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-tensor-memory-ld-st">9.7.16.8. Tensor Memory and Register Load/Store Instructions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-tensor-memory-ld-st-access-restrictions">9.7.16.8.1. Access restrictions</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-tensor-memory-ld-st-packing-unpacking">9.7.16.8.2. Packing and Unpacking</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-ld">9.7.16.8.3. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-st">9.7.16.8.4. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-wait">9.7.16.8.5. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-data-movement-instructions">9.7.16.9. Tensor Memory Data Movement Instructions</a><ul>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-optional-decompression">9.7.16.9.1. Optional Decompression</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-optional-decompression-4bit-8bit">9.7.16.9.1.1. Decompression of 4-bit floating point to 8-bit type</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-optional-decompression-6bit-8bit">9.7.16.9.1.2. Decompression of 6-bit floating point to 8-bit type</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-cp">9.7.16.9.2. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-instructions-tcgen05-shift">9.7.16.9.3. Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-mma">9.7.16.10. TensorCore 5th Generation Matrix Multiply and accumulate Operations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-transpose-and-negate-operations">9.7.16.10.1. Transpose and Negate operations</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-matrix-layout-organization">9.7.16.10.2. Matrix Layout Organization</a></li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-matrix-layout-organization-valid-comb-type-size-majorness-swizzle">9.7.16.10.3. Valid Combinations of Type-Size, Major-ness and Swizzling</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-packing-formats">9.7.16.10.4. Packing formats of elements in Tensor and Shared memory</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mat-d">9.7.16.10.4.1. Packing format for matrix D in Tensor Memory</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mat-a-b">9.7.16.10.4.2. Packing format for matrix A and B</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-tmem">9.7.16.10.4.3. Packing format used for matrix A by <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> in Tensor Memory</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-smem">9.7.16.10.4.4. Packing format used for matrix A and B by <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> in Shared Memory</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mxf4-tmem">9.7.16.10.4.5. Packing format used for matrix A by <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> in Tensor Memory</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-packing-formats-mxf4-smem">9.7.16.10.4.6. Packing format used for matrix A and B by <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> in Shared Memory</a></li>
</ul>
</li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-data-path-layout-organization">9.7.16.10.5. Data Path Layout Organization</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-a">9.7.16.10.5.1. Layout A (M = 256)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-b">9.7.16.10.5.2. Layout B (M = 128 + cta-group::2 + Dense A matrix)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-c">9.7.16.10.5.3. Layout C (M = 128 + cta-group::2 + Sparse A matrix)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-d">9.7.16.10.5.4. Layout D (M = 128 + cta-group::1)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-e">9.7.16.10.5.5. Layout E (M = 64 + .ws mode)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-f">9.7.16.10.5.6. Layout F (M = 64 + non .ws mode)</a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-data-path-layout-g">9.7.16.10.5.7. Layout G (M = 32)</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-shared-memory-layout-swizzling">9.7.16.10.6. Shared Memory Layout and Swizzling</a></li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-block-scaling">9.7.16.10.7. Block Scaling for <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sync</span></code></a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-mma-scale-valid-vec-size">9.7.16.10.7.1. Valid combinations of scale_vectorsize with types and MMA-Kind</a></li>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-mma-scale-factor-a">9.7.16.10.7.2. Scale Factor A ID</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-1x">9.7.16.10.7.2.1. Layout of the Scale Factor A Matrix for scale_vec::1X/block32 with K=32/K=64</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-2x">9.7.16.10.7.2.2. Layout of the Scale Factor A Matrix for scale_vec::2X/block32 with K=64/K=128</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-4x">9.7.16.10.7.2.3. Layout of the Scale Factor A Matrix for scale_vec::4X/block16 with K=64/K=128</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-block32-k96">9.7.16.10.7.2.4. Layout of the Scale Factor A Matrix for block32 with K=96 (Semantically equivalent to scale_vec::3X)</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-block16-k96">9.7.16.10.7.2.5. Layout of the Scale Factor A Matrix for block16 with K=96 (Semantically equivalent to scale_vec::6X)</a></li>
</ul>
</li>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-mma-scale-factor-b">9.7.16.10.7.3. Scale Factor B ID</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-1x">9.7.16.10.7.3.1. Layout of the Scale Factor B Matrix for scale_vec::1X/block32 with K=32/K=64</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-2x">9.7.16.10.7.3.2. Layout of the Scale Factor B Matrix for scale_vec::2X/block32 with K=64/K=128</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-4x">9.7.16.10.7.3.3. Layout of the Scale Factor B Matrix for scale_vec::4X/block16 with K=64/K=128</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-block32-k96">9.7.16.10.7.3.4. Layout of the Scale Factor B Matrix for block32 with K=96 (Semantically equivalent to scale_vec::3X)</a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-block16-k96">9.7.16.10.7.3.5. Layout of the Scale Factor B Matrix for block16 with K=96 (Semantically equivalent to scale_vec::6X)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-sparse-matrices">9.7.16.10.8. Sparse Matrices</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-sparse-matrices-kind-tf32">9.7.16.10.8.1. Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-sparse-matrices-kind-f16-f8f8f4-mxf8f6f4">9.7.16.10.8.2. Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-sparse-matrices-kind-mxf4">9.7.16.10.8.3. Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a></li>
<li class="toctree-l6">
<a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector">9.7.16.10.8.4. Sparsity selector</a><ul>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64">9.7.16.10.8.4.1. Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256">9.7.16.10.8.4.2. Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64">9.7.16.10.8.4.3. Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256">9.7.16.10.8.4.4. Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64">9.7.16.10.8.4.5. Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a></li>
<li class="toctree-l7"><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256">9.7.16.10.8.4.6. Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a></li>
</ul>
</li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-sparse-matrices-alignment-restriction">9.7.16.10.8.5. Alignment restriction</a></li>
</ul>
</li>
<li class="toctree-l5">
<a class="reference internal" href="#tcgen05-mma-instructions">9.7.16.10.9. TensorCore 5th Generation of MMA Instructions</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-mma-instructions-mma">9.7.16.10.9.1. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-mma-instructions-mma-sp">9.7.16.10.9.2. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-mma-instructions-mma-ws">9.7.16.10.9.3. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#tcgen05-mma-instructions-mma-ws-sp">9.7.16.10.9.4. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen05-special-sync-operations">9.7.16.11. TensorCore 5th Generation Specialized Synchronization Operations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen05-special-sync-operations-fence">9.7.16.11.1. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.fence</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#tcgen-async-sync-operations">9.7.16.12. TensorCore 5th Generation Async Synchronization Operations</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tcgen-async-sync-operations-commit">9.7.16.12.1. TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#stack-manipulation-instructions">9.7.17. Stack Manipulation Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#stack-manipulation-instructions-stacksave">9.7.17.1. Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">stacksave</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#stack-manipulation-instructions-stackrestore">9.7.17.2. Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#stack-manipulation-instructions-alloca">9.7.17.3. Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">alloca</span></code></a></li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#video-instructions">9.7.18. Video Instructions</a><ul>
<li class="toctree-l4">
<a class="reference internal" href="#scalar-video-instructions">9.7.18.1. Scalar Video Instructions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#scalar-video-instructions-vadd-vsub-vabsdiff-vmin-vmax">9.7.18.1.1. Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#scalar-video-instructions-vshl-vshr">9.7.18.1.2. Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vshl</span></code>, <code class="docutils literal notranslate"><span class="pre">vshr</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#scalar-video-instructions-vmad">9.7.18.1.3. Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vmad</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#scalar-video-instructions-vset">9.7.18.1.4. Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset</span></code></a></li>
</ul>
</li>
<li class="toctree-l4">
<a class="reference internal" href="#simd-video-instructions">9.7.18.2. SIMD Video Instructions</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#simd-video-instructions-vadd2-vsub2-vavrg2-vabsdiff2-vmin2-vmax2">9.7.18.2.1. SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub2</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg2</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax2</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#simd-video-instructions-vset2">9.7.18.2.2. SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset2</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#simd-video-instructions-vadd4-vsub4-vavrg4-vabsdiff4-vmin4-vmax4">9.7.18.2.3. SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd4</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg4</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#simd-video-instructions-vset4">9.7.18.2.4. SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset4</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3">
<a class="reference internal" href="#miscellaneous-instructions">9.7.19. Miscellaneous Instructions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#miscellaneous-instructions-brkpt">9.7.19.1. Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">brkpt</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#miscellaneous-instructions-nanosleep">9.7.19.2. Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">nanosleep</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#miscellaneous-instructions-pmevent">9.7.19.3. Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">pmevent</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#miscellaneous-instructions-trap">9.7.19.4. Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">trap</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#miscellaneous-instructions-setmaxnreg">9.7.19.5. Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#special-registers">10. Special Registers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-tid">10.1. Special Registers: <code class="docutils literal notranslate"><span class="pre">%tid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-ntid">10.2. Special Registers: <code class="docutils literal notranslate"><span class="pre">%ntid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-laneid">10.3. Special Registers: <code class="docutils literal notranslate"><span class="pre">%laneid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-warpid">10.4. Special Registers: <code class="docutils literal notranslate"><span class="pre">%warpid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-nwarpid">10.5. Special Registers: <code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-ctaid">10.6. Special Registers: <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-nctaid">10.7. Special Registers: <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-smid">10.8. Special Registers: <code class="docutils literal notranslate"><span class="pre">%smid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-nsmid">10.9. Special Registers: <code class="docutils literal notranslate"><span class="pre">%nsmid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-gridid">10.10. Special Registers: <code class="docutils literal notranslate"><span class="pre">%gridid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-is-explicit-cluster">10.11. Special Registers: <code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-clusterid">10.12. Special Registers: <code class="docutils literal notranslate"><span class="pre">%clusterid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-nclusterid">10.13. Special Registers: <code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-cluster-ctaid">10.14. Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-cluster-nctaid">10.15. Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-cluster-ctarank">10.16. Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-cluster-nctarank">10.17. Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-lanemask-eq">10.18. Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-lanemask-le">10.19. Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-lanemask-lt">10.20. Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-lanemask-ge">10.21. Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-lanemask-gt">10.22. Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-clock">10.23. Special Registers: <code class="docutils literal notranslate"><span class="pre">%clock</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-clock64">10.24. Special Registers: <code class="docutils literal notranslate"><span class="pre">%clock64</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-pm0-pm7">10.25. Special Registers: <code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-pm0-64-pm7-64">10.26. Special Registers: <code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-envreg-32">10.27. Special Registers: <code class="docutils literal notranslate"><span class="pre">%envreg&lt;32&gt;</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-globaltimer">10.28. Special Registers: <code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-reserved-smem">10.29. Special Registers: <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code>,
<code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_&lt;2&gt;</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-total-smem-size">10.30. Special Registers: <code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-aggr-smem-size">10.31. Special Registers: <code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-dynamic-smem-size">10.32. Special Registers: <code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#special-registers-current-graph-exec">10.33. Special Registers: <code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code></a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#directives">11. Directives</a><ul>
<li class="toctree-l2">
<a class="reference internal" href="#ptx-module-directives">11.1. PTX Module Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ptx-module-directives-version">11.1.1. PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.version</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ptx-module-directives-target">11.1.2. PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.target</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#ptx-module-directives-address-size">11.1.3. PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.address_size</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#specifying-kernel-entry-points-and-functions">11.2. Specifying Kernel Entry Points and Functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#kernel-and-function-directives-entry">11.2.1. Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.entry</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel-and-function-directives-func">11.2.2. Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.func</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#kernel-and-function-directives-alias">11.2.3. Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.alias</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#control-flow-directives">11.3. Control Flow Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#control-flow-directives-branchtargets">11.3.1. Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#control-flow-directives-calltargets">11.3.2. Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#control-flow-directives-callprototype">11.3.3. Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.callprototype</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#performance-tuning-directives">11.4. Performance-Tuning Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-maxnreg">11.4.1. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-maxntid">11.4.2. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-reqntid">11.4.3. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-minnctapersm">11.4.4. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-maxnctapersm">11.4.5. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> (deprecated)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-noreturn">11.4.6. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-pragma">11.4.7. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.pragma</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-abi-preserve">11.4.8. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning-directives-abi-preserve-control">11.4.9. Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#debugging-directives">11.5. Debugging Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#debugging-directives-atatdwarf">11.5.1. Debugging Directives: <code class="docutils literal notranslate"><span class="pre">@@dwarf</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging-directives-section">11.5.2. Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.section</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging-directives-file">11.5.3. Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.file</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging-directives-loc">11.5.4. Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.loc</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#linking-directives">11.6. Linking Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#linking-directives-extern">11.6.1. Linking Directives: <code class="docutils literal notranslate"><span class="pre">.extern</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#linking-directives-visible">11.6.2. Linking Directives: <code class="docutils literal notranslate"><span class="pre">.visible</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#linking-directives-weak">11.6.3. Linking Directives: <code class="docutils literal notranslate"><span class="pre">.weak</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#linking-directives-common">11.6.4. Linking Directives: <code class="docutils literal notranslate"><span class="pre">.common</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#cluster-dimension-directives">11.7. Cluster Dimension Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cluster-dimension-directives-reqnctapercluster">11.7.1. Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cluster-dimension-directives-explicitcluster">11.7.2. Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#cluster-dimension-directives-maxclusterrank">11.7.3. Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code></a></li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="#miscellaneous-directives">11.8. Miscellaneous Directives</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#miscellaneous-directives-blocksareclusters">11.8.1. Miscellaneous Directives: <code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#descriptions-pragma-strings">12. Descriptions of <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> Strings</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pragma-strings-nounroll">12.1. Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"nounroll"</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#pragma-strings-used-bytes-mask">12.2. Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"used_bytes_mask"</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#pragma-strings-enable-smem-spilling">12.3. Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"enable_smem_spilling"</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="#pragma-strings-frequency">12.4. Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"frequency"</span></code></a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#release-notes">13. Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-9-1">13.1. Changes in PTX ISA Version 9.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-9-0">13.2. Changes in PTX ISA Version 9.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-8">13.3. Changes in PTX ISA Version 8.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-7">13.4. Changes in PTX ISA Version 8.7</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-6">13.5. Changes in PTX ISA Version 8.6</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-5">13.6. Changes in PTX ISA Version 8.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-4">13.7. Changes in PTX ISA Version 8.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-3">13.8. Changes in PTX ISA Version 8.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-2">13.9. Changes in PTX ISA Version 8.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-1">13.10. Changes in PTX ISA Version 8.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-8-0">13.11. Changes in PTX ISA Version 8.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-8">13.12. Changes in PTX ISA Version 7.8</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-7">13.13. Changes in PTX ISA Version 7.7</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-6">13.14. Changes in PTX ISA Version 7.6</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-5">13.15. Changes in PTX ISA Version 7.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-4">13.16. Changes in PTX ISA Version 7.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-3">13.17. Changes in PTX ISA Version 7.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-2">13.18. Changes in PTX ISA Version 7.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-1">13.19. Changes in PTX ISA Version 7.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-7-0">13.20. Changes in PTX ISA Version 7.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-5">13.21. Changes in PTX ISA Version 6.5</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-4">13.22. Changes in PTX ISA Version 6.4</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-3">13.23. Changes in PTX ISA Version 6.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-2">13.24. Changes in PTX ISA Version 6.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-1">13.25. Changes in PTX ISA Version 6.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-6-0">13.26. Changes in PTX ISA Version 6.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-5-0">13.27. Changes in PTX ISA Version 5.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-4-3">13.28. Changes in PTX ISA Version 4.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-4-2">13.29. Changes in PTX ISA Version 4.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-4-1">13.30. Changes in PTX ISA Version 4.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-4-0">13.31. Changes in PTX ISA Version 4.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-3-2">13.32. Changes in PTX ISA Version 3.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-3-1">13.33. Changes in PTX ISA Version 3.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-3-0">13.34. Changes in PTX ISA Version 3.0</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-2-3">13.35. Changes in PTX ISA Version 2.3</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-2-2">13.36. Changes in PTX ISA Version 2.2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-2-1">13.37. Changes in PTX ISA Version 2.1</a></li>
<li class="toctree-l2"><a class="reference internal" href="#changes-in-ptx-isa-version-2-0">13.38. Changes in PTX ISA Version 2.0</a></li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="#notices">14. Notices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#notice">14.1. Notice</a></li>
<li class="toctree-l2"><a class="reference internal" href="#opencl">14.2. OpenCL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#trademarks">14.3. Trademarks</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="contents.html">PTX ISA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">


  

<li>
<a href="../index.html" class="icon icon-home"></a> Â»</li>
  
<li>
<span class="section-number">1. </span>Introduction</li>

      <li class="wy-breadcrumbs-aside">
      </li>
<li class="wy-breadcrumbs-aside">


  <span>v9.1 |</span>



  <a href="../pdf/ptx_isa_9.1.pdf" class="reference external">PDF</a>



  <span>|</span>



  <a href="https://developer.nvidia.com/cuda-toolkit-archive" class="reference external">Archive</a>


  <span>Â </span>
</li>

  </ul>
  <hr>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p class="rubric-h1 rubric">Parallel Thread Execution ISA Version 9.1</p>
<p>The programming guide to using PTX (Parallel Thread Execution) and ISA (Instruction Set Architecture).</p>
<section id="introduction">
<span id="id1"></span><h1>
<span class="section-number">1. </span><a class="reference internal" href="#introduction">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this headline">ïƒ</a>
</h1>
<p>This document describes PTX, a low-level <em>parallel thread execution</em> virtual machine and instruction
set architecture (ISA). PTX exposes the GPU as a data-parallel computing <em>device</em>.</p>
<section id="scalable-data-parallel-computing-using-gpus">
<span id="id2"></span><h2>
<span class="section-number">1.1. </span><a class="reference internal" href="#scalable-data-parallel-computing-using-gpus">Scalable Data-Parallel Computing using GPUs</a><a class="headerlink" href="#scalable-data-parallel-computing-using-gpus" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Driven by the insatiable market demand for real-time, high-definition 3D graphics, the programmable
GPU has evolved into a highly parallel, multithreaded, many-core processor with tremendous
computational horsepower and very high memory bandwidth. The GPU is especially well-suited to
address problems that can be expressed as data-parallel computations - the same program is executed
on many data elements in parallel - with high arithmetic intensity - the ratio of arithmetic
operations to memory operations. Because the same program is executed for each data element, there
is a lower requirement for sophisticated flow control; and because it is executed on many data
elements and has high arithmetic intensity, the memory access latency can be hidden with
calculations instead of big data caches.</p>
<p>Data-parallel processing maps data elements to parallel processing threads. Many applications that
process large data sets can use a data-parallel programming model to speed up the computations. In
3D rendering large sets of pixels and vertices are mapped to parallel threads. Similarly, image and
media processing applications such as post-processing of rendered images, video encoding and
decoding, image scaling, stereo vision, and pattern recognition can map image blocks and pixels to
parallel processing threads. In fact, many algorithms outside the field of image rendering and
processing are accelerated by data-parallel processing, from general signal processing or physics
simulation to computational finance or computational biology.</p>
<p><em>PTX</em> defines a virtual machine and ISA for general purpose parallel thread execution. PTX programs
are translated at install time to the target hardware instruction set. The PTX-to-GPU translator
and driver enable NVIDIA GPUs to be used as programmable parallel computers.</p>
</section>
<section id="goals-of-ptx">
<span id="id3"></span><h2>
<span class="section-number">1.2. </span><a class="reference internal" href="#goals-of-ptx">Goals of PTX</a><a class="headerlink" href="#goals-of-ptx" title="Permalink to this headline">ïƒ</a>
</h2>
<p><em>PTX</em> provides a stable programming model and instruction set for general purpose parallel
programming. It is designed to be efficient on NVIDIA GPUs supporting the computation features
defined by the NVIDIA Tesla architecture. High level language compilers for languages such as CUDA
and C/C++ generate PTX instructions, which are optimized for and translated to native
target-architecture instructions.</p>
<p>The goals for PTX include the following:</p>
<ul class="simple">
<li><p>Provide a stable ISA that spans multiple GPU generations.</p></li>
<li><p>Achieve performance in compiled applications comparable to native GPU performance.</p></li>
<li><p>Provide a machine-independent ISA for C/C++ and other compilers to target.</p></li>
<li><p>Provide a code distribution ISA for application and middleware developers.</p></li>
<li><p>Provide a common source-level ISA for optimizing code generators and translators, which map PTX to
specific target machines.</p></li>
<li><p>Facilitate hand-coding of libraries, performance kernels, and architecture tests.</p></li>
<li><p>Provide a scalable programming model that spans GPU sizes from a single unit to many parallel units.</p></li>
</ul>
</section>
<section id="ptx-isa-version-9-1">
<span id="id4"></span><h2>
<span class="section-number">1.3. </span><a class="reference internal" href="#ptx-isa-version-9-1">PTX ISA Version 9.1</a><a class="headerlink" href="#ptx-isa-version-9-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX ISA version 9.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier with <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space for <code class="docutils literal notranslate"><span class="pre">ld</span></code> and
<code class="docutils literal notranslate"><span class="pre">st</span></code> instructions.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> source types for <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction
with destination types <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> with <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code> as <code class="docutils literal notranslate"><span class="pre">.stype</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> for
<code class="docutils literal notranslate"><span class="pre">mma</span></code>/<code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instructions.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> instruction type for <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code> instructions.</p></li>
</ul>
</section>
<section id="document-structure">
<span id="id5"></span><h2>
<span class="section-number">1.4. </span><a class="reference internal" href="#document-structure">Document Structure</a><a class="headerlink" href="#document-structure" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The information in this document is organized into the following Chapters:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#programming-model"><span class="std std-ref">Programming Model</span></a> outlines the programming model.</p></li>
<li><p><a class="reference internal" href="#ptx-machine-model"><span class="std std-ref">PTX Machine Model</span></a> gives an overview of the PTX virtual machine model.</p></li>
<li><p><a class="reference internal" href="#syntax"><span class="std std-ref">Syntax</span></a> describes the basic syntax of the PTX language.</p></li>
<li><p><a class="reference internal" href="#state-spaces-types-and-variables"><span class="std std-ref">State Spaces, Types, and Variables</span></a> describes
state spaces, types, and variable declarations.</p></li>
<li><p><a class="reference internal" href="#instruction-operands"><span class="std std-ref">Instruction Operands</span></a> describes instruction operands.</p></li>
<li><p><a class="reference internal" href="#abstracting-abi"><span class="std std-ref">Abstracting the ABI</span></a> describes the function and call syntax,
calling convention, and PTX support for abstracting the <em>Application Binary Interface (ABI)</em>.</p></li>
<li><p><a class="reference internal" href="#instruction-set"><span class="std std-ref">Instruction Set</span></a> describes the instruction set.</p></li>
<li><p><a class="reference internal" href="#special-registers"><span class="std std-ref">Special Registers</span></a> lists special registers.</p></li>
<li><p><a class="reference internal" href="#directives"><span class="std std-ref">Directives</span></a> lists the assembly directives supported in PTX.</p></li>
<li><p><a class="reference internal" href="#release-notes"><span class="std std-ref">Release Notes</span></a> provides release notes for PTX ISA versions 2.x and
beyond.</p></li>
</ul>
<p class="rubric">References</p>
<ul>
<li>
<p>754-2008 IEEE Standard for Floating-Point Arithmetic. ISBN 978-0-7381-5752-8, 2008.</p>
<p><a class="reference external" href="http://ieeexplore.ieee.org/servlet/opac?punumber=4610933">http://ieeexplore.ieee.org/servlet/opac?punumber=4610933</a></p>
</li>
<li>
<p>The OpenCL Specification, Version: 1.1, Document Revision: 44, June 1, 2011.</p>
<p><a class="reference external" href="http://www.khronos.org/registry/cl/specs/opencl-1.1.pdf">http://www.khronos.org/registry/cl/specs/opencl-1.1.pdf</a></p>
</li>
<li>
<p>CUDA Programming Guide.</p>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html</a></p>
</li>
<li>
<p>CUDA Dynamic Parallelism Programming Guide.</p>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-dynamic-parallelism">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-dynamic-parallelism</a></p>
</li>
<li>
<p>CUDA Atomicity Requirements.</p>
<p><a class="reference external" href="https://nvidia.github.io/cccl/libcudacxx/extended_api/memory_model.html#atomicity">https://nvidia.github.io/cccl/libcudacxx/extended_api/memory_model.html#atomicity</a></p>
</li>
<li>
<p>PTX Writers Guide to Interoperability.</p>
<p><a class="reference external" href="https://docs.nvidia.com/cuda/ptx-writers-guide-to-interoperability/index.html">https://docs.nvidia.com/cuda/ptx-writers-guide-to-interoperability/index.html</a></p>
</li>
</ul>
</section>
</section>
<section id="programming-model">
<span id="id6"></span><h1>
<span class="section-number">2. </span><a class="reference internal" href="#programming-model">Programming Model</a><a class="headerlink" href="#programming-model" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="highly-multithreaded-coprocessor">
<span id="id7"></span><h2>
<span class="section-number">2.1. </span><a class="reference internal" href="#highly-multithreaded-coprocessor">A Highly Multithreaded Coprocessor</a><a class="headerlink" href="#highly-multithreaded-coprocessor" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The GPU is a compute device capable of executing a very large number of threads in parallel. It
operates as a coprocessor to the main CPU, or host: In other words, data-parallel, compute-intensive
portions of applications running on the host are off-loaded onto the device.</p>
<p>More precisely, a portion of an application that is executed many times, but independently on
different data, can be isolated into a kernel function that is executed on the GPU as many different
threads. To that effect, such a function is compiled to the PTX instruction set and the resulting
kernel is translated at install time to the target GPU instruction set.</p>
</section>
<section id="thread-hierarchy">
<span id="id8"></span><h2>
<span class="section-number">2.2. </span><a class="reference internal" href="#thread-hierarchy">Thread Hierarchy</a><a class="headerlink" href="#thread-hierarchy" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The batch of threads that executes a kernel is organized as a grid. A grid consists of either
cooperative thread arrays or clusters of cooperative thread arrays as described in this section and
illustrated in <a class="reference internal" href="#grid-of-clusters-grid-with-ctas"><span class="std std-numref">Figure 1</span></a> and
<a class="reference internal" href="#grid-of-clusters-grid-with-clusters"><span class="std std-numref">Figure 2</span></a>. <em>Cooperative thread arrays (CTAs)</em> implement CUDA
thread blocks and clusters implement CUDA thread block clusters.</p>
<section id="cooperative-thread-arrays">
<span id="id9"></span><h3>
<span class="section-number">2.2.1. </span><a class="reference internal" href="#cooperative-thread-arrays">Cooperative Thread Arrays</a><a class="headerlink" href="#cooperative-thread-arrays" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <em>Parallel Thread Execution (PTX)</em> programming model is explicitly parallel: a PTX program
specifies the execution of a given thread of a parallel thread array. A <em>cooperative thread array</em>,
or CTA, is an array of threads that execute a kernel concurrently or in parallel.</p>
<p>Threads within a CTA can communicate with each other. To coordinate the communication of the threads
within the CTA, one can specify synchronization points where threads wait until all threads in the
CTA have arrived.</p>
<p>Each thread has a unique thread identifier within the CTA. Programs use a data parallel
decomposition to partition inputs, work, and results across the threads of the CTA. Each CTA thread
uses its thread identifier to determine its assigned role, assign specific input and output
positions, compute addresses, and select work to perform. The thread identifier is a three-element
vector <code class="docutils literal notranslate"><span class="pre">tid</span></code>, (with elements <code class="docutils literal notranslate"><span class="pre">tid.x</span></code>, <code class="docutils literal notranslate"><span class="pre">tid.y</span></code>, and <code class="docutils literal notranslate"><span class="pre">tid.z</span></code>) that specifies the threadâ€™s
position within a 1D, 2D, or 3D CTA. Each thread identifier component ranges from zero up to the
number of thread ids in that CTA dimension.</p>
<p>Each CTA has a 1D, 2D, or 3D shape specified by a three-element vector <code class="docutils literal notranslate"><span class="pre">ntid</span></code> (with elements
<code class="docutils literal notranslate"><span class="pre">ntid.x</span></code>, <code class="docutils literal notranslate"><span class="pre">ntid.y</span></code>, and <code class="docutils literal notranslate"><span class="pre">ntid.z</span></code>). The vector <code class="docutils literal notranslate"><span class="pre">ntid</span></code> specifies the number of threads in each
CTA dimension.</p>
<p>Threads within a CTA execute in SIMT (single-instruction, multiple-thread) fashion in groups called
<em>warps</em>. A <em>warp</em> is a maximal subset of threads from a single CTA, such that the threads execute
the same instructions at the same time. Threads within a warp are sequentially numbered. The warp
size is a machine-dependent constant. Typically, a warp has 32 threads. Some applications may be
able to maximize performance with knowledge of the warp size, so PTX includes a run-time immediate
constant, <code class="docutils literal notranslate"><span class="pre">WARP_SZ</span></code>, which may be used in any instruction where an immediate operand is allowed.</p>
</section>
<section id="cluster-of-cooperative-thread-arrays">
<span id="id10"></span><h3>
<span class="section-number">2.2.2. </span><a class="reference internal" href="#cluster-of-cooperative-thread-arrays">Cluster of Cooperative Thread Arrays</a><a class="headerlink" href="#cluster-of-cooperative-thread-arrays" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Cluster is a group of CTAs that run concurrently or in parallel and can synchronize and communicate
with each other via shared memory. The executing CTA has to make sure that the shared memory of the
peer CTA exists before communicating with it via shared memory and the peer CTA hasnâ€™t exited before
completing the shared memory operation.</p>
<p>Threads within the different CTAs in a cluster can synchronize and communicate with each other via
shared memory. Cluster-wide barriers can be used to synchronize all the threads within the
cluster. Each CTA in a cluster has a unique CTA identifier within its cluster
(<em>cluster_ctaid</em>). Each cluster of CTAs has 1D, 2D or 3D shape specified by the parameter
<em>cluster_nctaid</em>. Each CTA in the cluster also has a unique CTA identifier (<em>cluster_ctarank</em>)
across all dimensions. The total number of CTAs across all the dimensions in the cluster is
specified by <em>cluster_nctarank</em>. Threads may read and use these values through predefined, read-only
special registers <code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code>, <code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code>, <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code>,
<code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code>.</p>
<p>Cluster level is applicable only on target architecture <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher. Specifying cluster
level during launch time is optional. If the user specifies the cluster dimensions at launch time
then it will be treated as explicit cluster launch, otherwise it will be treated as implicit cluster
launch with default dimension 1x1x1. PTX provides read-only special register
<code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code> to differentiate between explicit and implicit cluster launch.</p>
</section>
<section id="grid-of-clusters">
<span id="id11"></span><h3>
<span class="section-number">2.2.3. </span><a class="reference internal" href="#grid-of-clusters">Grid of Clusters</a><a class="headerlink" href="#grid-of-clusters" title="Permalink to this headline">ïƒ</a>
</h3>
<p>There is a maximum number of threads that a CTA can contain and a maximum number of CTAs that a
cluster can contain. However, clusters with CTAs that execute the same kernel can be batched
together into a grid of clusters, so that the total number of threads that can be launched in a
single kernel invocation is very large. This comes at the expense of reduced thread communication
and synchronization, because threads in different clusters cannot communicate and synchronize with
each other.</p>
<p>Each cluster has a unique cluster identifier (<em>clusterid</em>) within a grid of clusters. Each grid of
clusters has a 1D, 2D , or 3D shape specified by the parameter <em>nclusterid</em>. Each grid also has a
unique temporal grid identifier (<em>gridid</em>). Threads may read and use these values through
predefined, read-only special registers <code class="docutils literal notranslate"><span class="pre">%tid</span></code>, <code class="docutils literal notranslate"><span class="pre">%ntid</span></code>, <code class="docutils literal notranslate"><span class="pre">%clusterid</span></code>, <code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code>, and
<code class="docutils literal notranslate"><span class="pre">%gridid</span></code>.</p>
<p>Each CTA has a unique identifier (<em>ctaid</em>) within a grid. Each grid of CTAs has 1D, 2D, or 3D shape
specified by the parameter <em>nctaid</em>. Thread may use and read these values through predefined,
read-only special registers <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code> and <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code>.</p>
<p>Each kernel is executed as a batch of threads organized as a grid of clusters consisting of CTAs
where cluster is optional level and is applicable only for target architectures <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> and
higher. <a class="reference internal" href="#grid-of-clusters-grid-with-ctas"><span class="std std-numref">Figure 1</span></a> shows a grid consisting of CTAs and
<a class="reference internal" href="#grid-of-clusters-grid-with-clusters"><span class="std std-numref">Figure 2</span></a> shows a grid consisting of clusters.</p>
<p>Grids may be launched with dependencies between one another - a grid may be a dependent grid and/or
a prerequisite grid. To understand how grid dependencies may be defined, refer to the section on
<em>CUDA Graphs</em> in the <em>Cuda Programming Guide</em>.</p>
<figure class="align-center" id="grid-of-clusters-grid-with-ctas">
<img alt="Grid with CTAs" src="_images/grid-with-CTAs.png">
<figcaption>
<p><span class="caption-number">Figure 1 </span><span class="caption-text">Grid with CTAs</span><a class="headerlink" href="#grid-of-clusters-grid-with-ctas" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="grid-of-clusters-grid-with-clusters">
<img alt="Grid with clusters" src="_images/grid-with-clusters.png">
<figcaption>
<p><span class="caption-number">Figure 2 </span><span class="caption-text">Grid with clusters</span><a class="headerlink" href="#grid-of-clusters-grid-with-clusters" title="Permalink to this image">ïƒ</a></p>
<div class="legend">
<p>A cluster is a set of cooperative thread arrays (CTAs) where a CTA is a set of concurrent threads
that execute the same kernel program. A grid is a set of clusters consisting of CTAs that
execute independently.</p>
</div>
</figcaption>
</figure>
</section>
</section>
<section id="memory-hierarchy">
<span id="id12"></span><h2>
<span class="section-number">2.3. </span><a class="reference internal" href="#memory-hierarchy">Memory Hierarchy</a><a class="headerlink" href="#memory-hierarchy" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX threads may access data from multiple state spaces during their execution as illustrated by
<a class="reference internal" href="#memory-hierarchy-memory-hierarchy-with-clusters"><span class="std std-numref">Figure 3</span></a> where cluster level is introduced from
target architecture <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> onwards. Each thread has a private local memory. Each thread block
(CTA) has a shared memory visible to all threads of the block and to all active blocks in the
cluster and with the same lifetime as the block. Finally, all threads have access to the same global
memory.</p>
<p>There are additional state spaces accessible by all threads: the constant, param, texture, and
surface state spaces.  Constant and texture memory are read-only; surface memory is readable and
writable. The global, constant, param, texture, and surface state spaces are optimized for different
memory usages. For example, texture memory offers different addressing modes as well as data
filtering for specific data formats. Note that texture and surface memory is cached, and within the
same kernel call, the cache is not kept coherent with respect to global memory writes and surface
memory writes, so any texture fetch or surface read to an address that has been written to via a
global or a surface write in the same kernel call returns undefined data. In other words, a thread
can safely read some texture or surface memory location only if this memory location has been
updated by a previous kernel call or memory copy, but not if it has been previously updated by the
same thread or another thread from the same kernel call.</p>
<p>The global, constant, and texture state spaces are persistent across kernel launches by the same
application.</p>
<p>Both the host and the device maintain their own local memory, referred to as <em>host memory</em> and
<em>device memory</em>, respectively. The device memory may be mapped and read or written by the host, or,
for more efficient transfer, copied from the host memory through optimized API calls that utilize
the deviceâ€™s high-performance <em>Direct Memory Access (DMA)</em> engine.</p>
<figure class="align-center" id="memory-hierarchy-memory-hierarchy-with-clusters">
<img alt="Memory Hierarchy" src="_images/memory-hierarchy-with-clusters.png">
<figcaption>
<p><span class="caption-number">Figure 3 </span><span class="caption-text">Memory Hierarchy</span><a class="headerlink" href="#memory-hierarchy-memory-hierarchy-with-clusters" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="ptx-machine-model">
<span id="id13"></span><h1>
<span class="section-number">3. </span><a class="reference internal" href="#ptx-machine-model">PTX Machine Model</a><a class="headerlink" href="#ptx-machine-model" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="set-of-simt-multiprocessors">
<span id="id14"></span><h2>
<span class="section-number">3.1. </span><a class="reference internal" href="#set-of-simt-multiprocessors">A Set of SIMT Multiprocessors</a><a class="headerlink" href="#set-of-simt-multiprocessors" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The NVIDIA GPU architecture is built around a scalable array of multithreaded <em>Streaming
Multiprocessors (SMs)</em>. When a host program invokes a kernel grid, the blocks of the grid are
enumerated and distributed to multiprocessors with available execution capacity. The threads of a
thread block execute concurrently on one multiprocessor. As thread blocks terminate, new blocks are
launched on the vacated multiprocessors.</p>
<p>A multiprocessor consists of multiple <em>Scalar Processor (SP)</em> cores, a multithreaded instruction
unit, and on-chip shared memory. The multiprocessor creates, manages, and executes concurrent
threads in hardware with zero scheduling overhead. It implements a single-instruction barrier
synchronization. Fast barrier synchronization together with lightweight thread creation and
zero-overhead thread scheduling efficiently support very fine-grained parallelism, allowing, for
example, a low granularity decomposition of problems by assigning one thread to each data element
(such as a pixel in an image, a voxel in a volume, a cell in a grid-based computation).</p>
<p>To manage hundreds of threads running several different programs, the multiprocessor employs an
architecture we call <em>SIMT (single-instruction, multiple-thread)</em>. The multiprocessor maps each
thread to one scalar processor core, and each scalar thread executes independently with its own
instruction address and register state. The multiprocessor SIMT unit creates, manages, schedules,
and executes threads in groups of parallel threads called <em>warps</em>. (This term originates from
weaving, the first parallel thread technology.) Individual threads composing a SIMT warp start
together at the same program address but are otherwise free to branch and execute independently.</p>
<p>When a multiprocessor is given one or more thread blocks to execute, it splits them into warps that
get scheduled by the SIMT unit. The way a block is split into warps is always the same; each warp
contains threads of consecutive, increasing thread IDs with the first warp containing thread 0.</p>
<p>At every instruction issue time, the SIMT unit selects a warp that is ready to execute and issues
the next instruction to the active threads of the warp. A warp executes one common instruction at a
time, so full efficiency is realized when all threads of a warp agree on their execution path. If
threads of a warp diverge via a data-dependent conditional branch, the warp serially executes each
branch path taken, disabling threads that are not on that path, and when all paths complete, the
threads converge back to the same execution path. Branch divergence occurs only within a warp;
different warps execute independently regardless of whether they are executing common or disjointed
code paths.</p>
<p>SIMT architecture is akin to SIMD (Single Instruction, Multiple Data) vector organizations in that a
single instruction controls multiple processing elements. A key difference is that SIMD vector
organizations expose the SIMD width to the software, whereas SIMT instructions specify the execution
and branching behavior of a single thread. In contrast with SIMD vector machines, SIMT enables
programmers to write thread-level parallel code for independent, scalar threads, as well as
data-parallel code for coordinated threads. For the purposes of correctness, the programmer can
essentially ignore the SIMT behavior; however, substantial performance improvements can be realized
by taking care that the code seldom requires threads in a warp to diverge. In practice, this is
analogous to the role of cache lines in traditional code: Cache line size can be safely ignored when
designing for correctness but must be considered in the code structure when designing for peak
performance. Vector architectures, on the other hand, require the software to coalesce loads into
vectors and manage divergence manually.</p>
<p>How many blocks a multiprocessor can process at once depends on how many registers per thread and
how much shared memory per block are required for a given kernel since the multiprocessorâ€™s
registers and shared memory are split among all the threads of the batch of blocks. If there are not
enough registers or shared memory available per multiprocessor to process at least one block, the
kernel will fail to launch.</p>
<figure class="align-center" id="set-of-simt-multiprocessors-hardware-model">
<img alt="_images/hardware-model.png" src="_images/hardware-model.png">
<figcaption>
<p><span class="caption-number">Figure 4 </span><span class="caption-text">Hardware Model</span><a class="headerlink" href="#set-of-simt-multiprocessors-hardware-model" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>A set of SIMT multiprocessors with on-chip shared memory.</p>
</section>
<section id="independent-thread-scheduling">
<span id="id15"></span><h2>
<span class="section-number">3.2. </span><a class="reference internal" href="#independent-thread-scheduling">Independent Thread Scheduling</a><a class="headerlink" href="#independent-thread-scheduling" title="Permalink to this headline">ïƒ</a>
</h2>
<p>On architectures prior to Volta, warps used a single program counter shared amongst all 32 threads
in the warp together with an active mask specifying the active threads of the warp. As a result,
threads from the same warp in divergent regions or different states of execution cannot signal each
other or exchange data, and algorithms requiring fine-grained sharing of data guarded by locks or
mutexes can easily lead to deadlock, depending on which warp the contending threads come from.</p>
<p>Starting with the Volta architecture, <em>Independent Thread Scheduling</em> allows full concurrency
between threads, regardless of warp. With <em>Independent Thread Scheduling</em>, the GPU maintains
execution state per thread, including a program counter and call stack, and can yield execution at a
per-thread granularity, either to make better use of execution resources or to allow one thread to
wait for data to be produced by another. A schedule optimizer determines how to group active threads
from the same warp together into SIMT units. This retains the high throughput of SIMT execution as
in prior NVIDIA GPUs, but with much more flexibility: threads can now diverge and reconverge at
sub-warp granularity.</p>
<p><em>Independent Thread Scheduling</em> can lead to a rather different set of threads participating in the
executed code than intended if the developer made assumptions about warp-synchronicity of previous
hardware architectures. In particular, any warp-synchronous code (such as synchronization-free,
intra-warp reductions) should be revisited to ensure compatibility with Volta and beyond. See the
section on Compute Capability 7.x in the <em>Cuda Programming Guide</em> for further details.</p>
</section>
<section id="on-chip-shared-memory">
<span id="id16"></span><h2>
<span class="section-number">3.3. </span><a class="reference internal" href="#on-chip-shared-memory">On-chip Shared Memory</a><a class="headerlink" href="#on-chip-shared-memory" title="Permalink to this headline">ïƒ</a>
</h2>
<p>As illustrated by <a class="reference internal" href="#set-of-simt-multiprocessors-hardware-model"><span class="std std-numref">Figure 4</span></a>, each multiprocessor has
on-chip memory of the four following types:</p>
<ul class="simple">
<li><p>One set of local 32-bit <em>registers</em> per processor,</p></li>
<li><p>A parallel data cache or <em>shared memory</em> that is shared by all scalar processor cores and is where
the shared memory space resides,</p></li>
<li><p>A read-only <em>constant cache</em> that is shared by all scalar processor cores and speeds up reads from
the constant memory space, which is a read-only region of device memory,</p></li>
<li><p>A read-only <em>texture cache</em> that is shared by all scalar processor cores and speeds up reads from
the texture memory space, which is a read-only region of device memory; each multiprocessor
accesses the texture cache via a <em>texture unit</em> that implements the various addressing modes and
data filtering.</p></li>
</ul>
<p>The local and global memory spaces are read-write regions of device memory.</p>
</section>
</section>
<section id="syntax">
<span id="id17"></span><h1>
<span class="section-number">4. </span><a class="reference internal" href="#syntax">Syntax</a><a class="headerlink" href="#syntax" title="Permalink to this headline">ïƒ</a>
</h1>
<p>PTX programs are a collection of text source modules (files). PTX source modules have an
assembly-language style syntax with instruction operation codes and operands. Pseudo-operations
specify symbol and addressing management. The ptxas optimizing backend compiler optimizes and
assembles PTX source modules to produce corresponding binary object files.</p>
<section id="source-format">
<span id="id18"></span><h2>
<span class="section-number">4.1. </span><a class="reference internal" href="#source-format">Source Format</a><a class="headerlink" href="#source-format" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Source modules are ASCII text. Lines are separated by the newline character (<code class="docutils literal notranslate"><span class="pre">\n</span></code>).</p>
<p>All whitespace characters are equivalent; whitespace is ignored except for its use in separating
tokens in the language.</p>
<p>The C preprocessor cpp may be used to process PTX source modules. Lines beginning with <code class="docutils literal notranslate"><span class="pre">#</span></code> are
preprocessor directives. The following are common preprocessor directives:</p>
<p><code class="docutils literal notranslate"><span class="pre">#include</span></code>, <code class="docutils literal notranslate"><span class="pre">#define</span></code>, <code class="docutils literal notranslate"><span class="pre">#if</span></code>, <code class="docutils literal notranslate"><span class="pre">#ifdef</span></code>, <code class="docutils literal notranslate"><span class="pre">#else</span></code>, <code class="docutils literal notranslate"><span class="pre">#endif</span></code>, <code class="docutils literal notranslate"><span class="pre">#line</span></code>, <code class="docutils literal notranslate"><span class="pre">#file</span></code></p>
<p><em>C: A Reference Manual</em> by Harbison and Steele provides a good description of the C preprocessor.</p>
<p>PTX is case sensitive and uses lowercase for keywords.</p>
<p>Each PTX module must begin with a <code class="docutils literal notranslate"><span class="pre">.version</span></code> directive specifying the PTX language version,
followed by a <code class="docutils literal notranslate"><span class="pre">.target</span></code> directive specifying the target architecture assumed. See
<a class="reference internal" href="#ptx-module-directives"><span class="std std-ref">PTX Module Directives</span></a> for a more information on these directives.</p>
</section>
<section id="comments">
<span id="id19"></span><h2>
<span class="section-number">4.2. </span><a class="reference internal" href="#comments">Comments</a><a class="headerlink" href="#comments" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Comments in PTX follow C/C++ syntax, using non-nested <code class="docutils literal notranslate"><span class="pre">/*</span></code> and <code class="docutils literal notranslate"><span class="pre">*/</span></code> for comments that may span
multiple lines, and using <code class="docutils literal notranslate"><span class="pre">//</span></code> to begin a comment that extends up to the next newline character,
which terminates the current line. Comments cannot occur within character constants, string
literals, or within other comments.</p>
<p>Comments in PTX are treated as whitespace.</p>
</section>
<section id="statements">
<span id="id20"></span><h2>
<span class="section-number">4.3. </span><a class="reference internal" href="#statements">Statements</a><a class="headerlink" href="#statements" title="Permalink to this headline">ïƒ</a>
</h2>
<p>A PTX statement is either a directive or an instruction. Statements begin with an optional label and
end with a semicolon.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>        .reg     .b32 r1, r2;
        .global  .f32  array[N];

start:  mov.b32   r1, %tid.x;
        shl.b32   r1, r1, 2;          // shift thread id by 2 bits
        ld.global.b32 r2, array[r1];  // thread[tid] gets array[tid]
        add.f32   r2, r2, 0.5;        // add 1/2
</pre></div>
</div>
<section id="directive-statements">
<span id="id21"></span><h3>
<span class="section-number">4.3.1. </span><a class="reference internal" href="#directive-statements">Directive Statements</a><a class="headerlink" href="#directive-statements" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Directive keywords begin with a dot, so no conflict is possible with user-defined identifiers. The
directives in PTX are listed in <a class="reference internal" href="#directive-statements-ptx-directives"><span class="std std-numref">Table 1</span></a> and
described in <a class="reference internal" href="#state-spaces-types-and-variables"><span class="std std-ref">State Spaces, Types, and Variables</span></a>
and <a class="reference internal" href="#directives"><span class="std std-ref">Directives</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="directive-statements-ptx-directives">
<caption>
<span class="caption-number">Table 1 </span><span class="caption-text">PTX Directives</span><a class="headerlink" href="#directive-statements-ptx-directives" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 28%">
<col style="width: 30%">
<col style="width: 18%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.address_size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.section</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.alias</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.extern</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.maxntid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.align</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.file</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.sreg</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.func</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.noreturn</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.callprototype</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.param</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tex</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.calltargets</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.loc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.pragma</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.version</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.common</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.local</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.reg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.visible</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.const</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.weak</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.entry</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.reqntid</span></code></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="instruction-statements">
<span id="id22"></span><h3>
<span class="section-number">4.3.2. </span><a class="reference internal" href="#instruction-statements">Instruction Statements</a><a class="headerlink" href="#instruction-statements" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Instructions are formed from an instruction opcode followed by a comma-separated list of zero or
more operands, and terminated with a semicolon. Operands may be register variables, constant
expressions, address expressions, or label names. Instructions have an optional guard predicate
which controls conditional execution. The guard predicate follows the optional label and precedes
the opcode, and is written as <code class="docutils literal notranslate"><span class="pre">@p</span></code>, where <code class="docutils literal notranslate"><span class="pre">p</span></code> is a predicate register. The guard predicate may
be optionally negated, written as <code class="docutils literal notranslate"><span class="pre">@!p</span></code>.</p>
<p>The destination operand is first, followed by source operands.</p>
<p>Instruction keywords are listed in
<a class="reference internal" href="#instruction-statements-reserved-instruction-keywords-new"><span class="std std-numref">Table 2</span></a>. All instruction keywords are
reserved tokens in PTX.</p>
<table class="table-no-stripes docutils align-default" id="instruction-statements-reserved-instruction-keywords-new">
<caption>
<span class="caption-number">Table 2 </span><span class="caption-text">Reserved Instruction Keywords</span><a class="headerlink" href="#instruction-statements-reserved-instruction-keywords-new" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">abs</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">cvta</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">membar</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">activemask</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">discard</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">min</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shf</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">add</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">div</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shfl</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">addc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">dp2a</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mov</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shl</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vadd</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">alloca</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">dp4a</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">movmatrix</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shr</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vadd2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">and</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">elect</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mul</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sin</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vadd4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">applypriority</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ex2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mul24</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">slct</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vavrg2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">atom</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">exit</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">multimem</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sqrt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vavrg4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">bar</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fence</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nanosleep</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">st</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmad</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">barrier</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fma</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">neg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stackrestore</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmax</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">bfe</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fns</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">not</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stacksave</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmax2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">bfi</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">getctarank</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">or</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmax4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">bfind</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">pmevent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sub</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmin</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">bmsk</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">isspacep</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">popc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">subc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmin2</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">bra</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">istypep</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">prefetch</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">suld</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vmin4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">brev</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ld</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">prefetchu</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">suq</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vote</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">brkpt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">prmt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sured</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vset</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">brx</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ldu</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rcp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sust</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vset2</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">call</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">lg2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">red</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">szext</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vset4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">clz</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">lop3</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">redux</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tanh</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vshl</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cnot</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mad</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rem</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tcgen05</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vshr</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">copysign</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mad24</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ret</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tensormap</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vsub</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cos</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">madc</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">rsqrt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">testp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vsub2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mapa</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sad</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tex</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">vsub4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">match</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">selp</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tld4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">wgmma</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">createpolicy</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">set</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">trap</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mbarrier</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">txq</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">xor</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="identifiers">
<span id="id23"></span><h2>
<span class="section-number">4.4. </span><a class="reference internal" href="#identifiers">Identifiers</a><a class="headerlink" href="#identifiers" title="Permalink to this headline">ïƒ</a>
</h2>
<p>User-defined identifiers follow extended C++ rules: they either start with a letter followed by zero
or more letters, digits, underscore, or dollar characters; or they start with an underscore, dollar,
or percentage character followed by one or more letters, digits, underscore, or dollar characters:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>followsym:   [a-zA-Z0-9_$]
identifier:  [a-zA-Z]{followsym}* | {[_$%]{followsym}+
</pre></div>
</div>
<p>PTX does not specify a maximum length for identifiers and suggests that all implementations support
a minimum length of at least 1024 characters.</p>
<p>Many high-level languages such as C and C++ follow similar rules for identifier names, except that
the percentage sign is not allowed. PTX allows the percentage sign as the first character of an
identifier. The percentage sign can be used to avoid name conflicts, e.g., between user-defined
variable names and compiler-generated names.</p>
<p>PTX predefines one constant and a small number of special registers that begin with the percentage
sign, listed in <a class="reference internal" href="#identifiers-predefined-identifiers"><span class="std std-numref">Table 3</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="identifiers-predefined-identifiers">
<caption>
<span class="caption-number">Table 3 </span><span class="caption-text">Predefined Identifiers</span><a class="headerlink" href="#identifiers-predefined-identifiers" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 22%">
<col style="width: 23%">
<col style="width: 26%">
<col style="width: 28%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%clock</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%envreg&lt;32&gt;</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%clock64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%smid</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%nctaid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%tid</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%gridid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%nsmid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%ntid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%clusterid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%laneid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">WARP_SZ</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%ctaid</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%pm0,</span> <span class="pre">...,</span> <span class="pre">%pm7</span></code></p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_&lt;2&gt;</span></code></p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="constants">
<span id="id24"></span><h2>
<span class="section-number">4.5. </span><a class="reference internal" href="#constants">Constants</a><a class="headerlink" href="#constants" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX supports integer and floating-point constants and constant expressions. These constants may be
used in data initialization and as operands to instructions. Type checking rules remain the same for
integer, floating-point, and bit-size types. For predicate-type data and instructions, integer
constants are allowed and are interpreted as in C, i.e., zero values are <code class="docutils literal notranslate"><span class="pre">False</span></code> and non-zero
values are <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<section id="integer-constants">
<span id="id25"></span><h3>
<span class="section-number">4.5.1. </span><a class="reference internal" href="#integer-constants">Integer Constants</a><a class="headerlink" href="#integer-constants" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Integer constants are 64-bits in size and are either signed or unsigned, i.e., every integer
constant has type <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code>. The signed/unsigned nature of an integer constant is needed
to correctly evaluate constant expressions containing operations such as division and ordered
comparisons, where the behavior of the operation depends on the operand types. When used in an
instruction or data initialization, each integer constant is converted to the appropriate size based
on the data or instruction type at its use.</p>
<p>Integer literals may be written in decimal, hexadecimal, octal, or binary notation. The syntax
follows that of C. Integer literals may be followed immediately by the letter <code class="docutils literal notranslate"><span class="pre">U</span></code> to indicate that
the literal is unsigned.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>hexadecimal literal:  0[xX]{hexdigit}+U?
octal literal:        0{octal digit}+U?
binary literal:       0[bB]{bit}+U?
decimal literal       {nonzero-digit}{digit}*U?
</pre></div>
</div>
<p>Integer literals are non-negative and have a type determined by their magnitude and optional type
suffix as follows: literals are signed (<code class="docutils literal notranslate"><span class="pre">.s64</span></code>) unless the value cannot be fully represented in
<code class="docutils literal notranslate"><span class="pre">.s64</span></code> or the unsigned suffix is specified, in which case the literal is unsigned (<code class="docutils literal notranslate"><span class="pre">.u64</span></code>).</p>
<p>The predefined integer constant <code class="docutils literal notranslate"><span class="pre">WARP_SZ</span></code> specifies the number of threads per warp for the target
platform; to date, all target architectures have a <code class="docutils literal notranslate"><span class="pre">WARP_SZ</span></code> value of 32.</p>
</section>
<section id="floating-point-constants">
<span id="id26"></span><h3>
<span class="section-number">4.5.2. </span><a class="reference internal" href="#floating-point-constants">Floating-Point Constants</a><a class="headerlink" href="#floating-point-constants" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Floating-point constants are represented as 64-bit double-precision values, and all floating-point
constant expressions are evaluated using 64-bit double precision arithmetic. The only exception is
the 32-bit hex notation for expressing an exact single-precision floating-point value; such values
retain their exact 32-bit single-precision value and may not be used in constant expressions. Each
64-bit floating-point constant is converted to the appropriate floating-point size based on the data
or instruction type at its use.</p>
<p>Floating-point literals may be written with an optional decimal point and an optional signed
exponent. Unlike C and C++, there is no suffix letter to specify size; literals are always
represented in 64-bit double-precision format.</p>
<p>PTX includes a second representation of floating-point constants for specifying the exact machine
representation using a hexadecimal constant. To specify IEEE 754 double-precision floating point
values, the constant begins with <code class="docutils literal notranslate"><span class="pre">0d</span></code> or <code class="docutils literal notranslate"><span class="pre">0D</span></code> followed by 16 hex digits. To specify IEEE 754
single-precision floating point values, the constant begins with <code class="docutils literal notranslate"><span class="pre">0f</span></code> or <code class="docutils literal notranslate"><span class="pre">0F</span></code> followed by 8 hex
digits.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0[fF]{hexdigit}{8}      // single-precision floating point
0[dD]{hexdigit}{16}     // double-precision floating point
</pre></div>
</div>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.f32  $f3, 0F3f800000;       //  1.0
</pre></div>
</div>
</section>
<section id="predicate-constants">
<span id="id27"></span><h3>
<span class="section-number">4.5.3. </span><a class="reference internal" href="#predicate-constants">Predicate Constants</a><a class="headerlink" href="#predicate-constants" title="Permalink to this headline">ïƒ</a>
</h3>
<p>In PTX, integer constants may be used as predicates. For predicate-type data initializers and
instruction operands, integer constants are interpreted as in C, i.e., zero values are <code class="docutils literal notranslate"><span class="pre">False</span></code> and
non-zero values are <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</section>
<section id="constant-expressions">
<span id="id28"></span><h3>
<span class="section-number">4.5.4. </span><a class="reference internal" href="#constant-expressions">Constant Expressions</a><a class="headerlink" href="#constant-expressions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>In PTX, constant expressions are formed using operators as in C and are evaluated using rules
similar to those in C, but simplified by restricting types and sizes, removing most casts, and
defining full semantics to eliminate cases where expression evaluation in C is implementation
dependent.</p>
<p>Constant expressions are formed from constant literals, unary plus and minus, basic arithmetic
operators (addition, subtraction, multiplication, division), comparison operators, the conditional
ternary operator ( <code class="docutils literal notranslate"><span class="pre">?:</span></code> ), and parentheses. Integer constant expressions also allow unary logical
negation (<code class="docutils literal notranslate"><span class="pre">!</span></code>), bitwise complement (<code class="docutils literal notranslate"><span class="pre">~</span></code>), remainder (<code class="docutils literal notranslate"><span class="pre">%</span></code>), shift operators (<code class="docutils literal notranslate"><span class="pre">&lt;&lt;</span></code> and
<code class="docutils literal notranslate"><span class="pre">&gt;&gt;</span></code>), bit-type operators (<code class="docutils literal notranslate"><span class="pre">&amp;</span></code>, <code class="docutils literal notranslate"><span class="pre">|</span></code>, and <code class="docutils literal notranslate"><span class="pre">^</span></code>), and logical operators (<code class="docutils literal notranslate"><span class="pre">&amp;&amp;</span></code>, <code class="docutils literal notranslate"><span class="pre">||</span></code>).</p>
<p>Constant expressions in PTX do not support casts between integer and floating-point.</p>
<p>Constant expressions are evaluated using the same operator precedence as
in C. <a class="reference internal" href="#constant-expressions-operator-precedence"><span class="std std-numref">Table 4</span></a> gives operator precedence and
associativity. Operator precedence is highest for unary operators and decreases with each line in
the chart. Operators on the same line have the same precedence and are evaluated right-to-left for
unary operators and left-to-right for binary operators.</p>
<table class="table-no-stripes docutils align-default" id="constant-expressions-operator-precedence">
<caption>
<span class="caption-number">Table 4 </span><span class="caption-text">Operator Precedence</span><a class="headerlink" href="#constant-expressions-operator-precedence" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 11%">
<col style="width: 29%">
<col style="width: 45%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Kind</p></th>
<th class="head"><p>Operator Symbols</p></th>
<th class="head"><p>Operator Names</p></th>
<th class="head"><p>Associates</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Primary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">()</span></code></p></td>
<td><p>parenthesis</p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Unary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">+-</span> <span class="pre">!</span> <span class="pre">~</span></code></p></td>
<td><p>plus, minus, negation, complement</p></td>
<td><p>right</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">(.s64)</span></code><code class="docutils literal notranslate"><span class="pre">(.u64)</span></code></p></td>
<td><p>casts</p></td>
<td><p>right</p></td>
</tr>
<tr class="row-odd">
<td rowspan="10"><p>Binary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">*/</span> <span class="pre">%</span></code></p></td>
<td><p>multiplication, division, remainder</p></td>
<td rowspan="10"><p>left</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">+-</span></code></p></td>
<td><p>addition, subtraction</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">&gt;&gt;</span> <span class="pre">&lt;&lt;</span></code></p></td>
<td><p>shifts</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">&gt;</span> <span class="pre">&lt;=</span> <span class="pre">&gt;=</span></code></p></td>
<td><p>ordered comparisons</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">==</span> <span class="pre">!=</span></code></p></td>
<td><p>equal, not equal</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">&amp;</span></code></p></td>
<td><p>bitwise AND</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">^</span></code></p></td>
<td><p>bitwise XOR</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">|</span></code></p></td>
<td><p>bitwise OR</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">&amp;&amp;</span></code></p></td>
<td><p>logical AND</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">||</span></code></p></td>
<td><p>logical OR</p></td>
</tr>
<tr class="row-odd">
<td><p>Ternary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">?:</span></code></p></td>
<td><p>conditional</p></td>
<td><p>right</p></td>
</tr>
</tbody>
</table>
</section>
<section id="integer-constant-expression-evaluation">
<span id="id29"></span><h3>
<span class="section-number">4.5.5. </span><a class="reference internal" href="#integer-constant-expression-evaluation">Integer Constant Expression Evaluation</a><a class="headerlink" href="#integer-constant-expression-evaluation" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Integer constant expressions are evaluated at compile time according to a set of rules that
determine the type (signed <code class="docutils literal notranslate"><span class="pre">.s64</span></code> versus unsigned <code class="docutils literal notranslate"><span class="pre">.u64</span></code>) of each sub-expression. These rules
are based on the rules in C, but theyâ€™ve been simplified to apply only to 64-bit integers, and
behavior is fully defined in all cases (specifically, for remainder and shift operators).</p>
<ul class="simple">
<li>
<p>Literals are signed unless unsigned is needed to prevent overflow, or unless the literal uses a
<code class="docutils literal notranslate"><span class="pre">U</span></code> suffix. For example:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">42</span></code>, <code class="docutils literal notranslate"><span class="pre">0x1234</span></code>, <code class="docutils literal notranslate"><span class="pre">0123</span></code> are signed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0xfabc123400000000</span></code>, <code class="docutils literal notranslate"><span class="pre">42U</span></code>, <code class="docutils literal notranslate"><span class="pre">0x1234U</span></code> are unsigned.</p></li>
</ul>
</li>
<li>
<p>Unary plus and minus preserve the type of the input operand. For example:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">+123</span></code>, <code class="docutils literal notranslate"><span class="pre">-1</span></code>, <code class="docutils literal notranslate"><span class="pre">-(-42)</span></code> are signed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">-1U</span></code>, <code class="docutils literal notranslate"><span class="pre">-0xfabc123400000000</span></code> are unsigned.</p></li>
</ul>
</li>
<li><p>Unary logical negation (<code class="docutils literal notranslate"><span class="pre">!</span></code>) produces a signed result with value <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p>Unary bitwise complement (<code class="docutils literal notranslate"><span class="pre">~</span></code>) interprets the source operand as unsigned and produces an
unsigned result.</p></li>
<li><p>Some binary operators require normalization of source operands. This normalization is known as
<em>the usual arithmetic conversions</em> and simply converts both operands to unsigned type if either
operand is unsigned.</p></li>
<li><p>Addition, subtraction, multiplication, and division perform the usual arithmetic conversions and
produce a result with the same type as the converted operands. That is, the operands and result
are unsigned if either source operand is unsigned, and is otherwise signed.</p></li>
<li><p>Remainder (<code class="docutils literal notranslate"><span class="pre">%</span></code>) interprets the operands as unsigned. Note that this differs from C, which allows
a negative divisor but defines the behavior to be implementation dependent.</p></li>
<li><p>Left and right shift interpret the second operand as unsigned and produce a result with the same
type as the first operand. Note that the behavior of right-shift is determined by the type of the
first operand: right shift of a signed value is arithmetic and preserves the sign, and right shift
of an unsigned value is logical and shifts in a zero bit.</p></li>
<li><p>AND (<code class="docutils literal notranslate"><span class="pre">&amp;</span></code>), OR (<code class="docutils literal notranslate"><span class="pre">|</span></code>), and XOR (<code class="docutils literal notranslate"><span class="pre">^</span></code>) perform the usual arithmetic conversions and produce a
result with the same type as the converted operands.</p></li>
<li><p>AND_OP (<code class="docutils literal notranslate"><span class="pre">&amp;&amp;</span></code>), OR_OP (<code class="docutils literal notranslate"><span class="pre">||</span></code>), Equal (<code class="docutils literal notranslate"><span class="pre">==</span></code>), and Not_Equal (<code class="docutils literal notranslate"><span class="pre">!=</span></code>) produce a signed
result. The result value is 0 or 1.</p></li>
<li><p>Ordered comparisons (<code class="docutils literal notranslate"><span class="pre">&lt;</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;=</span></code>, <code class="docutils literal notranslate"><span class="pre">&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">&gt;=</span></code>) perform the usual arithmetic conversions on
source operands and produce a signed result. The result value is <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></li>
<li><p>Casting of expressions to signed or unsigned is supported using (<code class="docutils literal notranslate"><span class="pre">.s64</span></code>) and (<code class="docutils literal notranslate"><span class="pre">.u64</span></code>) casts.</p></li>
<li><p>For the conditional operator ( <code class="docutils literal notranslate"><span class="pre">?</span> <span class="pre">:</span></code> ) , the first operand must be an integer, and the second
and third operands are either both integers or both floating-point. The usual arithmetic
conversions are performed on the second and third operands, and the result type is the same as the
converted type.</p></li>
</ul>
</section>
<section id="summary-of-constant-expression-evaluation-rules">
<span id="id30"></span><h3>
<span class="section-number">4.5.6. </span><a class="reference internal" href="#summary-of-constant-expression-evaluation-rules">Summary of Constant Expression Evaluation Rules</a><a class="headerlink" href="#summary-of-constant-expression-evaluation-rules" title="Permalink to this headline">ïƒ</a>
</h3>
<p><a class="reference internal" href="#summary-of-constant-expression-evaluation-rules-constant-expression-evaluation-rules"><span class="std std-numref">Table 5</span></a>
contains a summary of the constant expression evaluation rules.</p>
<table class="table-no-stripes docutils align-default" id="summary-of-constant-expression-evaluation-rules-constant-expression-evaluation-rules">
<caption>
<span class="caption-number">Table 5 </span><span class="caption-text">Constant Expression Evaluation Rules</span><a class="headerlink" href="#summary-of-constant-expression-evaluation-rules-constant-expression-evaluation-rules" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 8%">
<col style="width: 16%">
<col style="width: 20%">
<col style="width: 28%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Kind</p></th>
<th class="head"><p>Operator</p></th>
<th class="head"><p>Operand Types</p></th>
<th class="head"><p>Operand Interpretation</p></th>
<th class="head"><p>Result Type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p>Primary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">()</span></code></p></td>
<td><p>any type</p></td>
<td><p>same as source</p></td>
<td><p>same as source</p></td>
</tr>
<tr class="row-odd">
<td><p>constant literal</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code>, or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p>Unary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">+-</span></code></p></td>
<td><p>any type</p></td>
<td><p>same as source</p></td>
<td><p>same as source</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">!</span></code></p></td>
<td><p>integer</p></td>
<td><p>zero or non-zero</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">~</span></code></p></td>
<td><p>integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Cast</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">(.u64)</span></code></p></td>
<td><p>integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">(.s64)</span></code></p></td>
<td><p>integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="10"><p>Binary</p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">+-</span> <span class="pre">*</span> <span class="pre">/</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>integer</p></td>
<td><p>use usual conversions</p></td>
<td><p>converted type</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">&gt;</span> <span class="pre">&lt;=</span> <span class="pre">&gt;=</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>integer</p></td>
<td><p>use usual conversions</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">==</span> <span class="pre">!=</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>integer</p></td>
<td><p>use usual conversions</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%</span></code></p></td>
<td><p>integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">&gt;&gt;</span> <span class="pre">&lt;&lt;</span></code></p></td>
<td><p>integer</p></td>
<td><p>1st unchanged, 2nd is <code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p>same as 1st operand</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">&amp;</span> <span class="pre">|</span> <span class="pre">^</span></code></p></td>
<td><p>integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">&amp;&amp;</span> <span class="pre">||</span></code></p></td>
<td><p>integer</p></td>
<td><p>zero or non-zero</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Ternary</p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">?:</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int</span> <span class="pre">?</span> <span class="pre">.f64</span> <span class="pre">:</span> <span class="pre">.f64</span></code></p></td>
<td><p>same as sources</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">int</span> <span class="pre">?</span> <span class="pre">int</span> <span class="pre">:</span> <span class="pre">int</span></code></p></td>
<td><p>use usual conversions</p></td>
<td><p>converted type</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="state-spaces-types-and-variables">
<span id="id31"></span><h1>
<span class="section-number">5. </span><a class="reference internal" href="#state-spaces-types-and-variables">State Spaces, Types, and Variables</a><a class="headerlink" href="#state-spaces-types-and-variables" title="Permalink to this headline">ïƒ</a>
</h1>
<p>While the specific resources available in a given target GPU will vary, the kinds of resources will
be common across platforms, and these resources are abstracted in PTX through state spaces and data
types.</p>
<section id="state-spaces">
<span id="id32"></span><h2>
<span class="section-number">5.1. </span><a class="reference internal" href="#state-spaces">State Spaces</a><a class="headerlink" href="#state-spaces" title="Permalink to this headline">ïƒ</a>
</h2>
<p>A state space is a storage area with particular characteristics. All variables reside in some state
space. The characteristics of a state space include its size, addressability, access speed, access
rights, and level of sharing between threads.</p>
<p>The state spaces defined in PTX are a byproduct of parallel programming and graphics
programming. The list of state spaces is shown in <a class="reference internal" href="#state-spaces-state-spaces-tab"><span class="std std-numref">Table 6</span></a>,and
properties of state spaces are shown in <a class="reference internal" href="#state-spaces-properties-state-spaces"><span class="std std-numref">Table 7</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="state-spaces-state-spaces-tab">
<caption>
<span class="caption-number">Table 6 </span><span class="caption-text">State Spaces</span><a class="headerlink" href="#state-spaces-state-spaces-tab" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.reg</span></code></p></td>
<td><p>Registers, fast.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.sreg</span></code></p></td>
<td><p>Special registers. Read-only; pre-defined; platform-specific.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.const</span></code></p></td>
<td><p>Shared, read-only memory.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p>Global memory, shared by all threads.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.local</span></code></p></td>
<td><p>Local memory, private to each thread.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.param</span></code></p></td>
<td>
<p>Kernel parameters, defined per-grid; or</p>
<p>Function or local parameters, defined per-thread.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared</span></code></p></td>
<td><p>Addressable memory, defined per CTA, accessible to all threads in the cluster
throughout the lifetime of the CTA that defines it.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.tex</span></code></p></td>
<td><p>Global texture memory (deprecated).</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="state-spaces-properties-state-spaces">
<caption>
<span class="caption-number">Table 7 </span><span class="caption-text">Properties of State Spaces</span><a class="headerlink" href="#state-spaces-properties-state-spaces" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 23%">
<col style="width: 18%">
<col style="width: 13%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Name</p></th>
<th class="head"><p>Addressable</p></th>
<th class="head"><p>Initializable</p></th>
<th class="head"><p>Access</p></th>
<th class="head"><p>Sharing</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.reg</span></code></p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>R/W</p></td>
<td><p>per-thread</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.sreg</span></code></p></td>
<td><p>No</p></td>
<td><p>No</p></td>
<td><p>RO</p></td>
<td><p>per-CTA</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.const</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes<sup>1</sup></p></td>
<td><p>RO</p></td>
<td><p>per-grid</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes<sup>1</sup></p></td>
<td><p>R/W</p></td>
<td><p>Context</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.local</span></code></p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
<td><p>R/W</p></td>
<td><p>per-thread</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.param</span></code>
(as input to kernel)</p></td>
<td><p>Yes<sup>2</sup></p></td>
<td><p>No</p></td>
<td><p>RO</p></td>
<td><p>per-grid</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.param</span></code>
(used in functions)</p></td>
<td><p>Restricted<sup>3</sup></p></td>
<td><p>No</p></td>
<td><p>R/W</p></td>
<td><p>per-thread</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared</span></code></p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
<td><p>R/W</p></td>
<td><p>per-cluster<sup>5</sup></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tex</span></code></p></td>
<td><p>No<sup>4</sup></p></td>
<td><p>Yes, via driver</p></td>
<td><p>RO</p></td>
<td><p>Context</p></td>
</tr>
<tr class="row-odd">
<td colspan="5">
<p><strong>Notes:</strong></p>
<p><sup>1</sup> Variables in <code class="docutils literal notranslate"><span class="pre">.const</span></code> and <code class="docutils literal notranslate"><span class="pre">.global</span></code> state spaces are initialized to zero by default.</p>
<p><sup>2</sup> Accessible only via the <code class="docutils literal notranslate"><span class="pre">ld.param{::entry}</span></code> instruction. Address may be taken via
<code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction.</p>
<p><sup>3</sup> Accessible via <code class="docutils literal notranslate"><span class="pre">ld.param{::func}</span></code> and <code class="docutils literal notranslate"><span class="pre">st.param{::func}</span></code> instructions. Device function
input and return parameters may have their address taken via <code class="docutils literal notranslate"><span class="pre">mov</span></code>; the parameter is then located
on the stack frame and its address is in the <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space.</p>
<p><sup>4</sup> Accessible only via the <code class="docutils literal notranslate"><span class="pre">tex</span></code> instruction.</p>
<p><sup>5</sup> Visible to the owning CTA and other active CTAs in the cluster.</p>
</td>
</tr>
</tbody>
</table>
<section id="register-state-space">
<span id="id33"></span><h3>
<span class="section-number">5.1.1. </span><a class="reference internal" href="#register-state-space">Register State Space</a><a class="headerlink" href="#register-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Registers (<code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space) are fast storage locations. The number of registers is limited, and
will vary from platform to platform. When the limit is exceeded, register variables will be spilled
to memory, causing changes in performance. For each architecture, there is a recommended maximum
number of registers to use (see the <em>CUDA Programming Guide</em> for details).</p>
<p>Registers may be typed (signed integer, unsigned integer, floating point, predicate) or
untyped. Register size is restricted; aside from predicate registers which are 1-bit, scalar
registers have a width of 8-, 16-, 32-, 64-, or 128-bits, and vector registers have a width of
16-, 32-, 64-, or 128-bits. The most common use of 8-bit registers is with <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt</span></code>
instructions, or as elements of vector tuples.</p>
<p>Registers differ from the other state spaces in that they are not fully addressable, i.e., it is not
possible to refer to the address of a register. When compiling to use the Application Binary
Interface (ABI), register variables are restricted to function scope and may not be declared at
module scope. When compiling legacy PTX code (ISA versions prior to 3.0) containing module-scoped
<code class="docutils literal notranslate"><span class="pre">.reg</span></code> variables, the compiler silently disables use of the ABI. Registers may have alignment
boundaries required by multi-word loads and stores.</p>
</section>
<section id="special-register-state-space">
<span id="id34"></span><h3>
<span class="section-number">5.1.2. </span><a class="reference internal" href="#special-register-state-space">Special Register State Space</a><a class="headerlink" href="#special-register-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The special register (<code class="docutils literal notranslate"><span class="pre">.sreg</span></code>) state space holds predefined, platform-specific registers, such as
grid, cluster, CTA, and thread parameters, clock counters, and performance monitoring registers. All
special registers are predefined.</p>
</section>
<section id="constant-state-space">
<span id="id35"></span><h3>
<span class="section-number">5.1.3. </span><a class="reference internal" href="#constant-state-space">Constant State Space</a><a class="headerlink" href="#constant-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The constant (<code class="docutils literal notranslate"><span class="pre">.const</span></code>) state space is a read-only memory initialized by the host. Constant memory
is accessed with a <code class="docutils literal notranslate"><span class="pre">ld.const</span></code> instruction. Constant memory is restricted in size, currently
limited to 64 KB which can be used to hold statically-sized constant variables. There is an
additional 640 KB of constant memory, organized as ten independent 64 KB regions. The driver may
allocate and initialize constant buffers in these regions and pass pointers to the buffers as kernel
function parameters. Since the ten regions are not contiguous, the driver must ensure that constant
buffers are allocated so that each buffer fits entirely within a 64 KB region and does not span a
region boundary.</p>
<p>Statically-sized constant variables have an optional variable initializer; constant variables with
no explicit initializer are initialized to zero by default. Constant buffers allocated by the driver
are initialized by the host, and pointers to such buffers are passed to the kernel as
parameters. See the description of kernel parameter attributes in
<a class="reference internal" href="#kernel-function-parameter-attributes"><span class="std std-ref">Kernel Function Parameter Attributes</span></a> for more details on passing pointers
to constant buffers as kernel parameters.</p>
<section id="banked-constant-state-space-deprecated">
<span id="id36"></span><h4>
<span class="section-number">5.1.3.1. </span><a class="reference internal" href="#banked-constant-state-space-deprecated">Banked Constant State Space (deprecated)</a><a class="headerlink" href="#banked-constant-state-space-deprecated" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Previous versions of PTX exposed constant memory as a set of eleven 64 KB banks, with explicit bank
numbers required for variable declaration and during access.</p>
<p>Prior to PTX ISA version 2.2, the constant memory was organized into fixed size banks. There were
eleven 64 KB banks, and banks were specified using the <code class="docutils literal notranslate"><span class="pre">.const[bank]</span></code> modifier, where <em>bank</em>
ranged from 0 to 10. If no bank number was given, bank zero was assumed.</p>
<p>By convention, bank zero was used for all statically-sized constant variables. The remaining banks
were used to declare <em>incomplete</em> constant arrays (as in C, for example), where the size is not
known at compile time. For example, the declaration</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.extern .const[2] .b32 const_buffer[];
</pre></div>
</div>
<p>resulted in <code class="docutils literal notranslate"><span class="pre">const_buffer</span></code> pointing to the start of constant bank two. This pointer could then be
used to access the entire 64 KB constant bank. Multiple incomplete array variables declared in the
same bank were aliased, with each pointing to the start address of the specified constant bank.</p>
<p>To access data in contant banks 1 through 10, the bank number was required in the state space of the
load instruction. For example, an incomplete array in bank 2 was accessed as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.extern .const[2] .b32 const_buffer[];
ld.const[2].b32  %r1, [const_buffer+4]; // load second word
</pre></div>
</div>
<p>In PTX ISA version 2.2, we eliminated explicit banks and replaced the incomplete array
representation of driver-allocated constant buffers with kernel parameter attributes that allow
pointers to constant buffers to be passed as kernel parameters.</p>
</section>
</section>
<section id="global-state-space">
<span id="id37"></span><h3>
<span class="section-number">5.1.4. </span><a class="reference internal" href="#global-state-space">Global State Space</a><a class="headerlink" href="#global-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The global (<code class="docutils literal notranslate"><span class="pre">.global</span></code>) state space is memory that is accessible by all threads in a context. It is
the mechanism by which threads in different CTAs, clusters, and grids can communicate. Use
<code class="docutils literal notranslate"><span class="pre">ld.global</span></code>, <code class="docutils literal notranslate"><span class="pre">st.global</span></code>, and <code class="docutils literal notranslate"><span class="pre">atom.global</span></code> to access global variables.</p>
<p>Global variables have an optional variable initializer; global variables with no explicit
initializer are initialized to zero by default.</p>
</section>
<section id="local-state-space">
<span id="id38"></span><h3>
<span class="section-number">5.1.5. </span><a class="reference internal" href="#local-state-space">Local State Space</a><a class="headerlink" href="#local-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The local state space (<code class="docutils literal notranslate"><span class="pre">.local</span></code>) is private memory for each thread to keep its own data. It is
typically standard memory with cache. The size is limited, as it must be allocated on a per-thread
basis. Use <code class="docutils literal notranslate"><span class="pre">ld.local</span></code> and <code class="docutils literal notranslate"><span class="pre">st.local</span></code> to access local variables.</p>
<p>When compiling to use the <em>Application Binary Interface (ABI)</em>, <code class="docutils literal notranslate"><span class="pre">.local</span></code> state-space variables
must be declared within function scope and are allocated on the stack. In implementations that do
not support a stack, all local memory variables are stored at fixed addresses, recursive function
calls are not supported, and <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables may be declared at module scope. When compiling
legacy PTX code (ISA versions prior to 3.0) containing module-scoped <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables, the
compiler silently disables use of the ABI.</p>
</section>
<section id="parameter-state-space">
<span id="id39"></span><h3>
<span class="section-number">5.1.6. </span><a class="reference internal" href="#parameter-state-space">Parameter State Space</a><a class="headerlink" href="#parameter-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The parameter (<code class="docutils literal notranslate"><span class="pre">.param</span></code>) state space is used (1) to pass input arguments from the host to the
kernel, (2a) to declare formal input and return parameters for device functions called from within
kernel execution, and (2b) to declare locally-scoped byte array variables that serve as function
call arguments, typically for passing large structures by value to a function. Kernel function
parameters differ from device function parameters in terms of access and sharing (read-only versus
read-write, per-kernel versus per-thread). Note that PTX ISA versions 1.x supports only kernel
function parameters in .param space; device function parameters were previously restricted to the
register state space. The use of parameter state space for device function parameters was introduced
in PTX ISA version 2.0 and requires target architecture <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. Additional sub-qualifiers
<code class="docutils literal notranslate"><span class="pre">::entry</span></code> or <code class="docutils literal notranslate"><span class="pre">::func</span></code> can be specified on instructions with <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space to indicate
whether the address refers to kernel function parameter or device function parameter. If no
sub-qualifier is specified with the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space, then the default sub-qualifier is specific
to and dependent on the exact instruction. For example, <code class="docutils literal notranslate"><span class="pre">st.param</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">st.param::func</span></code>
whereas <code class="docutils literal notranslate"><span class="pre">isspacep.param</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">isspacep.param::entry</span></code>. Refer to the instruction
description for more details on default sub-qualifier assumption.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The location of parameter space is implementation specific. For example, in some implementations
kernel parameters reside in global memory. No access protection is provided between parameter and
global space in this case. Though the exact location of the kernel parameter space is
implementation specific, the kernel parameter space window is always contained within the global
space window. Similarly, function parameters are mapped to parameter passing registers and/or
stack locations based on the function calling conventions of the <em>Application Binary Interface
(ABI)</em>. Therefore, PTX code should make no assumptions about the relative locations or ordering
of <code class="docutils literal notranslate"><span class="pre">.param</span></code> space variables.</p>
</div>
<section id="kernel-function-parameters">
<span id="id40"></span><h4>
<span class="section-number">5.1.6.1. </span><a class="reference internal" href="#kernel-function-parameters">Kernel Function Parameters</a><a class="headerlink" href="#kernel-function-parameters" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Each kernel function definition includes an optional list of parameters. These parameters are
addressable, read-only variables declared in the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space. Values passed from the host
to the kernel are accessed through these parameter variables using <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> instructions. The
kernel parameter variables are shared across all CTAs from all clusters within a grid.</p>
<p>The address of a kernel parameter may be moved into a register using the <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction. The
resulting address is in the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space and is accessed using <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> instructions.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo ( .param .b32 N, .param .align 8 .b8 buffer[64] )
{
    .reg .u32 %n;
    .reg .f64 %d;

    ld.param.u32 %n, [N];
    ld.param.f64 %d, [buffer];
    ...
</pre></div>
</div>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry bar ( .param .b32 len )
{
    .reg .u32 %ptr, %n;

    mov.u32      %ptr, len;
    ld.param.u32 %n, [%ptr];
    ...
</pre></div>
</div>
<p>Kernel function parameters may represent normal data values, or they may hold addresses to objects
in constant, global, local, or shared state spaces. In the case of pointers, the compiler and
runtime system need information about which parameters are pointers, and to which state space they
point. Kernel parameter attribute directives are used to provide this information at the PTX
level. See <a class="reference internal" href="#kernel-function-parameter-attributes"><span class="std std-ref">Kernel Function Parameter Attributes</span></a>
for a description of kernel parameter attribute
directives.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The current implementation does not allow creation of generic pointers to constant variables
(<code class="docutils literal notranslate"><span class="pre">cvta.const</span></code>) in programs that have pointers to constant buffers passed as kernel parameters.</p>
</div>
</section>
<section id="kernel-function-parameter-attributes">
<span id="id41"></span><h4>
<span class="section-number">5.1.6.2. </span><a class="reference internal" href="#kernel-function-parameter-attributes">Kernel Function Parameter Attributes</a><a class="headerlink" href="#kernel-function-parameter-attributes" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Kernel function parameters may be declared with an optional .ptr attribute to indicate that a
parameter is a pointer to memory, and also indicate the state space and alignment of the memory
being pointed to. <a class="reference internal" href="#kernel-parameter-attribute-ptr"><span class="std std-ref">Kernel Parameter Attribute: .ptr</span></a>
describes the <code class="docutils literal notranslate"><span class="pre">.ptr</span></code> kernel parameter attribute.</p>
</section>
<section id="kernel-parameter-attribute-ptr">
<span id="id42"></span><h4>
<span class="section-number">5.1.6.3. </span><a class="reference internal" href="#kernel-parameter-attribute-ptr">Kernel Parameter Attribute: <code class="docutils literal notranslate"><span class="pre">.ptr</span></code></a><a class="headerlink" href="#kernel-parameter-attribute-ptr" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.ptr</span></code></p>
<p>Kernel parameter alignment attribute.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.param .type .ptr .space .align N  varname
.param .type .ptr        .align N  varname

.space = { .const, .global, .local, .shared };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Used to specify the state space and, optionally, the alignment of memory pointed to by a pointer
type kernel parameter. The alignment value <em>N</em>, if present, must be a power of two. If no state
space is specified, the pointer is assumed to be a generic address pointing to one of const, global,
local, or shared memory. If no alignment is specified, the memory pointed to is assumed to be
aligned to a 4 byte boundary.</p>
<p>Spaces between <code class="docutils literal notranslate"><span class="pre">.ptr</span></code>, <code class="docutils literal notranslate"><span class="pre">.space</span></code>, and <code class="docutils literal notranslate"><span class="pre">.align</span></code> may be eliminated to improve readability.</p>
<p class="rubric">PTX ISA Notes</p>
<ul class="simple">
<li><p>Introduced in PTX ISA version 2.2.</p></li>
<li><p>Support for generic addressing of .const space added in PTX ISA version 3.1.</p></li>
</ul>
<p class="rubric">Target ISA Notes</p>
<ul class="simple">
<li><p>Supported on all target architectures.</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo ( .param .u32 param1,
             .param .u32 .ptr.global.align 16 param2,
             .param .u32 .ptr.const.align 8 param3,
             .param .u32 .ptr.align 16 param4  // generic address
                                               // pointer
) { .. }
</pre></div>
</div>
</section>
<section id="device-function-parameters">
<span id="id43"></span><h4>
<span class="section-number">5.1.6.4. </span><a class="reference internal" href="#device-function-parameters">Device Function Parameters</a><a class="headerlink" href="#device-function-parameters" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX ISA version 2.0 extended the use of parameter space to device function parameters. The most
common use is for passing objects by value that do not fit within a PTX register, such as C
structures larger than 8 bytes. In this case, a byte array in parameter space is used. Typically,
the caller will declare a locally-scoped <code class="docutils literal notranslate"><span class="pre">.param</span></code> byte array variable that represents a flattened
C structure or union. This will be passed by value to a callee, which declares a <code class="docutils literal notranslate"><span class="pre">.param</span></code> formal
parameter having the same size and alignment as the passed argument.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// pass object of type struct { double d; int y; };
.func foo ( .reg .b32 N, .param .align 8 .b8 buffer[12] )
{
    .reg .f64 %d;
    .reg .s32 %y;

    ld.param.f64 %d, [buffer];
    ld.param.s32 %y, [buffer+8];
    ...
}

// code snippet from the caller
// struct { double d; int y; } mystruct; is flattened, passed to foo
    ...
    .reg .f64 dbl;
    .reg .s32 x;
    .param .align 8 .b8 mystruct;
    ...
    st.param.f64 [mystruct+0], dbl;
    st.param.s32 [mystruct+8], x;
    call foo, (4, mystruct);
    ...
</pre></div>
</div>
<p>See the section on function call syntax for more details.</p>
<p>Function input parameters may be read via <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> and function return parameters may be written
using <code class="docutils literal notranslate"><span class="pre">st.param</span></code>; it is illegal to write to an input parameter or read from a return parameter.</p>
<p>Aside from passing structures by value, <code class="docutils literal notranslate"><span class="pre">.param</span></code> space is also required whenever a formal
parameter has its address taken within the called function. In PTX, the address of a function input
parameter may be moved into a register using the <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction. Note that the parameter will
be copied to the stack if necessary, and so the address will be in the <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space and is
accessed via <code class="docutils literal notranslate"><span class="pre">ld.local</span></code> and <code class="docutils literal notranslate"><span class="pre">st.local</span></code> instructions. It is not possible to use <code class="docutils literal notranslate"><span class="pre">mov</span></code> to get
the address of or a locally-scoped <code class="docutils literal notranslate"><span class="pre">.param</span></code> space variable. Starting PTX ISA version 6.0, it is
possible to use <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction to get address of return parameter of device function.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// pass array of up to eight floating-point values in buffer
.func foo ( .param .b32 N, .param .b32 buffer[32] )
{
    .reg .u32  %n, %r;
    .reg .f32  %f;
    .reg .pred %p;

    ld.param.u32 %n, [N];
    mov.u32      %r, buffer;  // forces buffer to .local state space
Loop:
    setp.eq.u32  %p, %n, 0;
@%p bra         Done;
    ld.local.f32 %f, [%r];
    ...
    add.u32      %r, %r, 4;
    sub.u32      %n, %n, 1;
    bra          Loop;
Done:
    ...
}
</pre></div>
</div>
</section>
</section>
<section id="shared-state-space">
<span id="id44"></span><h3>
<span class="section-number">5.1.7. </span><a class="reference internal" href="#shared-state-space">Shared State Space</a><a class="headerlink" href="#shared-state-space" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The shared (<code class="docutils literal notranslate"><span class="pre">.shared</span></code>) state space is a memory that is owned by an executing CTA and is accessible
to the threads of all the CTAs within a cluster. An address in shared memory can be read and written
by any thread in a CTA cluster.</p>
<p>Additional sub-qualifiers <code class="docutils literal notranslate"><span class="pre">::cta</span></code> or <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> can be specified on instructions with
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space to indicate whether the address belongs to the shared memory window of the
executing CTA or of any CTA in the cluster respectively. The addresses in the <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code>
window also fall within the <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> window. If no sub-qualifier is specified with the
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then it defaults to <code class="docutils literal notranslate"><span class="pre">::cta</span></code>. For example, <code class="docutils literal notranslate"><span class="pre">ld.shared</span></code> is equivalent to
<code class="docutils literal notranslate"><span class="pre">ld.shared::cta</span></code>.</p>
<p>Variables declared in <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space refer to the memory addresses in the current
CTA. Instruction <code class="docutils literal notranslate"><span class="pre">mapa</span></code> gives the <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> address of the corresponding variable in
another CTA in the cluster.</p>
<p>Shared memory typically has some optimizations to support the sharing. One example is broadcast;
where all threads read from the same address. Another is sequential access from sequential threads.</p>
</section>
<section id="texture-state-space-deprecated">
<span id="id45"></span><h3>
<span class="section-number">5.1.8. </span><a class="reference internal" href="#texture-state-space-deprecated">Texture State Space (deprecated)</a><a class="headerlink" href="#texture-state-space-deprecated" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The texture (<code class="docutils literal notranslate"><span class="pre">.tex</span></code>) state space is global memory accessed via the texture instruction. It is
shared by all threads in a context. Texture memory is read-only and cached, so accesses to texture
memory are not coherent with global memory stores to the texture image.</p>
<p>The GPU hardware has a fixed number of texture bindings that can be accessed within a single kernel
(typically 128). The .tex directive will bind the named texture memory variable to a hardware
texture identifier, where texture identifiers are allocated sequentially beginning with
zero. Multiple names may be bound to the same physical texture identifier. An error is generated if
the maximum number of physical resources is exceeded. The texture name must be of type <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or
<code class="docutils literal notranslate"><span class="pre">.u64</span></code>.</p>
<p>Physical texture resources are allocated on a per-kernel granularity, and <code class="docutils literal notranslate"><span class="pre">.tex</span></code> variables are
required to be defined in the global scope.</p>
<p>Texture memory is read-only. A textureâ€™s base address is assumed to be aligned to a 16 byte
boundary.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.tex .u32 tex_a;         // bound to physical texture 0
.tex .u32 tex_c, tex_d;  // both bound to physical texture 1
.tex .u32 tex_d;         // bound to physical texture 2
.tex .u32 tex_f;         // bound to physical texture 3
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Explicit declarations of variables in the texture state space is deprecated, and programs should
instead reference texture memory through variables of type <code class="docutils literal notranslate"><span class="pre">.texref</span></code>. The <code class="docutils literal notranslate"><span class="pre">.tex</span></code> directive is
retained for backward compatibility, and variables declared in the <code class="docutils literal notranslate"><span class="pre">.tex</span></code> state space are
equivalent to module-scoped <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variables in the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
</div>
<p>For example, a legacy PTX definitions such as</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.tex .u32 tex_a;
</pre></div>
</div>
<p>is equivalent to:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .texref tex_a;
</pre></div>
</div>
<p>See <a class="reference internal" href="#texture-sampler-and-surface-types"><span class="std std-ref">Texture Sampler and Surface Types</span></a> for the
description of the <code class="docutils literal notranslate"><span class="pre">.texref</span></code> type and <a class="reference internal" href="#texture-instructions"><span class="std std-ref">Texture Instructions</span></a>
for its use in texture instructions.</p>
</section>
</section>
<section id="types">
<span id="id46"></span><h2>
<span class="section-number">5.2. </span><a class="reference internal" href="#types">Types</a><a class="headerlink" href="#types" title="Permalink to this headline">ïƒ</a>
</h2>
<section id="fundamental-types">
<span id="id47"></span><h3>
<span class="section-number">5.2.1. </span><a class="reference internal" href="#fundamental-types">Fundamental Types</a><a class="headerlink" href="#fundamental-types" title="Permalink to this headline">ïƒ</a>
</h3>
<p>In PTX, the fundamental types reflect the native data types supported by the target architectures. A
fundamental type specifies both a basic type and a size. Register variables are always of a
fundamental type, and instructions operate on these types. The same type-size specifiers are used
for both variable definitions and for typing instructions, so their names are intentionally short.</p>
<p><a class="reference internal" href="#fundamental-types-fundamental-type-specifiers"><span class="std std-numref">Table 8</span></a> lists the fundamental type specifiers for
each basic type:</p>
<table class="table-no-stripes docutils align-default" id="fundamental-types-fundamental-type-specifiers">
<caption>
<span class="caption-number">Table 8 </span><span class="caption-text">Fundamental Type Specifiers</span><a class="headerlink" href="#fundamental-types-fundamental-type-specifiers" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 26%">
<col style="width: 74%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Basic Type</p></th>
<th class="head"><p>Fundamental Type Specifiers</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Signed integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Unsigned integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code>, <code class="docutils literal notranslate"><span class="pre">.u16</span></code>, <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Floating-point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Bits (untyped)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b8</span></code>, <code class="docutils literal notranslate"><span class="pre">.b16</span></code>, <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b128</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Predicate</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.pred</span></code></p></td>
</tr>
</tbody>
</table>
<p>Most instructions have one or more type specifiers, needed to fully specify instruction
behavior. Operand types and sizes are checked against instruction types for compatibility.</p>
<p>Two fundamental types are compatible if they have the same basic type and are the same size. Signed
and unsigned integer types are compatible if they have the same size. The bit-size type is
compatible with any fundamental type having the same size.</p>
<p>In principle, all variables (aside from predicates) could be declared using only bit-size types, but
typed variables enhance program readability and allow for better operand type checking.</p>
</section>
<section id="restricted-use-of-sub-word-sizes">
<span id="id48"></span><h3>
<span class="section-number">5.2.2. </span><a class="reference internal" href="#restricted-use-of-sub-word-sizes">Restricted Use of Sub-Word Sizes</a><a class="headerlink" href="#restricted-use-of-sub-word-sizes" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <code class="docutils literal notranslate"><span class="pre">.u8</span></code>, <code class="docutils literal notranslate"><span class="pre">.s8</span></code>, and <code class="docutils literal notranslate"><span class="pre">.b8</span></code> instruction types are restricted to <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt</span></code>
instructions. The <code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating-point type is allowed only in conversions to and from <code class="docutils literal notranslate"><span class="pre">.f32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> types, in half precision floating point instructions and texture fetch instructions. The
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> floating point type is allowed only in half precision floating point arithmetic
instructions and texture fetch instructions.</p>
<p>For convenience, <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions permit source and destination data
operands to be wider than the instruction-type size, so that narrow values may be loaded, stored,
and converted using regular-width registers. For example, 8-bit or 16-bit values may be held
directly in 32-bit or 64-bit registers when being loaded, stored, or converted to other types and
sizes.</p>
</section>
<section id="alternate-floating-point-data-formats">
<span id="id49"></span><h3>
<span class="section-number">5.2.3. </span><a class="reference internal" href="#alternate-floating-point-data-formats">Alternate Floating-Point Data Formats</a><a class="headerlink" href="#alternate-floating-point-data-formats" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The fundamental floating-point types supported in PTX have implicit bit representations that
indicate the number of bits used to store exponent and mantissa. For example, the <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type
indicates 5 bits reserved for exponent and 10 bits reserved for mantissa. In addition to the
floating-point representations assumed by the fundamental types, PTX allows the following alternate
floating-point data formats:</p>
<dl class="simple">
<dt>
<code class="docutils literal notranslate"><span class="pre">bf16</span></code> data format:</dt>
<dd>
<p>This data format is a 16-bit floating point format with 8 bits for exponent and 7 bits for
mantissa. A register variable containing <code class="docutils literal notranslate"><span class="pre">bf16</span></code> data must be declared with <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">e4m3</span></code> data format:</dt>
<dd>
<p>This data format is an 8-bit floating point format with 4 bits for exponent and 3 bits for
mantissa. The <code class="docutils literal notranslate"><span class="pre">e4m3</span></code> encoding does not support infinity and <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values are limited to
<code class="docutils literal notranslate"><span class="pre">0x7f</span></code> and <code class="docutils literal notranslate"><span class="pre">0xff</span></code>. A register variable containing <code class="docutils literal notranslate"><span class="pre">e4m3</span></code> value must be declared using
bit-size type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">e5m2</span></code> data format:</dt>
<dd>
<p>This data format is an 8-bit floating point format with 5 bits for exponent and 2 bits for
mantissa. A register variable containing <code class="docutils literal notranslate"><span class="pre">e5m2</span></code> value must be declared using bit-size type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">tf32</span></code> data format:</dt>
<dd>
<p>This data format is a special 32-bit floating point format supported by the matrix
multiply-and-accumulate instructions, with the same range as <code class="docutils literal notranslate"><span class="pre">.f32</span></code> and reduced precision (&gt;=10
bits). The internal layout of <code class="docutils literal notranslate"><span class="pre">tf32</span></code> format is implementation defined. PTX facilitates
conversion from single precision <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type to <code class="docutils literal notranslate"><span class="pre">tf32</span></code> format. A register variable containing
<code class="docutils literal notranslate"><span class="pre">tf32</span></code> data must be declared with <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">e2m1</span></code> data format:</dt>
<dd>
<p>This data format is a 4-bit floating point format with 2 bits for exponent and 1 bit for mantissa.
The <code class="docutils literal notranslate"><span class="pre">e2m1</span></code> encoding does not support infinity and <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. <code class="docutils literal notranslate"><span class="pre">e2m1</span></code> values must be used in a
packed format specified as <code class="docutils literal notranslate"><span class="pre">e2m1x2</span></code>. A register variable containing two <code class="docutils literal notranslate"><span class="pre">e2m1</span></code> values must be
declared with <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">e2m3</span></code> data format:</dt>
<dd>
<p>This data format is a 6-bit floating point format with 2 bits for exponent and 3 bits for mantissa.
The <code class="docutils literal notranslate"><span class="pre">e2m3</span></code> encoding does not support infinity and <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. <code class="docutils literal notranslate"><span class="pre">e2m3</span></code> values must be used in a
packed format specified as <code class="docutils literal notranslate"><span class="pre">e2m3x2</span></code>. A register variable containing two <code class="docutils literal notranslate"><span class="pre">e2m3</span></code> values must be
declared with <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type where each <code class="docutils literal notranslate"><span class="pre">.b8</span></code> element has 6-bit floating point value and 2 MSB
bits padded with zeros.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">e3m2</span></code> data format:</dt>
<dd>
<p>This data format is a 6-bit floating point format with 3 bits for exponent and 2 bits for mantissa.
The <code class="docutils literal notranslate"><span class="pre">e3m2</span></code> encoding does not support infinity and <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. <code class="docutils literal notranslate"><span class="pre">e3m2</span></code> values must be used in a
packed format specified as <code class="docutils literal notranslate"><span class="pre">e3m2x2</span></code>. A register variable containing two <code class="docutils literal notranslate"><span class="pre">e3m2</span></code> values must be
declared with <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type where each <code class="docutils literal notranslate"><span class="pre">.b8</span></code> element has 6-bit floating point value and 2 MSB
bits padded with zeros.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">ue8m0</span></code> data format:</dt>
<dd>
<p>This data format is an 8-bit unsigned floating-point format with 8 bits for exponent and 0 bits for
mantissa. The <code class="docutils literal notranslate"><span class="pre">ue8m0</span></code> encoding does not support infinity. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> value is limited to <code class="docutils literal notranslate"><span class="pre">0xff</span></code>.
<code class="docutils literal notranslate"><span class="pre">ue8m0</span></code> values must be used in a packed format specified as <code class="docutils literal notranslate"><span class="pre">ue8m0x2</span></code>. A register variable
containing two <code class="docutils literal notranslate"><span class="pre">ue8m0</span></code> values must be declared with <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">ue4m3</span></code> data format:</dt>
<dd>
<p>This data format is a 7-bit unsigned floating-point format with 4 bits for exponent and 3 bits for
mantissa. The <code class="docutils literal notranslate"><span class="pre">ue4m3</span></code> encoding does not support infinity. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> value is limited to <code class="docutils literal notranslate"><span class="pre">0x7f</span></code>.
A register variable containing single <code class="docutils literal notranslate"><span class="pre">ue4m3</span></code> value must be declared with <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type having
MSB bit padded with zero.</p>
</dd>
</dl>
<p>Alternate data formats cannot be used as fundamental types. They are supported as source or
destination formats by certain instructions.</p>
</section>
<section id="fixed-point-data-formats">
<span id="id50"></span><h3>
<span class="section-number">5.2.4. </span><a class="reference internal" href="#fixed-point-data-formats">Fixed-point Data format</a><a class="headerlink" href="#fixed-point-data-formats" title="Permalink to this headline">ïƒ</a>
</h3>
<p>PTX supports following fixed-point data formats:</p>
<dl>
<dt>
<code class="docutils literal notranslate"><span class="pre">s2f6</span></code> data format:</dt>
<dd>
<p>This data format is 8-bit signed 2â€™s complement integer with 2 sign-integer bits and
6 fractional bits with form <strong>xx.xxxxxx</strong>. The <code class="docutils literal notranslate"><span class="pre">s2f6</span></code> encoding does not support infinity
and <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">s2f6</span></code> value = s8 value * 2^(-6)
Positive max representation = 01.111111 = 127 * 2^(-6) = 1.984375
Negative max representation = 10.000000 = -128 * 2^(-6) = -2.0</p>
</dd>
</dl>
</section>
<section id="packed-data-types">
<span id="id51"></span><h3>
<span class="section-number">5.2.5. </span><a class="reference internal" href="#packed-data-types">Packed Data Types</a><a class="headerlink" href="#packed-data-types" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Certain PTX instructions operate on two or more sets of inputs in parallel, and produce two or more
outputs. Such instructions can use the data stored in a packed format. PTX supports packing two or
four values of the same scalar data type into a single, larger value. The packed value is considered
as a value of a <em>packed data type</em>. In this section we describe the packed data types supported in PTX.</p>
<section id="packed-floating-point-data-types">
<span id="id52"></span><h4>
<span class="section-number">5.2.5.1. </span><a class="reference internal" href="#packed-floating-point-data-types">Packed Floating Point Data Types</a><a class="headerlink" href="#packed-floating-point-data-types" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX supports various variants of packed floating point data types. Out of them, only <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> is
supported as a fundamental type, while others cannot be used as fundamental types - they are
supported as instruction types on certain instructions. When using an instruction with such
non-fundamental types, the operand data variables must be of bit type of appropriate size.
For example, all of the operand variables must be of type <code class="docutils literal notranslate"><span class="pre">.b32</span></code> for an instruction with
instruction type as <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>.
<a class="reference internal" href="#operand-types-for-packed-floating-point-instruction-type"><span class="std std-numref">Table 9</span></a> described various variants
of packed floating point data types in PTX.</p>
<table class="table-no-stripes docutils align-default" id="operand-types-for-packed-floating-point-instruction-type">
<caption>
<span class="caption-number">Table 9 </span><span class="caption-text">Operand types for packed floating point instruction type.</span><a class="headerlink" href="#operand-types-for-packed-floating-point-instruction-type" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 27%">
<col style="width: 19%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Packed floating
point type</p></th>
<th class="head"><p>Number of elements
contained in a
packed format</p></th>
<th class="head"><p>Type of each
element</p></th>
<th class="head"><p>Register variable type
to be used in the
declaration</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code></p></td>
<td rowspan="10"><p>Two</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.b32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code></p></td>
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.b16</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m3</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s2f6</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b8</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
<td rowspan="5"><p>Four</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code></p></td>
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m3</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b16</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="packed-integer-data-types">
<span id="id53"></span><h4>
<span class="section-number">5.2.5.2. </span><a class="reference internal" href="#packed-integer-data-types">Packed Integer Data Types</a><a class="headerlink" href="#packed-integer-data-types" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX supports two variants of packed integer data types: <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>. The packed data
type consists of two <code class="docutils literal notranslate"><span class="pre">.u16</span></code> or <code class="docutils literal notranslate"><span class="pre">.s16</span></code> values. A register variable containing <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> data must be declared with <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. Packed integer data types cannot be used as
fundamental types. They are supported as instruction types on certain instructions.</p>
</section>
<section id="packed-fixed-point-data-types">
<span id="id54"></span><h4>
<span class="section-number">5.2.5.3. </span><a class="reference internal" href="#packed-fixed-point-data-types">Packed Fixed-Point Data Types</a><a class="headerlink" href="#packed-fixed-point-data-types" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX supports <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> packed fixed-point data type consisting of two <code class="docutils literal notranslate"><span class="pre">.s2f6</span></code> packed
fixed-point values. A register variable containing <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> value must be declared with
<code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. Packed fixed-point data type cannot be used as fundamental type and is only
supported as instruction type.</p>
</section>
</section>
</section>
<section id="texture-sampler-and-surface-types">
<span id="id55"></span><h2>
<span class="section-number">5.3. </span><a class="reference internal" href="#texture-sampler-and-surface-types">Texture Sampler and Surface Types</a><a class="headerlink" href="#texture-sampler-and-surface-types" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX includes built-in <em>opaque</em> types for defining texture, sampler, and surface descriptor
variables. These types have named fields similar to structures, but all information about layout,
field ordering, base address, and overall size is hidden to a PTX program, hence the term
<em>opaque</em>. The use of these opaque types is limited to:</p>
<ul class="simple">
<li><p>Variable definition within global (module) scope and in kernel entry parameter lists.</p></li>
<li><p>Static initialization of module-scope variables using comma-delimited static assignment
expressions for the named members of the type.</p></li>
<li><p>Referencing textures, samplers, or surfaces via texture and surface load/store instructions
(<code class="docutils literal notranslate"><span class="pre">tex</span></code>, <code class="docutils literal notranslate"><span class="pre">suld</span></code>, <code class="docutils literal notranslate"><span class="pre">sust</span></code>, <code class="docutils literal notranslate"><span class="pre">sured</span></code>).</p></li>
<li><p>Retrieving the value of a named member via query instructions (<code class="docutils literal notranslate"><span class="pre">txq</span></code>, <code class="docutils literal notranslate"><span class="pre">suq</span></code>).</p></li>
<li><p>Creating pointers to opaque variables using <code class="docutils literal notranslate"><span class="pre">mov</span></code>, e.g., <code class="docutils literal notranslate"><span class="pre">mov.u64</span> <span class="pre">reg,</span> <span class="pre">opaque_var;</span></code>. The
resulting pointer may be stored to and loaded from memory, passed as a parameter to functions, and
de-referenced by texture and surface load, store, and query instructions, but the pointer cannot
otherwise be treated as an address, i.e., accessing the pointer with <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code>
instructions, or performing pointer arithmetic will result in undefined results.</p></li>
<li><p>Opaque variables may not appear in initializers, e.g., to initialize a pointer to an opaque
variable.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Indirect access to textures and surfaces using pointers to opaque variables is supported
beginning with PTX ISA version 3.1 and requires target <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or later.</p>
<p>Indirect access to textures is supported only in unified texture mode (see below).</p>
</div>
<p>The three built-in types are <code class="docutils literal notranslate"><span class="pre">.texref</span></code>, <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code>, and <code class="docutils literal notranslate"><span class="pre">.surfref</span></code>. For working with
textures and samplers, PTX has two modes of operation. In the <em>unified mode,</em> texture and sampler
information is accessed through a single <code class="docutils literal notranslate"><span class="pre">.texref</span></code> handle. In the <em>independent mode</em>, texture and
sampler information each have their own handle, allowing them to be defined separately and combined
at the site of usage in the program. In independent mode, the fields of the <code class="docutils literal notranslate"><span class="pre">.texref</span></code> type that
describe sampler properties are ignored, since these properties are defined by <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code>
variables.</p>
<p><a class="reference internal" href="#texture-sampler-and-surface-types-opaque-type-fields-in-unified-texture-mode"><span class="std std-numref">Table 10</span></a> and
<a class="reference internal" href="#sampler-properties-opaque-type-fields-in-independent-texture-mode"><span class="std std-numref">Table 11</span></a> list the named members
of each type for unified and independent texture modes. These members and their values have
precise mappings to methods and values defined in the texture <code class="docutils literal notranslate"><span class="pre">HW</span></code> class as well as
exposed values via the API.</p>
<table class="table-no-stripes docutils align-default" id="texture-sampler-and-surface-types-opaque-type-fields-in-unified-texture-mode">
<caption>
<span class="caption-number">Table 10 </span><span class="caption-text">Opaque Type Fields in Unified Texture Mode</span><a class="headerlink" href="#texture-sampler-and-surface-types-opaque-type-fields-in-unified-texture-mode" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 28%">
<col style="width: 32%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Member</p></th>
<th class="head"><p>.texref values</p></th>
<th class="head"><p>.surfref values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">width</span></code></p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">height</span></code></p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">depth</span></code></p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code></p></td>
<td colspan="2"><p><code class="docutils literal notranslate"><span class="pre">enum</span></code> type corresponding to source language API</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">channel_order</span></code></p></td>
<td colspan="2"><p><code class="docutils literal notranslate"><span class="pre">enum</span></code> type corresponding to source language API</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code></p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">filter_mode</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nearest</span></code>, <code class="docutils literal notranslate"><span class="pre">linear</span></code></p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">addr_mode_0</span></code>, <code class="docutils literal notranslate"><span class="pre">addr_mode_1</span></code>,
<code class="docutils literal notranslate"><span class="pre">addr_mode_2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">wrap</span></code>, <code class="docutils literal notranslate"><span class="pre">mirror</span></code>, <code class="docutils literal notranslate"><span class="pre">clamp_ogl</span></code>,
<code class="docutils literal notranslate"><span class="pre">clamp_to_edge</span></code>, <code class="docutils literal notranslate"><span class="pre">clamp_to_border</span></code></p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">array_size</span></code></p></td>
<td><p>as number of textures in a texture
array</p></td>
<td><p>as number of surfaces in a surface array</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">num_mipmap_levels</span></code></p></td>
<td><p>as number of levels in a mipmapped
texture</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">num_samples</span></code></p></td>
<td><p>as number of samples in a multi-sample
texture</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">memory_layout</span></code></p></td>
<td><p>N/A</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code> for linear memory layout; <code class="docutils literal notranslate"><span class="pre">0</span></code> otherwise</p></td>
</tr>
</tbody>
</table>
<section id="texture-surface-properties">
<span id="id56"></span><h3>
<span class="section-number">5.3.1. </span><a class="reference internal" href="#texture-surface-properties">Texture and Surface Properties</a><a class="headerlink" href="#texture-surface-properties" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Fields <code class="docutils literal notranslate"><span class="pre">width</span></code>, <code class="docutils literal notranslate"><span class="pre">height</span></code>, and <code class="docutils literal notranslate"><span class="pre">depth</span></code> specify the size of the texture or surface in number of
elements in each dimension.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">channel_order</span></code> fields specify these properties of the texture or
surface using enumeration types corresponding to the source language API. For example, see
<a class="reference internal" href="#channel-data-type-and-channel-order-fields"><span class="std std-ref">Channel Data Type and Channel Order Fields</span></a> for
the OpenCL enumeration types currently supported in PTX.</p>
</section>
<section id="sampler-properties">
<span id="id57"></span><h3>
<span class="section-number">5.3.2. </span><a class="reference internal" href="#sampler-properties">Sampler Properties</a><a class="headerlink" href="#sampler-properties" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code> field indicates whether the texture or surface uses normalized coordinates
in the range [0.0, 1.0) instead of unnormalized coordinates in the range [0, N). If no value is
specified, the default is set by the runtime system based on the source language.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">filter_mode</span></code> field specifies how the values returned by texture reads are computed based on
the input texture coordinates.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">addr_mode_{0,1,2}</span></code> fields define the addressing mode in each dimension, which determine how
out-of-range coordinates are handled.</p>
<p>See the <em>CUDA C++ Programming Guide</em> for more details of these properties.</p>
<table class="table-no-stripes docutils align-default" id="sampler-properties-opaque-type-fields-in-independent-texture-mode">
<caption>
<span class="caption-number">Table 11 </span><span class="caption-text">Opaque Type Fields in Independent Texture Mode</span><a class="headerlink" href="#sampler-properties-opaque-type-fields-in-independent-texture-mode" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 26%">
<col style="width: 33%">
<col style="width: 19%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Member</p></th>
<th class="head"><p>.samplerref values</p></th>
<th class="head"><p>.texref values</p></th>
<th class="head"><p>.surfref values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">width</span></code></p></td>
<td><p>N/A</p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">height</span></code></p></td>
<td><p>N/A</p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">depth</span></code></p></td>
<td><p>N/A</p></td>
<td colspan="2"><p>in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code></p></td>
<td><p>N/A</p></td>
<td colspan="2"><p><code class="docutils literal notranslate"><span class="pre">enum</span></code> type corresponding to source
language API</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">channel_order</span></code></p></td>
<td><p>N/A</p></td>
<td colspan="2"><p><code class="docutils literal notranslate"><span class="pre">enum</span></code> type corresponding to source
language AP</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code></p></td>
<td><p>N/A</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code></p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code></p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">filter_mode</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nearest</span></code>, <code class="docutils literal notranslate"><span class="pre">linear</span></code></p></td>
<td><p>ignored</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">addr_mode_0</span></code>,
<code class="docutils literal notranslate"><span class="pre">addr_mode_1</span></code>,
<code class="docutils literal notranslate"><span class="pre">addr_mode_2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">wrap</span></code>, <code class="docutils literal notranslate"><span class="pre">mirror</span></code>, <code class="docutils literal notranslate"><span class="pre">clamp_ogl</span></code>,
<code class="docutils literal notranslate"><span class="pre">clamp_to_edge</span></code>, <code class="docutils literal notranslate"><span class="pre">clamp_to_border</span></code></p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">array_size</span></code></p></td>
<td><p>N/A</p></td>
<td><p>as number of textures
in a texture array</p></td>
<td><p>as number of surfaces in
a surface array</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">num_mipmap_levels</span></code></p></td>
<td><p>N/A</p></td>
<td><p>as number of levels
in a mipmapped
texture</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">num_samples</span></code></p></td>
<td><p>N/A</p></td>
<td><p>as number of samples
in a multi-sample
texture</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">memory_layout</span></code></p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code> for linear memory
layout; <code class="docutils literal notranslate"><span class="pre">0</span></code> otherwise</p></td>
</tr>
</tbody>
</table>
<p>In independent texture mode, the sampler properties are carried in an independent <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code>
variable, and these fields are disabled in the <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variables. One additional sampler
property, <code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code>, is available in independent texture mode.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code> field is a property of <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> variables that allows the
sampler to override the texture header <code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code> property. This field is defined only in
independent texture mode. When <code class="docutils literal notranslate"><span class="pre">True</span></code>, the texture header setting is overridden and unnormalized
coordinates are used; when <code class="docutils literal notranslate"><span class="pre">False</span></code>, the texture header setting is used.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code> property is used in compiling OpenCL; in OpenCL, the property of
normalized coordinates is carried in sampler headers. To compile OpenCL to PTX, texture headers are
always initialized with <code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code> set to True, and the OpenCL sampler-based
<code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code> flag maps (negated) to the PTX-level <code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code> flag.</p>
<p>Variables using these types may be declared at module scope or within kernel entry parameter
lists. At module scope, these variables must be in the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space. As kernel
parameters, these variables are declared in the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .texref     my_texture_name;
.global .samplerref my_sampler_name;
.global .surfref    my_surface_name;
</pre></div>
</div>
<p>When declared at module scope, the types may be initialized using a list of static expressions
assigning values to the named members.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .texref tex1;
.global .samplerref tsamp1 = { addr_mode_0 = clamp_to_border,
                               filter_mode = nearest
                             };
</pre></div>
</div>
</section>
<section id="channel-data-type-and-channel-order-fields">
<span id="id58"></span><h3>
<span class="section-number">5.3.3. </span><a class="reference internal" href="#channel-data-type-and-channel-order-fields">Channel Data Type and Channel Order Fields</a><a class="headerlink" href="#channel-data-type-and-channel-order-fields" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">channel_order</span></code> fields have enumeration types corresponding to the
source language API. Currently, OpenCL is the only source language that defines these
fields. <a class="reference internal" href="#channel-data-type-and-channel-order-fields-opencl-channel-order-definition"><span class="std std-numref">Table 13</span></a> and
<a class="reference internal" href="#channel-data-type-and-channel-order-fields-opencl-channel-data-type-definition"><span class="std std-numref">Table 12</span></a> show the
enumeration values defined in OpenCL version 1.0 for channel data type and channel order.</p>
<table class="table-no-stripes docutils align-default" id="channel-data-type-and-channel-order-fields-opencl-channel-data-type-definition">
<caption>
<span class="caption-number">Table 12 </span><span class="caption-text">OpenCL 1.0 Channel Data Type Definition</span><a class="headerlink" href="#channel-data-type-and-channel-order-fields-opencl-channel-data-type-definition" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 68%">
<col style="width: 32%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_SNORM_INT8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D0</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_SNORM_INT16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D1</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNORM_INT8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNORM_INT16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D3</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNORM_SHORT_565</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNORM_SHORT_555</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D5</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNORM_INT_101010</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D6</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_SIGNED_INT8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D7</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_SIGNED_INT16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D8</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_SIGNED_INT32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10D9</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNSIGNED_INT8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10DA</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNSIGNED_INT16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10DB</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_UNSIGNED_INT32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10DC</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_HALF_FLOAT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10DD</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_FLOAT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10DE</span></code></p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="channel-data-type-and-channel-order-fields-opencl-channel-order-definition">
<caption>
<span class="caption-number">Table 13 </span><span class="caption-text">OpenCL 1.0 Channel Order Definition</span><a class="headerlink" href="#channel-data-type-and-channel-order-fields-opencl-channel-order-definition" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_R</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B0</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_A</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B1</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_RG</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B2</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_RA</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B3</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_RGB</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_RGBA</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B5</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_BGRA</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B6</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_ARGB</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B7</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_INTENSITY</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B8</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">CL_LUMINANCE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0x10B9</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="variables">
<span id="id59"></span><h2>
<span class="section-number">5.4. </span><a class="reference internal" href="#variables">Variables</a><a class="headerlink" href="#variables" title="Permalink to this headline">ïƒ</a>
</h2>
<p>In PTX, a variable declaration describes both the variableâ€™s type and its state space. In addition
to fundamental types, PTX supports types for simple aggregate objects such as vectors and arrays.</p>
<section id="variable-declarations">
<span id="id60"></span><h3>
<span class="section-number">5.4.1. </span><a class="reference internal" href="#variable-declarations">Variable Declarations</a><a class="headerlink" href="#variable-declarations" title="Permalink to this headline">ïƒ</a>
</h3>
<p>All storage for data is specified with variable declarations. Every variable must reside in one of
the state spaces enumerated in the previous section.</p>
<p>A variable declaration names the space in which the variable resides, its type and size, its name,
an optional array size, an optional initializer, and an optional fixed address for the variable.</p>
<p>Predicate variables may only be declared in the register state space.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .u32 loc;
.reg    .s32 i;
.const  .f32 bias[] = {-1.0, 1.0};
.global .u8  bg[4] = {0, 0, 0, 0};
.reg    .v4 .f32 accel;
.reg    .pred p, q, r;
</pre></div>
</div>
</section>
<section id="vectors">
<span id="id61"></span><h3>
<span class="section-number">5.4.2. </span><a class="reference internal" href="#vectors">Vectors</a><a class="headerlink" href="#vectors" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Limited-length vector types are supported. Vectors of length 2 and 4 of any non-predicate
fundamental type can be declared by prefixing the type with <code class="docutils literal notranslate"><span class="pre">.v2</span></code> or <code class="docutils literal notranslate"><span class="pre">.v4</span></code>. Vectors must be
based on a fundamental type, and they may reside in the register space. Vectors cannot exceed
128-bits in length; for example, <code class="docutils literal notranslate"><span class="pre">.v4</span> <span class="pre">.f64</span></code> is not allowed. Three-element vectors may be
handled by using a <code class="docutils literal notranslate"><span class="pre">.v4</span></code> vector, where the fourth element provides padding. This is a common case
for three-dimensional grids, textures, etc.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .v4 .f32 V;   // a length-4 vector of floats
.shared .v2 .u16 uv;  // a length-2 vector of unsigned ints
.global .v4 .b8  v;   // a length-4 vector of bytes
</pre></div>
</div>
<p>By default, vector variables are aligned to a multiple of their overall size (vector length times
base-type size), to enable vector load and store instructions which require addresses aligned to a
multiple of the access size.</p>
</section>
<section id="array-declarations">
<span id="id62"></span><h3>
<span class="section-number">5.4.3. </span><a class="reference internal" href="#array-declarations">Array Declarations</a><a class="headerlink" href="#array-declarations" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Array declarations are provided to allow the programmer to reserve space. To declare an array, the
variable name is followed with dimensional declarations similar to fixed-size array declarations
in C. The size of each dimension is a constant expression.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.local  .u16 kernel[19][19];
.shared .u8  mailbox[128];
</pre></div>
</div>
<p>The size of the array specifies how many elements should be reserved. For the declaration of array
<em>kernel</em> above, 19*19 = 361 halfwords are reserved, for a total of 722 bytes.</p>
<p>When declared with an initializer, the first dimension of the array may be omitted. The size of the
first array dimension is determined by the number of elements in the array initializer.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .u32 index[] = { 0, 1, 2, 3, 4, 5, 6, 7 };
.global .s32 offset[][2] = { {-1, 0}, {0, -1}, {1, 0}, {0, 1} };
</pre></div>
</div>
<p>Array <em>index</em> has eight elements, and array <em>offset</em> is a 4x2 array.</p>
</section>
<section id="initializers">
<span id="id63"></span><h3>
<span class="section-number">5.4.4. </span><a class="reference internal" href="#initializers">Initializers</a><a class="headerlink" href="#initializers" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Declared variables may specify an initial value using a syntax similar to C/C++, where the variable
name is followed by an equals sign and the initial value or values for the variable. A scalar takes
a single value, while vectors and arrays take nested lists of values inside of curly braces (the
nesting matches the dimensionality of the declaration).</p>
<p>As in C, array initializers may be incomplete, i.e., the number of initializer elements may be less
than the extent of the corresponding array dimension, with remaining array locations initialized to
the default value for the specified array type.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.const  .f32 vals[8] = { 0.33, 0.25, 0.125 };
.global .s32 x[3][2] = { {1,2}, {3} };
</pre></div>
</div>
<p>is equivalent to</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.const  .f32 vals[8] = { 0.33, 0.25, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0 };
.global .s32 x[3][2] = { {1,2}, {3,0}, {0,0} };
</pre></div>
</div>
<p>Currently, variable initialization is supported only for constant and global state spaces. Variables
in constant and global state spaces with no explicit initializer are initialized to zero by
default. Initializers are not allowed in external variable declarations.</p>
<p>Variable names appearing in initializers represent the address of the variable; this can be used to
statically initialize a pointer to a variable. Initializers may also contain <em>var+offset</em>
expressions, where <em>offset</em> is a byte offset added to the address of <em>var</em>. Only variables in
<code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.const</span></code> state spaces may be used in initializers. By default, the resulting
address is the offset in the variableâ€™s state space (as is the case when taking the address of a
variable with a <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction). An operator, <code class="docutils literal notranslate"><span class="pre">generic()</span></code>, is provided to create a generic
address for variables used in initializers.</p>
<p>Starting PTX ISA version 7.1, an operator <code class="docutils literal notranslate"><span class="pre">mask()</span></code> is provided, where <code class="docutils literal notranslate"><span class="pre">mask</span></code> is an integer
immediate. The only allowed expressions in the <code class="docutils literal notranslate"><span class="pre">mask()</span></code> operator are integer constant expression
and symbol expression representing address of variable. The <code class="docutils literal notranslate"><span class="pre">mask()</span></code> operator extracts <code class="docutils literal notranslate"><span class="pre">n</span></code>
consecutive bits from the expression used in initializers and inserts these bits at the lowest
position of the initialized variable. The number <code class="docutils literal notranslate"><span class="pre">n</span></code> and the starting position of the bits to be
extracted is specified by the integer immediate <code class="docutils literal notranslate"><span class="pre">mask</span></code>. PTX ISA version 7.1 only supports
extracting a single byte starting at byte boundary from the address of the variable. PTX ISA version
7.3 supports Integer constant expression as an operand in the <code class="docutils literal notranslate"><span class="pre">mask()</span></code> operator.</p>
<p>Supported values for <code class="docutils literal notranslate"><span class="pre">mask</span></code> are: 0xFF, 0xFF00, 0XFF0000, 0xFF000000, 0xFF00000000, 0xFF0000000000,
0xFF000000000000, 0xFF00000000000000.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.const  .u32 foo = 42;
.global .u32 bar[] = { 2, 3, 5 };
.global .u32 p1 = foo;          // offset of foo in .const space
.global .u32 p2 = generic(foo); // generic address of foo

// array of generic-address pointers to elements of bar
.global .u32 parr[] = { generic(bar), generic(bar)+4,
generic(bar)+8 };

// examples using mask() operator are pruned for brevity
.global .u8 addr[] = {0xff(foo), 0xff00(foo), 0xff0000(foo), ...};

.global .u8 addr2[] = {0xff(foo+4), 0xff00(foo+4), 0xff0000(foo+4),...}

.global .u8 addr3[] = {0xff(generic(foo)), 0xff00(generic(foo)),...}

.global .u8 addr4[] = {0xff(generic(foo)+4), 0xff00(generic(foo)+4),...}

// mask() operator with integer const expression
.global .u8 addr5[] = { 0xFF(1000 + 546), 0xFF00(131187), ...};
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PTX 3.1 redefines the default addressing for global variables in initializers, from generic
addresses to offsets in the global state space. Legacy PTX code is treated as having an implicit
<code class="docutils literal notranslate"><span class="pre">generic()</span></code> operator for each global variable used in an initializer. PTX 3.1 code should
either include explicit <code class="docutils literal notranslate"><span class="pre">generic()</span></code> operators in initializers, use <code class="docutils literal notranslate"><span class="pre">cvta.global</span></code> to form
generic addresses at runtime, or load from the non-generic address using <code class="docutils literal notranslate"><span class="pre">ld.global</span></code>.</p>
</div>
<p>Device function names appearing in initializers represent the address of the first instruction in
the function; this can be used to initialize a table of function pointers to be used with indirect
calls. Beginning in PTX ISA version 3.1, kernel function names can be used as initializers e.g. to
initialize a table of kernel function pointers, to be used with CUDA Dynamic Parallelism to launch
kernels from GPU. See the <em>CUDA Dynamic Parallelism Programming Guide</em> for details.</p>
<p>Labels cannot be used in initializers.</p>
<p>Variables that hold addresses of variables or functions should be of type <code class="docutils literal notranslate"><span class="pre">.u8</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or
<code class="docutils literal notranslate"><span class="pre">.u64</span></code>.</p>
<p>Type <code class="docutils literal notranslate"><span class="pre">.u8</span></code> is allowed only if the <code class="docutils literal notranslate"><span class="pre">mask()</span></code> operator is used.</p>
<p>Initializers are allowed for all types except <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.pred</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .s32 n = 10;
.global .f32 blur_kernel[][3]
               = {{.05,.1,.05},{.1,.4,.1},{.05,.1,.05}};

.global .u32 foo[] = { 2, 3, 5, 7, 9, 11 };
.global .u64 ptr = generic(foo);   // generic address of foo[0]
.global .u64 ptr = generic(foo)+8; // generic address of foo[2]
</pre></div>
</div>
</section>
<section id="alignment">
<span id="id64"></span><h3>
<span class="section-number">5.4.5. </span><a class="reference internal" href="#alignment">Alignment</a><a class="headerlink" href="#alignment" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Byte alignment of storage for all addressable variables can be specified in the variable
declaration. Alignment is specified using an optional <code class="docutils literal notranslate"><span class="pre">.align</span></code> <em>byte-count</em> specifier immediately
following the state-space specifier. The variable will be aligned to an address which is an integer
multiple of byte-count. The alignment value byte-count must be a power of two. For arrays, alignment
specifies the address alignment for the starting address of the entire array, not for individual
elements.</p>
<p>The default alignment for scalar and array variables is to a multiple of the base-type size. The
default alignment for vector variables is to a multiple of the overall vector size.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> // allocate array at 4-byte aligned address.  Elements are bytes.
.const .align 4 .b8 bar[8] = {0,0,0,0,2,0,0,0};
</pre></div>
</div>
<p>Note that all PTX instructions that access memory require that the address be aligned to a multiple
of the access size. The access size of a memory instruction is the total number of bytes accessed in
memory. For example, the access size of <code class="docutils literal notranslate"><span class="pre">ld.v4.b32</span></code> is 16 bytes, while the access size of
<code class="docutils literal notranslate"><span class="pre">atom.f16x2</span></code> is 4 bytes.</p>
</section>
<section id="parameterized-variable-names">
<span id="id65"></span><h3>
<span class="section-number">5.4.6. </span><a class="reference internal" href="#parameterized-variable-names">Parameterized Variable Names</a><a class="headerlink" href="#parameterized-variable-names" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Since PTX supports virtual registers, it is quite common for a compiler frontend to generate a large
number of register names. Rather than require explicit declaration of every name, PTX supports a
syntax for creating a set of variables having a common prefix string appended with integer suffixes.</p>
<p>For example, suppose a program uses a large number, say one hundred, of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> variables, named
<code class="docutils literal notranslate"><span class="pre">%r0</span></code>, <code class="docutils literal notranslate"><span class="pre">%r1</span></code>, â€¦, <code class="docutils literal notranslate"><span class="pre">%r99</span></code>. These 100 register variables can be declared as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r&lt;100&gt;;    // declare %r0, %r1, ..., %r99
</pre></div>
</div>
<p>This shorthand syntax may be used with any of the fundamental types and with any state space, and
may be preceded by an alignment specifier. Array variables cannot be declared this way, nor are
initializers permitted.</p>
</section>
<section id="variable-attributes">
<span id="id66"></span><h3>
<span class="section-number">5.4.7. </span><a class="reference internal" href="#variable-attributes">Variable Attributes</a><a class="headerlink" href="#variable-attributes" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Variables may be declared with an optional <code class="docutils literal notranslate"><span class="pre">.attribute</span></code> directive which allows specifying special
attributes of variables. Keyword <code class="docutils literal notranslate"><span class="pre">.attribute</span></code> is followed by attribute specification inside
parenthesis. Multiple attributes are separated by comma.</p>
<p><a class="reference internal" href="#variable-and-function-attribute-directive-attribute"><span class="std std-ref">Variable and Function Attribute Directive: .attribute</span></a> describes the <code class="docutils literal notranslate"><span class="pre">.attribute</span></code>
directive.</p>
</section>
<section id="variable-and-function-attribute-directive-attribute">
<span id="id67"></span><h3>
<span class="section-number">5.4.8. </span><a class="reference internal" href="#variable-and-function-attribute-directive-attribute">Variable and Function Attribute Directive: <code class="docutils literal notranslate"><span class="pre">.attribute</span></code></a><a class="headerlink" href="#variable-and-function-attribute-directive-attribute" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.attribute</span></code></p>
<p>Variable and function attributes</p>
<p class="rubric">Description</p>
<p>Used to specify special attributes of a variable or a function.</p>
<p>The following attributes are supported.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.managed</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">.managed</span></code> attribute specifies that variable will be allocated at a location in unified virtual
memory environment where host and other devices in the system can reference the variable
directly. This attribute can only be used with variables in .global state space. See the <em>CUDA
UVM-Lite Programming Guide</em> for details.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.unified</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">.unified</span></code> attribute specifies that function has the same memory address on the host and on
other devices in the system. Integer constants <code class="docutils literal notranslate"><span class="pre">uuid1</span></code> and <code class="docutils literal notranslate"><span class="pre">uuid2</span></code> respectively specify upper
and lower 64 bits of the unique identifier associated with the function or the variable. This
attribute can only be used on device functions or on variables in the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state
space. Variables with <code class="docutils literal notranslate"><span class="pre">.unified</span></code> attribute are read-only and must be loaded by specifying
<code class="docutils literal notranslate"><span class="pre">.unified</span></code> qualifier on the address operand of <code class="docutils literal notranslate"><span class="pre">ld</span></code> instruction, otherwise the behavior is
undefined.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<ul class="simple">
<li><p>Introduced in PTX ISA version 4.0.</p></li>
<li><p>Support for function attributes introduced in PTX ISA version 8.0.</p></li>
</ul>
<p class="rubric">Target ISA Notes</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.managed</span></code> attribute requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.unified</span></code> attribute requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .attribute(.managed) .s32 g;
.global .attribute(.managed) .u64 x;

.global .attribute(.unified(19,95)) .f32 f;

.func .attribute(.unified(0xAB, 0xCD)) bar() { ... }
</pre></div>
</div>
</section>
</section>
<section id="tensors">
<span id="id68"></span><h2>
<span class="section-number">5.5. </span><a class="reference internal" href="#tensors">Tensors</a><a class="headerlink" href="#tensors" title="Permalink to this headline">ïƒ</a>
</h2>
<p>A tensor is a multi-dimensional matrix structure in the memory. Tensor is defined by the following
properties:</p>
<ul class="simple">
<li><p>Dimensionality</p></li>
<li><p>Dimension sizes across each dimension</p></li>
<li><p>Individual element types</p></li>
<li><p>Tensor stride across each dimension</p></li>
</ul>
<p>PTX supports instructions which can operate on the tensor data. PTX Tensor instructions include:</p>
<ul class="simple">
<li><p>Copying data between global and shared memories</p></li>
<li><p>Reducing the destination tensor data with the source.</p></li>
</ul>
<p>The Tensor data can be operated on by various <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>, <code class="docutils literal notranslate"><span class="pre">mma</span></code> and <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instructions.</p>
<p>PTX Tensor instructions treat the tensor data in the global memory as a multi-dimensional structure
and treat the data in the shared memory as a linear data.</p>
<section id="tensor-dimension-size-format">
<span id="id69"></span><h3>
<span class="section-number">5.5.1. </span><a class="reference internal" href="#tensor-dimension-size-format">Tensor Dimension, size and format</a><a class="headerlink" href="#tensor-dimension-size-format" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Tensors can have dimensions: 1D, 2D, 3D, 4D or 5D.</p>
<p>Each dimension has a size which represents the number of elements along the dimension. The elements
can have one the following types:</p>
<ul class="simple">
<li><p>Bit-sized type: <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></li>
<li><p>Sub-byte types: <code class="docutils literal notranslate"><span class="pre">.b4x16</span></code>, <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code></p></li>
<li><p>Integer: <code class="docutils literal notranslate"><span class="pre">.u8</span></code>, <code class="docutils literal notranslate"><span class="pre">.u16</span></code>, <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></li>
<li><p>Floating point and alternate floating point: <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f64</span></code>
(rounded to nearest even).</p></li>
</ul>
<p>Tensor can have padding at the end in each of the dimensions to provide alignment for the data in
the subsequent dimensions. Tensor stride can be used to specify the amount of padding in each
dimension.</p>
<section id="tensor-dimension-size-format-sub-bytes">
<span id="id70"></span><h4>
<span class="section-number">5.5.1.1. </span><a class="reference internal" href="#tensor-dimension-size-format-sub-bytes">Sub-byte Types</a><a class="headerlink" href="#tensor-dimension-size-format-sub-bytes" title="Permalink to this headline">ïƒ</a>
</h4>
<section id="tensor-dimension-size-format-sub-bytes-padding-align">
<span id="id71"></span><h5>
<span class="section-number">5.5.1.1.1. </span><a class="reference internal" href="#tensor-dimension-size-format-sub-bytes-padding-align">Padding and alignment of the sub-byte types</a><a class="headerlink" href="#tensor-dimension-size-format-sub-bytes-padding-align" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The sub-byte types are expected to packed contiguously in the global memory and
the Tensor copy instruction will expand them by appending empty spaces as shown below:</p>
<ol class="arabic">
<li><p>Type <code class="docutils literal notranslate"><span class="pre">.b4x16</span></code>:
With this type, there is no padding involved and the packed sixteen <code class="docutils literal notranslate"><span class="pre">.b4</span></code> elements
in a 64-bits container is copied as is between the shared memory and the global memory.</p></li>
<li>
<p>Type <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>:
With this type, sixteen contiguous 4-bits of data is copied from global memory to the
shared memory with the append of 64-bits of padding as shown in
<a class="reference internal" href="#tensor-dimension-size-format-sub-bytes-padding-align-b4-16-p64"><span class="std std-numref">Figure 5</span></a></p>
<figure class="align-center" id="tensor-dimension-size-format-sub-bytes-padding-align-b4-16-p64">
<img alt="_images/tensor-dimension-size-format-sub-bytes-padding-align-b4-16-p64.png" class="image" src="_images/tensor-dimension-size-format-sub-bytes-padding-align-b4-16-p64.png">
<figcaption>
<p><span class="caption-number">Figure 5 </span><span class="caption-text">Layout for .b4x16_p64</span><a class="headerlink" href="#tensor-dimension-size-format-sub-bytes-padding-align-b4-16-p64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The padded region that gets added is un-initialized.</p>
</li>
<li>
<p>Type <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>:
With this type, sixteen 6-bits of data is copied from global memory to the shared memory
with an append of 32-bits of padding as shown in
<a class="reference internal" href="#tensor-dimension-size-format-sub-bytes-padding-align-b6-16-p32"><span class="std std-numref">Figure 6</span></a></p>
<figure class="align-center" id="tensor-dimension-size-format-sub-bytes-padding-align-b6-16-p32">
<img alt="_images/tensor-dimension-size-format-sub-bytes-padding-align-b6-16-p32.png" class="image" src="_images/tensor-dimension-size-format-sub-bytes-padding-align-b6-16-p32.png">
<figcaption>
<p><span class="caption-number">Figure 6 </span><span class="caption-text">Layout for .b6x16_p32</span><a class="headerlink" href="#tensor-dimension-size-format-sub-bytes-padding-align-b6-16-p32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The padded region that gets added is un-initialized.</p>
</li>
<li>
<p>Type <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>:
With this type, sixteen elements, each containing 6-bits of data at the LSB and 2-bits
of padding at the MSB, are copied from shared memory into the global memory by discarding
the 2-bits of padding data and packing the 6-bits data contiguously as shown in
<a class="reference internal" href="#tensor-dimension-size-format-sub-bytes-padding-align-b6-p2-16"><span class="std std-numref">Figure 7</span></a></p>
<figure class="align-center" id="tensor-dimension-size-format-sub-bytes-padding-align-b6-p2-16">
<img alt="_images/tensor-dimension-size-format-sub-bytes-padding-align-b6-p2-16.png" class="image" src="_images/tensor-dimension-size-format-sub-bytes-padding-align-b6-p2-16.png">
<figcaption>
<p><span class="caption-number">Figure 7 </span><span class="caption-text">Layout for .b6p2x16</span><a class="headerlink" href="#tensor-dimension-size-format-sub-bytes-padding-align-b6-p2-16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ol>
<p>In case of <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, the padded region that gets added is
un-initialized.</p>
<p>The types <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code> share the same encoding value in the
descriptor (value 15) as the two types are applicable for different types of
tensor copy operations:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 35%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Type</p></th>
<th class="head"><p>Valid Tensor Copy Direction</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster.global</span></code>,
<code class="docutils literal notranslate"><span class="pre">.shared::cta.global</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global.shared::cta</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="tensor-access-modes">
<span id="id72"></span><h3>
<span class="section-number">5.5.2. </span><a class="reference internal" href="#tensor-access-modes">Tensor Access Modes</a><a class="headerlink" href="#tensor-access-modes" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Tensor data can be accessed in two modes:</p>
<ul>
<li>
<p>Tiled mode:</p>
<p>In tiled mode, the source multi-dimensional tensor layout is preserved at the destination.</p>
</li>
<li>
<p>Im2col mode:</p>
<p>In im2col mode, the elements in the Bounding Box of the source tensor are rearranged into columns
at the destination. Refer <a class="reference external" href="https://in.mathworks.com/help/images/ref/im2col.html">here</a> for more details.</p>
</li>
</ul>
</section>
<section id="tensor-tiled-mode">
<span id="id73"></span><h3>
<span class="section-number">5.5.3. </span><a class="reference internal" href="#tensor-tiled-mode">Tiled Mode</a><a class="headerlink" href="#tensor-tiled-mode" title="Permalink to this headline">ïƒ</a>
</h3>
<p>This section talks about how Tensor and Tensor access work in tiled mode.</p>
<section id="tensor-tiled-mode-bounding-box">
<span id="id74"></span><h4>
<span class="section-number">5.5.3.1. </span><a class="reference internal" href="#tensor-tiled-mode-bounding-box">Bounding Box</a><a class="headerlink" href="#tensor-tiled-mode-bounding-box" title="Permalink to this headline">ïƒ</a>
</h4>
<p>A tensor can be accessed in chunks known as <em>Bounding Box</em>. The Bounding Box has the same
dimensionality as the tensor they are accessing into. Size of each bounding Box must be a multiple
of 16 bytes. The address of the bounding Box must also be aligned to 16 bytes.</p>
<p>Bounding Box has the following access properties:</p>
<ul class="simple">
<li><p>Bounding Box dimension sizes</p></li>
<li><p>Out of boundary access mode</p></li>
<li><p>Traversal strides</p></li>
</ul>
<p>The tensor-coordinates, specified in the PTX tensor instructions, specify the starting offset of the
bounding box. Starting offset of the bounding box along with the rest of the bounding box
information together are used to determine the elements which are to be accessed.</p>
</section>
<section id="tensor-tiled-mode-traversal-stride">
<span id="id75"></span><h4>
<span class="section-number">5.5.3.2. </span><a class="reference internal" href="#tensor-tiled-mode-traversal-stride">Traversal-Stride</a><a class="headerlink" href="#tensor-tiled-mode-traversal-stride" title="Permalink to this headline">ïƒ</a>
</h4>
<p>While the Bounding Box is iterating the tensor across a dimension, the traversal stride specifies
the exact number of elements to be skipped. If no jump over is required, default value of 1 must be
specified.</p>
<p>The traversal stride in dimension 0 can be used for the <a class="reference internal" href="#tensor-interleaved-layout"><span class="std std-ref">Interleave layout</span></a>.
For non-interleaved layout, the traversal stride in
dimension 0 must always be 1.</p>
<p><a class="reference internal" href="#tensor-tiled-mode-bb-example"><span class="std std-numref">Figure 8</span></a> illustrates tensor, tensor size, tensor stride,
Bounding Box size and traversal stride.</p>
<figure class="align-center" id="tensor-tiled-mode-bb-example">
<img alt="_images/tensor-tiled-mode-bounding-box-example.png" class="image" src="_images/tensor-tiled-mode-bounding-box-example.png">
<figcaption>
<p><span class="caption-number">Figure 8 </span><span class="caption-text">Tiled mode bounding box, tensor size and traversal stride</span><a class="headerlink" href="#tensor-tiled-mode-bb-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-tiled-mode-oob-access">
<span id="id76"></span><h4>
<span class="section-number">5.5.3.3. </span><a class="reference internal" href="#tensor-tiled-mode-oob-access">Out of Boundary Access</a><a class="headerlink" href="#tensor-tiled-mode-oob-access" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX Tensor operation can detect and handle the case when the Bounding Box crosses the tensor
boundary in any dimension. There are 2 modes:</p>
<ul>
<li>
<p>Zero fill mode:</p>
<p>Elements in the Bounding Box which fall outside of the tensor boundary are set to 0.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">OOB-NaN</span></code> fill mode:</p>
<p>Elements in the Bounding Box which fall outside of the tensor boundary are set to a special NaN
called <code class="docutils literal notranslate"><span class="pre">OOB-NaN</span></code>.</p>
</li>
</ul>
<p><a class="reference internal" href="#tensor-oob-access"><span class="std std-numref">Figure 9</span></a> shows an example of the out of boundary access.</p>
<figure class="align-center" id="tensor-oob-access">
<img alt="_images/tensor-oob-access.png" class="image" src="_images/tensor-oob-access.png">
<figcaption>
<p><span class="caption-number">Figure 9 </span><span class="caption-text">Out of boundary access</span><a class="headerlink" href="#tensor-oob-access" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-tiled-scatter4-gather4-modes">
<span id="id77"></span><h4>
<span class="section-number">5.5.3.4. </span><a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes"><code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> modes</a><a class="headerlink" href="#tensor-tiled-scatter4-gather4-modes" title="Permalink to this headline">ïƒ</a>
</h4>
<p>These modes are similar to the tiled mode with restriction that these modes work only on 2D tensor data.
<code class="docutils literal notranslate"><span class="pre">Tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">Tile::gather4</span></code> modes are used to access multiple non-contiguous rows of tensor data.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">Tile::scatter4</span></code> mode single 2D source tensor is divided into four rows in the 2D destination tensor.
In <code class="docutils literal notranslate"><span class="pre">Tile::gather4</span></code> mode four rows in the source 2D tensor are combined to form single 2D destination tensor.</p>
<p>These modes work on four rows and hence the instruction will take:</p>
<ol class="arabic simple">
<li><p>four tensor coordinates across the dimension 0</p></li>
<li><p>one tensor coordinate across the dimension 1</p></li>
</ol>
<p>The interleave layout is not supported for <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> modes.</p>
<p>All other constraints and rules of the tile mode apply to these modes as well.</p>
<section id="tensor-tiled-scatter4-gather4-modes-bounding-box">
<span id="id78"></span><h5>
<span class="section-number">5.5.3.4.1. </span><a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes-bounding-box">Bounding Box</a><a class="headerlink" href="#tensor-tiled-scatter4-gather4-modes-bounding-box" title="Permalink to this headline">ïƒ</a>
</h5>
<p>For <code class="docutils literal notranslate"><span class="pre">Tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">Tile::gather4</span></code> modes, four request coordinates will form four Bounding
Boxes in the tensor space.</p>
<p><a class="reference internal" href="#tiled-scatter4-gather4-bounding-box"><span class="std std-numref">Figure 10</span></a> shows an example of the same with start
coordinates (1, 2), (1, 5), (1, 0) and (1, 9).</p>
<p>The size of the bounding box in the dimension 0 represents the length of the rows.
The size of the bounding box in the dimension 1 must be one.</p>
<figure class="align-center" id="tiled-scatter4-gather4-bounding-box">
<img alt="_images/tiled-scatter4-gather4-bounding-box.png" class="image" src="_images/tiled-scatter4-gather4-bounding-box.png">
<figcaption>
<p><span class="caption-number">Figure 10 </span><span class="caption-text">tiled::scatter4/tiled::gather4 mode bounding box example</span><a class="headerlink" href="#tiled-scatter4-gather4-bounding-box" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
</section>
<section id="tensor-im2col-mode">
<span id="id79"></span><h3>
<span class="section-number">5.5.4. </span><a class="reference internal" href="#tensor-im2col-mode"><code class="docutils literal notranslate"><span class="pre">im2col</span></code> mode</a><a class="headerlink" href="#tensor-im2col-mode" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Im2col mode supports the following tensor dimensions : 3D, 4D and 5D. In this mode, the tensor data
is treated as a batch of images with the following properties:</p>
<ul class="simple">
<li><p>N : number of images in the batch</p></li>
<li><p>D, H, W : size of a 3D image (depth, height and width)</p></li>
<li><p>C: channels per image element</p></li>
</ul>
<p>The above properties are associated with 3D, 4D and 5D tensors as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 31%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Dimension</p></th>
<th class="head"><p>N/D/H/W/C applicability</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>3D</p></td>
<td><p>NWC</p></td>
</tr>
<tr class="row-odd">
<td><p>4D</p></td>
<td><p>NHWC</p></td>
</tr>
<tr class="row-even">
<td><p>5D</p></td>
<td><p>NDHWC</p></td>
</tr>
</tbody>
</table>
<section id="tensor-im2col-mode-bounding-box">
<span id="id80"></span><h4>
<span class="section-number">5.5.4.1. </span><a class="reference internal" href="#tensor-im2col-mode-bounding-box">Bounding Box</a><a class="headerlink" href="#tensor-im2col-mode-bounding-box" title="Permalink to this headline">ïƒ</a>
</h4>
<p>In im2col mode, the Bounding Box is defined in DHW space. Boundaries along other dimensions are
specified by Pixels-per-Column and Channels-per-Pixel parameters as described below.</p>
<p>The dimensionality of the Bounding Box is two less than the tensor dimensionality.</p>
<p>The following properties describe how to access of the elements in im2col mode:</p>
<ul class="simple">
<li><p>Bounding-Box Lower-Corner</p></li>
<li><p>Bounding-Box Upper-Corner</p></li>
<li><p>Pixels-per-Column</p></li>
<li><p>Channels-per-Pixel</p></li>
</ul>
<p><em>Bounding-box Lower-Corner</em> and <em>Bounding-box Upper-Corner</em> specify the two opposite corners of the
Bounding Box in the DHW space. <em>Bounding-box Lower-Corner</em> specifies the corner with the smallest
coordinate and <em>Bounding-box Upper-Corner</em> specifies the corner with the largest coordinate.</p>
<p><em>Bounding-box Upper-</em> and <em>Lower-Corners</em> are 16-bit signed values whose limits varies across the
dimensions and are as shown below:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 24%">
<col style="width: 26%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"></th>
<th class="head"><p>3D</p></th>
<th class="head"><p>4D</p></th>
<th class="head"><p>5D</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Upper- / Lower- Corner sizes</p></td>
<td><p>[-2<sup>15</sup>, 2<sup>15</sup>-1]</p></td>
<td><p>[-2<sup>7</sup>, 2<sup>7</sup>-1]</p></td>
<td><p>[-2<sup>4</sup>, 2<sup>4</sup>-1]</p></td>
</tr>
</tbody>
</table>
<p><a class="reference internal" href="#im2col-mode-bounding-box1"><span class="std std-numref">Figure 11</span></a> and <a class="reference internal" href="#im2col-mode-bounding-box2"><span class="std std-numref">Figure 12</span></a> show the Upper-Corners and Lower-Corners.</p>
<figure class="align-center" id="im2col-mode-bounding-box1">
<img alt="_images/tensor-im2col-mode-bounding-box1.png" class="image" src="_images/tensor-im2col-mode-bounding-box1.png">
<figcaption>
<p><span class="caption-number">Figure 11 </span><span class="caption-text">im2col mode bounding box example 1</span><a class="headerlink" href="#im2col-mode-bounding-box1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="im2col-mode-bounding-box2">
<img alt="_images/tensor-im2col-mode-bounding-box2.png" class="image" src="_images/tensor-im2col-mode-bounding-box2.png">
<figcaption>
<p><span class="caption-number">Figure 12 </span><span class="caption-text">im2col mode bounding box example 2</span><a class="headerlink" href="#im2col-mode-bounding-box2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The <em>Bounding-box Upper-</em> and <em>Lower- Corners</em> specify only the boundaries and not the number of
elements to be accessed. <em>Pixels-per-Column</em> specifies the number of elements to be accessed in the
NDHW space.</p>
<p><em>Channels-per-Pixel</em> specifies the number of elements to access across the C dimension.</p>
<p>The tensor coordinates, specified in the PTX tensor instructions, behaves differently in different
dimensions:</p>
<ul class="simple">
<li><p>Across N and C dimensions: specify the starting offsets along the dimension, similar to the tiled
mode.</p></li>
<li><p>Across DHW dimensions: specify the location of the convolution filter base in the tensor
space. The filter corner location must be within the bounding box.</p></li>
</ul>
<p>The im2col offsets, specified in the PTX tensor instructions in im2col mode, are added to the filter
base coordinates to determine the starting location in the tensor space from where the elements are
accessed.</p>
<p>The size of the im2col offsets varies across the dimensions and their valid ranges are as shown
below:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 27%">
<col style="width: 25%">
<col style="width: 24%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"></th>
<th class="head"><p>3D</p></th>
<th class="head"><p>4D</p></th>
<th class="head"><p>5D</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>im2col offsets range</p></td>
<td><p>[0, 2<sup>16</sup>-1]</p></td>
<td><p>[0, 2<sup>8</sup>-1]</p></td>
<td><p>[0, 2<sup>5</sup>-1]</p></td>
</tr>
</tbody>
</table>
<p>Following are some examples of the im2col mode accesses:</p>
<ul>
<li>
<p>Example 1 (<a class="reference internal" href="#tensor-im2col-mode-example1"><span class="std std-numref">Figure 13</span></a>):</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">14</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">Pixels</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">Column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">channels</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">pixel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Lower</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Lower</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Upper</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-1</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Upper</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">-1.</span><span class="w"></span>

<span class="n">tensor</span><span class="w"> </span><span class="n">coordinates</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="n">im2col</span><span class="w"> </span><span class="n">offsets</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<figure class="align-center" id="tensor-im2col-mode-example1">
<img alt="_images/tensor-im2col-mode-example1.png" class="image" src="_images/tensor-im2col-mode-example1.png">
<figcaption>
<p><span class="caption-number">Figure 13 </span><span class="caption-text">im2col mode example 1</span><a class="headerlink" href="#tensor-im2col-mode-example1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Example 2 (<a class="reference internal" href="#tensor-im2col-mode-example2"><span class="std std-numref">Figure 14</span></a>):</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">9</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">14</span><span class="w"></span>
<span class="n">Tensor</span><span class="w"> </span><span class="n">Size</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">Pixels</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">Column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="n">channels</span><span class="o">-</span><span class="n">per</span><span class="o">-</span><span class="n">pixel</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Lower</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Lower</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Upper</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">W</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-2</span><span class="w"></span>
<span class="n">Bounding</span><span class="o">-</span><span class="n">Box</span><span class="w"> </span><span class="n">Upper</span><span class="o">-</span><span class="n">Corner</span><span class="w"> </span><span class="n">H</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">-2</span><span class="w"></span>

<span class="n">tensor</span><span class="w"> </span><span class="n">coordinates</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"></span>
<span class="n">im2col</span><span class="w"> </span><span class="n">offsets</span><span class="o">:</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<figure class="align-center" id="tensor-im2col-mode-example2">
<img alt="_images/tensor-im2col-mode-example2.png" class="image" src="_images/tensor-im2col-mode-example2.png">
<figcaption>
<p><span class="caption-number">Figure 14 </span><span class="caption-text">im2col mode example 2</span><a class="headerlink" href="#tensor-im2col-mode-example2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</section>
<section id="tensor-im2col-mode-traversal-stride">
<span id="id81"></span><h4>
<span class="section-number">5.5.4.2. </span><a class="reference internal" href="#tensor-im2col-mode-traversal-stride">Traversal Stride</a><a class="headerlink" href="#tensor-im2col-mode-traversal-stride" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The traversal stride, in im2col mode, does not impact the total number of elements (or pixels) being
accessed unlike the tiled mode. Pixels-per-Column determines the total number of elements being
accessed, in im2col mode.</p>
<p>The number of elements traversed along the D, H and W dimensions is strided by the traversal stride
for that dimension.</p>
<p>The following example with <a class="reference internal" href="#tensor-im2col-mode-example3"><span class="std std-numref">Figure 15</span></a> illustrates accesse with traversal-strides:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Tensor Size[0] = 64
Tensor Size[1] = 8
Tensor Size[2] = 14
Tensor Size[3] = 64
Traversal Stride = 2
Pixels-per-Column = 32
channels-per-pixel = 16
Bounding-Box Lower-Corner W = -1
Bounding-Box Lower-Corner H = -1
Bounding-Box Upper-Corner W = -1
Bounding-Box Upper-Corner H = -1.
Tensor coordinates in the instruction = (7, 7, 5, 0)
Im2col offsets in the instruction : (1, 1)
</pre></div>
</div>
<figure class="align-center" id="tensor-im2col-mode-example3">
<img alt="_images/tensor-im2col-mode-example3.png" class="image" src="_images/tensor-im2col-mode-example3.png">
<figcaption>
<p><span class="caption-number">Figure 15 </span><span class="caption-text">im2col mode traversal stride example</span><a class="headerlink" href="#tensor-im2col-mode-example3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-im2col-mode-oob-access">
<span id="id82"></span><h4>
<span class="section-number">5.5.4.3. </span><a class="reference internal" href="#tensor-im2col-mode-oob-access">Out of Boundary Access</a><a class="headerlink" href="#tensor-im2col-mode-oob-access" title="Permalink to this headline">ïƒ</a>
</h4>
<p>In im2col mode, when the number of requested pixels in NDHW space specified by <em>Pixels-per-Column</em>
exceeds the number of available pixels in the image batch then out-of-bounds access is performed.</p>
<p>Similar to tiled mode, zero fill or <code class="docutils literal notranslate"><span class="pre">OOB-NaN</span></code> fill can be performed based on the Fill-Mode
specified.</p>
</section>
</section>
<section id="tensor-im2col-w-w128-modes">
<span id="id83"></span><h3>
<span class="section-number">5.5.5. </span><a class="reference internal" href="#tensor-im2col-w-w128-modes"><code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> modes</a><a class="headerlink" href="#tensor-im2col-w-w128-modes" title="Permalink to this headline">ïƒ</a>
</h3>
<p>These modes are similar to the im2col mode with the restriction that elements are accessed across
the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension only while keeping the <code class="docutils literal notranslate"><span class="pre">H</span></code> and <code class="docutils literal notranslate"><span class="pre">D</span></code> dimension constant.</p>
<p>All the constraints and rules of the im2col mode apply to these modes as well.</p>
<p>The number of elements accessed in the <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> mode is fixed and is equal to 128.
The number of elements accessed in the <code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> mode depends on the field Pixels-per-Column
field in the TensorMap.</p>
<section id="tensor-im2col-w-w128-modes-bounding-box">
<span id="id84"></span><h4>
<span class="section-number">5.5.5.1. </span><a class="reference internal" href="#tensor-im2col-w-w128-modes-bounding-box">Bounding Box</a><a class="headerlink" href="#tensor-im2col-w-w128-modes-bounding-box" title="Permalink to this headline">ïƒ</a>
</h4>
<p>In these modes, the size of the bounding box in <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">H</span></code> dimensions are 1.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">H</span></code> dimensions in the tensor coordinates argument in the PTX instruction specify
the position of the bounding box in the tensor space.</p>
<p>The Bounding-Box <code class="docutils literal notranslate"><span class="pre">Lower-Corner-W</span></code> and Bounding-Box <code class="docutils literal notranslate"><span class="pre">Upper-Corner-W</span></code> specify the two opposite
corners of the Bounding Box in the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension in the tensor coordinates argument in the PTX instruction specify the location
of the first element that is to be accessed in the bounding box.</p>
<p>Number of pixels loaded in <code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> mode is as specified by Pixels-per-Column in the TensorMap.
Number of pixels loaded in <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> mode is always 128. So, Pixels-per-Column is ignored
in <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> mode.</p>
<p><a class="reference internal" href="#tensor-im2col-w-w128-modes-example"><span class="std std-numref">Figure 16</span></a> shows an example of the <code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> and
<code class="docutils literal notranslate"><span class="pre">im2col::w:128</span></code> modes.</p>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example">
<img alt="_images/tensor-im2col-w-w128-modes-example.png" class="image" src="_images/tensor-im2col-w-w128-modes-example.png">
<figcaption>
<p><span class="caption-number">Figure 16 </span><span class="caption-text">im2col::w and im2col::w::128 modes example</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The first element can lie outside of the Bounding Box in the W-dimension only and only on the left
side of the Bounding Box. <a class="reference internal" href="#tensor-im2col-w-w128-modes-example2"><span class="std std-numref">Figure 17</span></a> shows of an example of this.</p>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example2">
<img alt="_images/tensor-im2col-w-w128-modes-example2.png" class="image" src="_images/tensor-im2col-w-w128-modes-example2.png">
<figcaption>
<p><span class="caption-number">Figure 17 </span><span class="caption-text">im2col::w and im2col::w::128 modes first element outside Bounding Box example</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-im2col-w-w128-modes-traversal-stride">
<span id="id85"></span><h4>
<span class="section-number">5.5.5.2. </span><a class="reference internal" href="#tensor-im2col-w-w128-modes-traversal-stride">Traversal Stride</a><a class="headerlink" href="#tensor-im2col-w-w128-modes-traversal-stride" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This is similar to im2col mode with the exception of that the number of elements traversed
along only the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension is strided by the traversal stride as specified in the TensorMap.</p>
</section>
<section id="tensor-im2col-w-w128-modes-whalo">
<span id="id86"></span><h4>
<span class="section-number">5.5.5.3. </span><a class="reference internal" href="#tensor-im2col-w-w128-modes-whalo"><code class="docutils literal notranslate"><span class="pre">wHalo</span></code></a><a class="headerlink" href="#tensor-im2col-w-w128-modes-whalo" title="Permalink to this headline">ïƒ</a>
</h4>
<p>In <code class="docutils literal notranslate"><span class="pre">im2col::w</span></code> mode, the <code class="docutils literal notranslate"><span class="pre">wHalo</span></code> argument in the PTX instruction specifies how many filter
halo elements must be loaded at the end of the image.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">im2col::w::128</span></code> mode, the halo elements are loaded after every 32 elements in the bounding
box along the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension. The <code class="docutils literal notranslate"><span class="pre">wHalo</span></code> argument in the PTX instruction specifies how many
halo elements must be loaded after every 32 elements.</p>
<p>Following is an example of <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> mode access:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Tensor Size [0] = 128
Tensor Size [1] = 9
Tensor Size [2] = 7
Tensor Size [3] = 64
Pixels-per-column = 128
Channels-per-pixel = 64
Bounding Box Lower Corner W = 0
Bounding Box Upper Corner W = 0

Tensor Coordinates in the instruction = (7, 2, 3, 0)
wHalo in the instruction = 2 (as 3x3 convolution filter is used)
</pre></div>
</div>
<p>A tensor copy operation with the above parameters loads 128 pixels and the two halo pixels as shown in
<a class="reference internal" href="#tensor-im2col-w-w128-modes-example3"><span class="std std-numref">Figure 18</span></a>.</p>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example3">
<img alt="_images/tensor-im2col-w-w128-modes-example3.png" class="image" src="_images/tensor-im2col-w-w128-modes-example3.png">
<figcaption>
<p><span class="caption-number">Figure 18 </span><span class="caption-text">tensor copy operation with im2col::w mode example</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The halo pixels are always loaded in the shared memory next to the main row pixels as shown in
<a class="reference internal" href="#tensor-im2col-w-w128-modes-example3"><span class="std std-numref">Figure 18</span></a>.</p>
<p>Following is an example of <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> mode access:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Tensor Size [0] = 128
Tensor Size [1] = 9
Tensor Size [2] = 7
Tensor Size [3] = 64
Channels-per-pixel = 64
Bounding Box Lower Corner W = 0
Bounding Box Upper Corner W = 0

Tensor Coordinates in the instruction = (7, 2, 3, 0)
wHalo in the instruction = 2 (as 3x3 convolution filter is used)
</pre></div>
</div>
<p>A tensor copy operation with the above parameters loads 128 elements such that after every 32 elements,
wHalo number of elements are loaded as shown in <a class="reference internal" href="#tensor-im2col-w-w128-modes-example4"><span class="std std-numref">Figure 19</span></a>.</p>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example4">
<img alt="_images/tensor-im2col-w-w128-modes-example4.png" class="image" src="_images/tensor-im2col-w-w128-modes-example4.png">
<figcaption>
<p><span class="caption-number">Figure 19 </span><span class="caption-text">tensor copy operation with im2col::w::128 mode example</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-im2col-w-w128-modes-woffset">
<span id="id87"></span><h4>
<span class="section-number">5.5.5.4. </span><a class="reference internal" href="#tensor-im2col-w-w128-modes-woffset"><code class="docutils literal notranslate"><span class="pre">wOffset</span></code></a><a class="headerlink" href="#tensor-im2col-w-w128-modes-woffset" title="Permalink to this headline">ïƒ</a>
</h4>
<p>In the convolution calculations, the same elements along the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension are reused for different
locations within the convolution filter footprint. Based on the number of times a pixel is used, the
pixels may be loaded into different shared memory buffers. Each buffer can be loaded by a separate
tensor copy operation.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">wOffset</span></code> argument in the tensor copy and prefetch instruction adjusts the source pixel location
for each buffer. The exact position of the buffer is adjusted along the <code class="docutils literal notranslate"><span class="pre">W</span></code> dimension using the
following formula:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Bounding Box Lower Corner W += wOffset
Bounding Box Upper Corner W += wOffset
W += wOffset
</pre></div>
</div>
<p>Following are examples of tensor copy to multiple buffers with various <code class="docutils literal notranslate"><span class="pre">wHalo</span></code> and <code class="docutils literal notranslate"><span class="pre">wOffset</span></code> values:</p>
<p>Example 1:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Tensor Size [0] = 128
Tensor Size [1] = 9
Tensor Size [2] = 67
Tensor Size [3] = 64
Pixels-per-Column = 128
Channels-per-pixel = 64
Bounding Box Lower Corner W = -1
Bounding Box Upper Corner W = 0
Traversal Stride = 2

Tensor Coordinates in the instruction = (7, 2, -1, 0)

Shared memory buffer 1:
   wHalo = 1
   wOffset = 0

Shared memory buffer 2:
   wHalo = 0
   wOffset = 1
</pre></div>
</div>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example5">
<img alt="_images/tensor-im2col-w-w128-modes-example5.png" class="image" src="_images/tensor-im2col-w-w128-modes-example5.png">
<figcaption>
<p><span class="caption-number">Figure 20 </span><span class="caption-text">tensor copy operation to buffer 1 of Example 1</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example5" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example6">
<img alt="_images/tensor-im2col-w-w128-modes-example6.png" class="image" src="_images/tensor-im2col-w-w128-modes-example6.png">
<figcaption>
<p><span class="caption-number">Figure 21 </span><span class="caption-text">tensor copy operation to buffer 2 of Example 1</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example6" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Example 2:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Tensor Size [0] = 128
Tensor Size [1] = 7
Tensor Size [2] = 7
Tensor Size [3] = 64
Pixels-per-Column = 128
Channels-per-pixel = 64
Bounding Box Lower Corner W = -1
Bounding Box Upper Corner W = -1
Traversal Stride = 3

Tensor Coordinates in the instruction = (7, 2, -1, 0)

Shared memory buffer 1:
   wHalo = 0
   wOffset = 0

Shared memory buffer 2:
   wHalo = 0
   wOffset = 1

Shared memory buffer 3:
   wHalo = 0
   wOffset = 2
</pre></div>
</div>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example7">
<img alt="_images/tensor-im2col-w-w128-modes-example7.png" class="image" src="_images/tensor-im2col-w-w128-modes-example7.png">
<figcaption>
<p><span class="caption-number">Figure 22 </span><span class="caption-text">tensor copy operation to buffer 1 of Example 2</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example7" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example8">
<img alt="_images/tensor-im2col-w-w128-modes-example8.png" class="image" src="_images/tensor-im2col-w-w128-modes-example8.png">
<figcaption>
<p><span class="caption-number">Figure 23 </span><span class="caption-text">tensor copy operation to buffer 2 of Example 2</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tensor-im2col-w-w128-modes-example9">
<img alt="_images/tensor-im2col-w-w128-modes-example9.png" class="image" src="_images/tensor-im2col-w-w128-modes-example9.png">
<figcaption>
<p><span class="caption-number">Figure 24 </span><span class="caption-text">tensor copy operation to buffer 3 of Example 2</span><a class="headerlink" href="#tensor-im2col-w-w128-modes-example9" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="tensor-interleaved-layout">
<span id="id88"></span><h3>
<span class="section-number">5.5.6. </span><a class="reference internal" href="#tensor-interleaved-layout">Interleave layout</a><a class="headerlink" href="#tensor-interleaved-layout" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Tensor can be interleaved and the following interleave layouts are supported:</p>
<ul class="simple">
<li><p>No interleave (NDHWC)</p></li>
<li><p>8 byte interleave (NC/8DHWC8) : C8 utilizes 16 bytes in memory assuming 2B per channel.</p></li>
<li><p>16 byte interleave (NC/16HWC16) : C16 utilizes 32 bytes in memory assuming 4B per channel.</p></li>
</ul>
<p>The <em>C</em> information is organized in slices where sequential C elements are grouped in 16 byte or 32
byte quantities.</p>
<p>If the total number of channels is not a multiple of the number of channels per slice, then the last
slice must be padded with zeros to make it complete 16B or 32B slice.</p>
<p>Interleaved layouts are supported only for the dimensionalities : 3D, 4D and 5D.</p>
<p>The interleave layout is not supported for <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> modes.</p>
</section>
<section id="tensor-swizzling-modes">
<span id="id89"></span><h3>
<span class="section-number">5.5.7. </span><a class="reference internal" href="#tensor-swizzling-modes">Swizzling Modes</a><a class="headerlink" href="#tensor-swizzling-modes" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The layout of the data in the shared memory can be different to that of global memory, for access
performance reasons. The following describes various swizzling modes:</p>
<ul>
<li>
<p>No swizzle mode:</p>
<p>There is no swizzling in this mode and the destination data layout is exactly similar to the
source data layout.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-even">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-odd">
<td colspan="8"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>32 byte swizzle mode:</p>
<p>The following table, where each elements (numbered cell) is 16 byte and the starting address is
256 bytes aligned, shows the pattern of the destination data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
</tr>
<tr class="row-odd">
<td colspan="8"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>An example of the 32 byte swizzle mode for NC/(32B)HWC(32B) tensor of 1x2x10x10xC16 dimension,
with the innermost dimension holding slice of 16 channels with 2 byte/channel, is shown in
<a class="reference internal" href="#tensor-32b-swizzle"><span class="std std-numref">Figure 25</span></a>.</p>
<figure class="align-center" id="tensor-32b-swizzle">
<img alt="_images/tensor-32B-swizzle.png" class="image" src="_images/tensor-32B-swizzle.png">
<figcaption>
<p><span class="caption-number">Figure 25 </span><span class="caption-text">32-byte swizzle mode example</span><a class="headerlink" href="#tensor-32b-swizzle" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#tensor-32b-swizzle-frag"><span class="std std-numref">Figure 26</span></a> shows the two fragments of the tensor : one for C/(32B) = 0 and another for C/(32B) = 1.</p>
<figure class="align-center" id="tensor-32b-swizzle-frag">
<img alt="_images/tensor-32B-swizzle-frag.png" class="image" src="_images/tensor-32B-swizzle-frag.png">
<figcaption>
<p><span class="caption-number">Figure 26 </span><span class="caption-text">32-byte swizzle mode fragments</span><a class="headerlink" href="#tensor-32b-swizzle-frag" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#tensor-32b-swizzle-dst"><span class="std std-numref">Figure 27</span></a> shows the destination data layout with 32 byte swizzling.</p>
<figure class="align-center" id="tensor-32b-swizzle-dst">
<img alt="_images/tensor-32B-swizzle-dst.png" class="image" src="_images/tensor-32B-swizzle-dst.png">
<figcaption>
<p><span class="caption-number">Figure 27 </span><span class="caption-text">32-byte swizzle mode destination data layout</span><a class="headerlink" href="#tensor-32b-swizzle-dst" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>64 byte swizzle mode:</p>
<p>The following table, where each elements (numbered cell) is 16 byte and the starting address is
512 bytes aligned, shows the pattern of the destination data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
</tr>
<tr class="row-odd">
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even">
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td colspan="8"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>An example of the 64 byte swizzle mode for NHWC tensor of 1x10x10x64 dimension, with 2 bytes /
channel and 32 channels, is shown in <a class="reference internal" href="#tensor-64b-swizzle"><span class="std std-numref">Figure 28</span></a>.</p>
<figure class="align-center" id="tensor-64b-swizzle">
<img alt="_images/tensor-64B-swizzle.png" class="image" src="_images/tensor-64B-swizzle.png">
<figcaption>
<p><span class="caption-number">Figure 28 </span><span class="caption-text">64-byte swizzle mode example</span><a class="headerlink" href="#tensor-64b-swizzle" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Each colored cell represents 8 channels. <a class="reference internal" href="#tensor-64b-swizzle-src"><span class="std std-numref">Figure 29</span></a> shows the source data layout.</p>
<figure class="align-center" id="tensor-64b-swizzle-src">
<img alt="_images/tensor-64B-swizzle-src.png" class="image" src="_images/tensor-64B-swizzle-src.png">
<figcaption>
<p><span class="caption-number">Figure 29 </span><span class="caption-text">64-byte swizzle mode source data layout</span><a class="headerlink" href="#tensor-64b-swizzle-src" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#tensor-64b-swizzle-dst"><span class="std std-numref">Figure 30</span></a> shows the destination data layout with 64 byte swizzling.</p>
<figure class="align-center" id="tensor-64b-swizzle-dst">
<img alt="_images/tensor-64B-swizzle-dst.png" class="image" src="_images/tensor-64B-swizzle-dst.png">
<figcaption>
<p><span class="caption-number">Figure 30 </span><span class="caption-text">64-byte swizzle mode destination data layout</span><a class="headerlink" href="#tensor-64b-swizzle-dst" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>96 byte swizzle mode:</p>
<p>The following table where each element (numbered cell) is 16 byte shows the swizzling pattern at the destination
data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
</tr>
<tr class="row-odd">
<td colspan="8"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>An example of the data layout in global memory and its swizzled data layout in shared memory where each element
(colored cell) is 16 bytes and the starting address is 256 bytes aligned is shown in <a class="reference internal" href="#tensor-96b-swizzle"><span class="std std-numref">Figure 31</span></a>.</p>
<figure class="align-center" id="tensor-96b-swizzle">
<img alt="_images/tensor-96B-swizzle.png" class="image" src="_images/tensor-96B-swizzle.png">
<figcaption>
<p><span class="caption-number">Figure 31 </span><span class="caption-text">96-byte swizzle mode example</span><a class="headerlink" href="#tensor-96b-swizzle" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>128 byte swizzle mode:</p>
<p>The 128-byte swizzling mode supports the following sub-modes:</p>
<ul>
<li>
<p>16-byte atomicity sub-mode:</p>
<p>In this sub-mode, the 16-byte of data is kept intact while swizzling.</p>
</li>
</ul>
<p>The following table, where each elements (numbered cell) is 16 byte and the starting address is
1024 bytes aligned, shows the pattern of the destination data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
</tr>
<tr class="row-odd">
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
</tr>
<tr class="row-even">
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even">
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>7</p></td>
<td><p>6</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>4</p></td>
<td><p>5</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td><p>7</p></td>
<td><p>6</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td colspan="8"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>An example of the 128 byte swizzle mode for NHWC tensor of 1x10x10x64 dimension, with 2 bytes /
channel and 64 channels, is shown in <a class="reference internal" href="#tensor-128b-swizzle"><span class="std std-numref">Figure 32</span></a>.</p>
<figure class="align-center" id="tensor-128b-swizzle">
<img alt="_images/tensor-128B-swizzle.png" class="image" src="_images/tensor-128B-swizzle.png">
<figcaption>
<p><span class="caption-number">Figure 32 </span><span class="caption-text">128-byte swizzle mode example</span><a class="headerlink" href="#tensor-128b-swizzle" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Each colored cell represents 8 channels. <a class="reference internal" href="#tensor-128b-swizzle-src"><span class="std std-numref">Figure 33</span></a> shows the source data layout.</p>
<figure class="align-center" id="tensor-128b-swizzle-src">
<img alt="_images/tensor-128B-swizzle-src.png" class="image" src="_images/tensor-128B-swizzle-src.png">
<figcaption>
<p><span class="caption-number">Figure 33 </span><span class="caption-text">128-byte swizzle mode source data layout</span><a class="headerlink" href="#tensor-128b-swizzle-src" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#tensor-128b-swizzle-dst"><span class="std std-numref">Figure 34</span></a> shows the destination data layout with 128 byte swizzling.</p>
<figure class="align-center" id="tensor-128b-swizzle-dst">
<img alt="_images/tensor-128B-swizzle-dst.png" class="image" src="_images/tensor-128B-swizzle-dst.png">
<figcaption>
<p><span class="caption-number">Figure 34 </span><span class="caption-text">128-byte swizzle mode destination data layout</span><a class="headerlink" href="#tensor-128b-swizzle-dst" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<ul>
<li>
<p>32-byte atomicity sub-mode:</p>
<p>In this sub-mode, the 32-byte of data is kept intact while swizzling.</p>
<p>The following table where each element (numbered cell) is 16 byte shows the
swizzling pattern at the destination data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0   1</p></td>
<td><p>2   3</p></td>
<td><p>4   5</p></td>
<td><p>6   7</p></td>
</tr>
<tr class="row-even">
<td><p>2   3</p></td>
<td><p>0   1</p></td>
<td><p>6   7</p></td>
<td><p>4   5</p></td>
</tr>
<tr class="row-odd">
<td><p>4   5</p></td>
<td><p>6   7</p></td>
<td><p>0   1</p></td>
<td><p>2   3</p></td>
</tr>
<tr class="row-even">
<td><p>6   7</p></td>
<td><p>4   5</p></td>
<td><p>2   3</p></td>
<td><p>0   1</p></td>
</tr>
<tr class="row-odd">
<td colspan="4"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>This sub-mode requires 32 byte alignment at shared memory.</p>
<p>An example of the data layout in global memory and its swizzled data layout in shared memory
where each element (colored cell) is 16 bytes is shown in <a class="reference internal" href="#tensor-128b-swizzle-32b-atom"><span class="std std-numref">Figure 35</span></a></p>
<figure class="align-center" id="tensor-128b-swizzle-32b-atom">
<img alt="_images/tensor-128B-swizzle-32B-atom.png" class="image" src="_images/tensor-128B-swizzle-32B-atom.png">
<figcaption>
<p><span class="caption-number">Figure 35 </span><span class="caption-text">128-byte swizzle mode example with 32-byte atomicity</span><a class="headerlink" href="#tensor-128b-swizzle-32b-atom" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>32-byte atomicity with 8-byte flip sub-mode:</p>
<p>The swizzling pattern for this sub-mode is similar to the 32-byte atomicity sub-mode except that
there is a flip of adjacent 8-bytes within the 16-byte data at every alternate shared memory line.</p>
<p>An example of the data layout in global memory and its swizzled data layout in shared memory where
each element (colored cell) is 16 bytes (two 8-byte sub-elements for each 16-byte colored cell are
shown to show the flip) is shown in <a class="reference internal" href="#tensor-128b-swizzle-32b-atom-8b-flip"><span class="std std-numref">Figure 36</span></a></p>
<figure class="align-center" id="tensor-128b-swizzle-32b-atom-8b-flip">
<img alt="_images/tensor-128B-swizzle-32B-atom-8B-flip.png" class="image" src="_images/tensor-128B-swizzle-32B-atom-8B-flip.png">
<figcaption>
<p><span class="caption-number">Figure 36 </span><span class="caption-text">128-byte swizzle mode example with 32-byte atomicity with 8-byte flip</span><a class="headerlink" href="#tensor-128b-swizzle-32b-atom-8b-flip" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>64-byte atomicity sub-mode:</p>
<p>In this sub-mode, the 64-byte of data is kept intact while swizzling.</p>
<p>The following table where each element (numbered cell) is 16 byte shows the swizzling
pattern at the destination data layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>0   1   2   3</p></td>
<td><p>4   5   6   7</p></td>
</tr>
<tr class="row-even">
<td><p>4   5   6   7</p></td>
<td><p>0   1   2   3</p></td>
</tr>
<tr class="row-odd">
<td colspan="2"><p>â€¦ Pattern repeats â€¦</p></td>
</tr>
</tbody>
</table>
<p>This sub-mode requires 64-byte alignment at shared memory.</p>
<p>An example of the data layout in global memory and its swizzled data layout
in shared memory where each element (colored cell) is 16 bytes is shown
in <a class="reference internal" href="#tensor-128b-swizzle-64b-atom"><span class="std std-numref">Figure 37</span></a></p>
<figure class="align-center" id="tensor-128b-swizzle-64b-atom">
<img alt="_images/tensor-128B-swizzle-64B-atom.png" class="image" src="_images/tensor-128B-swizzle-64B-atom.png">
<figcaption>
<p><span class="caption-number">Figure 37 </span><span class="caption-text">128-byte swizzle mode example with 64-byte atomicity</span><a class="headerlink" href="#tensor-128b-swizzle-64b-atom" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</li>
</ul>
<p><a class="reference internal" href="#valid-combination-of-swizzle-atomicity-with-swizzling-mode"><span class="std std-numref">Table 14</span></a>
lists the valid combination of swizzle-atomicity with the swizzling-mode.</p>
<table class="table-no-stripes docutils align-default" id="valid-combination-of-swizzle-atomicity-with-swizzling-mode">
<caption>
<span class="caption-number">Table 14 </span><span class="caption-text">Valid combination of swizzle-atomicity with swizzling-mode</span><a class="headerlink" href="#valid-combination-of-swizzle-atomicity-with-swizzling-mode" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 46%">
<col style="width: 54%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling Mode</p></th>
<th class="head"><p>Swizzle-Atomicity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>No Swizzling</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p>32B Swizzling Mode</p></td>
<td><p>16B</p></td>
</tr>
<tr class="row-even">
<td><p>64B Swizzling Mode</p></td>
<td><p>16B</p></td>
</tr>
<tr class="row-odd">
<td><p>96B Swizzling Mode</p></td>
<td><p>16B</p></td>
</tr>
<tr class="row-even">
<td><p>128B Swizzling Mode</p></td>
<td>
<ul class="simple">
<li><p>16B</p></li>
<li><p>32B</p></li>
<li><p>32B + 8B-flip</p></li>
<li><p>64B</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>The value of swizzle base offset is 0 when the <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> shared memory address is located
at the following boundary:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 31%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling Mode</p></th>
<th class="head"><p>Starting address of the repeating pattern</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>128-Byte swizzle</p></td>
<td><p>1024-Byte boundary</p></td>
</tr>
<tr class="row-odd">
<td><p>96-Byte swizzle</p></td>
<td><p>256-Byte boundary</p></td>
</tr>
<tr class="row-even">
<td><p>64-Byte swizzle</p></td>
<td><p>512-Byte boundary</p></td>
</tr>
<tr class="row-odd">
<td><p>32-Byte swizzle</p></td>
<td><p>256-Byte boundary</p></td>
</tr>
</tbody>
</table>
<p>Otherwise, the swizzle base offset is a non-zero value, computed using following formula:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 36%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling Mode</p></th>
<th class="head"><p>Formula</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>128-Byte swizzle</p></td>
<td><p>base offset = (dstMem / 128) % 8</p></td>
</tr>
<tr class="row-odd">
<td><p>96-Byte swizzle</p></td>
<td><p>base offset = (dstMem / 128) % 2</p></td>
</tr>
<tr class="row-even">
<td><p>64-Byte swizzle</p></td>
<td><p>base offset = (dstMem / 128) % 4</p></td>
</tr>
<tr class="row-odd">
<td><p>32-Byte swizzle</p></td>
<td><p>base offset = (dstMem / 128) % 2</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tensor-tensormap">
<span id="id90"></span><h3>
<span class="section-number">5.5.8. </span><a class="reference internal" href="#tensor-tensormap">Tensor-map</a><a class="headerlink" href="#tensor-tensormap" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The tensor-map is a 128-byte opaque object either in <code class="docutils literal notranslate"><span class="pre">.const</span></code> space or <code class="docutils literal notranslate"><span class="pre">.param</span></code> (kernel function
parameter) space or <code class="docutils literal notranslate"><span class="pre">.global</span></code> space which describes the tensor properties and the access properties
of the tensor data described in previous sections.</p>
<p>Tensor-Map can be created using CUDA APIs. Refer to <em>CUDA programming guide</em> for more details.</p>
</section>
</section>
</section>
<section id="instruction-operands">
<span id="id91"></span><h1>
<span class="section-number">6. </span><a class="reference internal" href="#instruction-operands">Instruction Operands</a><a class="headerlink" href="#instruction-operands" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="operand-type-information">
<span id="id92"></span><h2>
<span class="section-number">6.1. </span><a class="reference internal" href="#operand-type-information">Operand Type Information</a><a class="headerlink" href="#operand-type-information" title="Permalink to this headline">ïƒ</a>
</h2>
<p>All operands in instructions have a known type from their declarations. Each operand type must be
compatible with the type determined by the instruction template and instruction type. There is no
automatic conversion between types.</p>
<p>The bit-size type is compatible with every type having the same size. Integer types of a common size
are compatible with each other. Operands having type different from but compatible with the
instruction type are silently cast to the instruction type.</p>
</section>
<section id="source-operands">
<span id="id93"></span><h2>
<span class="section-number">6.2. </span><a class="reference internal" href="#source-operands">Source Operands</a><a class="headerlink" href="#source-operands" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The source operands are denoted in the instruction descriptions by the names <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, and
<code class="docutils literal notranslate"><span class="pre">c</span></code>. PTX describes a load-store machine, so operands for ALU instructions must all be in variables
declared in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> register state space. For most operations, the sizes of the operands must
be consistent.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">cvt</span></code> (convert) instruction takes a variety of operand types and sizes, as its job is to
convert from nearly any data type to any other data type (and size).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">mov</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions copy data from one location to
another. Instructions <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> move data from/to addressable state spaces to/from
registers. The <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction copies data between registers.</p>
<p>Most instructions have an optional predicate guard that controls conditional execution, and a few
instructions have additional predicate source operands. Predicate operands are denoted by the names
<code class="docutils literal notranslate"><span class="pre">p</span></code>, <code class="docutils literal notranslate"><span class="pre">q</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>, <code class="docutils literal notranslate"><span class="pre">s</span></code>.</p>
</section>
<section id="destination-operands">
<span id="id94"></span><h2>
<span class="section-number">6.3. </span><a class="reference internal" href="#destination-operands">Destination Operands</a><a class="headerlink" href="#destination-operands" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX instructions that produce a single result store the result in the field denoted by <code class="docutils literal notranslate"><span class="pre">d</span></code> (for
destination) in the instruction descriptions. The result operand is a scalar or vector variable in
the register state space.</p>
</section>
<section id="using-addresses-arrays-and-vectors">
<span id="id95"></span><h2>
<span class="section-number">6.4. </span><a class="reference internal" href="#using-addresses-arrays-and-vectors">Using Addresses, Arrays, and Vectors</a><a class="headerlink" href="#using-addresses-arrays-and-vectors" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Using scalar variables as operands is straightforward. The interesting capabilities begin with
addresses, arrays, and vectors.</p>
<section id="addresses-as-operands">
<span id="id96"></span><h3>
<span class="section-number">6.4.1. </span><a class="reference internal" href="#addresses-as-operands">Addresses as Operands</a><a class="headerlink" href="#addresses-as-operands" title="Permalink to this headline">ïƒ</a>
</h3>
<p>All the memory instructions take an address operand that specifies the memory location being
accessed. This addressable operand is one of:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">[var]</span></code></dt>
<dd>
<p>the name of an addressable variable <code class="docutils literal notranslate"><span class="pre">var</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">[reg]</span></code></dt>
<dd>
<p>an integer or bit-size type register <code class="docutils literal notranslate"><span class="pre">reg</span></code> containing a byte address.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">[reg+immOff]</span></code></dt>
<dd>
<p>a sum of register <code class="docutils literal notranslate"><span class="pre">reg</span></code> containing a byte address plus a constant integer byte offset (signed, 32-bit).</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">[var+immOff]</span></code></dt>
<dd>
<p>a sum of address of addressable variable <code class="docutils literal notranslate"><span class="pre">var</span></code> containing a byte address plus a constant integer
byte offset (signed, 32-bit).</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">[immAddr]</span></code></dt>
<dd>
<p>an immediate absolute byte address (unsigned, 32-bit).</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">var[immOff]</span></code></dt>
<dd>
<p>an array element as described in <a class="reference internal" href="#arrays-as-operands"><span class="std std-ref">Arrays as Operands</span></a>.</p>
</dd>
</dl>
<p>The register containing an address may be declared as a bit-size type or integer type.</p>
<p>The access size of a memory instruction is the total number of bytes accessed in memory. For
example, the access size of <code class="docutils literal notranslate"><span class="pre">ld.v4.b32</span></code> is 16 bytes, while the access size of <code class="docutils literal notranslate"><span class="pre">atom.f16x2</span></code> is 4
bytes.</p>
<p>The address must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined. For example, among other things, the access
may proceed by silently masking off low-order address bits to achieve proper rounding, or the
instruction may fault.</p>
<p>The address size may be either 32-bit or 64-bit. 128-bit adresses are not supported. Addresses are
zero-extended to the specified width as needed, and truncated if the register width exceeds the
state space address width for the target architecture.</p>
<p>Address arithmetic is performed using integer arithmetic and logical instructions. Examples include
pointer arithmetic and pointer comparisons. All addresses and address computations are byte-based;
there is no support for C-style pointer arithmetic.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction can be used to move the address of a variable into a pointer. The address is
an offset in the state space in which the variable is declared. Load and store operations move data
between registers and locations in addressable state spaces. The syntax is similar to that used in
many assembly languages, where scalar variables are simply named and addresses are de-referenced by
enclosing the address expression in square brackets. Address expressions include variable names,
address registers, address register plus byte offset, and immediate address expressions which
evaluate at compile-time to a constant address.</p>
<p>Here are a few examples:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.shared .u16 x;
.reg    .u16 r0;
.global .v4 .f32 V;
.reg    .v4 .f32 W;
.const  .s32 tbl[256];
.reg    .b32 p;
.reg    .s32 q;

ld.shared.u16   r0,[x];
ld.global.v4.f32 W, [V];
ld.const.s32    q, [tbl+12];
mov.u32         p, tbl;
</pre></div>
</div>
<section id="generic-addressing">
<span id="id97"></span><h4>
<span class="section-number">6.4.1.1. </span><a class="reference internal" href="#generic-addressing">Generic Addressing</a><a class="headerlink" href="#generic-addressing" title="Permalink to this headline">ïƒ</a>
</h4>
<p>If a memory instruction does not specify a state space, the operation is performed using generic
addressing. The state spaces <code class="docutils literal notranslate"><span class="pre">.const</span></code>, <a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a>
(<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">.local</span></code> and <code class="docutils literal notranslate"><span class="pre">.shared</span></code> are modeled as
windows within the generic address space. Each window is defined by a window base and a window size
that is equal to the size of the corresponding state space. A generic address maps to <code class="docutils literal notranslate"><span class="pre">global</span></code>
memory unless it falls within the window for <code class="docutils literal notranslate"><span class="pre">const</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> memory. The
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>) window is contained
within the <code class="docutils literal notranslate"><span class="pre">.global</span></code> window. Within each window, a generic address maps to an address in the
underlying state space by subtracting the window base from the generic address.</p>
</section>
</section>
<section id="arrays-as-operands">
<span id="id98"></span><h3>
<span class="section-number">6.4.2. </span><a class="reference internal" href="#arrays-as-operands">Arrays as Operands</a><a class="headerlink" href="#arrays-as-operands" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Arrays of all types can be declared, and the identifier becomes an address constant in the space
where the array is declared. The size of the array is a constant in the program.</p>
<p>Array elements can be accessed using an explicitly calculated byte address, or by indexing into the
array using square-bracket notation. The expression within square brackets is either a constant
integer, a register variable, or a simple <em>register with constant offset</em> expression, where the
offset is a constant expression that is either added or subtracted from a register variable. If more
complicated indexing is desired, it must be written as an address calculation prior to use. Examples
are:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld.global.u32  s, a[0];
ld.global.u32  s, a[N-1];
mov.u32        s, a[1];  // move address of a[1] into s
</pre></div>
</div>
</section>
<section id="vectors-as-operands">
<span id="id99"></span><h3>
<span class="section-number">6.4.3. </span><a class="reference internal" href="#vectors-as-operands">Vectors as Operands</a><a class="headerlink" href="#vectors-as-operands" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Vector operands can be specified as source and destination operands for instructions. However, when
specified as destination operand, all elements in vector expression must be unique, otherwise behavior
is undefined.
Vectors may also be passed as arguments to called functions.</p>
<p>Vector elements can be extracted from the vector with the suffixes <code class="docutils literal notranslate"><span class="pre">.x</span></code>, <code class="docutils literal notranslate"><span class="pre">.y</span></code>, <code class="docutils literal notranslate"><span class="pre">.z</span></code> and
<code class="docutils literal notranslate"><span class="pre">.w</span></code>, as well as the typical color fields <code class="docutils literal notranslate"><span class="pre">.r</span></code>, <code class="docutils literal notranslate"><span class="pre">.g</span></code>, <code class="docutils literal notranslate"><span class="pre">.b</span></code> and <code class="docutils literal notranslate"><span class="pre">.a</span></code>.</p>
<p>A brace-enclosed list is used for pattern matching to pull apart vectors.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .v4 .f32 V;
.reg .f32     a, b, c, d;

mov.v4.f32 {a,b,c,d}, V;
</pre></div>
</div>
<p>Vector loads and stores can be used to implement wide loads and stores, which may improve memory
performance. The registers in the load/store operations can be a vector, or a brace-enclosed list of
similarly typed scalars. Here are examples:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld.global.v4.f32  {a,b,c,d}, [addr+16];
ld.global.v2.u32  V2, [addr+8];
</pre></div>
</div>
<p>Elements in a brace-enclosed vector, say {Ra, Rb, Rc, Rd}, correspond to extracted elements as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Ra = V.x = V.r
Rb = V.y = V.g
Rc = V.z = V.b
Rd = V.w = V.a
</pre></div>
</div>
</section>
<section id="labels-and-function-names-as-operands">
<span id="id100"></span><h3>
<span class="section-number">6.4.4. </span><a class="reference internal" href="#labels-and-function-names-as-operands">Labels and Function Names as Operands</a><a class="headerlink" href="#labels-and-function-names-as-operands" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Labels and function names can be used only in <code class="docutils literal notranslate"><span class="pre">bra</span></code>/<code class="docutils literal notranslate"><span class="pre">brx.idx</span></code> and <code class="docutils literal notranslate"><span class="pre">call</span></code> instructions
respectively. Function names can be used in <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction to get the address of the function
into a register, for use in an indirect call.</p>
<p>Beginning in PTX ISA version 3.1, the <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction may be used to take the address of kernel
functions, to be passed to a system call that initiates a kernel launch from the GPU. This feature
is part of the support for CUDA Dynamic Parallelism. See the <em>CUDA Dynamic Parallelism Programming
Guide</em> for details.</p>
</section>
</section>
<section id="type-conversion">
<span id="id101"></span><h2>
<span class="section-number">6.5. </span><a class="reference internal" href="#type-conversion">Type Conversion</a><a class="headerlink" href="#type-conversion" title="Permalink to this headline">ïƒ</a>
</h2>
<p>All operands to all arithmetic, logic, and data movement instruction must be of the same type and
size, except for operations where changing the size and/or type is part of the definition of the
instruction. Operands of different sizes or types must be converted prior to the operation.</p>
<section id="scalar-conversions">
<span id="id102"></span><h3>
<span class="section-number">6.5.1. </span><a class="reference internal" href="#scalar-conversions">Scalar Conversions</a><a class="headerlink" href="#scalar-conversions" title="Permalink to this headline">ïƒ</a>
</h3>
<p><a class="reference internal" href="#scalar-conversions-convert-instruction-precision-and-format-t1"><span class="std std-numref">Table 15</span></a> and
<a class="reference internal" href="#scalar-conversions-convert-instruction-precision-and-format-t2"><span class="std std-numref">Table 16</span></a> show what
precision and format the cvt instruction uses given operands of differing types. For example, if a
<code class="docutils literal notranslate"><span class="pre">cvt.s32.u16</span></code> instruction is given a <code class="docutils literal notranslate"><span class="pre">u16</span></code> source operand and <code class="docutils literal notranslate"><span class="pre">s32</span></code> as a destination operand,
the <code class="docutils literal notranslate"><span class="pre">u16</span></code> is zero-extended to <code class="docutils literal notranslate"><span class="pre">s32</span></code>.</p>
<p>Conversions to floating-point that are beyond the range of floating-point numbers are represented
with the maximum floating-point value (IEEE 754 Inf for <code class="docutils literal notranslate"><span class="pre">f32</span></code> and <code class="docutils literal notranslate"><span class="pre">f64</span></code>, and ~131,000 for
<code class="docutils literal notranslate"><span class="pre">f16</span></code>).</p>
<table class="table-no-stripes longtable docutils align-default" id="scalar-conversions-convert-instruction-precision-and-format-t1">
<caption>
<span class="caption-number">Table 15 </span><span class="caption-text">Convert Instruction Precision and Format Table 1</span><a class="headerlink" href="#scalar-conversions-convert-instruction-precision-and-format-t1" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="2" rowspan="2"></th>
<th class="head" colspan="13"><p><strong>Destination Format</strong></p></th>
</tr>
<tr class="row-even">
<th class="head"><p><strong>s8</strong></p></th>
<th class="head"><p><strong>s16</strong></p></th>
<th class="head"><p><strong>s32</strong></p></th>
<th class="head"><p><strong>s64</strong></p></th>
<th class="head"><p><strong>u8</strong></p></th>
<th class="head"><p><strong>u16</strong></p></th>
<th class="head"><p><strong>u32</strong></p></th>
<th class="head"><p><strong>u64</strong></p></th>
<th class="head"><p><strong>f16</strong></p></th>
<th class="head"><p><strong>f32</strong></p></th>
<th class="head"><p><strong>f64</strong></p></th>
<th class="head"><p><strong>bf16</strong></p></th>
<th class="head"><p><strong>tf32</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="13"><p><strong>Source
Format</strong></p></td>
<td><p><strong>s8</strong></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s16</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>s32</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s64</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>s2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u8</strong></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u16</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u32</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u64</strong></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>chop<sup>1</sup></p></td>
<td><p>â€“</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>u2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>f16</strong></p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f32</strong></p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>f64</strong></p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>bf16</strong></p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2s</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2u</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>tf32</strong></p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes longtable docutils align-default" id="scalar-conversions-convert-instruction-precision-and-format-t2">
<caption>
<span class="caption-number">Table 16 </span><span class="caption-text">Convert Instruction Precision and Format Table 2</span><a class="headerlink" href="#scalar-conversions-convert-instruction-precision-and-format-t2" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 8%">
<col style="width: 9%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="2" rowspan="2"></th>
<th class="head" colspan="10"><p><strong>Destination Format</strong></p></th>
</tr>
<tr class="row-even">
<th class="head"><p><strong>f16</strong></p></th>
<th class="head"><p><strong>f32</strong></p></th>
<th class="head"><p><strong>bf16</strong></p></th>
<th class="head"><p><strong>e4m3</strong></p></th>
<th class="head"><p><strong>e5m2</strong></p></th>
<th class="head"><p><strong>e2m3</strong></p></th>
<th class="head"><p><strong>e3m2</strong></p></th>
<th class="head"><p><strong>e2m1</strong></p></th>
<th class="head"><p><strong>ue8m0</strong></p></th>
<th class="head"><p><strong>s2f6</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="10"><p><strong>Source
Format</strong></p></td>
<td><p><strong>f16</strong></p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f32</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>bf16</strong></p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
<td><p>f2f</p></td>
</tr>
<tr class="row-even">
<td><p><strong>e4m3</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>e5m2</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>e2m3</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>e3m2</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>e2m1</strong></p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>ue8m0</strong></p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s2f6</strong></p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>f2f</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
</tbody>
</table>
<p><strong>Notes</strong></p>
<p>sext = sign-extend; zext = zero-extend; chop = keep only low bits that fit;</p>
<p>s2f = signed-to-float; f2s = float-to-signed; u2f = unsigned-to-float;</p>
<p>f2u = float-to-unsigned; f2f = float-to-float.</p>
<p><sup>1</sup> If the destination register is wider than the destination format, the result is extended to the
destination register width after chopping. The type of extension (sign or zero) is based on the
destination format. For example, cvt.s16.u32 targeting a 32-bit register first chops to 16-bit, then
sign-extends to 32-bit.</p>
</section>
<section id="rounding-modifiers">
<span id="id103"></span><h3>
<span class="section-number">6.5.2. </span><a class="reference internal" href="#rounding-modifiers">Rounding Modifiers</a><a class="headerlink" href="#rounding-modifiers" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Conversion instructions may specify a rounding modifier. In PTX, there are four integer rounding
modifiers and six floating-point rounding
modifiers. <a class="reference internal" href="#rounding-modifiers-floating-point-rounding-modifiers"><span class="std std-numref">Table 17</span></a> and
<a class="reference internal" href="#rounding-modifiers-integer-rounding-modifiers"><span class="std std-numref">Table 18</span></a> summarize the rounding modifiers.</p>
<table class="table-no-stripes docutils align-default" id="rounding-modifiers-floating-point-rounding-modifiers">
<caption>
<span class="caption-number">Table 17 </span><span class="caption-text">Floating-Point Rounding Modifiers</span><a class="headerlink" href="#rounding-modifiers-floating-point-rounding-modifiers" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 84%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Modifier</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.rn</span></code></p></td>
<td><p>rounds to nearest even</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.rna</span></code></p></td>
<td><p>rounds to nearest, ties away from zero</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.rz</span></code></p></td>
<td><p>rounds towards zero</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.rm</span></code></p></td>
<td><p>rounds towards negative infinity</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.rp</span></code></p></td>
<td><p>rounds towards positive infinity</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.rs</span></code></p></td>
<td><p>rounds either towards zero or away from zero based
on the carry out of the integer addition of random
bits and the discarded bits of mantissa</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="rounding-modifiers-integer-rounding-modifiers">
<caption>
<span class="caption-number">Table 18 </span><span class="caption-text">Integer Rounding Modifiers</span><a class="headerlink" href="#rounding-modifiers-integer-rounding-modifiers" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 9%">
<col style="width: 91%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Modifier</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.rni</span></code></p></td>
<td><p>round to nearest integer, choosing even integer if source is equidistant between two integers.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.rzi</span></code></p></td>
<td><p>round to nearest integer in the direction of zero</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.rmi</span></code></p></td>
<td><p>round to nearest integer in direction of negative infinity</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.rpi</span></code></p></td>
<td><p>round to nearest integer in direction of positive infinity</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="operand-costs">
<span id="id104"></span><h2>
<span class="section-number">6.6. </span><a class="reference internal" href="#operand-costs">Operand Costs</a><a class="headerlink" href="#operand-costs" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Operands from different state spaces affect the speed of an operation. Registers are fastest, while
global memory is slowest. Much of the delay to memory can be hidden in a number of ways. The first
is to have multiple threads of execution so that the hardware can issue a memory operation and then
switch to other execution. Another way to hide latency is to issue the load instructions as early as
possible, as execution is not blocked until the desired result is used in a subsequent (in time)
instruction. The register in a store operation is available much more
quickly. <a class="reference internal" href="#operand-costs-cost-estimates-for-sccessing-state-spaces"><span class="std std-numref">Table 19</span></a> gives estimates of the
costs of using different kinds of memory.</p>
<table class="table-no-stripes docutils align-default" id="operand-costs-cost-estimates-for-sccessing-state-spaces">
<caption>
<span class="caption-number">Table 19 </span><span class="caption-text">Cost Estimates for Accessing State-Spaces</span><a class="headerlink" href="#operand-costs-cost-estimates-for-sccessing-state-spaces" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 20%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Space</p></th>
<th class="head"><p>Time</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Register</p></td>
<td><p>0</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>Shared</p></td>
<td><p>0</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>Constant</p></td>
<td><p>0</p></td>
<td><p>Amortized cost is low, first access is high</p></td>
</tr>
<tr class="row-odd">
<td><p>Local</p></td>
<td><p>&gt; 100 clocks</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>Parameter</p></td>
<td><p>0</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>Immediate</p></td>
<td><p>0</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>Global</p></td>
<td><p>&gt; 100 clocks</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>Texture</p></td>
<td><p>&gt; 100 clocks</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p>Surface</p></td>
<td><p>&gt; 100 clocks</p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="abstracting-abi">
<span id="id105"></span><h1>
<span class="section-number">7. </span><a class="reference internal" href="#abstracting-abi">Abstracting the ABI</a><a class="headerlink" href="#abstracting-abi" title="Permalink to this headline">ïƒ</a>
</h1>
<p>Rather than expose details of a particular calling convention, stack layout, and Application Binary
Interface (ABI), PTX provides a slightly higher-level abstraction and supports multiple ABI
implementations. In this section, we describe the features of PTX needed to achieve this hiding of
the ABI. These include syntax for function definitions, function calls, parameter passing, and
memory allocated on the stack (<code class="docutils literal notranslate"><span class="pre">alloca</span></code>).</p>
<p>Refer to <em>PTX Writers Guide to Interoperability</em> for details on generating PTX compliant with
Application Binary Interface (ABI) for the CUDA<sup>Â®</sup> architecture.</p>
<section id="function-declarations-and-definitions">
<span id="id106"></span><h2>
<span class="section-number">7.1. </span><a class="reference internal" href="#function-declarations-and-definitions">Function Declarations and Definitions</a><a class="headerlink" href="#function-declarations-and-definitions" title="Permalink to this headline">ïƒ</a>
</h2>
<p>In PTX, functions are declared and defined using the <code class="docutils literal notranslate"><span class="pre">.func</span></code> directive. A function <em>declaration</em>
specifies an optional list of return parameters, the function name, and an optional list of input
parameters; together these specify the functionâ€™s interface, or prototype. A function <em>definition</em>
specifies both the interface and the body of the function. A function must be declared or defined
prior to being called.</p>
<p>The simplest function has no parameters or return values, and is represented in PTX as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func foo
{
    ...
    ret;
}

    ...
    call foo;
    ...
</pre></div>
</div>
<p>Here, execution of the <code class="docutils literal notranslate"><span class="pre">call</span></code> instruction transfers control to <code class="docutils literal notranslate"><span class="pre">foo</span></code>, implicitly saving the
return address. Execution of the <code class="docutils literal notranslate"><span class="pre">ret</span></code> instruction within <code class="docutils literal notranslate"><span class="pre">foo</span></code> transfers control to the
instruction following the call.</p>
<p>Scalar and vector base-type input and return parameters may be represented simply as register
variables. At the call, arguments may be register variables or constants, and return values may be
placed directly into register variables. The arguments and return variables at the call must have
type and size that match the calleeâ€™s corresponding formal parameters.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func (.reg .u32 %res) inc_ptr ( .reg .u32 %ptr, .reg .u32 %inc )
{
    add.u32 %res, %ptr, %inc;
    ret;
}

    ...
    call (%r1), inc_ptr, (%r1,4);
    ...
</pre></div>
</div>
<p>When using the ABI, <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space parameters must be at least 32-bits in size. Subword scalar
objects in the source language should be promoted to 32-bit registers in PTX, or use <code class="docutils literal notranslate"><span class="pre">.param</span></code>
state space byte arrays described next.</p>
<p>Objects such as C structures and unions are flattened into registers or byte arrays in PTX and are
represented using <code class="docutils literal notranslate"><span class="pre">.param</span></code> space memory. For example, consider the following C structure, passed
by value to a function:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>struct {
    double dbl;
    char   c[4];
};
</pre></div>
</div>
<p>In PTX, this structure will be flattened into a byte array. Since memory accesses are required to be
aligned to a multiple of the access size, the structure in this example will be a 12 byte array with
8 byte alignment so that accesses to the <code class="docutils literal notranslate"><span class="pre">.f64</span></code> field are aligned. The <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space is
used to pass the structure by value:</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func (.reg .s32 out) bar (.reg .s32 x, .param .align 8 .b8 y[12])
{
    .reg .f64 f1;
    .reg .b32 c1, c2, c3, c4;
    ...
    ld.param.f64 f1, [y+0];
    ld.param.b8  c1, [y+8];
    ld.param.b8  c2, [y+9];
    ld.param.b8  c3, [y+10];
    ld.param.b8  c4, [y+11];
    ...
    ... // computation using x,f1,c1,c2,c3,c4;
}

{
     .param .b8 .align 8 py[12];
     ...
     st.param.b64 [py+ 0], %rd;
     st.param.b8  [py+ 8], %rc1;
     st.param.b8  [py+ 9], %rc2;
     st.param.b8  [py+10], %rc1;
     st.param.b8  [py+11], %rc2;
     // scalar args in .reg space, byte array in .param space
     call (%out), bar, (%x, py);
     ...
</pre></div>
</div>
<p>In this example, note that <code class="docutils literal notranslate"><span class="pre">.param</span></code> space variables are used in two ways. First, a <code class="docutils literal notranslate"><span class="pre">.param</span></code>
variable <code class="docutils literal notranslate"><span class="pre">y</span></code> is used in function definition bar to represent a formal parameter. Second, a
<code class="docutils literal notranslate"><span class="pre">.param</span></code> variable <code class="docutils literal notranslate"><span class="pre">py</span></code> is declared in the body of the calling function and used to set up the
structure being passed to bar.</p>
<p>The following is a conceptual way to think about the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space use in device functions.</p>
<p>For a caller,</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space is used to set values that will be passed to a called function and/or
to receive return values from a called function. Typically, a <code class="docutils literal notranslate"><span class="pre">.param</span></code> byte array is used to
collect together fields of a structure being passed by value.</p></li>
</ul>
<p>For a callee,</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space is used to receive parameter values and/or pass return values back to
the caller.</p></li>
</ul>
<p>The following restrictions apply to parameter passing.</p>
<p>For a caller,</p>
<ul class="simple">
<li><p>Arguments may be <code class="docutils literal notranslate"><span class="pre">.param</span></code> variables, <code class="docutils literal notranslate"><span class="pre">.reg</span></code> variables, or constants.</p></li>
<li><p>In the case of <code class="docutils literal notranslate"><span class="pre">.param</span></code> space formal parameters that are byte arrays, the argument must also be
a <code class="docutils literal notranslate"><span class="pre">.param</span></code> space byte array with matching type, size, and alignment. A <code class="docutils literal notranslate"><span class="pre">.param</span></code> argument must
be declared within the local scope of the caller.</p></li>
<li><p>In the case of <code class="docutils literal notranslate"><span class="pre">.param</span></code> space formal parameters that are base-type scalar or vector variables,
the corresponding argument may be either a <code class="docutils literal notranslate"><span class="pre">.param</span></code> or <code class="docutils literal notranslate"><span class="pre">.reg</span></code> space variable with matching
type and size, or a constant that can be represented in the type of the formal parameter.</p></li>
<li><p>In the case of <code class="docutils literal notranslate"><span class="pre">.reg</span></code> space formal parameters, the corresponding argument may be either a
<code class="docutils literal notranslate"><span class="pre">.param</span></code> or <code class="docutils literal notranslate"><span class="pre">.reg</span></code> space variable of matching type and size, or a constant that can be
represented in the type of the formal parameter.</p></li>
<li><p>In the case of <code class="docutils literal notranslate"><span class="pre">.reg</span></code> space formal parameters, the register must be at least 32-bits in size.</p></li>
<li><p>All <code class="docutils literal notranslate"><span class="pre">st.param</span></code> instructions used for passing arguments to function call must immediately precede
the corresponding <code class="docutils literal notranslate"><span class="pre">call</span></code> instruction and <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> instruction used for collecting return
value must immediately follow the <code class="docutils literal notranslate"><span class="pre">call</span></code> instruction without any control flow
alteration. <code class="docutils literal notranslate"><span class="pre">st.param</span></code> and <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> instructions used for argument passing cannot be
predicated. This enables compiler optimization and ensures that the <code class="docutils literal notranslate"><span class="pre">.param</span></code> variable does not
consume extra space in the callerâ€™s frame beyond that needed by the ABI. The <code class="docutils literal notranslate"><span class="pre">.param</span></code> variable
simply allows a mapping to be made at the call site between data that may be in multiple
locations (e.g., structure being manipulated by caller is located in registers and memory) to
something that can be passed as a parameter or return value to the callee.</p></li>
</ul>
<p>For a callee,</p>
<ul class="simple">
<li><p>Input and return parameters may be <code class="docutils literal notranslate"><span class="pre">.param</span></code> variables or <code class="docutils literal notranslate"><span class="pre">.reg</span></code> variables.</p></li>
<li><p>Parameters in <code class="docutils literal notranslate"><span class="pre">.param</span></code> memory must be aligned to a multiple of 1, 2, 4, 8, or 16 bytes.</p></li>
<li><p>Parameters in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space must be at least 32-bits in size.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space can be used to receive and return base-type scalar and vector values,
including sub-word size objects when compiling in non-ABI mode. Supporting the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state
space provides legacy support.</p></li>
</ul>
<p>Note that the choice of <code class="docutils literal notranslate"><span class="pre">.reg</span></code> or <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space for parameter passing has no impact on
whether the parameter is ultimately passed in physical registers or on the stack. The mapping of
parameters to physical registers and stack locations depends on the ABI definition and the order,
size, and alignment of parameters.</p>
<section id="changes-from-ptx-isa-version-1-x">
<span id="id107"></span><h3>
<span class="section-number">7.1.1. </span><a class="reference internal" href="#changes-from-ptx-isa-version-1-x">Changes from PTX ISA Version 1.x</a><a class="headerlink" href="#changes-from-ptx-isa-version-1-x" title="Permalink to this headline">ïƒ</a>
</h3>
<p>In PTX ISA version 1.x, formal parameters were restricted to .reg state space, and there was no
support for array parameters. Objects such as C structures were flattened and passed or returned
using multiple registers. PTX ISA version 1.x supports multiple return values for this purpose.</p>
<p>Beginning with PTX ISA version 2.0, formal parameters may be in either <code class="docutils literal notranslate"><span class="pre">.reg</span></code> or <code class="docutils literal notranslate"><span class="pre">.param</span></code> state
space, and <code class="docutils literal notranslate"><span class="pre">.param</span></code> space parameters support arrays. For targets <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher, PTX
restricts functions to a single return value, and a <code class="docutils literal notranslate"><span class="pre">.param</span></code> byte array should be used to return
objects that do not fit into a register. PTX continues to support multiple return registers for
<code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PTX implements a stack-based ABI only for targets <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
</div>
<p>PTX ISA versions prior to 3.0 permitted variables in <code class="docutils literal notranslate"><span class="pre">.reg</span></code> and <code class="docutils literal notranslate"><span class="pre">.local</span></code> state spaces to be
defined at module scope. When compiling to use the ABI, PTX ISA version 3.0 and later disallows
module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code> and <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables and restricts their use to within function
scope. When compiling without use of the ABI, module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code> and <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables are
supported as before. When compiling legacy PTX code (ISA versions prior to 3.0) containing
module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code> or <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables, the compiler silently disables use of the ABI.</p>
</section>
</section>
<section id="variadic-functions">
<span id="id108"></span><h2>
<span class="section-number">7.2. </span><a class="reference internal" href="#variadic-functions">Variadic Functions</a><a class="headerlink" href="#variadic-functions" title="Permalink to this headline">ïƒ</a>
</h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><strong>Support for variadic functions which was unimplemented has been removed from the spec.</strong></p>
</div>
<p>PTX version 6.0 supports passing unsized array parameter to a function which can be used to
implement variadic functions.</p>
<p>Refer to <a class="reference internal" href="#kernel-and-function-directives-func"><span class="std std-ref">Kernel and Function Directives: .func</span></a> for details</p>
</section>
<section id="alloca">
<span id="id109"></span><h2>
<span class="section-number">7.3. </span><a class="reference internal" href="#alloca">Alloca</a><a class="headerlink" href="#alloca" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX provides <code class="docutils literal notranslate"><span class="pre">alloca</span></code> instruction for allocating storage at runtime on the per-thread local memory
stack. The allocated stack memory can be accessed with <code class="docutils literal notranslate"><span class="pre">ld.local</span></code> and <code class="docutils literal notranslate"><span class="pre">st.local</span></code> instructions
using the pointer returned by <code class="docutils literal notranslate"><span class="pre">alloca</span></code>.</p>
<p>In order to facilitate deallocation of memory allocated with <code class="docutils literal notranslate"><span class="pre">alloca</span></code>, PTX provides two additional
instructions: <code class="docutils literal notranslate"><span class="pre">stacksave</span></code> which allows reading the value of stack pointer in a local variable, and
<code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> which can restore the stack pointer with the saved value.</p>
<p><code class="docutils literal notranslate"><span class="pre">alloca</span></code>, <code class="docutils literal notranslate"><span class="pre">stacksave</span></code>, and <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> instructions are described in
<a class="reference internal" href="#stack-manipulation-instructions"><span class="std std-ref">Stack Manipulation Instructions</span></a>.</p>
</section>
</section>
<section id="memory-consistency-model">
<span id="id110"></span><h1>
<span class="section-number">8. </span><a class="reference internal" href="#memory-consistency-model">Memory Consistency Model</a><a class="headerlink" href="#memory-consistency-model" title="Permalink to this headline">ïƒ</a>
</h1>
<p>In multi-threaded executions, the side-effects of memory operations performed by each thread become
visible to other threads in a partial and non-identical order. This means that any two operations
may appear to happen in no order, or in different orders, to different threads. The axioms
introduced by the memory consistency model specify exactly which contradictions are forbidden
between the orders observed by different threads.</p>
<p>In the absence of any constraint, each read operation returns the value committed by some write
operation to the same memory location, including the initial write to that memory location. The
memory consistency model effectively constrains the set of such candidate writes from which a read
operation can return a value.</p>
<section id="scope-and-applicability">
<span id="id111"></span><h2>
<span class="section-number">8.1. </span><a class="reference internal" href="#scope-and-applicability">Scope and applicability of the model</a><a class="headerlink" href="#scope-and-applicability" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The constraints specified under this model apply to PTX programs with any PTX ISA version number,
running on <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or later architectures.</p>
<p>The memory consistency model does not apply to texture (including <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code>) and surface
accesses.</p>
<section id="limitations-system-scope-atomicity">
<span id="id112"></span><h3>
<span class="section-number">8.1.1. </span><a class="reference internal" href="#limitations-system-scope-atomicity">Limitations on atomicity at system scope</a><a class="headerlink" href="#limitations-system-scope-atomicity" title="Permalink to this headline">ïƒ</a>
</h3>
<p>When communicating with the host CPU, certain strong operations with system scope may not be
performed atomically on some systems. For more details on atomicity guarantees to host memory, see
the <em>CUDA Atomicity Requirements</em>.</p>
</section>
</section>
<section id="memory-operations">
<span id="id113"></span><h2>
<span class="section-number">8.2. </span><a class="reference internal" href="#memory-operations">Memory operations</a><a class="headerlink" href="#memory-operations" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The fundamental storage unit in the PTX memory model is a byte, consisting of 8 bits. Each state
space available to a PTX program is a sequence of contiguous bytes in memory. Every byte in a PTX
state space has a unique address relative to all threads that have access to the same state space.</p>
<p>Each PTX memory instruction specifies an address operand and a data type. The address operand
contains a virtual address that gets converted to a physical address during memory access. The
physical address and the size of the data type together define a physical memory location, which is
the range of bytes starting from the physical address and extending up to the size of the data type
in bytes.</p>
<p>The memory consistency model specification uses the terms â€œaddressâ€ or â€œmemory addressâ€ to indicate
a virtual address, and the term â€œmemory locationâ€ to indicate a physical memory location.</p>
<p>Each PTX memory instruction also specifies the operation â€” either a read, a write or an atomic
read-modify-write â€” to be performed on all the bytes in the corresponding memory location.</p>
<section id="overlap">
<span id="id114"></span><h3>
<span class="section-number">8.2.1. </span><a class="reference internal" href="#overlap">Overlap</a><a class="headerlink" href="#overlap" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Two memory locations are said to overlap when the starting address of one location is within the
range of bytes constituting the other location. Two memory operations are said to overlap when they
specify the same virtual address and the corresponding memory locations overlap. The overlap is said
to be complete when both memory locations are identical, and it is said to be partial otherwise.</p>
</section>
<section id="aliases">
<span id="id115"></span><h3>
<span class="section-number">8.2.2. </span><a class="reference internal" href="#aliases">Aliases</a><a class="headerlink" href="#aliases" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Two distinct virtual addresses are said to be aliases if they map to the same memory location.</p>
</section>
<section id="multimem-addresses">
<span id="id116"></span><h3>
<span class="section-number">8.2.3. </span><a class="reference internal" href="#multimem-addresses">Multimem Addresses</a><a class="headerlink" href="#multimem-addresses" title="Permalink to this headline">ïƒ</a>
</h3>
<p>A multimem address is a virtual address which points to multiple distinct memory locations across
devices.</p>
<p>Only <em>multimem.</em>* operations are valid on multimem addresses. That is, the behavior of accessing
a multimem address in any other memory operation is undefined.</p>
</section>
<section id="memory-operations-on-vector-data-types">
<span id="id117"></span><h3>
<span class="section-number">8.2.4. </span><a class="reference internal" href="#memory-operations-on-vector-data-types">Memory Operations on Vector Data Types</a><a class="headerlink" href="#memory-operations-on-vector-data-types" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The memory consistency model relates operations executed on memory locations with scalar data types,
which have a maximum size and alignment of 64 bits. Memory operations with a vector data type are
modelled as a set of equivalent memory operations with a scalar data type, executed in an
unspecified order on the elements in the vector.</p>
</section>
<section id="memory-operations-on-packed-data-types">
<span id="id118"></span><h3>
<span class="section-number">8.2.5. </span><a class="reference internal" href="#memory-operations-on-packed-data-types">Memory Operations on Packed Data Types</a><a class="headerlink" href="#memory-operations-on-packed-data-types" title="Permalink to this headline">ïƒ</a>
</h3>
<p>A packed data type consists of two values of the same scalar data type, as described in
<a class="reference internal" href="#packed-data-types"><span class="std std-ref">Packed Data Types</span></a>. These values are accessed in adjacent memory locations. A
memory operation on a packed data type is modelled as a pair of equivalent memory operations on the
scalar data type, executed in an unspecified order on each element of the packed data.</p>
</section>
<section id="initialization">
<span id="id119"></span><h3>
<span class="section-number">8.2.6. </span><a class="reference internal" href="#initialization">Initialization</a><a class="headerlink" href="#initialization" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Each byte in memory is initialized by a hypothetical write <em>W0</em> executed before starting any thread
in the program. If the byte is included in a program variable, and that variable has an initial
value, then <em>W0</em> writes the corresponding initial value for that byte; else <em>W0</em> is assumed to have
written an unknown but constant value to the byte.</p>
</section>
</section>
<section id="memory-consistency-state-spaces">
<span id="id120"></span><h2>
<span class="section-number">8.3. </span><a class="reference internal" href="#memory-consistency-state-spaces">State spaces</a><a class="headerlink" href="#memory-consistency-state-spaces" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The relations defined in the memory consistency model are independent of state spaces. In
particular, causality order closes over all memory operations across all the state spaces. But the
side-effect of a memory operation in one state space can be observed directly only by operations
that also have access to the same state space. This further constrains the synchronizing effect of a
memory operation in addition to scope. For example, the synchronizing effect of the PTX instruction
<code class="docutils literal notranslate"><span class="pre">ld.relaxed.shared.sys</span></code> is identical to that of <code class="docutils literal notranslate"><span class="pre">ld.relaxed.shared.cluster</span></code>, since no thread
outside the same cluster can execute an operation that accesses the same memory location.</p>
</section>
<section id="operation-types">
<span id="id121"></span><h2>
<span class="section-number">8.4. </span><a class="reference internal" href="#operation-types">Operation types</a><a class="headerlink" href="#operation-types" title="Permalink to this headline">ïƒ</a>
</h2>
<p>For simplicity, the rest of the document refers to the following operation types, instead of
mentioning specific instructions that give rise to them.</p>
<table class="table-no-stripes docutils align-default" id="id678">
<caption>
<span class="caption-number">Table 20 </span><span class="caption-text">Operation Types</span><a class="headerlink" href="#id678" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Operation Type</p></th>
<th class="head"><p>Instruction/Operation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>atomic operation</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">atom</span></code> or <code class="docutils literal notranslate"><span class="pre">red</span></code> instruction.</p></td>
</tr>
<tr class="row-odd">
<td><p>read operation</p></td>
<td><p>All variants of <code class="docutils literal notranslate"><span class="pre">ld</span></code> instruction and <code class="docutils literal notranslate"><span class="pre">atom</span></code> instruction (but not
<code class="docutils literal notranslate"><span class="pre">red</span></code> instruction).</p></td>
</tr>
<tr class="row-even">
<td><p>write operation</p></td>
<td><p>All variants of <code class="docutils literal notranslate"><span class="pre">st</span></code> instruction, and <em>atomic</em> operations if they result
in a write.</p></td>
</tr>
<tr class="row-odd">
<td><p>memory operation</p></td>
<td><p>A <em>read</em> or <em>write</em> operation.</p></td>
</tr>
<tr class="row-even">
<td><p>volatile operation</p></td>
<td><p>An instruction with <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier.</p></td>
</tr>
<tr class="row-odd">
<td><p>acquire operation</p></td>
<td><p>A <em>memory</em> operation with <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> or <code class="docutils literal notranslate"><span class="pre">.acq_rel</span></code> qualifier.</p></td>
</tr>
<tr class="row-even">
<td><p>release operation</p></td>
<td><p>A <em>memory</em> operation with <code class="docutils literal notranslate"><span class="pre">.release</span></code> or <code class="docutils literal notranslate"><span class="pre">.acq_rel</span></code> qualifier.</p></td>
</tr>
<tr class="row-odd">
<td><p>mmio operation</p></td>
<td><p>An <code class="docutils literal notranslate"><span class="pre">ld</span></code> or <code class="docutils literal notranslate"><span class="pre">st</span></code> instruction with <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier.</p></td>
</tr>
<tr class="row-even">
<td><p>memory fence operation</p></td>
<td><p>A <code class="docutils literal notranslate"><span class="pre">membar</span></code>, <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> or <code class="docutils literal notranslate"><span class="pre">fence.acq_rel</span></code> instruction.</p></td>
</tr>
<tr class="row-odd">
<td><p>proxy fence operation</p></td>
<td><p>A <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> or a <code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> instruction.</p></td>
</tr>
<tr class="row-even">
<td><p>strong operation</p></td>
<td><p>A <em>memory fence</em> operation, or a <em>memory</em> operation with a <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>,
<code class="docutils literal notranslate"><span class="pre">.acquire</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code>, <code class="docutils literal notranslate"><span class="pre">.acq_rel</span></code>, <code class="docutils literal notranslate"><span class="pre">.volatile</span></code>, or <code class="docutils literal notranslate"><span class="pre">.mmio</span></code>
qualifier.</p></td>
</tr>
<tr class="row-odd">
<td><p>weak operation</p></td>
<td><p>An <code class="docutils literal notranslate"><span class="pre">ld</span></code> or <code class="docutils literal notranslate"><span class="pre">st</span></code> instruction with a <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifier.</p></td>
</tr>
<tr class="row-even">
<td><p>synchronizing operation</p></td>
<td><p>A <code class="docutils literal notranslate"><span class="pre">barrier</span></code> instruction, <em>fence</em> operation, <em>release</em> operation or
<em>acquire</em> operation.</p></td>
</tr>
</tbody>
</table>
<section id="mmio-operation">
<span id="id122"></span><h3>
<span class="section-number">8.4.1. </span><a class="reference internal" href="#mmio-operation">mmio Operation</a><a class="headerlink" href="#mmio-operation" title="Permalink to this headline">ïƒ</a>
</h3>
<p>An <em>mmio</em> operation is a memory operation with <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier specified. It is usually performed
on a memory location which is mapped to the control registers of peer I/O devices. It can also be
used for communication between threads but has poor performance relative to non-<em>mmio</em> operations.</p>
<p>The semantic meaning of <em>mmio</em> operations cannot be defined precisely as it is defined by the
underlying I/O device. For formal specification of semantics of <em>mmio</em> operation from Memory
Consistency Model perspective, it is equivalent to the semantics of a <em>strong</em> operation. But it
follows a few implementation-specific properties, if it meets the <em>CUDA atomicity requirements</em> at
the specified scope:</p>
<ul class="simple">
<li><p>Writes are always performed and are never combined within the scope specified.</p></li>
<li>
<p>Reads are always performed, and are not forwarded, prefetched, combined, or allowed to hit any
cache within the scope specified.</p>
<ul>
<li><p>As an exception, in some implementations, the surrounding locations may also be loaded. In such
cases the amount of data loaded is implementation specific and varies between 32 and 128 bytes
in size.</p></li>
</ul>
</li>
</ul>
</section>
<section id="volatile-operation">
<span id="id123"></span><h3>
<span class="section-number">8.4.2. </span><a class="reference internal" href="#volatile-operation">volatile Operation</a><a class="headerlink" href="#volatile-operation" title="Permalink to this headline">ïƒ</a>
</h3>
<p>A <em>volatile</em> operation is a memory operation with <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier specified.
The semantics of volatile operations are equivalent to a relaxed memory operation with system-scope
but with the following extra implementation-specific constraints:</p>
<ul class="simple">
<li><p>The number of volatile <em>instructions</em> (not operations) executed by a program is preserved.
Hardware may combine and merge volatile <em>operations</em> issued by multiple different volatile
<em>instructions</em>, that is, the number of volatile <em>operations</em> in the program is not preserved.</p></li>
<li><p>Volatile <em>instructions</em> are not re-ordered around other volatile <em>instructions</em>, but the memory
<em>operations</em> performed by those <em>instructions</em> may be re-ordered around each other.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>PTX volatile operations are intended for compilers to lower volatile read and write operations from
CUDA C++, and other programming languages sharing CUDA C++ volatile semantics, to PTX.</p>
<p>Since volatile operations are relaxed at system-scope with extra constraints, prefer using other
<em>strong</em> read or write operations (e.g. <code class="docutils literal notranslate"><span class="pre">ld.relaxed.sys</span></code> or <code class="docutils literal notranslate"><span class="pre">st.relaxed.sys</span></code>) for
<strong>Inter-Thread Synchronization</strong> instead, which may deliver better performance.</p>
<p>PTX volatile operations are not suited for <strong>Memory Mapped IO (MMIO)</strong> because volatile operations
do not preserve the number of memory operations performed, and may perform more or less operations
than requested in a non-deterministic way.
Use <a class="reference external" href="#mmio-operation">.mmio operations</a> instead, which strictly preserve the number of operations
performed.</p>
</div>
</section>
</section>
<section id="scope">
<span id="id124"></span><h2>
<span class="section-number">8.5. </span><a class="reference internal" href="#scope">Scope</a><a class="headerlink" href="#scope" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Each <em>strong</em> operation must specify a <em>scope</em>, which is the set of threads that may interact
directly with that operation and establish any of the relations described in the memory consistency
model. There are four scopes:</p>
<table class="table-no-stripes docutils align-default" id="id679">
<caption>
<span class="caption-number">Table 21 </span><span class="caption-text">Scopes</span><a class="headerlink" href="#id679" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Scope</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.cta</span></code></p></td>
<td><p>The set of all threads executing in the same CTA as the current thread.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.cluster</span></code></p></td>
<td><p>The set of all threads executing in the same cluster as the current thread.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.gpu</span></code></p></td>
<td><p>The set of all threads in the current program executing on the same compute
device as the current thread. This also includes other kernel grids invoked by
the host program on the same compute device.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.sys</span></code></p></td>
<td><p>The set of all threads in the current program, including all kernel grids
invoked by the host program on all compute devices, and all threads
constituting the host program itself.</p></td>
</tr>
</tbody>
</table>
<p>Note that the warp is not a <em>scope</em>; the CTA is the smallest collection of threads that qualifies as
a <em>scope</em> in the memory consistency model.</p>
</section>
<section id="proxies">
<span id="id125"></span><h2>
<span class="section-number">8.6. </span><a class="reference internal" href="#proxies">Proxies</a><a class="headerlink" href="#proxies" title="Permalink to this headline">ïƒ</a>
</h2>
<p>A <em>memory proxy</em>, or a <em>proxy</em> is an abstract label applied to a method of memory access. When two
memory operations use distinct methods of memory access, they are said to be different <em>proxies</em>.</p>
<p>Memory operations as defined in <a class="reference internal" href="#operation-types"><span class="std std-ref">Operation types</span></a> use <em>generic</em>
method of memory access, i.e. a <em>generic proxy</em>. Other operations such as textures and surfaces all
use distinct methods of memory access, also distinct from the <em>generic</em> method.</p>
<p>A <em>proxy fence</em> is required to synchronize memory operations across different <em>proxies</em>. Although
virtual aliases use the <em>generic</em> method of memory access, since using distinct virtual addresses
behaves as if using different <em>proxies</em>, they require a <em>proxy fence</em> to establish memory ordering.</p>
</section>
<section id="morally-strong-operations">
<span id="id126"></span><h2>
<span class="section-number">8.7. </span><a class="reference internal" href="#morally-strong-operations">Morally strong operations</a><a class="headerlink" href="#morally-strong-operations" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Two operations are said to be <em>morally strong</em> relative to each other if they satisfy all of the
following conditions:</p>
<ol class="arabic simple">
<li><p>The operations are related in <em>program order</em> (i.e, they are both executed by the same thread),
or each operation is <em>strong</em> and specifies a <em>scope</em> that includes the thread executing the
other operation.</p></li>
<li><p>Both operations are performed via the same <em>proxy</em>.</p></li>
<li><p>If both are memory operations, then they overlap completely.</p></li>
</ol>
<p>Most (but not all) of the axioms in the memory consistency model depend on relations between
<em>morally strong</em> operations.</p>
<section id="conflict-and-data-races">
<span id="id127"></span><h3>
<span class="section-number">8.7.1. </span><a class="reference internal" href="#conflict-and-data-races">Conflict and Data-races</a><a class="headerlink" href="#conflict-and-data-races" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Two <em>overlapping</em> memory operations are said to <em>conflict</em> when at least one of them is a <em>write</em>.</p>
<p>Two <em>conflicting</em> memory operations are said to be in a <em>data-race</em> if they are not related in
<em>causality order</em> and they are not <em>morally strong</em>.</p>
</section>
<section id="mixed-size-limitations">
<span id="id128"></span><h3>
<span class="section-number">8.7.2. </span><a class="reference internal" href="#mixed-size-limitations">Limitations on Mixed-size Data-races</a><a class="headerlink" href="#mixed-size-limitations" title="Permalink to this headline">ïƒ</a>
</h3>
<p>A <em>data-race</em> between operations that <em>overlap</em> completely is called a <em>uniform-size data-race</em>,
while a <em>data-race</em> between operations that <em>overlap</em> partially is called a <em>mixed-size data-race</em>.</p>
<p>The axioms in the memory consistency model do not apply if a PTX program contains one or more
<em>mixed-size data-races</em>. But these axioms are sufficient to describe the behavior of a PTX program
with only <em>uniform-size data-races</em>.</p>
<p class="rubric">Atomicity of mixed-size RMW operations</p>
<p>In any program with or without <em>mixed-size data-races</em>, the following property holds for every pair
of <em>overlapping atomic</em> operations A1 and A2 such that each specifies a <em>scope</em> that includes the
other: Either the <em>read-modify-write</em> operation specified by A1 is performed completely before A2 is
initiated, or vice versa. This property holds irrespective of whether the two operations A1 and A2
overlap partially or completely.</p>
</section>
</section>
<section id="release-acquire-patterns">
<span id="id129"></span><h2>
<span class="section-number">8.8. </span><a class="reference internal" href="#release-acquire-patterns">Release and Acquire Patterns</a><a class="headerlink" href="#release-acquire-patterns" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Some sequences of instructions give rise to patterns that participate in memory synchronization as
described later. The <em>release</em> pattern makes prior operations from the current thread<sup>1</sup>
visible to some operations from other threads. The <em>acquire</em> pattern makes some operations from
other threads visible to later operations from the current thread.</p>
<p>A <em>release</em> pattern on a location M consists of one of the following:</p>
<ol class="arabic">
<li>
<p>A <em>release</em> operation on M</p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">st.release</span> <span class="pre">[M];</span></code> or <code class="docutils literal notranslate"><span class="pre">atom.release</span> <span class="pre">[M];</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive.release</span> <span class="pre">[M];</span></code></p>
</li>
<li>
<p>Or a <em>release</em> or <em>acquire-release</em> operation on M followed by a <em>strong</em> write on M in <em>program order</em></p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">st.release</span> <span class="pre">[M]</span></code>; <code class="docutils literal notranslate"><span class="pre">st.relaxed</span> <span class="pre">[M];</span></code></p>
</li>
<li>
<p>Or a <em>release</em> or <em>acquire-release</em> <em>memory fence</em> followed by a <em>strong</em>
write on M in <em>program order</em></p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">fence.release;</span> <span class="pre">st.relaxed</span> <span class="pre">[M];</span></code> or <code class="docutils literal notranslate"><span class="pre">fence.release;</span> <span class="pre">atom.relaxed</span> <span class="pre">[M];</span></code></p>
</li>
</ol>
<p>Any <em>memory synchronization</em> established by a <em>release</em> pattern only affects operations occurring in
<em>program order</em> before the first instruction in that pattern.</p>
<p>An <em>acquire</em> pattern on a location M consists of one of the following:</p>
<ol class="arabic">
<li>
<p>An <em>acquire</em> operation on M</p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">ld.acquire</span> <span class="pre">[M];</span></code> or <code class="docutils literal notranslate"><span class="pre">atom.acquire</span> <span class="pre">[M];</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait.acquire</span> <span class="pre">[M];</span></code></p>
</li>
<li>
<p>Or a <em>strong</em> read on M followed by an <em>acquire</em> operation on M in <em>program order</em></p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">ld.relaxed</span> <span class="pre">[M];</span> <span class="pre">ld.acquire</span> <span class="pre">[M];</span></code></p>
</li>
<li>
<p>Or a <em>strong</em> read on M followed by an acquire <em>memory fence</em> in <em>program order</em></p>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">ld.relaxed</span> <span class="pre">[M];</span> <span class="pre">fence.acquire;</span></code> or <code class="docutils literal notranslate"><span class="pre">atom.relaxed</span> <span class="pre">[M];</span> <span class="pre">fence.acquire;</span></code></p>
</li>
</ol>
<p>Any <em>memory synchronization</em> established by an <em>acquire</em> pattern only affects operations occurring
in <em>program order</em> after the last instruction in that pattern.</p>
<p>Note that while atomic reductions conceptually perform a strong read as part of its
read-modify-write sequence, this strong read does not form an acquire pattern.</p>
<blockquote>
<div>
<p>E.g.: <code class="docutils literal notranslate"><span class="pre">red.add</span> <span class="pre">[M],</span> <span class="pre">1;</span> <span class="pre">fence.acquire;</span></code> is not an acquire pattern.</p>
</div>
</blockquote>
<p><sup>1</sup> For both <em>release</em> and <em>acquire</em> patterns, this effect is further extended to operations in
other threads through the transitive nature of <em>causality order</em>.</p>
</section>
<section id="ordering-memory-operations">
<span id="id130"></span><h2>
<span class="section-number">8.9. </span><a class="reference internal" href="#ordering-memory-operations">Ordering of memory operations</a><a class="headerlink" href="#ordering-memory-operations" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The sequence of operations performed by each thread is captured as <em>program order</em> while <em>memory
synchronization</em> across threads is captured as <em>causality order</em>. The visibility of the side-effects
of memory operations to other memory operations is captured as <em>communication order</em>. The memory
consistency model defines contradictions that are disallowed between communication order on the one
hand, and <em>causality order</em> and <em>program order</em> on the other.</p>
<section id="program-order">
<span id="id131"></span><h3>
<span class="section-number">8.9.1. </span><a class="reference internal" href="#program-order">Program Order</a><a class="headerlink" href="#program-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <em>program order</em> relates all operations performed by a thread to the order in which a sequential
processor will execute instructions in the corresponding PTX source. It is a transitive relation
that forms a total order over the operations performed by the thread, but does not relate operations
from different threads.</p>
<section id="program-order-async-operations">
<span id="id132"></span><h4>
<span class="section-number">8.9.1.1. </span><a class="reference internal" href="#program-order-async-operations">Asynchronous Operations</a><a class="headerlink" href="#program-order-async-operations" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Some PTX instructions (all variants of <code class="docutils literal notranslate"><span class="pre">cp.async</span></code>, <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code>, <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code>,
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>) perform operations that are asynchronous to the thread that executed the
instruction. These asynchronous operations are ordered after prior instructions in the same thread
(except in the case of <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>), but they are not part of the program order for that
thread. Instead, they provide weaker ordering guarantees as documented in the instruction
description.</p>
<p>For example, the loads and stores performed as part of a <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> are ordered with respect to
each other, but not to those of any other <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instructions initiated by the same thread,
nor any other instruction subsequently issued by the thread with the exception of
<code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code> or <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code>. The asynchronous mbarrier <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a> operation
performed by a <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code> instruction is ordered with respect to the memory
operations performed by all prior <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations initiated by the same thread, but not to
those of any other instruction issued by the thread. The implicit mbarrier <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation that is part of all variants of <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code>
instructions is ordered only with respect to the memory operations performed by the same
asynchronous instruction, and in particular it does not transitively establish ordering with respect
to prior instructions from the issuing thread.</p>
</section>
</section>
<section id="observation-order">
<span id="id133"></span><h3>
<span class="section-number">8.9.2. </span><a class="reference internal" href="#observation-order">Observation Order</a><a class="headerlink" href="#observation-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p><em>Observation order</em> relates a write W to a read R through an optional sequence of atomic
read-modify-write operations.</p>
<p>A write W precedes a read R in <em>observation order</em> if:</p>
<ol class="arabic simple">
<li><p>R and W are <em>morally strong</em> and R reads the value written by W, or</p></li>
<li><p>For some atomic operation Z, W precedes Z and Z precedes R in <em>observation order</em>.</p></li>
</ol>
</section>
<section id="fence-sc-order">
<span id="id134"></span><h3>
<span class="section-number">8.9.3. </span><a class="reference internal" href="#fence-sc-order">Fence-SC Order</a><a class="headerlink" href="#fence-sc-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <em>Fence-SC</em> order is an acyclic partial order, determined at runtime, that relates every pair of
<em>morally strong fence.sc</em> operations.</p>
</section>
<section id="memory-synchronization">
<span id="id135"></span><h3>
<span class="section-number">8.9.4. </span><a class="reference internal" href="#memory-synchronization">Memory synchronization</a><a class="headerlink" href="#memory-synchronization" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Synchronizing operations performed by different threads synchronize with each other at runtime as
described here. The effect of such synchronization is to establish <em>causality order</em> across threads.</p>
<ol class="arabic simple">
<li><p>A <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> operation X <em>synchronizes</em> with a <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> operation Y if X precedes Y in the
<em>Fence-SC</em> order.</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">bar{.cta}.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">bar{.cta}.red</span></code> or <code class="docutils literal notranslate"><span class="pre">bar{.cta}.arrive</span></code> operation <em>synchronizes</em> with a
<code class="docutils literal notranslate"><span class="pre">bar{.cta}.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">bar{.cta}.red</span></code> operation executed on the same barrier.</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> operation synchronizes with a <code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code> operation.</p></li>
<li><p>A <em>release</em> pattern X <em>synchronizes</em> with an <em>acquire</em> pattern Y, if a <em>write</em> operation in X
precedes a <em>read</em> operation in Y in <em>observation order</em>, and the first operation in X and the
last operation in Y are <em>morally strong</em>.</p></li>
</ol>
<p class="rubric">API synchronization</p>
<p>A <em>synchronizes</em> relation can also be established by certain CUDA APIs.</p>
<ol class="arabic simple">
<li><p>Completion of a task enqueued in a CUDA stream <em>synchronizes</em> with the start of the following
task in the same stream, if any.</p></li>
<li><p>For purposes of the above, recording or waiting on a CUDA event in a stream, or causing a
cross-stream barrier to be inserted due to <code class="docutils literal notranslate"><span class="pre">cudaStreamLegacy</span></code>, enqueues tasks in the associated
streams even if there are no direct side effects. An event record task <em>synchronizes</em> with
matching event wait tasks, and a barrier arrival task <em>synchronizes</em> with matching barrier wait
tasks.</p></li>
<li><p>Start of a CUDA kernel <em>synchronizes</em> with start of all threads in the kernel. End of all threads
in a kernel <em>synchronize</em> with end of the kernel.</p></li>
<li><p>Start of a CUDA graph <em>synchronizes</em> with start of all source nodes in the graph. Completion of
all sink nodes in a CUDA graph <em>synchronizes</em> with completion of the graph. Completion of a graph
node <em>synchronizes</em> with start of all nodes with a direct dependency.</p></li>
<li><p>Start of a CUDA API call to enqueue a task <em>synchronizes</em> with start of the task.</p></li>
<li><p>Completion of the last task queued to a stream, if any, <em>synchronizes</em> with return from
<code class="docutils literal notranslate"><span class="pre">cudaStreamSynchronize</span></code>. Completion of the most recently queued matching event record task, if
any, <em>synchronizes</em> with return from <code class="docutils literal notranslate"><span class="pre">cudaEventSynchronize</span></code>. Synchronizing a CUDA device or
context behaves as if synchronizing all streams in the context, including ones that have been
destroyed.</p></li>
<li><p>Returning <code class="docutils literal notranslate"><span class="pre">cudaSuccess</span></code> from an API to query a CUDA handle, such as a stream or event, behaves
the same as return from the matching synchronization API.</p></li>
</ol>
<p>In addition to establishing a <em>synchronizes</em> relation, the CUDA API synchronization mechanisms above
also participate in <em>proxy-preserved base causality order</em>.</p>
</section>
<section id="causality-order">
<span id="id136"></span><h3>
<span class="section-number">8.9.5. </span><a class="reference internal" href="#causality-order">Causality Order</a><a class="headerlink" href="#causality-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p><em>Causality order</em> captures how memory operations become visible across threads through synchronizing
operations. The axiom â€œCausalityâ€ uses this order to constrain the set of write operations from
which a read operation may read a value.</p>
<p>Relations in the <em>causality order</em> primarily consist of relations in <em>Base causality order</em><sup>1</sup> , which is a transitive order, determined at runtime.</p>
<p class="rubric">Base causality order</p>
<p>An operation X precedes an operation Y in <em>base causality order</em> if:</p>
<ol class="arabic simple">
<li><p>X precedes Y in <em>program order</em>, or</p></li>
<li><p>X <em>synchronizes</em> with Y, or</p></li>
<li>
<p>For some operation Z,</p>
<ol class="loweralpha simple">
<li><p>X precedes Z in <em>program order</em> and Z precedes Y in <em>base causality order</em>, or</p></li>
<li><p>X precedes Z in <em>base causality order</em> and Z precedes Y in <em>program order</em>, or</p></li>
<li><p>X precedes Z in <em>base causality order</em> and Z precedes Y in <em>base causality order</em>.</p></li>
</ol>
</li>
</ol>
<p class="rubric">Proxy-preserved base causality order</p>
<p>A memory operation X precedes a memory operation Y in <em>proxy-preserved base causality order</em> if X
precedes Y in <em>base causality order</em>, and:</p>
<ol class="arabic simple">
<li><p>X and Y are performed to the same address, using the <em>generic proxy</em>, or</p></li>
<li><p>X and Y are performed to the same address, using the same <em>proxy</em>, and by the same thread block,
or</p></li>
<li><p>X and Y are aliases and there is an alias <em>proxy fence</em> along the base causality path from X
to Y.</p></li>
</ol>
<p class="rubric">Causality order</p>
<p><em>Causality order</em> combines <em>base causality order</em> with some non-transitive relations as follows:</p>
<p>An operation X precedes an operation Y in <em>causality order</em> if:</p>
<ol class="arabic simple">
<li><p>X precedes Y in <em>proxy-preserved base causality order</em>, or</p></li>
<li><p>For some operation Z, X precedes Z in observation order, and Z precedes Y in <em>proxy-preserved
base causality order</em>.</p></li>
</ol>
<p><sup>1</sup> The transitivity of <em>base causality order</em> accounts for the â€œcumulativityâ€ of synchronizing
operations.</p>
</section>
<section id="coherence-order">
<span id="id137"></span><h3>
<span class="section-number">8.9.6. </span><a class="reference internal" href="#coherence-order">Coherence Order</a><a class="headerlink" href="#coherence-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p>There exists a partial transitive order that relates <em>overlapping</em> write operations, determined at
runtime, called the <em>coherence order</em><sup>1</sup>. Two <em>overlapping</em> write operations are related in
<em>coherence order</em> if they are <em>morally strong</em> or if they are related in <em>causality order</em>. Two
<em>overlapping</em> writes are unrelated in <em>coherence order</em> if they are in a <em>data-race</em>, which gives
rise to the partial nature of <em>coherence order</em>.</p>
<p><sup>1</sup> <em>Coherence order</em> cannot be observed directly since it consists entirely of write
operations. It may be observed indirectly by its use in constraining the set of candidate
writes that a read operation may read from.</p>
</section>
<section id="communication-order">
<span id="id138"></span><h3>
<span class="section-number">8.9.7. </span><a class="reference internal" href="#communication-order">Communication Order</a><a class="headerlink" href="#communication-order" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The <em>communication order</em> is a non-transitive order, determined at runtime, that relates write
operations to other <em>overlapping</em> memory operations.</p>
<ol class="arabic simple">
<li><p>A write W precedes an <em>overlapping</em> read R in <em>communication order</em> if R returns the value of any
byte that was written by W.</p></li>
<li><p>A write W precedes a write Wâ€™ in <em>communication order</em> if W precedes Wâ€™ in <em>coherence order</em>.</p></li>
<li><p>A read R precedes an <em>overlapping</em> write W in <em>communication order</em> if, for any byte accessed by
both R and W, R returns the value written by a write Wâ€™ that precedes W in <em>coherence order</em>.</p></li>
</ol>
<p><em>Communication order</em> captures the visibility of memory operations â€” when a memory operation X1
precedes a memory operation X2 in <em>communication order</em>, X1 is said to be visible to X2.</p>
</section>
</section>
<section id="axioms">
<span id="id139"></span><h2>
<span class="section-number">8.10. </span><a class="reference internal" href="#axioms">Axioms</a><a class="headerlink" href="#axioms" title="Permalink to this headline">ïƒ</a>
</h2>
<section id="coherence-axiom">
<span id="id140"></span><h3>
<span class="section-number">8.10.1. </span><a class="reference internal" href="#coherence-axiom">Coherence</a><a class="headerlink" href="#coherence-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p>If a write W precedes an <em>overlapping</em> write Wâ€™ in <em>causality order</em>, then W must precede Wâ€™ in
<em>coherence order</em>.</p>
</section>
<section id="fence-sc-axiom">
<span id="id141"></span><h3>
<span class="section-number">8.10.2. </span><a class="reference internal" href="#fence-sc-axiom">Fence-SC</a><a class="headerlink" href="#fence-sc-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p><em>Fence-SC</em> order cannot contradict <em>causality order</em>. For a pair of <em>morally strong</em> <em>fence.sc</em>
operations F1 and F2, if F1 precedes F2 in <em>causality order</em>, then F1 must precede F2 in <em>Fence-SC</em>
order.</p>
</section>
<section id="atomicity-axiom">
<span id="id142"></span><h3>
<span class="section-number">8.10.3. </span><a class="reference internal" href="#atomicity-axiom">Atomicity</a><a class="headerlink" href="#atomicity-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric">Single-Copy Atomicity</p>
<p>Conflicting <em>morally strong</em> operations are performed with <em>single-copy atomicity</em>. When a read R
and a write W are <em>morally strong</em>, then the following two communications cannot both exist in the
same execution, for the set of bytes accessed by both R and W:</p>
<ol class="arabic simple">
<li><p>R reads any byte from W.</p></li>
<li><p>R reads any byte from any write Wâ€™ which precedes W in <em>coherence order</em>.</p></li>
</ol>
<p class="rubric">Atomicity of read-modify-write (RMW) operations</p>
<p>When an <em>atomic</em> operation A and a write W <em>overlap</em> and are <em>morally strong</em>, then the following
two communications cannot both exist in the same execution, for the set of bytes accessed by both A
and W:</p>
<ol class="arabic simple">
<li><p>A reads any byte from a write Wâ€™ that precedes W in <em>coherence order</em>.</p></li>
<li><p>A follows W in <em>coherence order</em>.</p></li>
</ol>
<p class="rubric">Litmus Test 1</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A1</span><span class="p">:</span><span class="w"> </span><span class="n">atom</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">inc</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A2</span><span class="p">:</span><span class="w"> </span><span class="n">atom</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">inc</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">FINAL</span><span class="w"> </span><span class="n">STATE</span><span class="o">:</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>Atomicity is guaranteed when the operations are <em>morally strong</em>.</p>
<p class="rubric">Litmus Test 2</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2 (In a different CTA)</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A1</span><span class="p">:</span><span class="w"> </span><span class="n">atom</span><span class="p">.</span><span class="n">cta</span><span class="p">.</span><span class="n">inc</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A2</span><span class="p">:</span><span class="w"> </span><span class="n">atom</span><span class="p">.</span><span class="n">gpu</span><span class="p">.</span><span class="n">inc</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">FINAL</span><span class="w"> </span><span class="n">STATE</span><span class="o">:</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">OR</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>Atomicity is not guaranteed if the operations are not <em>morally strong</em>.</p>
</section>
<section id="no-thin-air-axiom">
<span id="id143"></span><h3>
<span class="section-number">8.10.4. </span><a class="reference internal" href="#no-thin-air-axiom">No Thin Air</a><a class="headerlink" href="#no-thin-air-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Values may not appear â€œout of thin airâ€: an execution cannot speculatively produce a value in such a
way that the speculation becomes self-satisfying through chains of instruction dependencies and
inter-thread communication. This matches both programmer intuition and hardware reality, but is
necessary to state explicitly when performing formal analysis.</p>
<p class="rubric">Litmus Test: Load Buffering</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A1</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
<span class="nl">B1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">y</span><span class="p">],</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">A2</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">y</span><span class="p">];</span><span class="w"></span>
<span class="nl">B2</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">],</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">FINAL</span><span class="w"> </span><span class="n">STATE</span><span class="o">:</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The litmus test known as â€œLBâ€ (Load Buffering) checks such forbidden values that may arise out of
thin air. Two threads T1 and T2 each read from a first variable and copy the observed result into a
second variable, with the first and second variable exchanged between the threads. If each variable
is initially zero, the final result shall also be zero. If A1 reads from B2 and A2 reads from B1,
then values passing through the memory operations in this example form a cycle:
A1-&gt;B1-&gt;A2-&gt;B2-&gt;A1. Only the values x == 0 and y == 0 are allowed to satisfy this cycle. If any of
the memory operations in this example were to speculatively associate a different value with the
corresponding memory location, then such a speculation would become self-fulfilling, and hence
forbidden.</p>
</section>
<section id="sc-per-loc-axiom">
<span id="id144"></span><h3>
<span class="section-number">8.10.5. </span><a class="reference internal" href="#sc-per-loc-axiom">Sequential Consistency Per Location</a><a class="headerlink" href="#sc-per-loc-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Within any set of <em>overlapping</em> memory operations that are pairwise <em>morally strong</em>, <em>communication
order</em> cannot contradict <em>program order</em>, i.e., a concatenation of <em>program order</em> between
<em>overlapping</em> operations and <em>morally strong</em> relations in <em>communication order</em> cannot result in a
cycle. This ensures that each program slice of <em>overlapping</em> pairwise morally <em>strong operations</em> is
strictly <em>sequentially-consistent</em>.</p>
<p class="rubric">Litmus Test: CoRR</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">R1</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
<span class="nl">R2</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">IF</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">THEN</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The litmus test â€œCoRRâ€ (Coherent Read-Read), demonstrates one consequence of this guarantee. A
thread T1 executes a write W1 on a location x, and a thread T2 executes two (or an infinite sequence
of) reads R1 and R2 on the same location x. No other writes are executed on x, except the one
modelling the initial value. The operations W1, R1 and R2 are pairwise <em>morally strong</em>. If R1 reads
from W1, then the subsequent read R2 must also observe the same value. If R2 observed the initial
value of x instead, then this would form a sequence of <em>morally-strong</em> relations R2-&gt;W1-&gt;R1 in
<em>communication order</em> that contradicts the <em>program order</em> R1-&gt;R2 in thread T2. Hence R2 cannot read
the initial value of x in such an execution.</p>
</section>
<section id="causality-axiom">
<span id="id145"></span><h3>
<span class="section-number">8.10.6. </span><a class="reference internal" href="#causality-axiom">Causality</a><a class="headerlink" href="#causality-axiom" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Relations in <em>communication order</em> cannot contradict <em>causality order</em>. This constrains the set of
candidate write operations that a read operation may read from:</p>
<ol class="arabic simple">
<li><p>If a read R precedes an <em>overlapping</em> write W in <em>causality order</em>, then R cannot read from W.</p></li>
<li><p>If a write W precedes an <em>overlapping</em> read R in <em>causality order</em>, then for any byte accessed by
both R and W, R cannot read from any write Wâ€™ that precedes W in <em>coherence order</em>.</p></li>
</ol>
<p class="rubric">Litmus Test: Message Passing</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">flag</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">data</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
<span class="nl">F1</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">sys</span><span class="p">;</span><span class="w"></span>
<span class="nl">W2</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">flag</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">R1</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">flag</span><span class="p">];</span><span class="w"></span>
<span class="nl">F2</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">sys</span><span class="p">;</span><span class="w"></span>
<span class="nl">R2</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">data</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">IF</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">THEN</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The litmus test known as â€œMPâ€ (Message Passing) represents the essence of typical synchronization
algorithms. A vast majority of useful programs can be reduced to sequenced applications of this
pattern.</p>
<p>Thread T1 first writes to a data variable and then to a flag variable while a second thread T2 first
reads from the flag variable and then from the data variable. The operations on the flag are
<em>morally strong</em> and the memory operations in each thread are separated by a <em>fence</em>, and these
<em>fences</em> are <em>morally strong</em>.</p>
<p>If R1 observes W2, then the release pattern â€œF1; W2â€ <em>synchronizes</em> with the <em>acquire pattern</em> â€œR1;
F2â€. This establishes the <em>causality order</em> W1 -&gt; F1 -&gt; W2 -&gt; R1 -&gt; F2 -&gt; R2. Then axiom <em>causality</em>
guarantees that R2 cannot read from any write that precedes W1 in <em>coherence order</em>. In the absence
of any other writes in this example, R2 must read from W1.</p>
<p class="rubric">Litmus Test: CoWR</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 100%">
</colgroup>
<tbody>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="c1">// These addresses are aliases</span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">data_alias_1</span><span class="p">;</span><span class="w"></span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">data_alias_2</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">data_alias_1</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
<span class="nl">F1</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">proxy</span><span class="p">.</span><span class="n">alias</span><span class="p">;</span><span class="w"></span>
<span class="nl">R1</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">data_alias_2</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">r1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>Virtual aliases require an alias <em>proxy fence</em> along the synchronization path.</p>
<p class="rubric">Litmus Test: Store Buffering</p>
<p>The litmus test known as â€œSBâ€ (Store Buffering) demonstrates the <em>sequential consistency</em> enforced
by the <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code>. A thread T1 writes to a first variable, and then reads the value of a second
variable, while a second thread T2 writes to the second variable and then reads the value of the
first variable. The memory operations in each thread are separated by <code class="docutils literal notranslate"><span class="pre">fence.</span></code>sc instructions,
and these <em>fences</em> are <em>morally strong</em>.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
<span class="nl">F1</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">sc</span><span class="p">.</span><span class="n">sys</span><span class="p">;</span><span class="w"></span>
<span class="nl">R1</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r0</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">y</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W2</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">y</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
<span class="nl">F2</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">sc</span><span class="p">.</span><span class="n">sys</span><span class="p">;</span><span class="w"></span>
<span class="nl">R2</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">r0</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">OR</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>In any execution, either F1 precedes F2 in <em>Fence-SC</em> order, or vice versa. If F1 precedes F2 in
<em>Fence-SC</em> order, then F1 <em>synchronizes</em> with F2. This establishes the <em>causality order</em> in W1 -&gt; F1
-&gt; F2 -&gt; R2. Axiom <em>causality</em> ensures that R2 cannot read from any write that precedes W1 in
<em>coherence order</em>. In the absence of any other write to that variable, R2 must read from
W1. Similarly, in the case where F2 precedes F1 in <em>Fence-SC</em> order, R1 must read from W2. If each
<code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> in this example were replaced by a <code class="docutils literal notranslate"><span class="pre">fence.acq_rel</span></code> instruction, then this outcome is
not guaranteed. There may be an execution where the write from each thread remains unobserved from
the other thread, i.e., an execution is possible, where both R1 and R2 return the initial value â€œ0â€
for variables y and x respectively.</p>
</section>
</section>
<section id="special-cases">
<span id="id146"></span><h2>
<span class="section-number">8.11. </span><a class="reference internal" href="#special-cases">Special Cases</a><a class="headerlink" href="#special-cases" title="Permalink to this headline">ïƒ</a>
</h2>
<section id="red-read">
<span id="id147"></span><h3>
<span class="section-number">8.11.1. </span><a class="reference internal" href="#red-read">Reductions do not form Acquire Patterns</a><a class="headerlink" href="#red-read" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Atomic reduction operations like <code class="docutils literal notranslate"><span class="pre">red</span></code> do not form acquire patterns with acquire fences.</p>
<p><strong>Litmus Test: Message Passing with a Red Instruction</strong></p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 47%">
<col style="width: 53%">
</colgroup>
<tbody>
<tr class="row-odd">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
<span class="p">.</span><span class="n">global</span><span class="w"> </span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="n">flag</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td><p>T1</p></td>
<td><p>T2</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">W1</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">],</span><span class="w"> </span><span class="mi">42</span><span class="p">;</span><span class="w"></span>
<span class="nl">W2</span><span class="p">:</span><span class="w"> </span><span class="n">st</span><span class="p">.</span><span class="n">release</span><span class="p">.</span><span class="n">gpu</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">flag</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
</pre></div>
</div>
</td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="nl">RMW1</span><span class="p">:</span><span class="w"> </span><span class="n">red</span><span class="p">.</span><span class="n">sys</span><span class="p">.</span><span class="n">global</span><span class="p">.</span><span class="n">add</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="p">[</span><span class="n">flag</span><span class="p">],</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"></span>
<span class="nl">F2</span><span class="p">:</span><span class="w"> </span><span class="n">fence</span><span class="p">.</span><span class="n">acquire</span><span class="p">.</span><span class="n">gpu</span><span class="p">;</span><span class="w"></span>
<span class="nl">R2</span><span class="p">:</span><span class="w"> </span><span class="n">ld</span><span class="p">.</span><span class="n">weak</span><span class="p">.</span><span class="n">u32</span><span class="w"> </span><span class="o">%</span><span class="n">r1</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">];</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-even">
<td colspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">r1</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">AND</span><span class="w"> </span><span class="n">flag</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The litmus test known as â€œMPâ€ (Message Passing) demonstrates the consequence
of reductions being excluded from acquire patterns.
It is possible to observe the outcome where <code class="docutils literal notranslate"><span class="pre">R2</span></code> reads the value <code class="docutils literal notranslate"><span class="pre">0</span></code>
from <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">flag</span></code> has the final value of <code class="docutils literal notranslate"><span class="pre">2</span></code>.
This outcome is possible since the release pattern in <code class="docutils literal notranslate"><span class="pre">T1</span></code> does not synchronize
with any acquire pattern in <code class="docutils literal notranslate"><span class="pre">T2</span></code>.
Using the <code class="docutils literal notranslate"><span class="pre">atom</span></code> instruction instead of <code class="docutils literal notranslate"><span class="pre">red</span></code> forbids this outcome.</p>
</section>
</section>
</section>
<section id="instruction-set">
<span id="id148"></span><h1>
<span class="section-number">9. </span><a class="reference internal" href="#instruction-set">Instruction Set</a><a class="headerlink" href="#instruction-set" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="format-and-semantics-of-instruction-descriptions">
<span id="id149"></span><h2>
<span class="section-number">9.1. </span><a class="reference internal" href="#format-and-semantics-of-instruction-descriptions">Format and Semantics of Instruction Descriptions</a><a class="headerlink" href="#format-and-semantics-of-instruction-descriptions" title="Permalink to this headline">ïƒ</a>
</h2>
<p>This section describes each PTX instruction. In addition to the name and the format of the
instruction, the semantics are described, followed by some examples that attempt to show several
possible instantiations of the instruction.</p>
</section>
<section id="ptx-instructions">
<span id="id150"></span><h2>
<span class="section-number">9.2. </span><a class="reference internal" href="#ptx-instructions">PTX Instructions</a><a class="headerlink" href="#ptx-instructions" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX instructions generally have from zero to four operands, plus an optional guard predicate
appearing after an <code class="docutils literal notranslate"><span class="pre">@</span></code> symbol to the left of the <code class="docutils literal notranslate"><span class="pre">opcode</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">@p</span>Â Â  <span class="pre">opcode;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@p</span>Â Â  <span class="pre">opcode</span> <span class="pre">a;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@p</span>Â Â  <span class="pre">opcode</span> <span class="pre">d,</span> <span class="pre">a;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@p</span>Â Â  <span class="pre">opcode</span> <span class="pre">d,</span> <span class="pre">a,</span> <span class="pre">b;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@p</span>Â Â  <span class="pre">opcode</span> <span class="pre">d,</span> <span class="pre">a,</span> <span class="pre">b,</span> <span class="pre">c;</span></code></p></li>
</ul>
<p>For instructions that create a result value, the <code class="docutils literal notranslate"><span class="pre">d</span></code> operand is the destination operand, while
<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, and <code class="docutils literal notranslate"><span class="pre">c</span></code> are source operands.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">setp</span></code> instruction writes two destination registers. We use a <code class="docutils literal notranslate"><span class="pre">|</span></code> symbol to separate
multiple destination registers.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setp.lt.s32  p|q, a, b;  // p = (a &lt; b); q = !(a &lt; b);
</pre></div>
</div>
<p>For some instructions the destination operand is optional. A <em>bit bucket</em> operand denoted with an
underscore (<code class="docutils literal notranslate"><span class="pre">_</span></code>) may be used in place of a destination register.</p>
</section>
<section id="predicated-execution">
<span id="id151"></span><h2>
<span class="section-number">9.3. </span><a class="reference internal" href="#predicated-execution">Predicated Execution</a><a class="headerlink" href="#predicated-execution" title="Permalink to this headline">ïƒ</a>
</h2>
<p>In PTX, predicate registers are virtual and have <code class="docutils literal notranslate"><span class="pre">.pred</span></code> as the type specifier. So, predicate
registers can be declared as</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .pred p, q, r;
</pre></div>
</div>
<p>All instructions have an optional <em>guard predicate</em> which controls conditional execution of the
instruction. The syntax to specify conditional execution is to prefix an instruction with <code class="docutils literal notranslate"><span class="pre">@{!}p</span></code>,
where <code class="docutils literal notranslate"><span class="pre">p</span></code> is a predicate variable, optionally negated. Instructions without a guard predicate are
executed unconditionally.</p>
<p>Predicates are most commonly set as the result of a comparison performed by the <code class="docutils literal notranslate"><span class="pre">setp</span></code>
instruction.</p>
<p>As an example, consider the high-level code</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (i &lt; n)
    j = j + 1;
</pre></div>
</div>
<p>This can be written in PTX as</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>      setp.lt.s32  p, i, n;    // p = (i &lt; n)
@p    add.s32      j, j, 1;    // if i &lt; n, add 1 to j
</pre></div>
</div>
<p>To get a conditional branch or conditional function call, use a predicate to control the execution
of the branch or call instructions. To implement the above example as a true conditional branch, the
following PTX instruction sequence might be used:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>      setp.lt.s32  p, i, n;    // compare i to n
@!p   bra  L1;                 // if False, branch over
      add.s32      j, j, 1;
L1:     ...
</pre></div>
</div>
<section id="comparisons">
<span id="id152"></span><h3>
<span class="section-number">9.3.1. </span><a class="reference internal" href="#comparisons">Comparisons</a><a class="headerlink" href="#comparisons" title="Permalink to this headline">ïƒ</a>
</h3>
<section id="integer-and-bit-size-comparisons">
<span id="id153"></span><h4>
<span class="section-number">9.3.1.1. </span><a class="reference internal" href="#integer-and-bit-size-comparisons">Integer and Bit-Size Comparisons</a><a class="headerlink" href="#integer-and-bit-size-comparisons" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The signed integer comparisons are the traditional <code class="docutils literal notranslate"><span class="pre">eq</span></code> (equal), <code class="docutils literal notranslate"><span class="pre">ne</span></code> (not-equal), <code class="docutils literal notranslate"><span class="pre">lt</span></code>
(less-than), <code class="docutils literal notranslate"><span class="pre">le</span></code> (less-than-or-equal), <code class="docutils literal notranslate"><span class="pre">gt</span></code> (greater-than), and <code class="docutils literal notranslate"><span class="pre">ge</span></code>
(greater-than-or-equal). The unsigned comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lo</span></code> (lower), <code class="docutils literal notranslate"><span class="pre">ls</span></code>
(lower-or-same), <code class="docutils literal notranslate"><span class="pre">hi</span></code> (higher), and <code class="docutils literal notranslate"><span class="pre">hs</span></code> (higher-or-same). The bit-size comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>
and <code class="docutils literal notranslate"><span class="pre">ne</span></code>; ordering comparisons are not defined for bit-size types.</p>
<p><a class="reference internal" href="#integer-and-bit-size-comparisons-operators-for-signed-integer-unsigned-integer-and-bit-size-types"><span class="std std-numref">Table 22</span></a>
shows the operators for signed integer, unsigned integer, and bit-size types.</p>
<table class="table-no-stripes docutils align-default" id="integer-and-bit-size-comparisons-operators-for-signed-integer-unsigned-integer-and-bit-size-types">
<caption>
<span class="caption-number">Table 22 </span><span class="caption-text">Operators for Signed Integer, Unsigned Integer, and Bit-Size Types</span><a class="headerlink" href="#integer-and-bit-size-comparisons-operators-for-signed-integer-unsigned-integer-and-bit-size-types" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 25%">
<col style="width: 28%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Signed Operator</p></th>
<th class="head"><p>Unsigned Operator</p></th>
<th class="head"><p>Bit-Size Operator</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">==</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">eq</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">eq</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">eq</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">!=</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ne</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ne</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ne</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">lt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">lo</span></code></p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;=</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">le</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ls</span></code></p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gt</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hi</span></code></p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;=</span> <span class="pre">b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ge</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">hs</span></code></p></td>
<td><p>n/a</p></td>
</tr>
</tbody>
</table>
</section>
<section id="floating-point-comparisons">
<span id="id154"></span><h4>
<span class="section-number">9.3.1.2. </span><a class="reference internal" href="#floating-point-comparisons">Floating Point Comparisons</a><a class="headerlink" href="#floating-point-comparisons" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The ordered floating-point comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, and <code class="docutils literal notranslate"><span class="pre">ge</span></code>. If
either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the result is
<code class="docutils literal notranslate"><span class="pre">False</span></code>. <a class="reference internal" href="#floating-point-comparisons-floating-point-operators"><span class="std std-numref">Table 23</span></a> lists the floating-point
comparison operators.</p>
<table class="table-no-stripes docutils align-default" id="floating-point-comparisons-floating-point-operators">
<caption>
<span class="caption-number">Table 23 </span><span class="caption-text">Floating-Point Comparison Operators</span><a class="headerlink" href="#floating-point-comparisons-floating-point-operators" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Floating-Point Operator</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">==</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">eq</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">!=</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ne</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">lt</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;=</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">le</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gt</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;=</span> <span class="pre">b</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ge</span></code></p></td>
</tr>
</tbody>
</table>
<p>To aid comparison operations in the presence of <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, unordered floating-point comparisons
are provided: <code class="docutils literal notranslate"><span class="pre">equ</span></code>, <code class="docutils literal notranslate"><span class="pre">neu</span></code>, <code class="docutils literal notranslate"><span class="pre">ltu</span></code>, <code class="docutils literal notranslate"><span class="pre">leu</span></code>, <code class="docutils literal notranslate"><span class="pre">gtu</span></code>, and <code class="docutils literal notranslate"><span class="pre">geu</span></code>. If both operands are numeric
values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), then the comparison has the same result as its ordered counterpart. If either
operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result of the comparison is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p><a class="reference internal" href="#floating-point-comparisons-floating-point-operators-nan"><span class="std std-numref">Table 24</span></a> lists the floating-point
comparison operators accepting <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values.</p>
<table class="table-no-stripes docutils align-default" id="floating-point-comparisons-floating-point-operators-nan">
<caption>
<span class="caption-number">Table 24 </span><span class="caption-text">Floating-Point Comparison Operators Accepting NaN</span><a class="headerlink" href="#floating-point-comparisons-floating-point-operators-nan" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 59%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Floating-Point Operator</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">==</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">equ</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">!=</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">neu</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ltu</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&lt;=</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">leu</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">gtu</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">&gt;=</span> <span class="pre">b</span> <span class="pre">||</span> <span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">geu</span></code></p></td>
</tr>
</tbody>
</table>
<p>To test for <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, two operators <code class="docutils literal notranslate"><span class="pre">num</span></code> (<code class="docutils literal notranslate"><span class="pre">numeric</span></code>) and <code class="docutils literal notranslate"><span class="pre">nan</span></code> (<code class="docutils literal notranslate"><span class="pre">isNaN</span></code>) are
provided. <code class="docutils literal notranslate"><span class="pre">num</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if both operands are numeric values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), and <code class="docutils literal notranslate"><span class="pre">nan</span></code>
returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if either operand is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>. <a class="reference internal" href="#floating-point-comparisons-floating-point-operators-testing-nan"><span class="std std-numref">Table 25</span></a> lists the
floating-point comparison operators testing for <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values.</p>
<table class="table-no-stripes docutils align-default" id="floating-point-comparisons-floating-point-operators-testing-nan">
<caption>
<span class="caption-number">Table 25 </span><span class="caption-text">Floating-Point Comparison Operators Testing for NaN</span><a class="headerlink" href="#floating-point-comparisons-floating-point-operators-testing-nan" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 53%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Meaning</p></th>
<th class="head"><p>Floating-Point Operator</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">!isNaN(a)</span> <span class="pre">&amp;&amp;</span> <span class="pre">!isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">num</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">isNaN(a)</span> <span class="pre">||</span> <span class="pre">isNaN(b)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nan</span></code></p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="manipulating-predicates">
<span id="id155"></span><h3>
<span class="section-number">9.3.2. </span><a class="reference internal" href="#manipulating-predicates">Manipulating Predicates</a><a class="headerlink" href="#manipulating-predicates" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Predicate values may be computed and manipulated using the following instructions: <code class="docutils literal notranslate"><span class="pre">and</span></code>, <code class="docutils literal notranslate"><span class="pre">or</span></code>,
<code class="docutils literal notranslate"><span class="pre">xor</span></code>, <code class="docutils literal notranslate"><span class="pre">not</span></code>, and <code class="docutils literal notranslate"><span class="pre">mov</span></code>.</p>
<p>There is no direct conversion between predicates and integer values, and no direct way to load or
store predicate register values. However, <code class="docutils literal notranslate"><span class="pre">setp</span></code> can be used to generate a predicate from an
integer, and the predicate-based select (<code class="docutils literal notranslate"><span class="pre">selp</span></code>) instruction can be used to generate an integer
value based on the value of a predicate; for example:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>selp.u32 %r1,1,0,%p;    // convert predicate to 32-bit value
</pre></div>
</div>
</section>
</section>
<section id="type-information-for-instructions-and-operands">
<span id="id156"></span><h2>
<span class="section-number">9.4. </span><a class="reference internal" href="#type-information-for-instructions-and-operands">Type Information for Instructions and Operands</a><a class="headerlink" href="#type-information-for-instructions-and-operands" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Typed instructions must have a type-size modifier. For example, the <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction requires
type and size information to properly perform the addition operation (signed, unsigned, float,
different sizes), and this information must be specified as a suffix to the opcode.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .u16 d, a, b;

add.u16 d, a, b;    // perform a 16-bit unsigned add
</pre></div>
</div>
<p>Some instructions require multiple type-size modifiers, most notably the data conversion instruction
<code class="docutils literal notranslate"><span class="pre">cvt</span></code>. It requires separate type-size modifiers for the result and source, and these are placed in
the same order as the operands. For example:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .u16 a;
.reg .f32 d;

cvt.f32.u16 d, a;   // convert 16-bit unsigned to 32-bit float
</pre></div>
</div>
<p>In general, an operandâ€™s type must agree with the corresponding instruction-type modifier. The rules
for operand and instruction type conformance are as follows:</p>
<ul class="simple">
<li><p>Bit-size types agree with any type of the same size.</p></li>
<li><p>Signed and unsigned integer types agree provided they have the same size, and integer operands are
silently cast to the instruction type if needed. For example, an unsigned integer operand used in
a signed integer instruction will be treated as a signed integer by the instruction.</p></li>
<li><p>Floating-point types agree only if they have the same size; i.e., they must match exactly.</p></li>
</ul>
<p><a class="reference internal" href="#type-information-for-instructions-and-operands-type-checking-rules"><span class="std std-numref">Table 26</span></a> summarizes these type
checking rules.</p>
<table class="table-no-stripes docutils align-default" id="type-information-for-instructions-and-operands-type-checking-rules">
<caption>
<span class="caption-number">Table 26 </span><span class="caption-text">Type Checking Rules</span><a class="headerlink" href="#type-information-for-instructions-and-operands-type-checking-rules" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="2"></th>
<th class="head" colspan="4"><p><strong>Operand Type</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td colspan="2"></td>
<td><p><strong>.bX</strong></p></td>
<td><p><strong>.sX</strong></p></td>
<td><p><strong>.uX</strong></p></td>
<td><p><strong>.fX</strong></p></td>
</tr>
<tr class="row-odd">
<td rowspan="4"><p><strong>Instruction Type</strong></p></td>
<td><p><strong>.bX</strong></p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
</tr>
<tr class="row-even">
<td><p><strong>.sX</strong></p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>invalid</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>.uX</strong></p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>okay</p></td>
<td><p>invalid</p></td>
</tr>
<tr class="row-even">
<td><p><strong>.fX</strong></p></td>
<td><p>okay</p></td>
<td><p>invalid</p></td>
<td><p>invalid</p></td>
<td><p>okay</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Some operands have their type and size defined independently from the instruction type-size. For
example, the shift amount operand for left and right shift instructions always has type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>,
while the remaining operands have their type and size determined by the instruction type.</p>
</div>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 64-bit arithmetic right shift; shift amount 'b' is .u32
    shr.s64 d,a,b;
</pre></div>
</div>
<section id="operand-size-exceeding-instruction-type-size">
<span id="id157"></span><h3>
<span class="section-number">9.4.1. </span><a class="reference internal" href="#operand-size-exceeding-instruction-type-size">Operand Size Exceeding Instruction-Type Size</a><a class="headerlink" href="#operand-size-exceeding-instruction-type-size" title="Permalink to this headline">ïƒ</a>
</h3>
<p>For convenience, <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions permit source and destination data
operands to be wider than the instruction-type size, so that narrow values may be loaded, stored,
and converted using regular-width registers. For example, 8-bit or 16-bit values may be held
directly in 32-bit or 64-bit registers when being loaded, stored, or converted to other types and
sizes. The operand type checking rules are relaxed for bit-size and integer (signed and unsigned)
instruction types; floating-point instruction types still require that the operand type-size matches
exactly, unless the operand is of bit-size type.</p>
<p>When a source operand has a size that exceeds the instruction-type size, the source data is
truncated (chopped) to the appropriate number of bits specified by the instruction type-size.</p>
<p><a class="reference internal" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-source-operands"><span class="std std-numref">Table 27</span></a>
summarizes the relaxed type-checking rules for source operands. Note that some combinations may
still be invalid for a particular instruction; for example, the <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction does not support
<code class="docutils literal notranslate"><span class="pre">.bX</span></code> instruction types, so those rows are invalid for <code class="docutils literal notranslate"><span class="pre">cvt</span></code>.</p>
<table class="table-no-stripes docutils align-default" id="operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-source-operands">
<caption>
<span class="caption-number">Table 27 </span><span class="caption-text">Relaxed Type-checking Rules for Source Operands</span><a class="headerlink" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-source-operands" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="2" rowspan="2"></th>
<th class="head" colspan="16"><p><strong>Source Operand Type</strong></p></th>
</tr>
<tr class="row-even">
<th class="head"><p><strong>b8</strong></p></th>
<th class="head"><p><strong>b16</strong></p></th>
<th class="head"><p><strong>b32</strong></p></th>
<th class="head"><p><strong>b64</strong></p></th>
<th class="head"><p><strong>b128</strong></p></th>
<th class="head"><p><strong>s8</strong></p></th>
<th class="head"><p><strong>s16</strong></p></th>
<th class="head"><p><strong>s32</strong></p></th>
<th class="head"><p><strong>s64</strong></p></th>
<th class="head"><p><strong>u8</strong></p></th>
<th class="head"><p><strong>u16</strong></p></th>
<th class="head"><p><strong>u32</strong></p></th>
<th class="head"><p><strong>u64</strong></p></th>
<th class="head"><p><strong>f16</strong></p></th>
<th class="head"><p><strong>f32</strong></p></th>
<th class="head"><p><strong>f64</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="16"><p><strong>Instruction Type</strong></p></td>
<td><p><strong>b8</strong></p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
</tr>
<tr class="row-even">
<td><p><strong>b16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>b32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
</tr>
<tr class="row-even">
<td><p><strong>b64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>b128</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s8</strong></p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>s16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>s64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u8</strong></p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>f32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>chop</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td colspan="2"><p><strong>Notes</strong></p></td>
<td colspan="16">
<p>chop = keep only low bits that fit; â€œâ€“â€ = allowed, but no conversion needed;</p>
<p>inv = invalid, parse error.</p>
<ol class="arabic simple">
<li><p>Source register size must be of equal or greater size than the instruction-type size.</p></li>
<li><p>Bit-size source registers may be used with any appropriately-sized instruction type. The data are
truncated (â€œchoppedâ€) to the instruction-type size and interpreted according to the instruction
type.</p></li>
<li><p>Integer source registers may be used with any appropriately-sized bit-size or integer instruction
type. The data are truncated to the instruction-type size and interpreted according to the
instruction type.</p></li>
<li><p>Floating-point source registers can only be used with bit-size or floating-point instruction types.
When used with a narrower bit-size instruction type, the data are truncated. When used with a
floating-point instruction type, the size must match exactly.</p></li>
</ol>
</td>
</tr>
</tbody>
</table>
<p>When a destination operand has a size that exceeds the instruction-type size, the destination data
is zero- or sign-extended to the size of the destination register. If the corresponding instruction
type is signed integer, the data is sign-extended; otherwise, the data is zero-extended.</p>
<p><a class="reference internal" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-destination-operands"><span class="std std-numref">Table 28</span></a>
summarizes the relaxed type-checking rules for destination operands.</p>
<table class="table-no-stripes docutils align-default" id="operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-destination-operands">
<caption>
<span class="caption-number">Table 28 </span><span class="caption-text">Relaxed Type-checking Rules for Destination Operands</span><a class="headerlink" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-destination-operands" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="2" rowspan="2"></th>
<th class="head" colspan="16"><p><strong>Destination Operand Type</strong></p></th>
</tr>
<tr class="row-even">
<th class="head"><p><strong>b8</strong></p></th>
<th class="head"><p><strong>b16</strong></p></th>
<th class="head"><p><strong>b32</strong></p></th>
<th class="head"><p><strong>b64</strong></p></th>
<th class="head"><p><strong>b128</strong></p></th>
<th class="head"><p><strong>s8</strong></p></th>
<th class="head"><p><strong>s16</strong></p></th>
<th class="head"><p><strong>s32</strong></p></th>
<th class="head"><p><strong>s64</strong></p></th>
<th class="head"><p><strong>u8</strong></p></th>
<th class="head"><p><strong>u16</strong></p></th>
<th class="head"><p><strong>u32</strong></p></th>
<th class="head"><p><strong>u64</strong></p></th>
<th class="head"><p><strong>f16</strong></p></th>
<th class="head"><p><strong>f32</strong></p></th>
<th class="head"><p><strong>f64</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="16"><p><strong>Instruction Type</strong></p></td>
<td><p><strong>b8</strong></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
</tr>
<tr class="row-even">
<td><p><strong>b16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>b32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
</tr>
<tr class="row-even">
<td><p><strong>b64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>b128</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s8</strong></p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>s16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>s32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>s64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>sext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u8</strong></p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>u32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>u64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f16</strong></p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-odd">
<td><p><strong>f32</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>inv</p></td>
</tr>
<tr class="row-even">
<td><p><strong>f64</strong></p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
<td><p>zext</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>inv</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td colspan="2"><p><strong>Notes</strong></p></td>
<td colspan="16">
<p>sext = sign-extend; zext = zero-extend; â€œâ€“â€ = allowed, but no conversion needed;</p>
<p>inv = invalid, parse error.</p>
<ol class="arabic simple">
<li><p>Destination register size must be of equal or greater size than the instruction-type size.</p></li>
<li><p>Bit-size destination registers may be used with any appropriately-sized instruction type. The data
are sign-extended to the destination register width for signed integer instruction types, and are
zero-extended to the destination register width otherwise.</p></li>
<li><p>Integer destination registers may be used with any appropriately-sized bit-size or integer
instruction type. The data are sign-extended to the destination register width for signed integer
instruction types, and are zero-extended to the destination register width for bit-size an d
unsigned integer instruction types.</p></li>
<li><p>Floating-point destination registers can only be used with bit-size or floating-point instruction
types. When used with a narrower bit-size instruction type, the data are zero-extended. When used
with a floating-point instruction type, the size must match exactly.</p></li>
</ol>
</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="divergence-of-threads-in-control-constructs">
<span id="id158"></span><h2>
<span class="section-number">9.5. </span><a class="reference internal" href="#divergence-of-threads-in-control-constructs">Divergence of Threads in Control Constructs</a><a class="headerlink" href="#divergence-of-threads-in-control-constructs" title="Permalink to this headline">ïƒ</a>
</h2>
<p>Threads in a CTA execute together, at least in appearance, until they come to a conditional control
construct such as a conditional branch, conditional function call, or conditional return. If threads
execute down different control flow paths, the threads are called <em>divergent</em>. If all of the threads
act in unison and follow a single control flow path, the threads are called <em>uniform</em>. Both
situations occur often in programs.</p>
<p>A CTA with divergent threads may have lower performance than a CTA with uniformly executing threads,
so it is important to have divergent threads re-converge as soon as possible. All control constructs
are assumed to be divergent points unless the control-flow instruction is marked as uniform, using
the <code class="docutils literal notranslate"><span class="pre">.uni</span></code> suffix. For divergent control flow, the optimizing code generator automatically
determines points of re-convergence. Therefore, a compiler or code author targeting PTX can ignore
the issue of divergent threads, but has the opportunity to improve performance by marking branch
points as uniform when the compiler or author can guarantee that the branch point is non-divergent.</p>
</section>
<section id="semantics">
<span id="id159"></span><h2>
<span class="section-number">9.6. </span><a class="reference internal" href="#semantics">Semantics</a><a class="headerlink" href="#semantics" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The goal of the semantic description of an instruction is to describe the results in all cases in as
simple language as possible. The semantics are described using C, until C is not expressive enough.</p>
<section id="machine-specific-semantics-of-16-bit-code">
<span id="id160"></span><h3>
<span class="section-number">9.6.1. </span><a class="reference internal" href="#machine-specific-semantics-of-16-bit-code">Machine-Specific Semantics of 16-bit Code</a><a class="headerlink" href="#machine-specific-semantics-of-16-bit-code" title="Permalink to this headline">ïƒ</a>
</h3>
<p>A PTX program may execute on a GPU with either a 16-bit or a 32-bit data path. When executing on a
32-bit data path, 16-bit registers in PTX are mapped to 32-bit physical registers, and 16-bit
computations are <em>promoted</em> to 32-bit computations. This can lead to computational differences
between code run on a 16-bit machine versus the same code run on a 32-bit machine, since the
promoted computation may have bits in the high-order half-word of registers that are not present in
16-bit physical registers. These extra precision bits can become visible at the application level,
for example, by a right-shift instruction.</p>
<p>At the PTX language level, one solution would be to define semantics for 16-bit code that is
consistent with execution on a 16-bit data path. This approach introduces a performance penalty for
16-bit code executing on a 32-bit data path, since the translated code would require many additional
masking instructions to suppress extra precision bits in the high-order half-word of 32-bit
registers.</p>
<p>Rather than introduce a performance penalty for 16-bit code running on 32-bit GPUs, the semantics of
16-bit instructions in PTX is machine-specific. A compiler or programmer may chose to enforce
portable, machine-independent 16-bit semantics by adding explicit conversions to 16-bit values at
appropriate points in the program to guarantee portability of the code. However, for many
performance-critical applications, this is not desirable, and for many applications the difference
in execution is preferable to limiting performance.</p>
</section>
</section>
<section id="instructions">
<span id="id161"></span><h2>
<span class="section-number">9.7. </span><a class="reference internal" href="#instructions">Instructions</a><a class="headerlink" href="#instructions" title="Permalink to this headline">ïƒ</a>
</h2>
<p>All PTX instructions may be predicated. In the following descriptions, the optional guard predicate
is omitted from the syntax.</p>
<section id="integer-arithmetic-instructions">
<span id="id162"></span><h3>
<span class="section-number">9.7.1. </span><a class="reference internal" href="#integer-arithmetic-instructions">Integer Arithmetic Instructions</a><a class="headerlink" href="#integer-arithmetic-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Integer arithmetic instructions operate on the integer types in register and constant immediate
forms. The integer arithmetic instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sub</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mul</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mul24</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad24</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sad</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">div</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rem</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">abs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neg</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">popc</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clz</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bfind</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fns</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">brev</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bfe</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bfi</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bmsk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">szext</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dp4a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dp2a</span></code></p></li>
</ul>
<section id="integer-arithmetic-instructions-add">
<span id="id163"></span><h4>
<span class="section-number">9.7.1.1. </span><a class="reference internal" href="#integer-arithmetic-instructions-add">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-add" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">add</span></code></p>
<p>Add two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>add.type       d, a, b;
add{.sat}.s32  d, a, b;     // .sat applies only to .s32

.type = { .u16, .u32, .u64,
          .s16, .s32, .s64,
          .u16x2, .s16x2 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs addition and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> instruction types, forms input vectors by half word values from source
operands. Half-word operands are then added in parallel to produce <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> result in
destination.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.type</span></code>. For instruction types <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>,
operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == u16x2 || type == s16x2) {
    iA[0] = a[0:15];
    iA[1] = a[16:31];
    iB[0] = b[0:15];
    iB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = iA[i] + iB[i];
    }
} else {
    d = a + b;
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Saturation modifier:</p>
<dl class="simple">
<dt>.sat</dt>
<dd>
<p>limits result to <code class="docutils literal notranslate"><span class="pre">MININT..MAXINT</span></code> (no overflow) for the size of the operation. Applies only to
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> type.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">add.s16x2</span></code> introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">add.s16x2</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  add.u32     x,y,z;
    add.sat.s32 c,c,1;
    add.u16x2   u,v,w;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-sub">
<span id="id164"></span><h4>
<span class="section-number">9.7.1.2. </span><a class="reference internal" href="#integer-arithmetic-instructions-sub">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-sub" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sub</span></code></p>
<p>Subtract one value from another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub.type       d, a, b;
sub{.sat}.s32  d, a, b;     // .sat applies only to .s32

.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs subtraction and writes the resulting value into a destination register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a - b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Saturation modifier:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.sat</span></code></dt>
<dd>
<p>limits result to <code class="docutils literal notranslate"><span class="pre">MININT..MAXINT</span></code> (no overflow) for the size of the operation. Applies only to
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> type.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub.s32 c,a,b;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-mul">
<span id="id165"></span><h4>
<span class="section-number">9.7.1.3. </span><a class="reference internal" href="#integer-arithmetic-instructions-mul">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-mul" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mul</span></code></p>
<p>Multiply two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul.mode.type  d, a, b;

.mode = { .hi, .lo, .wide };
.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the product of two values.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
n = bitwidth of type;
d = t;            // for .wide
d = t&lt;2n-1..n&gt;;   // for .hi variant
d = t&lt;n-1..0&gt;;    // for .lo variant
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The type of the operation represents the types of the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> operands. If <code class="docutils literal notranslate"><span class="pre">.hi</span></code> or
<code class="docutils literal notranslate"><span class="pre">.lo</span></code> is specified, then <code class="docutils literal notranslate"><span class="pre">d</span></code> is the same size as <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>, and either the upper or lower
half of the result is written to the destination register. If <code class="docutils literal notranslate"><span class="pre">.wide</span></code> is specified, then <code class="docutils literal notranslate"><span class="pre">d</span></code> is
twice as wide as <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to receive the full result of the multiplication.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.wide</span></code> suffix is supported only for 16- and 32-bit integer types.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul.wide.s16 fa,fxs,fys;   // 16*16 bits yields 32 bits
mul.lo.s16 fa,fxs,fys;     // 16*16 bits, save only the low 16 bits
mul.wide.s32 z,x,y;        // 32*32 bits, creates 64 bit result
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-mad">
<span id="id166"></span><h4>
<span class="section-number">9.7.1.4. </span><a class="reference internal" href="#integer-arithmetic-instructions-mad">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-mad" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mad</span></code></p>
<p>Multiply two values, optionally extract the high or low half of the intermediate result, and add a third value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mad.mode.type  d, a, b, c;
mad.hi.sat.s32 d, a, b, c;

.mode = { .hi, .lo, .wide };
.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Multiplies two values, optionally extracts the high or low half of the intermediate result, and adds
a third value. Writes the result into a destination register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
n = bitwidth of type;
d = t + c;           // for .wide
d = t&lt;2n-1..n&gt; + c;  // for .hi variant
d = t&lt;n-1..0&gt; + c;   // for .lo variant
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The type of the operation represents the types of the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> operands. If .hi or .lo is
specified, then <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> are the same size as <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>, and either the upper or lower
half of the result is written to the destination register. If <code class="docutils literal notranslate"><span class="pre">.wide</span></code> is specified, then <code class="docutils literal notranslate"><span class="pre">d</span></code> and
<code class="docutils literal notranslate"><span class="pre">c</span></code> are twice as wide as <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to receive the result of the multiplication.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.wide</span></code> suffix is supported only for 16-bit and 32-bit integer types.</p>
<p>Saturation modifier:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">.sat</span></code></dt>
<dd>
<p>limits result to <code class="docutils literal notranslate"><span class="pre">MININT..MAXINT</span></code> (no overflow) for the size of the operation.</p>
<p>Applies only to <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type in <code class="docutils literal notranslate"><span class="pre">.hi</span></code> mode.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  mad.lo.s32 d,a,b,c;
    mad.lo.s32 r,p,q,r;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-mul24">
<span id="id167"></span><h4>
<span class="section-number">9.7.1.5. </span><a class="reference internal" href="#integer-arithmetic-instructions-mul24">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mul24</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-mul24" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mul24</span></code></p>
<p>Multiply two 24-bit integer values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul24.mode.type  d, a, b;

.mode = { .hi, .lo };
.type = { .u32, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the product of two 24-bit integer values held in 32-bit source registers, and return either
the high or low 32-bits of the 48-bit result.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
d = t&lt;47..16&gt;;    // for .hi variant
d = t&lt;31..0&gt;;     // for .lo variant
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Integer multiplication yields a result that is twice the size of the input operands, i.e., 48-bits.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul24.hi</span></code> performs a 24x24-bit multiply and returns the high 32 bits of the 48-bit result.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul24.lo</span></code> performs a 24x24-bit multiply and returns the low 32 bits of the 48-bit result.</p>
<p>All operands are of the same type and size.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul24.hi</span></code> may be less efficient on machines without hardware support for 24-bit multiply.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul24.lo.s32 d,a,b;   // low 32-bits of 24x24-bit signed multiply.
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-mad24">
<span id="id168"></span><h4>
<span class="section-number">9.7.1.6. </span><a class="reference internal" href="#integer-arithmetic-instructions-mad24">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad24</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-mad24" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mad24</span></code></p>
<p>Multiply two 24-bit integer values and add a third value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mad24.mode.type  d, a, b, c;
mad24.hi.sat.s32 d, a, b, c;

.mode = { .hi, .lo };
.type = { .u32, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the product of two 24-bit integer values held in 32-bit source registers, and add a third,
32-bit value to either the high or low 32-bits of the 48-bit result. Return either the high or low
32-bits of the 48-bit result.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
d = t&lt;47..16&gt; + c;   // for .hi variant
d = t&lt;31..0&gt; + c;    // for .lo variant
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Integer multiplication yields a result that is twice the size of the input operands, i.e., 48-bits.</p>
<p><code class="docutils literal notranslate"><span class="pre">mad24.hi</span></code> performs a 24x24-bit multiply and adds the high 32 bits of the 48-bit result to a third
value.</p>
<p><code class="docutils literal notranslate"><span class="pre">mad24.lo</span></code> performs a 24x24-bit multiply and adds the low 32 bits of the 48-bit result to a third
value.</p>
<p>All operands are of the same type and size.</p>
<p>Saturation modifier:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.sat</span></code></dt>
<dd>
<p>limits result of 32-bit signed addition to <code class="docutils literal notranslate"><span class="pre">MININT..MAXINT</span></code> (no overflow). Applies only to
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> type in .hi mode.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">mad24.hi</span></code> may be less efficient on machines without hardware support for 24-bit multiply.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mad24.lo.s32 d,a,b,c;   // low 32-bits of 24x24-bit signed multiply.
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-sad">
<span id="id169"></span><h4>
<span class="section-number">9.7.1.7. </span><a class="reference internal" href="#integer-arithmetic-instructions-sad">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sad</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-sad" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sad</span></code></p>
<p>Sum of absolute differences.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sad.type  d, a, b, c;

.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Adds the absolute value of <code class="docutils literal notranslate"><span class="pre">a-b</span></code> to <code class="docutils literal notranslate"><span class="pre">c</span></code> and writes the resulting value into <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = c + ((a&lt;b) ? b-a : a-b);
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sad.s32  d,a,b,c;
sad.u32  d,a,b,d;  // running sum
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-div">
<span id="id170"></span><h4>
<span class="section-number">9.7.1.8. </span><a class="reference internal" href="#integer-arithmetic-instructions-div">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">div</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-div" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">div</span></code></p>
<p>Divide one value by another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>div.type  d, a, b;

.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Divides <code class="docutils literal notranslate"><span class="pre">a</span></code> by <code class="docutils literal notranslate"><span class="pre">b</span></code>, stores result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a / b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Division by zero yields an unspecified, machine-specific value.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>div.s32  b,n,i;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-rem">
<span id="id171"></span><h4>
<span class="section-number">9.7.1.9. </span><a class="reference internal" href="#integer-arithmetic-instructions-rem">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">rem</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-rem" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">rem</span></code></p>
<p>The remainder of integer division.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rem.type  d, a, b;

.type = { .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Divides <code class="docutils literal notranslate"><span class="pre">a</span></code> by <code class="docutils literal notranslate"><span class="pre">b</span></code>, store the remainder in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a % b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The behavior for negative numbers is machine-dependent and depends on whether divide rounds towards
zero or negative infinity.</p>
<p>Division by zero yields an unspecified, machine-specific value.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rem.s32  x,x,8;    // x = x%8;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-abs">
<span id="id172"></span><h4>
<span class="section-number">9.7.1.10. </span><a class="reference internal" href="#integer-arithmetic-instructions-abs">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-abs" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">abs</span></code></p>
<p>Absolute value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs.type  d, a;

.type = { .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Take the absolute value of <code class="docutils literal notranslate"><span class="pre">a</span></code> and store it in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = |a|;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Only for signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs.s32  r0,a;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-neg">
<span id="id173"></span><h4>
<span class="section-number">9.7.1.11. </span><a class="reference internal" href="#integer-arithmetic-instructions-neg">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-neg" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">neg</span></code></p>
<p>Arithmetic negate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg.type  d, a;

.type = { .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Negate the sign of <strong>a</strong> and store the result in <strong>d</strong>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = -a;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Only for signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg.s32  r0,a;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-min">
<span id="id174"></span><h4>
<span class="section-number">9.7.1.12. </span><a class="reference internal" href="#integer-arithmetic-instructions-min">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-min" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">min</span></code></p>
<p>Find the minimum of two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>min.atype         d, a, b;
min{.relu}.btype  d, a, b;

.atype = { .u16, .u32, .u64,
           .u16x2, .s16, .s64 };
.btype = { .s16x2, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the minimum of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> instruction types, forms input vectors by half word values from source
operands. Half-word operands are then processed in parallel to produce <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> result
in destination.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have the same type as the instruction type. For instruction types
<code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == u16x2 || type == s16x2) {
    iA[0] = a[0:15];
    iA[1] = a[16:31];
    iB[0] = b[0:15];
    iB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = (iA[i] &lt; iB[i]) ? iA[i] : iB[i];
    }
} else {
    d = (a &lt; b) ? a : b; // Integer (signed and unsigned)
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Signed and unsigned differ.</p>
<dl class="simple">
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">min.relu.{s16x2,</span> <span class="pre">s32}</span></code> clamps the result to 0 if negative.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">min{.relu}.s16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">min.relu.s32</span></code> introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">min{.relu}.s16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">min.relu.s32</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    min.s32  r0,a,b;
@p  min.u16  h,i,j;
    min.s16x2.relu u,v,w;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-max">
<span id="id175"></span><h4>
<span class="section-number">9.7.1.13. </span><a class="reference internal" href="#integer-arithmetic-instructions-max">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-max" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">max</span></code></p>
<p>Find the maximum of two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max.atype         d, a, b;
max{.relu}.btype  d, a, b;

.atype = { .u16, .u32, .u64,
           .u16x2, .s16, .s64 };
.btype = { .s16x2, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the maximum of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> instruction types, forms input vectors by half word values from source
operands. Half-word operands are then processed in parallel to produce <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> result
in destination.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have the same type as the instruction type. For instruction types
<code class="docutils literal notranslate"><span class="pre">.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == u16x2 || type == s16x2) {
    iA[0] = a[0:15];
    iA[1] = a[16:31];
    iB[0] = b[0:15];
    iB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = (iA[i] &gt; iB[i]) ? iA[i] : iB[i];
    }
} else {
    d = (a &gt; b) ? a : b; // Integer (signed and unsigned)
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Signed and unsigned differ.</p>
<dl class="simple">
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">max.relu.{s16x2,</span> <span class="pre">s32}</span></code> clamps the result to 0 if negative.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">max{.relu}.s16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">max.relu.s32</span></code> introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.u16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">max{.relu}.s16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">max.relu.s32</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max.u32  d,a,b;
max.s32  q,q,0;
max.relu.s16x2 t,t,u;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-popc">
<span id="id176"></span><h4>
<span class="section-number">9.7.1.14. </span><a class="reference internal" href="#integer-arithmetic-instructions-popc">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">popc</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-popc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">popc</span></code></p>
<p>Population count.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>popc.type  d, a;

.type = { .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Count the number of one bits in <code class="docutils literal notranslate"><span class="pre">a</span></code> and place the resulting <em>population count</em> in 32-bit
destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has the instruction type and destination <code class="docutils literal notranslate"><span class="pre">d</span></code> has type
<code class="docutils literal notranslate"><span class="pre">.u32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.u32  d = 0;
while (a != 0) {
   if (a &amp; 0x1)  d++;
   a = a &gt;&gt; 1;
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">popc</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>popc.b32  d, a;
popc.b64  cnt, X;  // cnt is .u32
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-clz">
<span id="id177"></span><h4>
<span class="section-number">9.7.1.15. </span><a class="reference internal" href="#integer-arithmetic-instructions-clz">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">clz</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-clz" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">clz</span></code></p>
<p>Count leading zeros.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>clz.type  d, a;

.type = { .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Count the number of leading zeros in <code class="docutils literal notranslate"><span class="pre">a</span></code> starting with the most-significant bit and place the
result in 32-bit destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has the instruction type, and destination
<code class="docutils literal notranslate"><span class="pre">d</span></code> has type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>. For <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type, the number of leading zeros is between 0 and 32,
inclusively. For <code class="docutils literal notranslate"><span class="pre">.b64</span></code> type, the number of leading zeros is between 0 and 64, inclusively.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.u32  d = 0;
if (.type == .b32)   { max = 32; mask = 0x80000000; }
else                 { max = 64; mask = 0x8000000000000000; }

while (d &lt; max &amp;&amp; (a&amp;mask == 0) ) {
    d++;
    a = a &lt;&lt; 1;
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">clz</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>clz.b32  d, a;
clz.b64  cnt, X;  // cnt is .u32
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-bfind">
<span id="id178"></span><h4>
<span class="section-number">9.7.1.16. </span><a class="reference internal" href="#integer-arithmetic-instructions-bfind">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfind</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-bfind" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bfind</span></code></p>
<p>Find most significant non-sign bit.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfind.type           d, a;
bfind.shiftamt.type  d, a;

.type = { .u32, .u64,
          .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Find the bit position of the most significant non-sign bit in <code class="docutils literal notranslate"><span class="pre">a</span></code> and place the result in
<code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has the instruction type, and destination <code class="docutils literal notranslate"><span class="pre">d</span></code> has type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>. For unsigned
integers, <code class="docutils literal notranslate"><span class="pre">bfind</span></code> returns the bit position of the most significant <code class="docutils literal notranslate"><span class="pre">1</span></code>. For signed integers,
<code class="docutils literal notranslate"><span class="pre">bfind</span></code> returns the bit position of the most significant <code class="docutils literal notranslate"><span class="pre">0</span></code> for negative inputs and the most
significant <code class="docutils literal notranslate"><span class="pre">1</span></code> for non-negative inputs.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.shiftamt</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">bfind</span></code> returns the shift amount needed to left-shift the found bit
into the most-significant bit position.</p>
<p><code class="docutils literal notranslate"><span class="pre">bfind</span></code> returns <code class="docutils literal notranslate"><span class="pre">0xffffffff</span></code> if no non-sign bit is found.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>msb = (.type==.u32 || .type==.s32) ? 31 : 63;
// negate negative signed inputs
if ( (.type==.s32 || .type==.s64) &amp;&amp; (a &amp; (1&lt;&lt;msb)) ) {
    a = ~a;
}
.u32  d = 0xffffffff;
for (.s32 i=msb; i&gt;=0; i--) {
    if (a &amp; (1&lt;&lt;i))  { d = i; break; }
}
if (.shiftamt &amp;&amp; d != 0xffffffff)  { d = msb - d; }
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">bfind</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfind.u32  d, a;
bfind.shiftamt.s64  cnt, X;  // cnt is .u32
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-fns">
<span id="id179"></span><h4>
<span class="section-number">9.7.1.17. </span><a class="reference internal" href="#integer-arithmetic-instructions-fns">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">fns</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-fns" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">fns</span></code></p>
<p>Find the n-th set bit</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>fns.b32 d, mask, base, offset;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Given a 32-bit value <code class="docutils literal notranslate"><span class="pre">mask</span></code> and an integer value <code class="docutils literal notranslate"><span class="pre">base</span></code> (between 0 and 31), find the n-th (given
by offset) set bit in <code class="docutils literal notranslate"><span class="pre">mask</span></code> from the <code class="docutils literal notranslate"><span class="pre">base</span></code> bit, and store the bit position in <code class="docutils literal notranslate"><span class="pre">d</span></code>. If not
found, store 0xffffffff in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">mask</span></code> has a 32-bit type. Operand <code class="docutils literal notranslate"><span class="pre">base</span></code> has <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code>
type. Operand offset has <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type. Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> has type <code class="docutils literal notranslate"><span class="pre">.b32.</span></code></p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">base</span></code> must be &lt;= 31, otherwise behavior is undefined.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = 0xffffffff;
if (offset == 0) {
    if (mask[base] == 1) {
        d = base;
    }
} else {
    pos = base;
    count = |offset| - 1;
    inc = (offset &gt; 0) ? 1 : -1;

    while ((pos &gt;= 0) &amp;&amp; (pos &lt; 32)) {
        if (mask[pos] == 1) {
            if (count == 0) {
              d = pos;
              break;
           } else {
               count = count - 1;
           }
        }
        pos = pos + inc;
    }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fns</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>fns.b32 d, 0xaaaaaaaa, 3, 1;   // d = 3
fns.b32 d, 0xaaaaaaaa, 3, -1;  // d = 3
fns.b32 d, 0xaaaaaaaa, 2, 1;   // d = 3
fns.b32 d, 0xaaaaaaaa, 2, -1;  // d = 1
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-brev">
<span id="id180"></span><h4>
<span class="section-number">9.7.1.18. </span><a class="reference internal" href="#integer-arithmetic-instructions-brev">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">brev</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-brev" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">brev</span></code></p>
<p>Bit reverse.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>brev.type  d, a;

.type = { .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Perform bitwise reversal of input.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>msb = (.type==.b32) ? 31 : 63;

for (i=0; i&lt;=msb; i++) {
    d[i] = a[msb-i];
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">brev</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>brev.b32  d, a;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-bfe">
<span id="id181"></span><h4>
<span class="section-number">9.7.1.19. </span><a class="reference internal" href="#integer-arithmetic-instructions-bfe">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfe</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-bfe" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bfe</span></code></p>
<p>Bit Field Extract.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfe.type  d, a, b, c;

.type = { .u32, .u64,
          .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Extract bit field from <code class="docutils literal notranslate"><span class="pre">a</span></code> and place the zero or sign-extended result in <code class="docutils literal notranslate"><span class="pre">d</span></code>. Source <code class="docutils literal notranslate"><span class="pre">b</span></code> gives
the bit field starting bit position, and source <code class="docutils literal notranslate"><span class="pre">c</span></code> gives the bit field length in bits.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> have the same type as the instruction type. Operands <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> are
type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, but are restricted to the 8-bit value range <code class="docutils literal notranslate"><span class="pre">0..255</span></code>.</p>
<p>The sign bit of the extracted field is defined as:</p>
<dl class="simple">
<dt>
<code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>:</dt>
<dd>
<p>zero</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code>:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">msb</span></code> of input a if the extracted field extends beyond the <code class="docutils literal notranslate"><span class="pre">msb</span></code> of a <code class="docutils literal notranslate"><span class="pre">msb</span></code> of extracted
field, otherwise</p>
</dd>
</dl>
<p>If the bit field length is zero, the result is zero.</p>
<p>The destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is padded with the sign bit of the extracted field. If the start position is
beyond the <code class="docutils literal notranslate"><span class="pre">msb</span></code> of the input, the destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is filled with the replicated sign bit of the
extracted field.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>msb = (.type==.u32 || .type==.s32) ? 31 : 63;
pos = b &amp; 0xff;  // pos restricted to 0..255 range
len = c &amp; 0xff;  // len restricted to 0..255 range

if (.type==.u32 || .type==.u64 || len==0)
    sbit = 0;
else
    sbit = a[min(pos+len-1,msb)];

d = 0;
for (i=0; i&lt;=msb; i++) {
    d[i] = (i&lt;len &amp;&amp; pos+i&lt;=msb) ? a[pos+i] : sbit;
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">bfe</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfe.b32  d,a,start,len;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-bfi">
<span id="id182"></span><h4>
<span class="section-number">9.7.1.20. </span><a class="reference internal" href="#integer-arithmetic-instructions-bfi">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bfi</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-bfi" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bfi</span></code></p>
<p>Bit Field Insert.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfi.type  f, a, b, c, d;

.type = { .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Align and insert a bit field from <code class="docutils literal notranslate"><span class="pre">a</span></code> into <code class="docutils literal notranslate"><span class="pre">b</span></code>, and place the result in <code class="docutils literal notranslate"><span class="pre">f</span></code>. Source <code class="docutils literal notranslate"><span class="pre">c</span></code>
gives the starting bit position for the insertion, and source <code class="docutils literal notranslate"><span class="pre">d</span></code> gives the bit field length in
bits.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, and <code class="docutils literal notranslate"><span class="pre">f</span></code> have the same type as the instruction type. Operands <code class="docutils literal notranslate"><span class="pre">c</span></code> and
<code class="docutils literal notranslate"><span class="pre">d</span></code> are type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, but are restricted to the 8-bit value range <code class="docutils literal notranslate"><span class="pre">0..255</span></code>.</p>
<p>If the bit field length is zero, the result is <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>If the start position is beyond the msb of the input, the result is <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>msb = (.type==.b32) ? 31 : 63;
pos = c &amp; 0xff;  // pos restricted to 0..255 range
len = d &amp; 0xff;  // len restricted to 0..255 range

f = b;
for (i=0; i&lt;len &amp;&amp; pos+i&lt;=msb; i++) {
    f[pos+i] = a[i];
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">bfi</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bfi.b32  d,a,b,start,len;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-szext">
<span id="id183"></span><h4>
<span class="section-number">9.7.1.21. </span><a class="reference internal" href="#integer-arithmetic-instructions-szext">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">szext</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-szext" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">szext</span></code></p>
<p>Sign-extend or Zero-extend.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>szext.mode.type  d, a, b;

.mode = { .clamp, .wrap };
.type = { .u32, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Sign-extends or zero-extends an N-bit value from operand <code class="docutils literal notranslate"><span class="pre">a</span></code> where N is specified in operand
<code class="docutils literal notranslate"><span class="pre">b</span></code>. The resulting value is stored in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">.s32</span></code> instruction type, the value in <code class="docutils literal notranslate"><span class="pre">a</span></code> is treated as an N-bit signed value and the
most significant bit of this N-bit value is replicated up to bit 31. For the <code class="docutils literal notranslate"><span class="pre">.u32</span></code> instruction
type, the value in <code class="docutils literal notranslate"><span class="pre">a</span></code> is treated as an N-bit unsigned number and is zero-extended to 32
bits. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is an unsigned 32-bit value.</p>
<p>If the value of N is 0, then the result of <code class="docutils literal notranslate"><span class="pre">szext</span></code> is 0. If the value of N is 32 or higher, then
the result of <code class="docutils literal notranslate"><span class="pre">szext</span></code> depends upon the value of the <code class="docutils literal notranslate"><span class="pre">.mode</span></code> qualifier as follows:</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">.mode</span></code> is <code class="docutils literal notranslate"><span class="pre">.clamp</span></code>, then the result is the same as the source operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.mode</span></code> is <code class="docutils literal notranslate"><span class="pre">.wrap</span></code>, then the result is computed using the wrapped value of N.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>b1        = b &amp; 0x1f;
too_large = (b &gt;= 32 &amp;&amp; .mode == .clamp) ? true : false;
mask      = too_large ? 0 : (~0) &lt;&lt; b1;
sign_pos  = (b1 - 1) &amp; 0x1f;

if (b1 == 0 || too_large || .type != .s32) {
    sign_bit = false;
} else {
    sign_bit = (a &gt;&gt; sign_pos) &amp; 1;
}
d = (a &amp; ~mask) | (sign_bit ? mask | 0);
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">szext</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>szext.clamp.s32 rd, ra, rb;
szext.wrap.u32  rd, 0xffffffff, 0; // Result is 0.
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-bmsk">
<span id="id184"></span><h4>
<span class="section-number">9.7.1.22. </span><a class="reference internal" href="#integer-arithmetic-instructions-bmsk">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">bmsk</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-bmsk" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bmsk</span></code></p>
<p>Bit Field Mask.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bmsk.mode.b32  d, a, b;

.mode = { .clamp, .wrap };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Generates a 32-bit mask starting from the bit position specified in operand <code class="docutils literal notranslate"><span class="pre">a</span></code>, and of the width
specified in operand <code class="docutils literal notranslate"><span class="pre">b</span></code>. The generated bitmask is stored in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>The resulting bitmask is 0 in the following cases:</p>
<ul class="simple">
<li><p>When the value of <code class="docutils literal notranslate"><span class="pre">a</span></code> is 32 or higher and <code class="docutils literal notranslate"><span class="pre">.mode</span></code> is <code class="docutils literal notranslate"><span class="pre">.clamp</span></code>.</p></li>
<li><p>When either the specified value of <code class="docutils literal notranslate"><span class="pre">b</span></code> or the wrapped value of <code class="docutils literal notranslate"><span class="pre">b</span></code> (when <code class="docutils literal notranslate"><span class="pre">.mode</span></code> is
specified as <code class="docutils literal notranslate"><span class="pre">.wrap</span></code>) is 0.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>a1    = a &amp; 0x1f;
mask0 = (~0) &lt;&lt; a1;
b1    = b &amp; 0x1f;
sum   = a1 + b1;
mask1 = (~0) &lt;&lt; sum;

sum-overflow          = sum &gt;= 32 ? true : false;
bit-position-overflow = false;
bit-width-overflow    = false;

if (.mode == .clamp) {
    if (a &gt;= 32) {
        bit-position-overflow = true;
        mask0 = 0;
    }
    if (b &gt;= 32) {
        bit-width-overflow = true;
    }
}

if (sum-overflow || bit-position-overflow || bit-width-overflow) {
    mask1 = 0;
} else if (b1 == 0) {
    mask1 = ~0;
}
d = mask0 &amp; ~mask1;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The bitmask width specified by operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is limited to range <code class="docutils literal notranslate"><span class="pre">0..32</span></code> in <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> mode and to
range <code class="docutils literal notranslate"><span class="pre">0..31</span></code> in <code class="docutils literal notranslate"><span class="pre">.wrap</span></code> mode.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">bmsk</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bmsk.clamp.b32  rd, ra, rb;
bmsk.wrap.b32   rd, 1, 2; // Creates a bitmask of 0x00000006.
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-dp4a">
<span id="id185"></span><h4>
<span class="section-number">9.7.1.23. </span><a class="reference internal" href="#integer-arithmetic-instructions-dp4a">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">dp4a</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-dp4a" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">dp4a</span></code></p>
<p>Four-way byte dot product-accumulate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>dp4a.atype.btype  d, a, b, c;

.atype = .btype = { .u32, .s32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Four-way byte dot product which is accumulated in 32-bit result.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are 32-bit inputs which hold 4 byte inputs in packed form for dot product.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.u32</span></code> if both <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> are <code class="docutils literal notranslate"><span class="pre">.u32</span></code> else operand <code class="docutils literal notranslate"><span class="pre">c</span></code>
has type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = c;

// Extract 4 bytes from a 32bit input and sign or zero extend
// based on input type.
Va = extractAndSignOrZeroExt_4(a, .atype);
Vb = extractAndSignOrZeroExt_4(b, .btype);

for (i = 0; i &lt; 4; ++i) {
    d += Va[i] * Vb[i];
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 5.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_61</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>dp4a.u32.u32           d0, a0, b0, c0;
dp4a.u32.s32           d1, a1, b1, c1;
</pre></div>
</div>
</section>
<section id="integer-arithmetic-instructions-dp2a">
<span id="id186"></span><h4>
<span class="section-number">9.7.1.24. </span><a class="reference internal" href="#integer-arithmetic-instructions-dp2a">Integer Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">dp2a</span></code></a><a class="headerlink" href="#integer-arithmetic-instructions-dp2a" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">dp2a</span></code></p>
<p>Two-way dot product-accumulate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>dp2a.mode.atype.btype  d, a, b, c;

.atype = .btype = { .u32, .s32 };
.mode = { .lo, .hi };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Two-way 16-bit to 8-bit dot product which is accumulated in 32-bit result.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are 32-bit inputs. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> holds two 16-bits inputs in packed form and
operand <code class="docutils literal notranslate"><span class="pre">b</span></code> holds 4 byte inputs in packed form for dot product.</p>
<p>Depending on the <code class="docutils literal notranslate"><span class="pre">.mode</span></code> specified, either lower half or upper half of operand <code class="docutils literal notranslate"><span class="pre">b</span></code> will be used
for dot product.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.u32</span></code> if both <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> are <code class="docutils literal notranslate"><span class="pre">.u32</span></code> else operand <code class="docutils literal notranslate"><span class="pre">c</span></code>
has type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = c;
// Extract two 16-bit values from a 32-bit input and sign or zero extend
// based on input type.
Va = extractAndSignOrZeroExt_2(a, .atype);

// Extract four 8-bit values from a 32-bit input and sign or zer extend
// based on input type.
Vb = extractAndSignOrZeroExt_4(b, .btype);

b_select = (.mode == .lo) ? 0 : 2;

for (i = 0; i &lt; 2; ++i) {
    d += Va[i] * Vb[b_select + i];
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 5.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_61</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>dp2a.lo.u32.u32           d0, a0, b0, c0;
dp2a.hi.u32.s32           d1, a1, b1, c1;
</pre></div>
</div>
</section>
</section>
<section id="extended-precision-integer-arithmetic-instructions">
<span id="id187"></span><h3>
<span class="section-number">9.7.2. </span><a class="reference internal" href="#extended-precision-integer-arithmetic-instructions">Extended-Precision Integer Arithmetic Instructions</a><a class="headerlink" href="#extended-precision-integer-arithmetic-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">add.cc</span></code>, <code class="docutils literal notranslate"><span class="pre">addc</span></code>, <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code>, <code class="docutils literal notranslate"><span class="pre">subc</span></code>, <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code> and <code class="docutils literal notranslate"><span class="pre">madc</span></code> reference an
implicitly specified condition code register (<code class="docutils literal notranslate"><span class="pre">CC</span></code>) having a single carry flag bit (<code class="docutils literal notranslate"><span class="pre">CC.CF</span></code>)
holding carry-in/carry-out or borrow-in/borrow-out. These instructions support extended-precision
integer addition, subtraction, and multiplication. No other instructions access the condition code,
and there is no support for setting, clearing, or testing the condition code. The condition code
register is not preserved across calls and is mainly intended for use in straight-line code
sequences for computing extended-precision integer addition, subtraction, and multiplication.</p>
<p>The extended-precision arithmetic instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add.cc</span></code>, <code class="docutils literal notranslate"><span class="pre">addc</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sub.cc</span></code>, <code class="docutils literal notranslate"><span class="pre">subc</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad.cc</span></code>, <code class="docutils literal notranslate"><span class="pre">madc</span></code></p></li>
</ul>
<section id="extended-precision-arithmetic-instructions-add-cc">
<span id="id188"></span><h4>
<span class="section-number">9.7.2.1. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-add-cc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">add.cc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-add-cc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">add.cc</span></code></p>
<p>Add two values with carry-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>add.cc.type  d, a, b;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs integer addition and writes the carry-out value into the condition code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a + b;
</pre></div>
</div>
<p>carry-out written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>No integer rounding modifiers.</p>
<p>No saturation.</p>
<p>Behavior is the same for unsigned and signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">add.cc</span></code> introduced in PTX ISA version 1.2.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">add.cc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">add.cc</span></code> is supported on all target architectures.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">add.cc</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  add.cc.u32   x1,y1,z1;   // extended-precision addition of
@p  addc.cc.u32  x2,y2,z2;   // two 128-bit values
@p  addc.cc.u32  x3,y3,z3;
@p  addc.u32     x4,y4,z4;
</pre></div>
</div>
</section>
<section id="extended-precision-arithmetic-instructions-addc">
<span id="id189"></span><h4>
<span class="section-number">9.7.2.2. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-addc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">addc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-addc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">addc</span></code></p>
<p>Add two values with carry-in and optional carry-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>addc{.cc}.type  d, a, b;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs integer addition with carry-in and optionally writes the carry-out value into the condition
code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a + b + CC.CF;
</pre></div>
</div>
<p>if <code class="docutils literal notranslate"><span class="pre">.cc</span></code> specified, carry-out written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>No integer rounding modifiers.</p>
<p>No saturation.</p>
<p>Behavior is the same for unsigned and signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">addc</span></code> introduced in PTX ISA version 1.2.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">addc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">addc</span></code> is supported on all target architectures.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">addc</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  add.cc.u32   x1,y1,z1;   // extended-precision addition of
@p  addc.cc.u32  x2,y2,z2;   // two 128-bit values
@p  addc.cc.u32  x3,y3,z3;
@p  addc.u32     x4,y4,z4;
</pre></div>
</div>
</section>
<section id="extended-precision-arithmetic-instructions-sub-cc">
<span id="id190"></span><h4>
<span class="section-number">9.7.2.3. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-sub-cc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-sub-cc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sub.cc</span></code></p>
<p>Subtract one value from another, with borrow-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub.cc.type  d, a, b;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs integer subtraction and writes the borrow-out value into the condition code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a - b;
</pre></div>
</div>
<p>borrow-out written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>No integer rounding modifiers.</p>
<p>No saturation.</p>
<p>Behavior is the same for unsigned and signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code> introduced in PTX ISA version 1.2.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code> is supported on all target architectures.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">sub.cc</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  sub.cc.u32   x1,y1,z1;   // extended-precision subtraction
@p  subc.cc.u32  x2,y2,z2;   // of two 128-bit values
@p  subc.cc.u32  x3,y3,z3;
@p  subc.u32     x4,y4,z4;
</pre></div>
</div>
</section>
<section id="extended-precision-arithmetic-instructions-subc">
<span id="id191"></span><h4>
<span class="section-number">9.7.2.4. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-subc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">subc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-subc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">subc</span></code></p>
<p>Subtract one value from another, with borrow-in and optional borrow-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>subc{.cc}.type  d, a, b;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs integer subtraction with borrow-in and optionally writes the borrow-out value into the
condition code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a  - (b + CC.CF);
</pre></div>
</div>
<p>if <code class="docutils literal notranslate"><span class="pre">.cc</span></code> specified, borrow-out written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>No integer rounding modifiers.</p>
<p>No saturation.</p>
<p>Behavior is the same for unsigned and signed integers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">subc</span></code> introduced in PTX ISA version 1.2.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">subc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">subc</span></code> is supported on all target architectures.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">subc</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  sub.cc.u32   x1,y1,z1;   // extended-precision subtraction
@p  subc.cc.u32  x2,y2,z2;   // of two 128-bit values
@p  subc.cc.u32  x3,y3,z3;
@p  subc.u32     x4,y4,z4;
</pre></div>
</div>
</section>
<section id="extended-precision-arithmetic-instructions-mad-cc">
<span id="id192"></span><h4>
<span class="section-number">9.7.2.5. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-mad-cc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-mad-cc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mad.cc</span></code></p>
<p>Multiply two values, extract high or low half of result, and add a third value with carry-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mad{.hi,.lo}.cc.type  d, a, b, c;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Multiplies two values, extracts either the high or low part of the result, and adds a third
value. Writes the result to the destination register and the carry-out from the addition into the
condition code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
d = t&lt;63..32&gt; + c;    // for .hi variant
d = t&lt;31..0&gt; + c;     // for .lo variant
</pre></div>
</div>
<p>carry-out from addition is written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>Generally used in combination with <code class="docutils literal notranslate"><span class="pre">madc</span></code> and <code class="docutils literal notranslate"><span class="pre">addc</span></code> to implement extended-precision multi-word
multiplication. See <code class="docutils literal notranslate"><span class="pre">madc</span></code> for an example.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code> introduced in PTX ISA version 3.0.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires target <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  mad.lo.cc.u32 d,a,b,c;
    mad.lo.cc.u32 r,p,q,r;
</pre></div>
</div>
</section>
<section id="extended-precision-arithmetic-instructions-madc">
<span id="id193"></span><h4>
<span class="section-number">9.7.2.6. </span><a class="reference internal" href="#extended-precision-arithmetic-instructions-madc">Extended-Precision Arithmetic Instructions: <code class="docutils literal notranslate"><span class="pre">madc</span></code></a><a class="headerlink" href="#extended-precision-arithmetic-instructions-madc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">madc</span></code></p>
<p>Multiply two values, extract high or low half of result, and add a third value with carry-in and
optional carry-out.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>madc{.hi,.lo}{.cc}.type  d, a, b, c;

.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Multiplies two values, extracts either the high or low part of the result, and adds a third value
along with carry-in. Writes the result to the destination register and optionally writes the
carry-out from the addition into the condition code register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = a * b;
d = t&lt;63..32&gt; + c + CC.CF;     // for .hi variant
d = t&lt;31..0&gt; + c + CC.CF;      // for .lo variant
</pre></div>
</div>
<p>if <code class="docutils literal notranslate"><span class="pre">.cc</span></code> specified, carry-out from addition is written to <code class="docutils literal notranslate"><span class="pre">CC.CF</span></code></p>
<p class="rubric">Notes</p>
<p>Generally used in combination with <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code> and <code class="docutils literal notranslate"><span class="pre">addc</span></code> to implement extended-precision
multi-word multiplication. See example below.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit <code class="docutils literal notranslate"><span class="pre">madc</span></code> introduced in PTX ISA version 3.0.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">madc</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires target <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extended-precision multiply:  [r3,r2,r1,r0] = [r5,r4] * [r7,r6]
mul.lo.u32     r0,r4,r6;      // r0=(r4*r6).[31:0], no carry-out
mul.hi.u32     r1,r4,r6;      // r1=(r4*r6).[63:32], no carry-out
mad.lo.cc.u32  r1,r5,r6,r1;   // r1+=(r5*r6).[31:0], may carry-out
madc.hi.u32    r2,r5,r6,0;    // r2 =(r5*r6).[63:32]+carry-in,
                              // no carry-out
mad.lo.cc.u32   r1,r4,r7,r1;  // r1+=(r4*r7).[31:0], may carry-out
madc.hi.cc.u32  r2,r4,r7,r2;  // r2+=(r4*r7).[63:32]+carry-in,
                              // may carry-out
addc.u32        r3,0,0;       // r3 = carry-in, no carry-out
mad.lo.cc.u32   r2,r5,r7,r2;  // r2+=(r5*r7).[31:0], may carry-out
madc.hi.u32     r3,r5,r7,r3;  // r3+=(r5*r7).[63:32]+carry-in
</pre></div>
</div>
</section>
</section>
<section id="floating-point-instructions">
<span id="id194"></span><h3>
<span class="section-number">9.7.3. </span><a class="reference internal" href="#floating-point-instructions">Floating-Point Instructions</a><a class="headerlink" href="#floating-point-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Floating-point instructions operate on <code class="docutils literal notranslate"><span class="pre">.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register operands and constant
immediate values. The floating-point instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">testp</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copysign</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sub</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mul</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">div</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">abs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neg</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rcp</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sqrt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsqrt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sin</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cos</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lg2</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ex2</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tanh</span></code></p></li>
</ul>
<p>Instructions that support rounding modifiers are IEEE-754 compliant. Double-precision instructions
support subnormal inputs and results. Single-precision instructions support subnormal inputs and
results by default for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and subsequent targets, and flush subnormal inputs and results to
sign-preserving zero for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets. The optional <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier on single-precision
instructions provides backward compatibility with <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets by flushing subnormal inputs and
results to sign-preserving zero regardless of the target architecture.</p>
<p>Single-precision <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">mul</span></code>, and <code class="docutils literal notranslate"><span class="pre">mad</span></code> support saturation of results to the range
[0.0, 1.0], with <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s being flushed to positive zero. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> payloads are supported for
double-precision instructions (except for <code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code> and <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code>, which
maps input <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s to a canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code>). Single-precision instructions return an unspecified
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Note that future implementations may support <code class="docutils literal notranslate"><span class="pre">NaN</span></code> payloads for single-precision
instructions, so PTX programs should not rely on the specific single-precision <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s being
generated.</p>
<p><a class="reference internal" href="#floating-point-instructions-summary-of-floating-point-instructions"><span class="std std-numref">Table 29</span></a> summarizes
floating-point instructions in PTX.</p>
<table class="table-no-stripes docutils align-default" id="floating-point-instructions-summary-of-floating-point-instructions">
<caption>
<span class="caption-number">Table 29 </span><span class="caption-text">Summary of Floating-Point Instructions</span><a class="headerlink" href="#floating-point-instructions-summary-of-floating-point-instructions" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Instruction</p></th>
<th class="head"><p>.rn</p></th>
<th class="head"><p>.rz</p></th>
<th class="head"><p>.rm</p></th>
<th class="head"><p>.rp</p></th>
<th class="head"><p>.ftz</p></th>
<th class="head"><p>.sat</p></th>
<th class="head"><p>Notes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">{add,sub,mul}.rnd.f32</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>If no rounding modifier is specified,
default is <code class="docutils literal notranslate"><span class="pre">.rn</span></code> and instructions may
be folded into a multiply-add.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">{add,sub,mul}.rnd.f64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>If no rounding modifier is specified,
default is <code class="docutils literal notranslate"><span class="pre">.rn</span></code> and instructions may
be folded into a multiply-add.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td>
<p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_1x</span></code></p>
<p>No rounding modifier.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">{mad,fma}.rnd.f32</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td>
<p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> or higher</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> are the same.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">{mad,fma}.rnd.f64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> and <code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> are the same.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">div.full.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p>No rounding modifier.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">{div,rcp,sqrt}.approx.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> or higher</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">{div,rcp,sqrt}.rnd.f32</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> or higher</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">{div,rcp,sqrt}.rnd.f64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> or higher</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">{abs,neg,min,max}.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">{abs,neg,min,max}.f64</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.f64</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> or higher</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">{sin,cos,lg2,ex2}.approx.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>x</p></td>
<td><p>n/a</p></td>
<td></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">tanh.approx.f32</span></code></p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p>n/a</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_75</span></code> or higher</p></td>
</tr>
</tbody>
</table>
<section id="floating-point-instructions-testp">
<span id="id195"></span><h4>
<span class="section-number">9.7.3.1. </span><a class="reference internal" href="#floating-point-instructions-testp">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">testp</span></code></a><a class="headerlink" href="#floating-point-instructions-testp" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">testp</span></code></p>
<p>Test floating-point property.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>testp.op.type  p, a;  // result is .pred

.op   = { .finite, .infinite,
          .number, .notanumber,
          .normal, .subnormal };
.type = { .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">testp</span></code> tests common properties of floating-point numbers and returns a predicate value of <code class="docutils literal notranslate"><span class="pre">1</span></code>
if <code class="docutils literal notranslate"><span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">0</span></code> if <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">testp.finite</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is not infinite or <code class="docutils literal notranslate"><span class="pre">NaN</span></code></p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">testp.infinite</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is positive or negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">testp.number</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is not <code class="docutils literal notranslate"><span class="pre">NaN</span></code></p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">testp.notanumber</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is <code class="docutils literal notranslate"><span class="pre">NaN</span></code></p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">testp.normal</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is a normal number (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, not infinity)</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">testp.subnormal</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if the input is a subnormal number (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, not infinity)</p>
</dd>
</dl>
<p>As a special case, positive and negative zero are considered normal numbers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>testp.notanumber.f32  isnan, f0;
testp.infinite.f64    p, X;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-copysign">
<span id="id196"></span><h4>
<span class="section-number">9.7.3.2. </span><a class="reference internal" href="#floating-point-instructions-copysign">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">copysign</span></code></a><a class="headerlink" href="#floating-point-instructions-copysign" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">copysign</span></code></p>
<p>Copy sign of one input to another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>copysign.type  d, a, b;

.type = { .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Copy sign bit of <code class="docutils literal notranslate"><span class="pre">a</span></code> into value of <code class="docutils literal notranslate"><span class="pre">b</span></code>, and return the result as <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>copysign.f32  x, y, z;
copysign.f64  A, B, C;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-add">
<span id="id197"></span><h4>
<span class="section-number">9.7.3.3. </span><a class="reference internal" href="#floating-point-instructions-add">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a><a class="headerlink" href="#floating-point-instructions-add" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">add</span></code></p>
<p>Add two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>add{.rnd}{.ftz}{.sat}.f32  d, a, b;
add{.rnd}{.ftz}.f32x2      d, a, b;
add{.rnd}.f64              d, a, b;

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs addition and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, forms input vectors of single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) values from
source operands. Single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) operands are then added in parallel to produce
<code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b64</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f32 || type == f64) {
    d = a + b;
} else if (type == f32x2) {
    fA[0] = a[0:31];
    fA[1] = a[32:63];
    fB[0] = b[0:31];
    fB[1] = b[32:63];
    for (i = 0; i &lt; 2; i++) {
        d[i] = fA[i] + fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that an <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. An <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">add</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.ftz.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">add.ftz.f32x2</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">add.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>Saturation modifier:</p>
<p><code class="docutils literal notranslate"><span class="pre">add.sat.f32</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f32x2</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Rounding modifiers have the following target requirements:</p>
<dl>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rn</span></code>, <code class="docutils literal notranslate"><span class="pre">.rz</span></code>
</dt>
<dd>
<p>available for all targets</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rm</span></code>, <code class="docutils literal notranslate"><span class="pre">.rp</span></code>
</dt>
<dd>
<p>for <code class="docutils literal notranslate"><span class="pre">add.f64</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>for <code class="docutils literal notranslate"><span class="pre">add.f32</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">add.f32x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  add.rz.ftz.f32  f1,f2,f3;
add.rp.ftz.f32x2    d, a, b;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-sub">
<span id="id198"></span><h4>
<span class="section-number">9.7.3.4. </span><a class="reference internal" href="#floating-point-instructions-sub">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a><a class="headerlink" href="#floating-point-instructions-sub" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sub</span></code></p>
<p>Subtract one value from another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub{.rnd}{.ftz}{.sat}.f32  d, a, b;
sub{.rnd}{.ftz}.f32x2      d, a, b;
sub{.rnd}.f64              d, a, b;

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs subtraction and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, forms input vectors of single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) values
from source operands. Single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) operands are then subtracted in parallel
to produce <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b64</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f32 || type == f64) {
    d = a - b;
} else if (type == f32x2) {
    fA[0] = a[0:31];
    fA[1] = a[32:63];
    fB[0] = b[0:31];
    fB[1] = b[32:63];
    for (i = 0; i &lt; 2; i++) {
        d[i] = fA[i] - fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that a <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. A <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">sub</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.ftz.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">sub.ftz.f32x2</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">sub.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>Saturation modifier:</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.sat.f32</span></code> clamps the result to [0.0, 1.0]. NaN results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32x2</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Rounding modifiers have the following target requirements:</p>
<dl>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rn</span></code>, <code class="docutils literal notranslate"><span class="pre">.rz</span></code>
</dt>
<dd>
<p>available for all targets</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rm</span></code>, <code class="docutils literal notranslate"><span class="pre">.rp</span></code>
</dt>
<dd>
<p>for <code class="docutils literal notranslate"><span class="pre">sub.f64</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>for <code class="docutils literal notranslate"><span class="pre">sub.f32</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub.f32 c,a,b;
sub.rn.ftz.f32  f1,f2,f3;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-mul">
<span id="id199"></span><h4>
<span class="section-number">9.7.3.5. </span><a class="reference internal" href="#floating-point-instructions-mul">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a><a class="headerlink" href="#floating-point-instructions-mul" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mul</span></code></p>
<p>Multiply two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul{.rnd}{.ftz}{.sat}.f32  d, a, b;
mul{.rnd}{.ftz}.f32x2      d, a, b;
mul{.rnd}.f64              d, a, b;

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the product of two values.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, forms input vectors of single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) values
from source operands. Single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) operands are then multiplied in parallel
to produce <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b64</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f32 || type == f64) {
    d = a * b;
} else if (type == f32x2) {
    fA[0] = a[0:31];
    fA[1] = a[32:63];
    fB[0] = b[0:31];
    fB[1] = b[32:63];
    for (i = 0; i &lt; 2; i++) {
        d[i] = fA[i] * fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>For floating-point multiplication, all operands must be the same size.</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that a <code class="docutils literal notranslate"><span class="pre">mul</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. A <code class="docutils literal notranslate"><span class="pre">mul</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul/add</span></code> and <code class="docutils literal notranslate"><span class="pre">mul/sub</span></code> sequences with no rounding modifiers may be
optimized to use fused-multiply-add instructions on the target device.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.ftz.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">mul.ftz.f32x2</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">mul.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>Saturation modifier:</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.sat.f32</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.f32x2</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Rounding modifiers have the following target requirements:</p>
<dl>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rn</span></code>, <code class="docutils literal notranslate"><span class="pre">.rz</span></code>
</dt>
<dd>
<p>available for all targets</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.rm</span></code>, <code class="docutils literal notranslate"><span class="pre">.rp</span></code>
</dt>
<dd>
<p>for <code class="docutils literal notranslate"><span class="pre">mul.f64</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>for <code class="docutils literal notranslate"><span class="pre">mul.f32</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">mul.f32x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul.ftz.f32 circumf,radius,pi  // a single-precision multiply
</pre></div>
</div>
</section>
<section id="floating-point-instructions-fma">
<span id="id200"></span><h4>
<span class="section-number">9.7.3.6. </span><a class="reference internal" href="#floating-point-instructions-fma">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a><a class="headerlink" href="#floating-point-instructions-fma" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">fma</span></code></p>
<p>Fused multiply-add.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>fma.rnd{.ftz}{.sat}.f32  d, a, b, c;
fma.rnd{.ftz}.f32x2      d, a, b, c;
fma.rnd.f64              d, a, b, c;

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs a fused multiply-add with no loss of precision in the intermediate product and addition.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, forms input vectors of single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) values from
source operands. Single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) operands are then operated in parallel to produce
<code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.b64</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f32 || type == f64) {
    d = a * b + c;
} else if (type == f32x2) {
    fA[0] = a[0:31];
    fA[1] = a[32:63];
    fB[0] = b[0:31];
    fB[1] = b[32:63];
    fC[0] = c[0:31];
    fC[1] = c[32:63];
    for (i = 0; i &lt; 2; i++) {
        d[i] = fA[i] * fB[i] + fC[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds <code class="docutils literal notranslate"><span class="pre">c</span></code> to
this product, again in infinite precision. The resulting value is then rounded to single precision
using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds <code class="docutils literal notranslate"><span class="pre">c</span></code> to
this product, again in infinite precision. The resulting value is then rounded to double precision
using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">mad.f64</span></code>.</p>
<p>Rounding modifiers (no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.ftz.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">fma.ftz.f32x2</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> is unimplemented for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets.</p>
</dd>
</dl>
<p>Saturation:</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.sat.f32</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> introduced in PTX ISA version 1.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32x2</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    fma.rn.ftz.f32  w,x,y,z;
@p  fma.rn.f64      d,a,b,c;
    fma.rp.ftz.f32x2 p,q,r,s;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-mad">
<span id="id201"></span><h4>
<span class="section-number">9.7.3.7. </span><a class="reference internal" href="#floating-point-instructions-mad">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mad</span></code></a><a class="headerlink" href="#floating-point-instructions-mad" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mad</span></code></p>
<p>Multiply two values and add a third value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mad{.ftz}{.sat}.f32      d, a, b, c;    // .target sm_1x
mad.rnd{.ftz}{.sat}.f32  d, a, b, c;    // .target sm_20
mad.rnd.f64              d, a, b, c;    // .target sm_13 and higher

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Multiplies two values and adds a third, and then writes the resulting value into a destination
register.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a*b + c;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_20</span></code> and higher:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds <code class="docutils literal notranslate"><span class="pre">c</span></code> to
this product, again in infinite precision. The resulting value is then rounded to single precision
using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds <code class="docutils literal notranslate"><span class="pre">c</span></code> to
this product, again in infinite precision. The resulting value is then rounded to double precision
using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad.{f32,f64}</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">fma.{f32,f64}</span></code>.</p></li>
</ul>
<p>For <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_1x</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> at double precision, and then the mantissa is
truncated to 23 bits, but the exponent is preserved. Note that this is different from computing
the product with <code class="docutils literal notranslate"><span class="pre">mul</span></code>, where the mantissa can be rounded and the exponent will be clamped. The
exception for <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> is when <code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">+/-0.0</span></code>, <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> is identical to the result computed
using separate mul and add instructions. When JIT-compiled for SM 2.0 devices, <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> is
implemented as a fused multiply-add (i.e., <code class="docutils literal notranslate"><span class="pre">fma.rn.ftz.f32</span></code>). In this case, <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> can
produce slightly different numeric results and backward compatibility is not guaranteed in this
case.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds <code class="docutils literal notranslate"><span class="pre">c</span></code> to
this product, again in infinite precision. The resulting value is then rounded to double precision
using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>. Unlike <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code>, the treatment of subnormal
inputs and output follows IEEE 754 standard.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> is the same as <code class="docutils literal notranslate"><span class="pre">fma.f64</span></code>.</p></li>
</ul>
<p>Rounding modifiers (no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>Saturation modifier:</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.sat.f32</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>In PTX ISA versions 1.4 and later, a rounding modifier is required for <code class="docutils literal notranslate"><span class="pre">mad.f64</span></code>.</p>
<p>Legacy <code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> instructions having no rounding modifier will map to <code class="docutils literal notranslate"><span class="pre">mad.rn.f64</span></code>.</p>
<p>In PTX ISA versions 2.0 and later, a rounding modifier is required for <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and higher targets.</p>
<p class="rubric">Errata</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> requires a rounding modifier for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and higher targets. However for PTX ISA
version 3.0 and earlier, ptxas does not enforce this requirement and <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> silently defaults
to <code class="docutils literal notranslate"><span class="pre">mad.rn.f32</span></code>. For PTX ISA version 3.1, ptxas generates a warning and defaults to
<code class="docutils literal notranslate"><span class="pre">mad.rn.f32</span></code>, and in subsequent releases ptxas will enforce the requirement for PTX ISA version
3.2 and later.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">mad.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Rounding modifiers have the following target requirements:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.rn</span></code>, <code class="docutils literal notranslate"><span class="pre">.rz</span></code>, <code class="docutils literal notranslate"><span class="pre">.rm</span></code>, <code class="docutils literal notranslate"><span class="pre">.rp</span></code> for <code class="docutils literal notranslate"><span class="pre">mad.f64</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.rn</span></code>, <code class="docutils literal notranslate"><span class="pre">.rz</span></code>, <code class="docutils literal notranslate"><span class="pre">.rm</span></code>, <code class="docutils literal notranslate"><span class="pre">.rp</span></code> for <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code>, requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  mad.f32  d,a,b,c;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-div">
<span id="id202"></span><h4>
<span class="section-number">9.7.3.8. </span><a class="reference internal" href="#floating-point-instructions-div">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">div</span></code></a><a class="headerlink" href="#floating-point-instructions-div" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">div</span></code></p>
<p>Divide one value by another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>div.approx{.ftz}.f32  d, a, b;  // fast, approximate divide
div.full{.ftz}.f32    d, a, b;  // full-range approximate divide
div.rnd{.ftz}.f32     d, a, b;  // IEEE 754 compliant rounding
div.rnd.f64           d, a, b;  // IEEE 754 compliant rounding

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Divides <code class="docutils literal notranslate"><span class="pre">a</span></code> by <code class="docutils literal notranslate"><span class="pre">b</span></code>, stores result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a / b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p class="rubric">Fast, approximate single-precision divides:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">div.approx.f32</span></code> implements a fast approximation to divide, computed as <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">a</span> <span class="pre">*</span> <span class="pre">(1/b)</span></code>. For
<code class="docutils literal notranslate"><span class="pre">|b|</span></code> in [2<sup>-126</sup>, 2<sup>126</sup>], the maximum <code class="docutils literal notranslate"><span class="pre">ulp</span></code> error is 2. For 2<sup>126</sup> &lt;
<code class="docutils literal notranslate"><span class="pre">|b|</span></code> &lt; 2<sup>128</sup>, if <code class="docutils literal notranslate"><span class="pre">a</span></code> is infinity, <code class="docutils literal notranslate"><span class="pre">div.approx.f32</span></code> returns <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, otherwise it
returns a sign-preserving zero.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">div.full.f32</span></code> implements a relatively fast, full-range approximation that scales operands to
achieve better accuracy, but is not fully IEEE 754 compliant and does not support rounding
modifiers. The maximum <code class="docutils literal notranslate"><span class="pre">ulp</span></code> error is 2 across the full range of inputs.</p></li>
</ul>
<p class="rubric">Divide with IEEE 754 compliant rounding:</p>
<p>Rounding modifiers (no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">div.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">div.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">div.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">div.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">div.f64</span></code> introduced in PTX ISA version 1.0.</p>
<p>Explicit modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code>, <code class="docutils literal notranslate"><span class="pre">.full</span></code>, <code class="docutils literal notranslate"><span class="pre">.ftz</span></code>, and rounding introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, one of <code class="docutils literal notranslate"><span class="pre">.approx</span></code>, <code class="docutils literal notranslate"><span class="pre">.full</span></code>, or <code class="docutils literal notranslate"><span class="pre">.rnd</span></code> is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">div.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">div.approx.ftz.f32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">div.f64</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">div.rn.f64</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">div.approx.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">div.full.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">div.rnd.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">div.rn.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher, or <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">map_f64_to_f32</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">div.{rz,rm,rp}.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>div.approx.ftz.f32  diam,circum,3.14159;
div.full.ftz.f32    x, y, z;
div.rn.f64          xd, yd, zd;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-abs">
<span id="id203"></span><h4>
<span class="section-number">9.7.3.9. </span><a class="reference internal" href="#floating-point-instructions-abs">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a><a class="headerlink" href="#floating-point-instructions-abs" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">abs</span></code></p>
<p>Absolute value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs{.ftz}.f32  d, a;
abs.f64        d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Take the absolute value of <code class="docutils literal notranslate"><span class="pre">a</span></code> and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = |a|;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">abs.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>For <code class="docutils literal notranslate"><span class="pre">abs.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">NaN</span></code> input yields unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. For <code class="docutils literal notranslate"><span class="pre">abs.f64</span></code>, <code class="docutils literal notranslate"><span class="pre">NaN</span></code> input is passed
through unchanged. Future implementations may comply with the IEEE 754 standard by preserving
payload and modifying only the sign bit.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs.ftz.f32  x,f0;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-neg">
<span id="id204"></span><h4>
<span class="section-number">9.7.3.10. </span><a class="reference internal" href="#floating-point-instructions-neg">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a><a class="headerlink" href="#floating-point-instructions-neg" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">neg</span></code></p>
<p>Arithmetic negate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg{.ftz}.f32  d, a;
neg.f64        d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Negate the sign of <code class="docutils literal notranslate"><span class="pre">a</span></code> and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = -a;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">neg.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">NaN</span></code> inputs yield an unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Future implementations may comply with the IEEE 754
standard by preserving payload and modifying only the sign bit.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg.ftz.f32  x,f0;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-min">
<span id="id205"></span><h4>
<span class="section-number">9.7.3.11. </span><a class="reference internal" href="#floating-point-instructions-min">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a><a class="headerlink" href="#floating-point-instructions-min" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">min</span></code></p>
<p>Find the minimum of given values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>min{.ftz}{.NaN}{.xorsign.abs}.f32  d, a, b;
min{.ftz}{.NaN}{.abs}.f32          d, a, b, c;
min.f64                            d, a, b;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the minimum of <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and optionally <code class="docutils literal notranslate"><span class="pre">c</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> modifier is specified, then the result is canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> if any of the inputs is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifier is specified, the magnitude of destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is the minimum of
absolute values of both input arguments.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> modifier is specified, the sign bit of destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is equal to the XOR of the
sign bits of both inputs <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>. The <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> qualifier cannot be specified for three
inputs operation.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> requires qualifier <code class="docutils literal notranslate"><span class="pre">.abs</span></code> to be specified. In such cases, <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code>
considers the sign bit of both inputs before applying <code class="docutils literal notranslate"><span class="pre">.abs</span></code> operation.</p>
<p>If the result of <code class="docutils literal notranslate"><span class="pre">min</span></code> is <code class="docutils literal notranslate"><span class="pre">NaN</span></code> then the <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifiers will be ignored.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>def min_num (z, x, y) {
    if (isNaN(x) &amp;&amp; isNaN(y))
        z = NaN;
    else if (isNaN(x))
        z = y;
    else if (isNaN(y))
        z = x;
    else
        // note: -0.0 &lt; +0.0 here
        z = (x &lt; y) ? x : y;
    return z;
}

def min_nan (z, x, y) {
    if (isNaN(x) || isNaN(y))
        z = NaN;
    else
        // note: -0.0 &lt; +0.0 here
        z = (x &lt; y) ? x : y;
    return z;
}

def two_inputs_min (z, x, y) {
    if (.NaN)
        z = min_nan(z, x, y);
    else
        z = min_num(z, x, y);
    return z;
}

if (.xorsign &amp;&amp; !isPresent(c)) {
    xorsign = getSignBit(a) ^ getSignBit(b);
}
if (.abs) {
    a = |a|;
    b = |b|;
    if (isPresent(c)) {
        c = |c|;
    }
}

d = two_inputs_min(d, a, b)
if (isPresent(c)) {
    d = two_inputs_min(d, d, c)
}
if (.xorsign &amp;&amp; !isPresent(c) &amp;&amp; !isNaN(d)) {
    setSignBit(d, xorsign);
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">min.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>If values of both inputs are 0.0, then +0.0 &gt; -0.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.NaN</span></code> introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.xorsign.abs</span></code> introduced in PTX ISA version 7.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">min</span></code> with three input arguments introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">min.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.NaN</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.xorsign.abs</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">min</span></code> with three input arguments requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  min.ftz.f32  z,z,x;
    min.f64      a,b,c;
    // fp32 min with .NaN
    min.NaN.f32  f0,f1,f2;
    // fp32 min with .xorsign.abs
    min.xorsign.abs.f32 Rd, Ra, Rb;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-max">
<span id="id206"></span><h4>
<span class="section-number">9.7.3.12. </span><a class="reference internal" href="#floating-point-instructions-max">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a><a class="headerlink" href="#floating-point-instructions-max" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">max</span></code></p>
<p>Find the maximum of given values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max{.ftz}{.NaN}{.xorsign.abs}.f32  d, a, b;
max{.ftz}{.NaN}{.abs}.f32          d, a, b, c;
max.f64                            d, a, b;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the maximum of <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and optionally <code class="docutils literal notranslate"><span class="pre">c</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> modifier is specified, the result is canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> if any of the inputs is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifier is specified, the magnitude of destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is the maximum of
absolute values of the input arguments.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> modifier is specified, the sign bit of destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is equal to the XOR of the
sign bits of the inputs: <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>. The <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> qualifier cannot be specified for three
inputs operation.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> requires qualifier <code class="docutils literal notranslate"><span class="pre">.abs</span></code> to be specified. In such cases, <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code>
considers the sign bit of both inputs before applying <code class="docutils literal notranslate"><span class="pre">.abs</span></code> operation.</p>
<p>If the result of <code class="docutils literal notranslate"><span class="pre">max</span></code> is <code class="docutils literal notranslate"><span class="pre">NaN</span></code> then the <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifiers will be ignored.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>def max_num (z, x, y) {
    if (isNaN(x) &amp;&amp; isNaN(y))
        z = NaN;
    else if (isNaN(x))
        z = y;
    else if (isNaN(y))
        z = x;
    else
        // note: +0.0 &gt; -0.0 here
        z = (x &gt; y) ? x : y;
    return z;
}

def max_nan (z, x, y) {
    if (isNaN(x) || isNaN(y))
        z = NaN;
    else
        // note: +0.0 &gt; -0.0 here
        z = (x &gt; y) ? x : y;
    return z;
}

def two_inputs_max (z, x, y) {
    if (.NaN)
        z = max_nan(z, x, y);
    else
        z = max_num(z, x, y);
    return z;
}

if (.xorsign &amp;&amp; !isPresent(c)) {
    xorsign = getSignBit(a) ^ getSignBit(b);
}
if (.abs) {
    a = |a|;
    b = |b|;
    if (isPresent(c)) {
        c = |c|;
    }
}

d = two_inputs_max (d, a, b)
if (isPresent(c)) {
    d = two_inputs_max (d, d, c)
}

if (.xorsign &amp;&amp; !isPresent(c) !isNaN(d)) {
    setSignBit(d, xorsign);
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">max.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>If values of both inputs are 0.0, then +0.0 &gt; -0.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.NaN</span></code> introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.xorsign.abs</span></code> introduced in PTX ISA version 7.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">max</span></code> with three input arguments introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">max.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.NaN</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.xorsign.abs</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">max</span></code> with three input arguments requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max.ftz.f32  f0,f1,f2;
max.f64      a,b,c;
// fp32 max with .NaN
max.NaN.f32  f0,f1,f2;
// fp32 max with .xorsign.abs
max.xorsign.abs.f32 Rd, Ra, Rb;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-rcp">
<span id="id207"></span><h4>
<span class="section-number">9.7.3.13. </span><a class="reference internal" href="#floating-point-instructions-rcp">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rcp</span></code></a><a class="headerlink" href="#floating-point-instructions-rcp" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">rcp</span></code></p>
<p>Take the reciprocal of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rcp.approx{.ftz}.f32  d, a;  // fast, approximate reciprocal
rcp.rnd{.ftz}.f32     d, a;  // IEEE 754 compliant rounding
rcp.rnd.f64           d, a;  // IEEE 754 compliant rounding

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute <code class="docutils literal notranslate"><span class="pre">1/a</span></code>, store result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = 1 / a;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p class="rubric">Fast, approximate single-precision reciprocal:</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.approx.f32</span></code> implements a fast approximation to reciprocal.
The maximum ulp error is 1 across the full range of inputs.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Reciprocal with IEEE 754 compliant rounding:</p>
<p>Rounding modifiers (no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">rcp.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">rcp.f64</span></code> introduced in PTX ISA version 1.0. <code class="docutils literal notranslate"><span class="pre">rcp.rn.f64</span></code> and explicit modifiers
<code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> were introduced in PTX ISA version 1.4. General rounding modifiers were
added in PTX ISA version 2.0.</p>
<p>For PTX ISA version 1.4 and later, one of <code class="docutils literal notranslate"><span class="pre">.approx</span></code> or <code class="docutils literal notranslate"><span class="pre">.rnd</span></code> is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">rcp.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">rcp.f64</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">rcp.rn.f64</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.approx.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.rnd.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.rn.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher, or <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">map_f64_to_f32.</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.{rz,rm,rp}.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rcp.approx.ftz.f32  ri,r;
rcp.rn.ftz.f32      xi,x;
rcp.rn.f64          xi,x;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-rcp-approx-ftz-f64">
<span id="id208"></span><h4>
<span class="section-number">9.7.3.14. </span><a class="reference internal" href="#floating-point-instructions-rcp-approx-ftz-f64">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code></a><a class="headerlink" href="#floating-point-instructions-rcp-approx-ftz-f64" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code></p>
<p>Compute a fast, gross approximation to the reciprocal of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rcp.approx.ftz.f64  d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute a fast, gross approximation to the reciprocal as follows:</p>
<ol class="arabic simple">
<li><p>extract the most-significant 32 bits of <code class="docutils literal notranslate"><span class="pre">.f64</span></code> operand <code class="docutils literal notranslate"><span class="pre">a</span></code> in 1.11.20 IEEE floating-point
format (i.e., ignore the least-significant 32 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code>),</p></li>
<li><p>compute an approximate <code class="docutils literal notranslate"><span class="pre">.f64</span></code> reciprocal of this value using the most-significant 20 bits of
the mantissa of operand <code class="docutils literal notranslate"><span class="pre">a</span></code>,</p></li>
<li><p>place the resulting 32-bits in 1.11.20 IEEE floating-point format in the most-significant 32-bits
of destination <code class="docutils literal notranslate"><span class="pre">d</span></code>,and</p></li>
<li><p>zero the least significant 32 mantissa bits of <code class="docutils literal notranslate"><span class="pre">.f64</span></code> destination <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ol>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tmp = a[63:32]; // upper word of a, 1.11.20 format
d[63:32] = 1.0 / tmp;
d[31:0] = 0x00000000;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code> implements a fast, gross approximation to reciprocal.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 48%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input a[63:32]</p></th>
<th class="head"><p>Result d[63:32]</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-subnormal</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>+subnormal</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>Input <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s map to a canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> with encoding <code class="docutils literal notranslate"><span class="pre">0x7fffffff00000000</span></code>.</p>
<p>Subnormal inputs and results are flushed to sign-preserving zero.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code> introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rcp.approx.ftz.f64  xi,x;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-sqrt">
<span id="id209"></span><h4>
<span class="section-number">9.7.3.15. </span><a class="reference internal" href="#floating-point-instructions-sqrt">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sqrt</span></code></a><a class="headerlink" href="#floating-point-instructions-sqrt" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sqrt</span></code></p>
<p>Take the square root of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sqrt.approx{.ftz}.f32  d, a; // fast, approximate square root
sqrt.rnd{.ftz}.f32     d, a; // IEEE 754 compliant rounding
sqrt.rnd.f64           d, a; // IEEE 754 compliant rounding

.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute sqrt(<code class="docutils literal notranslate"><span class="pre">a</span></code>) and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = sqrt(a);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.approx.f32</span></code> implements a fast approximation to square root.
The maximum relative error over the entire positive finite floating-point
range is 2<sup>-23</sup>.</p>
<p>For various corner-case inputs, results of <code class="docutils literal notranslate"><span class="pre">sqrt</span></code> instruction are shown
in below table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 57%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-normal</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-even">
<td><p>+Inf</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Square root with IEEE 754 compliant rounding:</p>
<p>Rounding modifiers (no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">sqrt.f64</span></code> introduced in PTX ISA version 1.0. <code class="docutils literal notranslate"><span class="pre">sqrt.rn.f64</span></code> and explicit
modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> were introduced in PTX ISA version 1.4. General rounding
modifiers were added in PTX ISA version 2.0.</p>
<p>For PTX ISA version 1.4 and later, one of <code class="docutils literal notranslate"><span class="pre">.approx</span></code> or <code class="docutils literal notranslate"><span class="pre">.rnd</span></code> is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">sqrt.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">sqrt.approx.ftz.f32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">sqrt.f64</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">sqrt.rn.f64</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.approx.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.rnd.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.rn.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher, or <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">map_f64_to_f32</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">sqrt.{rz,rm,rp}.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sqrt.approx.ftz.f32  r,x;
sqrt.rn.ftz.f32      r,x;
sqrt.rn.f64          r,x;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-rsqrt">
<span id="id210"></span><h4>
<span class="section-number">9.7.3.16. </span><a class="reference internal" href="#floating-point-instructions-rsqrt">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rsqrt</span></code></a><a class="headerlink" href="#floating-point-instructions-rsqrt" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">rsqrt</span></code></p>
<p>Take the reciprocal of the square root of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rsqrt.approx{.ftz}.f32  d, a;
rsqrt.approx.f64        d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute <code class="docutils literal notranslate"><span class="pre">1/sqrt(a)</span></code> and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = 1/sqrt(a);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx</span></code> implements an approximation to the reciprocal square root.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 57%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-normal</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>+Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum relative error for <code class="docutils literal notranslate"><span class="pre">rsqrt.f32</span></code> over the entire positive
finite floating-point range is 2<sup>-22.9</sup>.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>Note that <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.f64</span></code> is emulated in software and are relatively slow.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">rsqrt.f64</span></code> were introduced in PTX ISA version 1.0. Explicit modifiers
<code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> were introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, the <code class="docutils literal notranslate"><span class="pre">.approx</span></code> modifier is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">rsqrt.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f32</span></code>, and
<code class="docutils literal notranslate"><span class="pre">rsqrt.f64</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.f64</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.f32</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rsqrt.approx.ftz.f32  isr, x;
rsqrt.approx.f64      ISR, X;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-rsqrt-approx-ftz-f64">
<span id="id211"></span><h4>
<span class="section-number">9.7.3.17. </span><a class="reference internal" href="#floating-point-instructions-rsqrt-approx-ftz-f64">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code></a><a class="headerlink" href="#floating-point-instructions-rsqrt-approx-ftz-f64" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code></p>
<p>Compute an approximation of the square root reciprocal of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rsqrt.approx.ftz.f64 d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute a double-precision (<code class="docutils literal notranslate"><span class="pre">.f64</span></code>) approximation of the square root reciprocal of a value. The
least significant 32 bits of the double-precision (<code class="docutils literal notranslate"><span class="pre">.f64</span></code>) destination <code class="docutils literal notranslate"><span class="pre">d</span></code> are all zeros.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tmp = a[63:32]; // upper word of a, 1.11.20 format
d[63:32] = 1.0 / sqrt(tmp);
d[31:0] = 0x00000000;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code> implements a fast approximation of the square root reciprocal of a value.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 57%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-subnormal</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>+subnormal</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>Input <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s map to a canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> with encoding <code class="docutils literal notranslate"><span class="pre">0x7fffffff00000000</span></code>.</p>
<p>Subnormal inputs and results are flushed to sign-preserving zero.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code> introduced in PTX ISA version 4.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>rsqrt.approx.ftz.f64 xi,x;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-sin">
<span id="id212"></span><h4>
<span class="section-number">9.7.3.18. </span><a class="reference internal" href="#floating-point-instructions-sin">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sin</span></code></a><a class="headerlink" href="#floating-point-instructions-sin" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sin</span></code></p>
<p>Find the sine of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sin.approx{.ftz}.f32  d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Find the sine of the angle <code class="docutils literal notranslate"><span class="pre">a</span></code> (in radians).</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = sin(a);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sin.approx.f32</span></code> implements a fast approximation to sine.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum absolute error over input range is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 39%">
<col style="width: 46%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>Range</p></td>
<td><p>[-2pi .. 2pi]</p></td>
<td><p>[-100pi .. +100pi]</p></td>
</tr>
<tr class="row-even">
<td><p>Error</p></td>
<td><p>2<sup>-20.5</sup></p></td>
<td><p>2<sup>-14.7</sup></p></td>
</tr>
</tbody>
</table>
<p>Outside of the range [-100pi .. +100pi], only best effort
is provided. There are no defined error guarantees.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">sin.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>Subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sin.f32</span></code> introduced in PTX ISA version 1.0. Explicit modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code>
introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, the .approx modifier is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">sin.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">sin.approx.ftz.f32</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sin.approx.ftz.f32  sa, a;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-cos">
<span id="id213"></span><h4>
<span class="section-number">9.7.3.19. </span><a class="reference internal" href="#floating-point-instructions-cos">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">cos</span></code></a><a class="headerlink" href="#floating-point-instructions-cos" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cos</span></code></p>
<p>Find the cosine of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cos.approx{.ftz}.f32  d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Find the cosine of the angle <code class="docutils literal notranslate"><span class="pre">a</span></code> (in radians).</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = cos(a);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">cos.approx.f32</span></code> implements a fast approximation to cosine.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 57%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum absolute error over input range is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 39%">
<col style="width: 46%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>Range</p></td>
<td><p>[-2pi .. 2pi]</p></td>
<td><p>[-100pi .. +100pi]</p></td>
</tr>
<tr class="row-even">
<td><p>Error</p></td>
<td><p>2<sup>-20.5</sup></p></td>
<td><p>2<sup>-14.7</sup></p></td>
</tr>
</tbody>
</table>
<p>Outside of the range [-100pi .. +100pi], only best effort
is provided. There are no defined error guarantees.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">cos.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>Subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">cos.f32</span></code> introduced in PTX ISA version 1.0. Explicit modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code>
introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, the <code class="docutils literal notranslate"><span class="pre">.approx</span></code> modifier is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">cos.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">cos.approx.ftz.f32</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cos.approx.ftz.f32  ca, a;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-lg2">
<span id="id214"></span><h4>
<span class="section-number">9.7.3.20. </span><a class="reference internal" href="#floating-point-instructions-lg2">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">lg2</span></code></a><a class="headerlink" href="#floating-point-instructions-lg2" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">lg2</span></code></p>
<p>Find the base-2 logarithm of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>lg2.approx{.ftz}.f32  d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Determine the log<sub>2</sub> of <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = log(a) / log(2);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">lg2.approx.f32</span></code> implements a fast approximation to log<sub>2</sub>(a).</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 57%">
<col style="width: 43%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-odd">
<td><p>-normal</p></td>
<td><p>NaN</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>-Inf</p></td>
</tr>
<tr class="row-even">
<td><p>+Inf</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-odd">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum absolute error is 2<sup>-22</sup> when the input operand is in the
range (0.5, 2). For positive finite inputs outside of this interval, maximum
relative error is 2<sup>-22</sup>.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">lg2.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>Subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">lg2.f32</span></code> introduced in PTX ISA version 1.0. Explicit modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code>
introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, the <code class="docutils literal notranslate"><span class="pre">.approx</span></code> modifier is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">lg2.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">lg2.approx.ftz.f32</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>lg2.approx.ftz.f32  la, a;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-ex2">
<span id="id215"></span><h4>
<span class="section-number">9.7.3.21. </span><a class="reference internal" href="#floating-point-instructions-ex2">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">ex2</span></code></a><a class="headerlink" href="#floating-point-instructions-ex2" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ex2</span></code></p>
<p>Find the base-2 exponential of a value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ex2.approx{.ftz}.f32  d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Raise 2 to the power <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = 2 ^ a;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.approx.f32</span></code> implements a fast approximation to 2<sup>a</sup>.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum ulp error is 2 ulp from correctly rounded result across the
full range of inputs.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.ftz.f32</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>Subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.f32</span></code> introduced in PTX ISA version 1.0. Explicit modifiers <code class="docutils literal notranslate"><span class="pre">.approx</span></code> and <code class="docutils literal notranslate"><span class="pre">.ftz</span></code>
introduced in PTX ISA version 1.4.</p>
<p>For PTX ISA version 1.4 and later, the <code class="docutils literal notranslate"><span class="pre">.approx</span></code> modifier is required.</p>
<p>For PTX ISA versions 1.0 through 1.3, <code class="docutils literal notranslate"><span class="pre">ex2.f32</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">ex2.approx.ftz.f32</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ex2.approx.ftz.f32  xa, a;
</pre></div>
</div>
</section>
<section id="floating-point-instructions-tanh">
<span id="id216"></span><h4>
<span class="section-number">9.7.3.22. </span><a class="reference internal" href="#floating-point-instructions-tanh">Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">tanh</span></code></a><a class="headerlink" href="#floating-point-instructions-tanh" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tanh</span></code></p>
<p>Find the hyperbolic tangent of a value (in radians)</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tanh.approx.f32 d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Take hyperbolic tangent value of <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>The operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> are of type <code class="docutils literal notranslate"><span class="pre">.f32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = tanh(a);
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">tanh.approx.f32</span></code> implements a fast approximation to FP32 hyperbolic-tangent.</p>
<p>Results of <code class="docutils literal notranslate"><span class="pre">tanh</span></code> for various corner-case inputs are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 44%">
<col style="width: 56%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>-1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum relative error over the entire floating point
range is 2<sup>-11</sup>.
The subnormal numbers are supported.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The subnormal inputs gets passed through to the output since the value of <code class="docutils literal notranslate"><span class="pre">tanh(x)</span></code> for small
values of <code class="docutils literal notranslate"><span class="pre">x</span></code> is approximately the same as <code class="docutils literal notranslate"><span class="pre">x</span></code>.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tanh.approx.f32 ta, a;
</pre></div>
</div>
</section>
</section>
<section id="half-precision-floating-point-instructions">
<span id="id217"></span><h3>
<span class="section-number">9.7.4. </span><a class="reference internal" href="#half-precision-floating-point-instructions">Half Precision Floating-Point Instructions</a><a class="headerlink" href="#half-precision-floating-point-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Half precision floating-point instructions operate on <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> register operands. The
half precision floating-point instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sub</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mul</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">neg</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">abs</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tanh</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ex2</span></code></p></li>
</ul>
<p>Half-precision <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">mul</span></code>, and <code class="docutils literal notranslate"><span class="pre">fma</span></code> support saturation of results to the range
[0.0, 1.0], with <code class="docutils literal notranslate"><span class="pre">NaN</span></code>s being flushed to positive zero. Half-precision instructions return an
unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<section id="half-precision-floating-point-instructions-add">
<span id="id218"></span><h4>
<span class="section-number">9.7.4.1. </span><a class="reference internal" href="#half-precision-floating-point-instructions-add">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-add" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">add</span></code></p>
<p>Add two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>add{.rnd}{.ftz}{.sat}.f16   d, a, b;
add{.rnd}{.ftz}{.sat}.f16x2 d, a, b;

add{.rnd}.bf16   d, a, b;
add{.rnd}.bf16x2 d, a, b;

.rnd = { .rn };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs addition and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vectors by half word values from source
operands. Half-word operands are then added in parallel to produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> result
in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type,
operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = a + b;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = fA[i] + fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that an <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. An <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">add</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">add.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">add.sat.{f16,</span> <span class="pre">f16x2}</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">add{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">add{.rnd}.bf16x2</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">add{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">add{.rnd}.bf16x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// scalar f16 additions
add.f16        d0, a0, b0;
add.rn.f16     d1, a1, b1;
add.bf16       bd0, ba0, bb0;
add.rn.bf16    bd1, ba1, bb1;

// SIMD f16 addition
cvt.rn.f16.f32 h0, f0;
cvt.rn.f16.f32 h1, f1;
cvt.rn.f16.f32 h2, f2;
cvt.rn.f16.f32 h3, f3;
mov.b32  p1, {h0, h1};   // pack two f16 to 32bit f16x2
mov.b32  p2, {h2, h3};   // pack two f16 to 32bit f16x2
add.f16x2  p3, p1, p2;   // SIMD f16x2 addition

// SIMD bf16 addition
cvt.rn.bf16x2.f32 p4, f4, f5; // Convert two f32 into packed bf16x2
cvt.rn.bf16x2.f32 p5, f6, f7; // Convert two f32 into packed bf16x2
add.bf16x2  p6, p4, p5;       // SIMD bf16x2 addition

// SIMD fp16 addition
ld.global.b32   f0, [addr];     // load 32 bit which hold packed f16x2
ld.global.b32   f1, [addr + 4]; // load 32 bit which hold packed f16x2
add.f16x2       f2, f0, f1;     // SIMD f16x2 addition

ld.global.b32   f3, [addr + 8];  // load 32 bit which hold packed bf16x2
ld.global.b32   f4, [addr + 12]; // load 32 bit which hold packed bf16x2
add.bf16x2      f5, f3, f4;      // SIMD bf16x2 addition
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-sub">
<span id="id219"></span><h4>
<span class="section-number">9.7.4.2. </span><a class="reference internal" href="#half-precision-floating-point-instructions-sub">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-sub" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sub</span></code></p>
<p>Subtract two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub{.rnd}{.ftz}{.sat}.f16   d, a, b;
sub{.rnd}{.ftz}{.sat}.f16x2 d, a, b;

sub{.rnd}.bf16   d, a, b;
sub{.rnd}.bf16x2 d, a, b;

.rnd = { .rn };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs subtraction and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vectors by half word values from source
operands. Half-word operands are then subtracted in parallel to produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type,
operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = a - b;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = fA[i] - fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that a <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. A <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">sub</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">sub.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">sub.sat.{f16,</span> <span class="pre">f16x2}</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">sub{.rnd}.bf16x2</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">sub{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">sub{.rnd}.bf16x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// scalar f16 subtractions
sub.f16        d0, a0, b0;
sub.rn.f16     d1, a1, b1;
sub.bf16       bd0, ba0, bb0;
sub.rn.bf16    bd1, ba1, bb1;

// SIMD f16 subtraction
cvt.rn.f16.f32 h0, f0;
cvt.rn.f16.f32 h1, f1;
cvt.rn.f16.f32 h2, f2;
cvt.rn.f16.f32 h3, f3;
mov.b32  p1, {h0, h1};   // pack two f16 to 32bit f16x2
mov.b32  p2, {h2, h3};   // pack two f16 to 32bit f16x2
sub.f16x2  p3, p1, p2;   // SIMD f16x2 subtraction

// SIMD bf16 subtraction
cvt.rn.bf16x2.f32 p4, f4, f5; // Convert two f32 into packed bf16x2
cvt.rn.bf16x2.f32 p5, f6, f7; // Convert two f32 into packed bf16x2
sub.bf16x2  p6, p4, p5;       // SIMD bf16x2 subtraction

// SIMD fp16 subtraction
ld.global.b32   f0, [addr];     // load 32 bit which hold packed f16x2
ld.global.b32   f1, [addr + 4]; // load 32 bit which hold packed f16x2
sub.f16x2       f2, f0, f1;     // SIMD f16x2 subtraction

// SIMD bf16 subtraction
ld.global.b32   f3, [addr + 8];  // load 32 bit which hold packed bf16x2
ld.global.b32   f4, [addr + 12]; // load 32 bit which hold packed bf16x2
sub.bf16x2      f5, f3, f4;      // SIMD bf16x2 subtraction
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-mul">
<span id="id220"></span><h4>
<span class="section-number">9.7.4.3. </span><a class="reference internal" href="#half-precision-floating-point-instructions-mul">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">mul</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-mul" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mul</span></code></p>
<p>Multiply two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mul{.rnd}{.ftz}{.sat}.f16   d, a, b;
mul{.rnd}{.ftz}{.sat}.f16x2 d, a, b;

mul{.rnd}.bf16   d, a, b;
mul{.rnd}.bf16x2 d, a, b;

.rnd = { .rn };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs multiplication and writes the resulting value into a destination register.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vectors by half word values from source
operands. Half-word operands are then multiplied in parallel to produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type,
operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = a * b;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = fA[i] * fB[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that a <code class="docutils literal notranslate"><span class="pre">mul</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. A <code class="docutils literal notranslate"><span class="pre">mul</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">add</span></code> and <code class="docutils literal notranslate"><span class="pre">mul/sub</span></code> sequences with no rounding modifiers may
be optimized to use fused-multiply-add instructions on the target device.</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">mul.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">mul.sat.{f16,</span> <span class="pre">f16x2}</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">mul{.rnd}.bf16x2</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">mul{.rnd}.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">mul{.rnd}.bf16x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// scalar f16 multiplications
mul.f16        d0, a0, b0;
mul.rn.f16     d1, a1, b1;
mul.bf16       bd0, ba0, bb0;
mul.rn.bf16    bd1, ba1, bb1;

// SIMD f16 multiplication
cvt.rn.f16.f32 h0, f0;
cvt.rn.f16.f32 h1, f1;
cvt.rn.f16.f32 h2, f2;
cvt.rn.f16.f32 h3, f3;
mov.b32  p1, {h0, h1};   // pack two f16 to 32bit f16x2
mov.b32  p2, {h2, h3};   // pack two f16 to 32bit f16x2
mul.f16x2  p3, p1, p2;   // SIMD f16x2 multiplication

// SIMD bf16 multiplication
cvt.rn.bf16x2.f32 p4, f4, f5; // Convert two f32 into packed bf16x2
cvt.rn.bf16x2.f32 p5, f6, f7; // Convert two f32 into packed bf16x2
mul.bf16x2  p6, p4, p5;       // SIMD bf16x2 multiplication

// SIMD fp16 multiplication
ld.global.b32   f0, [addr];     // load 32 bit which hold packed f16x2
ld.global.b32   f1, [addr + 4]; // load 32 bit which hold packed f16x2
mul.f16x2       f2, f0, f1;     // SIMD f16x2 multiplication

// SIMD bf16 multiplication
ld.global.b32   f3, [addr + 8];  // load 32 bit which hold packed bf16x2
ld.global.b32   f4, [addr + 12]; // load 32 bit which hold packed bf16x2
mul.bf16x2      f5, f3, f4;      // SIMD bf16x2 multiplication
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-fma">
<span id="id221"></span><h4>
<span class="section-number">9.7.4.4. </span><a class="reference internal" href="#half-precision-floating-point-instructions-fma">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-fma" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">fma</span></code></p>
<p>Fused multiply-add</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>fma.rnd{.ftz}{.sat}.f16     d, a, b, c;
fma.rnd{.ftz}{.sat}.f16x2   d, a, b, c;
fma.rnd{.ftz}.relu.f16      d, a, b, c;
fma.rnd{.ftz}.relu.f16x2    d, a, b, c;
fma.rnd{.relu}.bf16         d, a, b, c;
fma.rnd{.relu}.bf16x2       d, a, b, c;
fma.rnd.oob.{relu}.type     d, a, b, c;

.rnd = { .rn };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs a fused multiply-add with no loss of precision in the intermediate product and addition.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vectors by half word values from source
operands. Half-word operands are then operated in parallel to produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code>
type. For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code>
type. For <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = a * b + c;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    fC[0] = c[0:15];
    fC[1] = c[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = fA[i] * fB[i] + fC[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers (default is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">fma.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">fma.sat.{f16,</span> <span class="pre">f16x2}</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.
<code class="docutils literal notranslate"><span class="pre">fma.relu.{f16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16,</span> <span class="pre">bf16x2}</span></code> clamps the result to 0 if negative. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> result is
converted to canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt>Out Of Bounds modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">fma.oob.{f16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16,</span> <span class="pre">bf16x2}</span></code> clamps the result to 0 if either of the operands
is <code class="docutils literal notranslate"><span class="pre">OOB</span> <span class="pre">NaN</span></code> (defined under <a class="reference internal" href="#tensors"><span class="std std-ref">Tensors</span></a>) value. The test for the special <code class="docutils literal notranslate"><span class="pre">NaN</span></code> value
and resultant forcing of the result to +0.0 is performed independently for each of the
two SIMD operations.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.relu.{f16,</span> <span class="pre">f16x2}</span></code> and <code class="docutils literal notranslate"><span class="pre">fma{.relu}.{bf16,</span> <span class="pre">bf16x2}</span></code> introduced in PTX ISA version 7.0.</p>
<p>Support for modifier <code class="docutils literal notranslate"><span class="pre">.oob</span></code> introduced in PTX ISA version 8.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.relu.{f16,</span> <span class="pre">f16x2}</span></code> and <code class="docutils literal notranslate"><span class="pre">fma{.relu}.{bf16,</span> <span class="pre">bf16x2}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fma{.oob}.{f16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16,</span> <span class="pre">bf16x2}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// scalar f16 fused multiply-add
fma.rn.f16         d0, a0, b0, c0;
fma.rn.f16         d1, a1, b1, c1;
fma.rn.relu.f16    d1, a1, b1, c1;
fma.rn.oob.f16      d1, a1, b1, c1;
fma.rn.oob.relu.f16 d1, a1, b1, c1;

// scalar bf16 fused multiply-add
fma.rn.bf16        d1, a1, b1, c1;
fma.rn.relu.bf16   d1, a1, b1, c1;
fma.rn.oob.bf16       d1, a1, b1, c1;
fma.rn.oob.relu.bf16  d1, a1, b1, c1;

// SIMD f16 fused multiply-add
cvt.rn.f16.f32 h0, f0;
cvt.rn.f16.f32 h1, f1;
cvt.rn.f16.f32 h2, f2;
cvt.rn.f16.f32 h3, f3;
mov.b32  p1, {h0, h1}; // pack two f16 to 32bit f16x2
mov.b32  p2, {h2, h3}; // pack two f16 to 32bit f16x2
fma.rn.f16x2  p3, p1, p2, p2;   // SIMD f16x2 fused multiply-add
fma.rn.relu.f16x2  p3, p1, p2, p2; // SIMD f16x2 fused multiply-add with relu saturation mode
fma.rn.oob.f16x2  p3, p1, p2, p2; // SIMD f16x2 fused multiply-add with oob modifier
fma.rn.oob.relu.f16x2 p3, p1, p2, p2; // SIMD f16x2 fused multiply-add with oob modifier and relu saturation mode

// SIMD fp16 fused multiply-add
ld.global.b32   f0, [addr];     // load 32 bit which hold packed f16x2
ld.global.b32   f1, [addr + 4]; // load 32 bit which hold packed f16x2
fma.rn.f16x2    f2, f0, f1, f1; // SIMD f16x2 fused multiply-add

// SIMD bf16 fused multiply-add
fma.rn.bf16x2       f2, f0, f1, f1; // SIMD bf16x2 fused multiply-add
fma.rn.relu.bf16x2  f2, f0, f1, f1; // SIMD bf16x2 fused multiply-add with relu saturation mode
fma.rn.oob.bf16x2  f2, f0, f1, f1; // SIMD bf16x2 fused multiply-add with oob modifier
fma.rn.oob.relu.bf16x2  f2, f0, f1, f1; // SIMD bf16x2 fused multiply-add with oob modifier and relu saturation mode
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-neg">
<span id="id222"></span><h4>
<span class="section-number">9.7.4.5. </span><a class="reference internal" href="#half-precision-floating-point-instructions-neg">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">neg</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-neg" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">neg</span></code></p>
<p>Arithmetic negate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg{.ftz}.f16    d, a;
neg{.ftz}.f16x2  d, a;
neg.bf16         d, a;
neg.bf16x2       d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Negate the sign of <code class="docutils literal notranslate"><span class="pre">a</span></code> and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vector by extracting half word values
from the source operand. Half-word operands are then negated in parallel to produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction
type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code>
and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = -a;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = -fA[i];
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">neg.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">NaN</span></code> inputs yield an unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Future implementations may comply with the IEEE 754
standard by preserving payload and modifying only the sign bit.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">neg.bf16x2</span></code> introduced in PTX ISA 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">neg.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">neg.bf16x2</span></code> requires architecture <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>neg.ftz.f16  x,f0;
neg.bf16     x,b0;
neg.bf16x2   x1,b1;
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-abs">
<span id="id223"></span><h4>
<span class="section-number">9.7.4.6. </span><a class="reference internal" href="#half-precision-floating-point-instructions-abs">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">abs</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-abs" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">abs</span></code></p>
<p>Absolute value</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs{.ftz}.f16    d, a;
abs{.ftz}.f16x2  d, a;
abs.bf16         d, a;
abs.bf16x2       d, a;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Take absolute value of <code class="docutils literal notranslate"><span class="pre">a</span></code> and store the result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, forms input vector by extracting half word values
from the source operand. Absolute values of half-word operands are then computed in parallel to
produce <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction
type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    d = |a|;
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    for (i = 0; i &lt; 2; i++) {
         d[i] = |fA[i]|;
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">abs.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p><code class="docutils literal notranslate"><span class="pre">NaN</span></code> inputs yield an unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>. Future implementations may comply with the IEEE 754
standard by preserving payload and modifying only the sign bit.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">abs.bf16x2</span></code> introduced in PTX ISA 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">abs.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">abs.bf16x2</span></code> requires architecture <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>abs.ftz.f16  x,f0;
abs.bf16     x,b0;
abs.bf16x2   x1,b1;
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-min">
<span id="id224"></span><h4>
<span class="section-number">9.7.4.7. </span><a class="reference internal" href="#half-precision-floating-point-instructions-min">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">min</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-min" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">min</span></code></p>
<p>Find the minimum of two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>min{.ftz}{.NaN}{.xorsign.abs}.f16      d, a, b;
min{.ftz}{.NaN}{.xorsign.abs}.f16x2    d, a, b;
min{.NaN}{.xorsign.abs}.bf16           d, a, b;
min{.NaN}{.xorsign.abs}.bf16x2         d, a, b;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the minimum of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction types, input vectors are formed with half-word values
from source operands. Half-word operands are then processed in parallel to store <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction
type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> modifier is specified, then the result is canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> if either of the inputs is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifier is specified, the magnitude of destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is the minimum of
absolute values of both the input arguments.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> modifier is specified, the sign bit of destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is equal to the XOR of the
sign bits of both the inputs.</p>
<p>Modifiers <code class="docutils literal notranslate"><span class="pre">.abs</span></code> and <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> must be specified together and <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> considers the sign
bit of both inputs before applying <code class="docutils literal notranslate"><span class="pre">.abs</span></code> operation.</p>
<p>If the result of <code class="docutils literal notranslate"><span class="pre">min</span></code> is <code class="docutils literal notranslate"><span class="pre">NaN</span></code> then the <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifiers will be ignored.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    if (.xorsign) {
        xorsign = getSignBit(a) ^ getSignBit(b);
        if (.abs) {
            a = |a|;
            b = |b|;
        }
    }
    if (isNaN(a) &amp;&amp; isNaN(b))              d = NaN;
    if (.NaN &amp;&amp; (isNaN(a) || isNaN(b)))    d = NaN;
    else if (isNaN(a))                     d = b;
    else if (isNaN(b))                     d = a;
    else                                   d = (a &lt; b) ? a : b;
    if (.xorsign &amp;&amp; !isNaN(d)) {
         setSignBit(d, xorsign);
    }
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
        if (.xorsign) {
            xorsign = getSignBit(fA[i]) ^ getSignBit(fB[i]);
            if (.abs) {
               fA[i] = |fA[i]|;
               fB[i] = |fB[i]|;
           }
        }
        if (isNaN(fA[i]) &amp;&amp; isNaN(fB[i]))              d[i] = NaN;
        if (.NaN &amp;&amp; (isNaN(fA[i]) || isNaN(fB[i])))    d[i] = NaN;
        else if (isNaN(fA[i]))                         d[i] = fB[i];
        else if (isNaN(fB[i]))                         d[i] = fA[i];
        else                                           d[i] = (fA[i] &lt; fB[i]) ? fA[i] : fB[i];
        if (.xorsign &amp;&amp; !isNaN(d[i])) {
            setSignBit(d[i], xorsign);
        }
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">min.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>If values of both inputs are 0.0, then +0.0 &gt; -0.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.xorsign</span></code> introduced in PTX ISA version 7.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">min.xorsign.abs</span></code> support requires <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>min.ftz.f16       h0,h1,h2;
min.f16x2         b0,b1,b2;
// SIMD fp16 min with .NaN
min.NaN.f16x2     b0,b1,b2;
min.bf16          h0, h1, h2;
// SIMD bf16 min with NaN
min.NaN.bf16x2    b0, b1, b2;
// scalar bf16 min with xorsign.abs
min.xorsign.abs.bf16 Rd, Ra, Rb
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-max">
<span id="id225"></span><h4>
<span class="section-number">9.7.4.8. </span><a class="reference internal" href="#half-precision-floating-point-instructions-max">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">max</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-max" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">max</span></code></p>
<p>Find the maximum of two values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max{.ftz}{.NaN}{.xorsign.abs}.f16      d, a, b;
max{.ftz}{.NaN}{.xorsign.abs}.f16x2    d, a, b;
max{.NaN}{.xorsign.abs}.bf16           d, a, b;
max{.NaN}{.xorsign.abs}.bf16x2         d, a, b;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the maximum of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction types, input vectors are formed with half-word values
from source operands. Half-word operands are then processed in parallel to store <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> result in destination.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction
type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> have <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> modifier is specified, the result is canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code> if either of the inputs is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifier is specified, the magnitude of destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is the maximum of
absolute values of both the input arguments.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> modifier is specified, the sign bit of destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is equal to the XOR of the
sign bits of both the inputs.</p>
<p>Modifiers <code class="docutils literal notranslate"><span class="pre">.abs</span></code> and <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> must be specified together and <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> considers the sign
bit of both inputs before applying <code class="docutils literal notranslate"><span class="pre">.abs</span></code> operation.</p>
<p>If the result of <code class="docutils literal notranslate"><span class="pre">max</span></code> is <code class="docutils literal notranslate"><span class="pre">NaN</span></code> then the <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifiers will be ignored.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == f16 || type == bf16) {
    if (.xorsign) {
        xorsign = getSignBit(a) ^ getSignBit(b);
        if (.abs) {
            a = |a|;
            b = |b|;
        }
    }
    if (isNaN(a) &amp;&amp; isNaN(b))              d = NaN;
    if (.NaN &amp;&amp; (isNaN(a) || isNaN(b)))    d = NaN;
    else if (isNaN(a))                     d = b;
    else if (isNaN(b))                     d = a;
    else                                   d = (a &gt; b) ? a : b;
    if (.xorsign &amp;&amp; !isNaN(d)) {
         setSignBit(d, xorsign);
    }
} else if (type == f16x2 || type == bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    for (i = 0; i &lt; 2; i++) {
        if (.xorsign) {
            xorsign = getSignBit(fA[i]) ^ getSignBit(fB[i]);
            if (.abs) {
                fA[i] = |fA[i]|;
                fB[i] = |fB[i]|;
            }
        }
        if (isNaN(fA[i]) &amp;&amp; isNaN(fB[i]))              d[i] = NaN;
        if (.NaN &amp;&amp; (isNaN(fA[i]) || isNaN(fB[i])))    d[i] = NaN;
        else if (isNaN(fA[i]))                         d[i] = fB[i];
        else if (isNaN(fB[i]))                         d[i] = fA[i];
        else                                           d[i] = (fA[i] &gt; fB[i]) ? fA[i] : fB[i];
        if (.xorsign &amp;&amp; !isNaN(fA[i])) {
            setSignBit(d[i], xorsign);
        }
    }
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.
<code class="docutils literal notranslate"><span class="pre">max.ftz.{f16,</span> <span class="pre">f16x2}</span></code> flushes subnormal inputs and results to sign-preserving zero.</p>
</dd>
</dl>
<p>If values of both inputs are 0.0, then +0.0 &gt; -0.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.xorsign.abs</span></code> introduced in PTX ISA version 7.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">max.xorsign.abs</span></code> support requires <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max.ftz.f16       h0,h1,h2;
max.f16x2         b0,b1,b2;
// SIMD fp16 max with NaN
max.NaN.f16x2     b0,b1,b2;
// scalar f16 max with xorsign.abs
max.xorsign.abs.f16 Rd, Ra, Rb;
max.bf16          h0, h1, h2;
// scalar bf16 max and NaN
max.NaN.bf16x2    b0, b1, b2;
// SIMD bf16 max with xorsign.abs
max.xorsign.abs.bf16x2 Rd, Ra, Rb;
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-tanh">
<span id="id226"></span><h4>
<span class="section-number">9.7.4.9. </span><a class="reference internal" href="#half-precision-floating-point-instructions-tanh">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">tanh</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-tanh" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tanh</span></code></p>
<p>Find the hyperbolic tangent of a value (in radians)</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tanh.approx.type d, a;

.type = {.f16, .f16x2, .bf16, .bf16x2}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Take hyperbolic tangent value of <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>The type of operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> are as specified by <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, each of the half-word operands are operated in
parallel and the results are packed appropriately into a <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (.type == .f16 || .type == .bf16) {
  d = tanh(a)
} else if (.type == .f16x2 || .type == .bf16x2) {
  fA[0] = a[0:15];
  fA[1] = a[16:31];
  d[0] = tanh(fA[0])
  d[1] = tanh(fA[1])
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">tanh.approx.{f16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16,</span> <span class="pre">bf16x2}</span></code> implements an approximate hyperbolic tangent in the
target format.</p>
<p>Results of <code class="docutils literal notranslate"><span class="pre">tanh</span></code> for various corner-case inputs are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 47%">
<col style="width: 53%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>-1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>-0.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum absolute error for <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type is 2-10.987. The maximum absolute error for <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
type is 2-8.</p>
<p>The subnormal numbers are supported.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">tanh.approx.{bf16/bf16x2}</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">tanh.approx.{bf16/bf16x2}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tanh.approx.f16    h1, h0;
tanh.approx.f16x2  hd1, hd0;
tanh.approx.bf16   b1, b0;
tanh.approx.bf16x2 hb1, hb0;
</pre></div>
</div>
</section>
<section id="half-precision-floating-point-instructions-ex2">
<span id="id227"></span><h4>
<span class="section-number">9.7.4.10. </span><a class="reference internal" href="#half-precision-floating-point-instructions-ex2">Half Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">ex2</span></code></a><a class="headerlink" href="#half-precision-floating-point-instructions-ex2" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ex2</span></code></p>
<p>Find the base-2 exponent of input.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ex2.approx.atype     d, a;
ex2.approx.ftz.btype d, a;

.atype = { .f16,  .f16x2}
.btype = { .bf16, .bf16x2}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Raise 2 to the power <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>The type of operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">a</span></code> are as specified by <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, each of the half-word operands are operated in
parallel and the results are packed appropriately into a <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (.type == .f16 || .type == .bf16) {
  d = 2 ^ a
} else if (.type == .f16x2 || .type == .bf16x2) {
  fA[0] = a[0:15];
  fA[1] = a[16:31];
  d[0] = 2 ^ fA[0]
  d[1] = 2 ^ fA[1]
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.approx.{f16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16,</span> <span class="pre">bf16x2}</span></code> implement a fast approximation to 2<sup>a</sup>.</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type, subnormal inputs are supported. <code class="docutils literal notranslate"><span class="pre">ex2.approx.ftz.bf16</span></code> flushes subnormal
inputs and results to sign-preserving zero.</p>
<p>Results of <code class="docutils literal notranslate"><span class="pre">ex2.approx.ftz.bf16</span></code> for various corner-case inputs are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 60%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-subnormal</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-even">
<td><p>-0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-even">
<td><p>+subnormal</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>Results of <code class="docutils literal notranslate"><span class="pre">ex2.approx.f16</span></code> for various corner-case inputs are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 47%">
<col style="width: 53%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Input</p></th>
<th class="head"><p>Result</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>-Inf</p></td>
<td><p>+0.0</p></td>
</tr>
<tr class="row-odd">
<td><p>-0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-even">
<td><p>+0.0</p></td>
<td><p>+1.0</p></td>
</tr>
<tr class="row-odd">
<td><p>+Inf</p></td>
<td><p>+Inf</p></td>
</tr>
<tr class="row-even">
<td><p>NaN</p></td>
<td><p>NaN</p></td>
</tr>
</tbody>
</table>
<p>The maximum relative error for <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type is 2-9.9. The maximum relative error for <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type
is 2-7.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.approx.ftz.{bf16/bf16x2}</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">ex2.approx.ftz.{bf16/bf16x2}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ex2.approx.f16         h1, h0;
ex2.approx.f16x2       hd1, hd0;
ex2.approx.ftz.bf16    b1, b2;
ex2.approx.ftz.bf16x2  hb1, hb2;
</pre></div>
</div>
</section>
</section>
<section id="mixed-precision-floating-point-instructions">
<span id="id228"></span><h3>
<span class="section-number">9.7.5. </span><a class="reference internal" href="#mixed-precision-floating-point-instructions">Mixed Precision Floating-Point Instructions</a><a class="headerlink" href="#mixed-precision-floating-point-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>Mixed precision floating-point instructions operate on data with varied floating point precision.
Before executing the specified operation, operands with different precision needs to be converted
such that all the instruction operands can be represented with a consistent floating-point precision.
The register variable to be used for holding a particular operand depends upon the combination of
the instruction types. Refer <a class="reference internal" href="#fundamental-types"><span class="std std-ref">Fundamental Types</span></a> and
<a class="reference internal" href="#alternate-floating-point-data-formats"><span class="std std-ref">Alternate Floating-Point Data Formats</span></a> for more details
around exact register operand to be used for a given data type.</p>
<p>The mixed precision floating point instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">add</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sub</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fma</span></code></p></li>
</ul>
<p>Mixed precision <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">fma</span></code> support saturation of results to the range [0.0, 1.0],
with <code class="docutils literal notranslate"><span class="pre">NaN</span></code> being flushed to positive zero.</p>
<section id="mixed-precision-floating-point-instructions-add">
<span id="id229"></span><h4>
<span class="section-number">9.7.5.1. </span><a class="reference internal" href="#mixed-precision-floating-point-instructions-add">Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">add</span></code></a><a class="headerlink" href="#mixed-precision-floating-point-instructions-add" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">add</span></code></p>
<p>Add 2 values.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>add{.rnd}{.sat}.f32.atype  d, a, c;

.atype = { .f16, .bf16};
.rnd   = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Converts input operand <code class="docutils literal notranslate"><span class="pre">a</span></code> from <code class="docutils literal notranslate"><span class="pre">.atype</span></code> into <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type. The converted value is then
used for the addition. The resulting value is stored in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = convert(a) + c;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that an <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. An <code class="docutils literal notranslate"><span class="pre">add</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">add</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">add.sat</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f32.{f16/bf16}</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">add.f32.{f16/bf16}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f32 fc, fd;
.reg .b16 ba;
add.rz.f32.bf16.sat   fd, fa, fc;
</pre></div>
</div>
</section>
<section id="mixed-precision-floating-point-instructions-sub">
<span id="id230"></span><h4>
<span class="section-number">9.7.5.2. </span><a class="reference internal" href="#mixed-precision-floating-point-instructions-sub">Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">sub</span></code></a><a class="headerlink" href="#mixed-precision-floating-point-instructions-sub" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sub</span></code></p>
<p>Subtract one value from another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sub{.rnd}{.sat}.f32.atype  d, a, c;

.atype = { .f16, .bf16};
.rnd   = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Converts input operand <code class="docutils literal notranslate"><span class="pre">a</span></code> from <code class="docutils literal notranslate"><span class="pre">.atype</span></code> into <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type. The converted value is then
used for the subtraction. The resulting value is stored in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = convert(a) - c;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The default value of rounding modifier is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>. Note that an <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with an explicit
rounding modifier is treated conservatively by the code optimizer. An <code class="docutils literal notranslate"><span class="pre">sub</span></code> instruction with no
rounding modifier defaults to round-to-nearest-even and may be optimized aggressively by the code
optimizer. In particular, <code class="docutils literal notranslate"><span class="pre">mul</span></code>/<code class="docutils literal notranslate"><span class="pre">sub</span></code> sequences with no rounding modifiers may be optimized to
use fused-multiply-add instructions on the target device.</p>
<dl class="simple">
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">sub.sat</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32.{f16/bf16}</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sub.f32.{f16/bf16}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f32 fc, fd;
.reg .f16 ha;
sub.rz.f32.f16.sat   fd, ha, fc;
</pre></div>
</div>
</section>
<section id="mixed-precision-floating-point-instructions-fma">
<span id="id231"></span><h4>
<span class="section-number">9.7.5.3. </span><a class="reference internal" href="#mixed-precision-floating-point-instructions-fma">Mixed Precision Floating Point Instructions: <code class="docutils literal notranslate"><span class="pre">fma</span></code></a><a class="headerlink" href="#mixed-precision-floating-point-instructions-fma" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">fma</span></code></p>
<p>Fused multiply-add.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>fma.rnd{.sat}.f32.abtype  d, a, b, c;

.abtype = { .f16, .bf16};
.rnd    = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Converts input operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> from <code class="docutils literal notranslate"><span class="pre">.atype</span></code> into <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type. The converted values
are then used to perform fused multiply-add operation with no loss of precision in the intermediate
product and addition. The resulting value is stored in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = convert(a) * convert(b) + c;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32.{f16/bf16}</span></code> computes the product of <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> to infinite precision and then adds
<code class="docutils literal notranslate"><span class="pre">c</span></code> to this product, again in infinite precision. The resulting value is then rounded to single
precision using the rounding mode specified by <code class="docutils literal notranslate"><span class="pre">.rnd</span></code>.</p>
<p>Rounding modifiers(no default):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
</dd>
<dt>Saturation modifier:</dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">fma.sat</span></code> clamps the result to [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are flushed to <code class="docutils literal notranslate"><span class="pre">+0.0f</span></code>.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32.{f16/bf16}</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">fma.f32.{f16/bf16}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f32 fc, fd;
.reg .f16 ha, hb;
fma.rz.sat.f32.f16.sat   fd, ha, hb, fc;
</pre></div>
</div>
</section>
</section>
<section id="comparison-and-selection-instructions">
<span id="id232"></span><h3>
<span class="section-number">9.7.6. </span><a class="reference internal" href="#comparison-and-selection-instructions">Comparison and Selection Instructions</a><a class="headerlink" href="#comparison-and-selection-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The comparison select instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">set</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">setp</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">selp</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slct</span></code></p></li>
</ul>
<p>As with single-precision floating-point instructions, the <code class="docutils literal notranslate"><span class="pre">set</span></code>, <code class="docutils literal notranslate"><span class="pre">setp</span></code>, and <code class="docutils literal notranslate"><span class="pre">slct</span></code>
instructions support subnormal numbers for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and higher targets and flush single-precision
subnormal inputs to sign-preserving zero for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets. The optional <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier
provides backward compatibility with <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets by flushing subnormal inputs and results to
sign-preserving zero regardless of the target architecture.</p>
<section id="comparison-and-selection-instructions-set">
<span id="id233"></span><h4>
<span class="section-number">9.7.6.1. </span><a class="reference internal" href="#comparison-and-selection-instructions-set">Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">set</span></code></a><a class="headerlink" href="#comparison-and-selection-instructions-set" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">set</span></code></p>
<p>Compare two numeric values with a relational operator, and optionally combine this result with a
predicate value by applying a Boolean operator.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>set.CmpOp{.ftz}.dtype.stype         d, a, b;
set.CmpOp.BoolOp{.ftz}.dtype.stype  d, a, b, {!}c;

.CmpOp  = { eq, ne, lt, le, gt, ge, lo, ls, hi, hs,
            equ, neu, ltu, leu, gtu, geu, num, nan };
.BoolOp = { and, or, xor };
.dtype  = { .u32, .s32, .f32 };
.stype  = { .b16, .b32, .b64,
            .u16, .u32, .u64,
            .s16, .s32, .s64,
                  .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compares two numeric values and optionally combines the result with another predicate value by
applying a Boolean operator. If this result is <code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">1.0f</span></code> is written for floating-point
destination types, and <code class="docutils literal notranslate"><span class="pre">0xffffffff</span></code> is written for integer destination types. Otherwise,
<code class="docutils literal notranslate"><span class="pre">0x00000000</span></code> is written.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has type <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>; operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.stype</span></code>; operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has
type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = (a CmpOp b) ? 1 : 0;
if (isFloat(dtype))
    d = BoolOp(t, c) ? 1.0f : 0x00000000;
else
    d = BoolOp(t, c) ? 0xffffffff : 0x00000000;
</pre></div>
</div>
<p class="rubric">Integer Notes</p>
<p>The signed and unsigned comparison operators are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>.</p>
<p>For unsigned values, the comparison operators <code class="docutils literal notranslate"><span class="pre">lo</span></code>, <code class="docutils literal notranslate"><span class="pre">ls</span></code>, <code class="docutils literal notranslate"><span class="pre">hi</span></code>, and <code class="docutils literal notranslate"><span class="pre">hs</span></code> for lower,
lower-or-same, higher, and higher-or-same may be used instead of <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>,
respectively.</p>
<p>The untyped, bit-size comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code> and <code class="docutils literal notranslate"><span class="pre">ne</span></code>.</p>
<p class="rubric">Floating Point Notes</p>
<p>The ordered comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>. If either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the result is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>To aid comparison operations in the presence of <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, unordered versions are included:
<code class="docutils literal notranslate"><span class="pre">equ</span></code>, <code class="docutils literal notranslate"><span class="pre">neu</span></code>, <code class="docutils literal notranslate"><span class="pre">ltu</span></code>, <code class="docutils literal notranslate"><span class="pre">leu</span></code>, <code class="docutils literal notranslate"><span class="pre">gtu</span></code>, <code class="docutils literal notranslate"><span class="pre">geu</span></code>. If both operands are numeric values (not
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>), then these comparisons have the same result as their ordered counterparts. If either
operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result of these comparisons is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">num</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if both operands are numeric values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), and <code class="docutils literal notranslate"><span class="pre">nan</span></code> returns
<code class="docutils literal notranslate"><span class="pre">True</span></code> if either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">set.ftz.dtype.f32</span></code> flushes subnormal inputs to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">set.dtype.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">set.dtype.f32</span></code> flushes subnormal inputs to sign-preserving zero.</p>
</dd>
</dl>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> applies only to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> comparisons.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">set</span></code> with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> source type requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p  set.lt.and.f32.s32  d,a,b,r;
    set.eq.u32.u32      d,i,n;
</pre></div>
</div>
</section>
<section id="comparison-and-selection-instructions-setp">
<span id="id234"></span><h4>
<span class="section-number">9.7.6.2. </span><a class="reference internal" href="#comparison-and-selection-instructions-setp">Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">setp</span></code></a><a class="headerlink" href="#comparison-and-selection-instructions-setp" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">setp</span></code></p>
<p>Compare two numeric values with a relational operator, and (optionally) combine this result with a
predicate value by applying a Boolean operator.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setp.CmpOp{.ftz}.type         p[|q], a, b;
setp.CmpOp.BoolOp{.ftz}.type  p[|q], a, b, {!}c;

.CmpOp  = { eq, ne, lt, le, gt, ge, lo, ls, hi, hs,
            equ, neu, ltu, leu, gtu, geu, num, nan };
.BoolOp = { and, or, xor };
.type   = { .b16, .b32, .b64,
            .u16, .u32, .u64,
            .s16, .s32, .s64,
                  .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compares two values and combines the result with another predicate value by applying a Boolean
operator. This result is written to the first destination operand. A related value computed using
the complement of the compare result is written to the second destination operand.</p>
<p>Applies to all numeric types. Operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.type</span></code>; operands <code class="docutils literal notranslate"><span class="pre">p</span></code>, <code class="docutils literal notranslate"><span class="pre">q</span></code>,
and <code class="docutils literal notranslate"><span class="pre">c</span></code> have type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>. The sink symbol â€˜_â€™ may be used in place of any one of the
destination operands.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>t = (a CmpOp b) ? 1 : 0;
p = BoolOp(t, c);
q = BoolOp(!t, c);
</pre></div>
</div>
<p class="rubric">Integer Notes</p>
<p>The signed and unsigned comparison operators are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>.</p>
<p>For unsigned values, the comparison operators <code class="docutils literal notranslate"><span class="pre">lo</span></code>, <code class="docutils literal notranslate"><span class="pre">ls</span></code>, <code class="docutils literal notranslate"><span class="pre">hi</span></code>, and <code class="docutils literal notranslate"><span class="pre">hs</span></code> for lower,
lower-or-same, higher, and higher-or-same may be used instead of <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>,
respectively.</p>
<p>The untyped, bit-size comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code> and <code class="docutils literal notranslate"><span class="pre">ne</span></code>.</p>
<p class="rubric">Floating Point Notes</p>
<p>The ordered comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>. If either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the result is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>To aid comparison operations in the presence of <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, unordered versions are included:
<code class="docutils literal notranslate"><span class="pre">equ</span></code>, <code class="docutils literal notranslate"><span class="pre">neu</span></code>, <code class="docutils literal notranslate"><span class="pre">ltu</span></code>, <code class="docutils literal notranslate"><span class="pre">leu</span></code>, <code class="docutils literal notranslate"><span class="pre">gtu</span></code>, <code class="docutils literal notranslate"><span class="pre">geu</span></code>. If both operands are numeric values (not
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>), then these comparisons have the same result as their ordered counterparts. If either
operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result of these comparisons is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">num</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if both operands are numeric values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), and <code class="docutils literal notranslate"><span class="pre">nan</span></code> returns
<code class="docutils literal notranslate"><span class="pre">True</span></code> if either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">setp.ftz.dtype.f32</span></code> flushes subnormal inputs to sign-preserving zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">setp.dtype.f64</span></code> supports subnormal numbers.</p>
<p><code class="docutils literal notranslate"><span class="pre">setp.dtype.f32</span></code> flushes subnormal inputs to sign-preserving zero.</p>
</dd>
</dl>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> applies only to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> comparisons.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">setp</span></code> with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> source type requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    setp.lt.and.s32  p|q,a,b,r;
@q  setp.eq.u32      p,i,n;
</pre></div>
</div>
</section>
<section id="comparison-and-selection-instructions-selp">
<span id="id235"></span><h4>
<span class="section-number">9.7.6.3. </span><a class="reference internal" href="#comparison-and-selection-instructions-selp">Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">selp</span></code></a><a class="headerlink" href="#comparison-and-selection-instructions-selp" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">selp</span></code></p>
<p>Select between source operands, based on the value of the predicate source operand.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>selp.type d, a, b, c;

.type = { .b16, .b32, .b64,
          .u16, .u32, .u64,
          .s16, .s32, .s64,
                .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Conditional selection. If <code class="docutils literal notranslate"><span class="pre">c</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> otherwise. Operands
<code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, and <code class="docutils literal notranslate"><span class="pre">b</span></code> must be of the same type. Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is a predicate.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = (c == 1) ? a : b;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">selp.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    selp.s32  r0,r,g,p;
@q  selp.f32  f0,t,x,xp;
</pre></div>
</div>
</section>
<section id="comparison-and-selection-instructions-slct">
<span id="id236"></span><h4>
<span class="section-number">9.7.6.4. </span><a class="reference internal" href="#comparison-and-selection-instructions-slct">Comparison and Selection Instructions: <code class="docutils literal notranslate"><span class="pre">slct</span></code></a><a class="headerlink" href="#comparison-and-selection-instructions-slct" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">slct</span></code></p>
<p>Select one source operand, based on the sign of the third operand.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>slct.dtype.s32        d, a, b, c;
slct{.ftz}.dtype.f32  d, a, b, c;

.dtype = { .b16, .b32, .b64,
           .u16, .u32, .u64,
           .s16, .s32, .s64,
                 .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Conditional selection. If <code class="docutils literal notranslate"><span class="pre">c</span></code> &gt;= 0, <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in <code class="docutils literal notranslate"><span class="pre">d</span></code>, otherwise <code class="docutils literal notranslate"><span class="pre">b</span></code> is stored in
<code class="docutils literal notranslate"><span class="pre">d</span></code>. Operands <code class="docutils literal notranslate"><span class="pre">d</span></code>, <code class="docutils literal notranslate"><span class="pre">a</span></code>, and <code class="docutils literal notranslate"><span class="pre">b</span></code> are treated as a bitsize type of the same width as the first
instruction type; operand <code class="docutils literal notranslate"><span class="pre">c</span></code> must match the second instruction type (<code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code>). The
selected input is copied to the output without modification.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = (c &gt;= 0) ? a : b;
</pre></div>
</div>
<p class="rubric">Floating Point Notes</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32</span></code> comparisons, negative zero equals zero.</p>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">slct.ftz.dtype.f32</span></code> flushes subnormal values of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> to sign-preserving zero, and
operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is selected.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">slct.dtype.f32</span></code> flushes subnormal values of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> to sign-preserving zero, and operand
<code class="docutils literal notranslate"><span class="pre">a</span></code> is selected.</p>
</dd>
</dl>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> applies only to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> comparisons.</p>
<p>If operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the comparison is ordered and operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is selected.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">slct.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>slct.u32.s32  x, y, z, val;
slct.ftz.u64.f32  A, B, C, fval;
</pre></div>
</div>
</section>
</section>
<section id="half-precision-comparison-instructions">
<span id="id237"></span><h3>
<span class="section-number">9.7.7. </span><a class="reference internal" href="#half-precision-comparison-instructions">Half Precision Comparison Instructions</a><a class="headerlink" href="#half-precision-comparison-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The comparison instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">set</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">setp</span></code></p></li>
</ul>
<section id="half-precision-comparison-instructions-set">
<span id="id238"></span><h4>
<span class="section-number">9.7.7.1. </span><a class="reference internal" href="#half-precision-comparison-instructions-set">Half Precision Comparison Instructions: <code class="docutils literal notranslate"><span class="pre">set</span></code></a><a class="headerlink" href="#half-precision-comparison-instructions-set" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">set</span></code></p>
<p>Compare two numeric values with a relational operator, and optionally combine this result with a
predicate value by applying a Boolean operator.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>set.CmpOp{.ftz}.f16.stype            d, a, b;
set.CmpOp.BoolOp{.ftz}.f16.stype     d, a, b, {!}c;

set.CmpOp.bf16.stype                 d, a, b;
set.CmpOp.BoolOp.bf16.stype          d, a, b, {!}c;

set.CmpOp{.ftz}.dtype.f16            d, a, b;
set.CmpOp.BoolOp{.ftz}.dtype.f16     d, a, b, {!}c;
.dtype  = { .u16, .s16, .u32, .s32}

set.CmpOp.dtype.bf16                 d, a, b;
set.CmpOp.BoolOp.dtype.bf16          d, a, b, {!}c;
.dtype  = { .u16, .s16, .u32, .s32}

set.CmpOp{.ftz}.dtype.f16x2          d, a, b;
set.CmpOp.BoolOp{.ftz}.dtype.f16x2   d, a, b, {!}c;
.dtype  = { .f16x2, .u32, .s32}

set.CmpOp.dtype.bf16x2               d, a, b;
set.CmpOp.BoolOp.dtype.bf16x2        d, a, b, {!}c;
.dtype  = { .bf16x2, .u32, .s32}

.CmpOp  = { eq, ne, lt, le, gt, ge,
            equ, neu, ltu, leu, gtu, geu, num, nan };
.BoolOp = { and, or, xor };
.stype  = { .b16, .b32, .b64,
            .u16, .u32, .u64,
            .s16, .s32, .s64,
            .f16, .f32, .f64};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compares two numeric values and optionally combines the result with another predicate value by
applying a Boolean operator.</p>
<p>Result of this computation is written in destination register in the following way:</p>
<ul class="simple">
<li>
<p>If result is <code class="docutils literal notranslate"><span class="pre">True</span></code>,</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">0xffffffff</span></code> is written for destination types <code class="docutils literal notranslate"><span class="pre">.u32</span></code>/<code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0xffff</span></code> is written for destination types <code class="docutils literal notranslate"><span class="pre">.u16</span></code>/<code class="docutils literal notranslate"><span class="pre">.s16</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">1.0</span></code> in target precision floating point format is written for destination type <code class="docutils literal notranslate"><span class="pre">.f16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code>.</p></li>
</ul>
</li>
<li>
<p>If result is <code class="docutils literal notranslate"><span class="pre">False</span></code>,</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">0x0</span></code> is written for all integer destination types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0.0</span></code> in target precision floating point format is written for destination type <code class="docutils literal notranslate"><span class="pre">.f16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code>.</p></li>
</ul>
</li>
</ul>
<p>If the source type is <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> then result of individual operations are packed in
the 32-bit destination operand.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (stype == .f16x2 || stype == .bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    t[0]   = (fA[0] CmpOp fB[0]) ? 1 : 0;
    t[1]   = (fA[1] CmpOp fB[1]) ? 1 : 0;
    if (dtype == .f16x2 || stype == .bf16x2) {
        for (i = 0; i &lt; 2; i++) {
            d[i] = BoolOp(t[i], c) ? 1.0 : 0.0;
        }
    } else {
        for (i = 0; i &lt; 2; i++) {
            d[i] = BoolOp(t[i], c) ? 0xffff : 0;
        }
    }
} else if (dtype == .f16 || stype == .bf16) {
    t = (a CmpOp b) ? 1 : 0;
    d = BoolOp(t, c) ? 1.0 : 0.0;
} else  { // Integer destination type
    trueVal = (isU16(dtype) || isS16(dtype)) ?  0xffff : 0xffffffff;
    t = (a CmpOp b) ? 1 : 0;
    d = BoolOp(t, c) ? trueVal : 0;
}
</pre></div>
</div>
<p class="rubric">Floating Point Notes</p>
<p>The ordered comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>. If either operand is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the result is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>To aid comparison operations in the presence of <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, unordered versions are included:
<code class="docutils literal notranslate"><span class="pre">equ</span></code>, <code class="docutils literal notranslate"><span class="pre">neu</span></code>, <code class="docutils literal notranslate"><span class="pre">ltu</span></code>, <code class="docutils literal notranslate"><span class="pre">leu</span></code>, <code class="docutils literal notranslate"><span class="pre">gtu</span></code>, <code class="docutils literal notranslate"><span class="pre">geu</span></code>. If both operands are numeric values (not
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>), then these comparisons have the same result as their ordered counterparts. If either
operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result of these comparisons is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">num</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if both operands are numeric values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), and <code class="docutils literal notranslate"><span class="pre">nan</span></code> returns
<code class="docutils literal notranslate"><span class="pre">True</span></code> if either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<dl>
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier is specified then subnormal inputs and results are flushed to sign
preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">set.{u16,</span> <span class="pre">u32,</span> <span class="pre">s16,</span> <span class="pre">s32}.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">set.{u32,</span> <span class="pre">s32}.f16x2</span></code> are introduced in PTX ISA version 6.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">set.{u16,</span> <span class="pre">u32,</span> <span class="pre">s16,</span> <span class="pre">s32}.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">set.{u32,</span> <span class="pre">s32,</span> <span class="pre">bf16x2}.bf16x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">set.bf16.{s16,u16,f16,b16,s32,u32,f32,b32,s64,u64,f64,b64}</span></code> are introduced in PTX ISA version
7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">set.{u16,</span> <span class="pre">u32,</span> <span class="pre">s16,</span> <span class="pre">s32}.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">set.{u32,</span> <span class="pre">s32,</span> <span class="pre">bf16x2}.bf16x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">set.bf16.{s16,u16,f16,b16,s32,u32,f32,b32,s64,u64,f64,b64}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>set.lt.and.f16.f16  d,a,b,r;
set.eq.f16x2.f16x2  d,i,n;
set.eq.u32.f16x2    d,i,n;
set.lt.and.u16.f16  d,a,b,r;
set.ltu.or.bf16.f16    d,u,v,s;
set.equ.bf16x2.bf16x2  d,j,m;
set.geu.s32.bf16x2     d,j,m;
set.num.xor.s32.bf16   d,u,v,s;
</pre></div>
</div>
</section>
<section id="half-precision-comparison-instructions-setp">
<span id="id239"></span><h4>
<span class="section-number">9.7.7.2. </span><a class="reference internal" href="#half-precision-comparison-instructions-setp">Half Precision Comparison Instructions: <code class="docutils literal notranslate"><span class="pre">setp</span></code></a><a class="headerlink" href="#half-precision-comparison-instructions-setp" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">setp</span></code></p>
<p>Compare two numeric values with a relational operator, and optionally combine this result with a
predicate value by applying a Boolean operator.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setp.CmpOp{.ftz}.f16           p, a, b;
setp.CmpOp.BoolOp{.ftz}.f16    p, a, b, {!}c;

setp.CmpOp{.ftz}.f16x2         p|q, a, b;
setp.CmpOp.BoolOp{.ftz}.f16x2  p|q, a, b, {!}c;

setp.CmpOp.bf16                p, a, b;
setp.CmpOp.BoolOp.bf16         p, a, b, {!}c;

setp.CmpOp.bf16x2              p|q, a, b;
setp.CmpOp.BoolOp.bf16x2       p|q, a, b, {!}c;

.CmpOp  = { eq, ne, lt, le, gt, ge,
            equ, neu, ltu, leu, gtu, geu, num, nan };
.BoolOp = { and, or, xor };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compares two values and combines the result with another predicate value by applying a Boolean
operator. This result is written to the destination operand.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code>, <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">q</span></code> has type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>.</p>
<p>For instruction type <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b16</span></code> or <code class="docutils literal notranslate"><span class="pre">.f16</span></code>.</p>
<p>For instruction type <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p>For instruction type <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b16</span></code>.</p>
<p>For instruction type <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> have type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (type == .f16 || type == .bf16) {
     t = (a CmpOp b) ? 1 : 0;
     p = BoolOp(t, c);
} else if (type == .f16x2 || type == .bf16x2) {
    fA[0] = a[0:15];
    fA[1] = a[16:31];
    fB[0] = b[0:15];
    fB[1] = b[16:31];
    t[0] = (fA[0] CmpOp fB[0]) ? 1 : 0;
    t[1] = (fA[1] CmpOp fB[1]) ? 1 : 0;
    p = BoolOp(t[0], c);
    q = BoolOp(t[1], c);
}
</pre></div>
</div>
<p class="rubric">Floating Point Notes</p>
<p>The ordered comparisons are <code class="docutils literal notranslate"><span class="pre">eq</span></code>, <code class="docutils literal notranslate"><span class="pre">ne</span></code>, <code class="docutils literal notranslate"><span class="pre">lt</span></code>, <code class="docutils literal notranslate"><span class="pre">le</span></code>, <code class="docutils literal notranslate"><span class="pre">gt</span></code>, <code class="docutils literal notranslate"><span class="pre">ge</span></code>. If either operand is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>, the result is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>To aid comparison operations in the presence of <code class="docutils literal notranslate"><span class="pre">NaN</span></code> values, unordered versions are included:
<code class="docutils literal notranslate"><span class="pre">equ</span></code>, <code class="docutils literal notranslate"><span class="pre">neu</span></code>, <code class="docutils literal notranslate"><span class="pre">ltu</span></code>, <code class="docutils literal notranslate"><span class="pre">leu</span></code>, <code class="docutils literal notranslate"><span class="pre">gtu</span></code>, <code class="docutils literal notranslate"><span class="pre">geu</span></code>. If both operands are numeric values (not
<code class="docutils literal notranslate"><span class="pre">NaN</span></code>), then these comparisons have the same result as their ordered counterparts. If either
operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result of these comparisons is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">num</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if both operands are numeric values (not <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), and <code class="docutils literal notranslate"><span class="pre">nan</span></code> returns
<code class="docutils literal notranslate"><span class="pre">True</span></code> if either operand is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<dl>
<dt>Subnormal numbers:</dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p><code class="docutils literal notranslate"><span class="pre">setp.ftz.{f16,f16x2}</span></code> flushes subnormal inputs to sign-preserving zero.</p>
</dd>
</dl>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">setp.{bf16/bf16x2}</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">setp.{bf16/bf16x2}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setp.lt.and.f16x2  p|q,a,b,r;
@q  setp.eq.f16    p,i,n;

setp.gt.or.bf16x2  u|v,c,d,s;
@q  setp.eq.bf16   u,j,m;
</pre></div>
</div>
</section>
</section>
<section id="logic-and-shift-instructions">
<span id="id240"></span><h3>
<span class="section-number">9.7.8. </span><a class="reference internal" href="#logic-and-shift-instructions">Logic and Shift Instructions</a><a class="headerlink" href="#logic-and-shift-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The logic and shift instructions are fundamentally untyped, performing bit-wise operations on
operands of any type, provided the operands are of the same size. This permits bit-wise operations
on floating point values without having to define a union to access the bits. Instructions <code class="docutils literal notranslate"><span class="pre">and</span></code>,
<code class="docutils literal notranslate"><span class="pre">or</span></code>, <code class="docutils literal notranslate"><span class="pre">xor</span></code>, and <code class="docutils literal notranslate"><span class="pre">not</span></code> also operate on predicates.</p>
<p>The logical shift instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">and</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">or</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">xor</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">not</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cnot</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lop3</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shf</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shl</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shr</span></code></p></li>
</ul>
<section id="logic-and-shift-instructions-and">
<span id="id241"></span><h4>
<span class="section-number">9.7.8.1. </span><a class="reference internal" href="#logic-and-shift-instructions-and">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">and</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-and" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">and</span></code></p>
<p>Bitwise AND.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>and.type d, a, b;

.type = { .pred, .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the bit-wise and operation for the bits in <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a &amp; b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The size of the operands must match, but not necessarily the type.</p>
<p>Allowed types include predicate registers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>and.b32  x,q,r;
and.b32  sign,fpvalue,0x80000000;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-or">
<span id="id242"></span><h4>
<span class="section-number">9.7.8.2. </span><a class="reference internal" href="#logic-and-shift-instructions-or">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">or</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-or" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">or</span></code></p>
<p>Biwise OR.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>or.type d, a, b;

.type = { .pred, .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the bit-wise or operation for the bits in <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a | b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The size of the operands must match, but not necessarily the type.</p>
<p>Allowed types include predicate registers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>or.b32  mask mask,0x00010001
or.pred  p,q,r;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-xor">
<span id="id243"></span><h4>
<span class="section-number">9.7.8.3. </span><a class="reference internal" href="#logic-and-shift-instructions-xor">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">xor</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-xor" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">xor</span></code></p>
<p>Bitwise exclusive-OR (inequality).</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>xor.type d, a, b;

.type = { .pred, .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the bit-wise exclusive-or operation for the bits in <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a ^ b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The size of the operands must match, but not necessarily the type.</p>
<p>Allowed types include predicate registers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>xor.b32  d,q,r;
xor.b16  d,x,0x0001;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-not">
<span id="id244"></span><h4>
<span class="section-number">9.7.8.4. </span><a class="reference internal" href="#logic-and-shift-instructions-not">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">not</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-not" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">not</span></code></p>
<p>Bitwise negation; oneâ€™s complement.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>not.type d, a;

.type = { .pred, .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Invert the bits in <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = ~a;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The size of the operands must match, but not necessarily the type.</p>
<p>Allowed types include predicates.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>not.b32  mask,mask;
not.pred  p,q;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-cnot">
<span id="id245"></span><h4>
<span class="section-number">9.7.8.5. </span><a class="reference internal" href="#logic-and-shift-instructions-cnot">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">cnot</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-cnot" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cnot</span></code></p>
<p>C/C++ style logical negation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cnot.type d, a;

.type = { .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute the logical negation using C/C++ semantics.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = (a==0) ? 1 : 0;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>The size of the operands must match, but not necessarily the type.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cnot.b32 d,a;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-lop3">
<span id="id246"></span><h4>
<span class="section-number">9.7.8.6. </span><a class="reference internal" href="#logic-and-shift-instructions-lop3">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">lop3</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-lop3" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">lop3</span></code></p>
<p>Arbitrary logical operation on 3 inputs.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>lop3.b32 d, a, b, c, immLut;
lop3.BoolOp.b32 d|p, a, b, c, immLut, q;

.BoolOp   = { .or , .and };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compute bitwise logical operation on inputs <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">c</span></code> and store the result in destination
<code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>Optionally, <code class="docutils literal notranslate"><span class="pre">.BoolOp</span></code> can be specified to compute the predicate result <code class="docutils literal notranslate"><span class="pre">p</span></code> by performing a
Boolean operation on the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> with the predicate <code class="docutils literal notranslate"><span class="pre">q</span></code> in the following manner:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>p = (d != 0) BoolOp q;
</pre></div>
</div>
<p>The sink symbol â€˜_â€™ may be used in place of the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> when <code class="docutils literal notranslate"><span class="pre">.BoolOp</span></code> qualifier
is specified.</p>
<p>The logical operation is defined by a look-up table which, for 3 inputs, can be represented as an
8-bit value specified by operand <code class="docutils literal notranslate"><span class="pre">immLut</span></code> as described below. <code class="docutils literal notranslate"><span class="pre">immLut</span></code> is an integer constant
that can take values from 0 to 255, thereby allowing up to 256 distinct logical operations on inputs
<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
<p>For a logical operation <code class="docutils literal notranslate"><span class="pre">F(a,</span> <span class="pre">b,</span> <span class="pre">c)</span></code> the value of <code class="docutils literal notranslate"><span class="pre">immLut</span></code> can be computed by applying the same
operation to three predefined constant values as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ta = 0xF0;
tb = 0xCC;
tc = 0xAA;

immLut = F(ta, tb, tc);
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>If F = (a &amp; b &amp; c);
immLut = 0xF0 &amp; 0xCC &amp; 0xAA = 0x80

If F = (a | b | c);
immLut = 0xF0 | 0xCC | 0xAA = 0xFE

If F = (a &amp; b &amp; ~c);
immLut = 0xF0 &amp; 0xCC &amp; (~0xAA) = 0x40

If F = ((a &amp; b | c) ^ a);
immLut = (0xF0 &amp; 0xCC | 0xAA) ^ 0xF0 = 0x1A
</pre></div>
</div>
<p>The following table illustrates computation of <code class="docutils literal notranslate"><span class="pre">immLut</span></code> for various logical operations:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 18%">
<col style="width: 7%">
<col style="width: 20%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>ta</p></th>
<th class="head"><p>tb</p></th>
<th class="head"><p>tc</p></th>
<th class="head"><p>Oper 0 (False)</p></th>
<th class="head"><p>Oper 1 (ta &amp; tb &amp; tc)</p></th>
<th class="head"><p>Oper 2 (ta &amp; tb &amp; ~tc)</p></th>
<th class="head"><p>â€¦</p></th>
<th class="head"><p>Oper 254 (ta | tb | tc)</p></th>
<th class="head"><p>Oper 255 (True)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td rowspan="8"><p>â€¦</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd">
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd">
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd">
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td colspan="3"><p><strong>immLut</strong></p></td>
<td><p><strong>0x0</strong></p></td>
<td><p><strong>0x80</strong></p></td>
<td><p><strong>0x40</strong></p></td>
<td><p><strong>â€¦</strong></p></td>
<td><p><strong>0xFE</strong></p></td>
<td><p><strong>0xFF</strong></p></td>
</tr>
</tbody>
</table>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>F = GetFunctionFromTable(immLut); // returns the function corresponding to immLut value
d = F(a, b, c);
if (BoolOp specified) {
    p = (d != 0) BoolOp q;
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.BoolOp</span></code> qualifier introduced in PTX ISA version 8.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> or higher.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.BoolOp</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>lop3.b32       d, a, b, c, 0x40;
lop3.or.b32  d|p, a, b, c, 0x3f, q;
lop3.and.b32 _|p, a, b, c, 0x3f, q;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-shf">
<span id="id247"></span><h4>
<span class="section-number">9.7.8.7. </span><a class="reference internal" href="#logic-and-shift-instructions-shf">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shf</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-shf" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">shf</span></code></p>
<p>Funnel shift.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shf.l.mode.b32  d, a, b, c;  // left shift
shf.r.mode.b32  d, a, b, c;  // right shift

.mode = { .clamp, .wrap };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Shift the 64-bit value formed by concatenating operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> left or right by the amount
specified by the unsigned 32-bit value in <code class="docutils literal notranslate"><span class="pre">c</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> holds bits <code class="docutils literal notranslate"><span class="pre">63:32</span></code> and operand a
holds bits <code class="docutils literal notranslate"><span class="pre">31:0</span></code> of the 64-bit source value. The source is shifted left or right by the clamped
or wrapped value in <code class="docutils literal notranslate"><span class="pre">c</span></code>. For <code class="docutils literal notranslate"><span class="pre">shf.l</span></code>, the most-significant 32-bits of the result are written
into <code class="docutils literal notranslate"><span class="pre">d</span></code>; for <code class="docutils literal notranslate"><span class="pre">shf.r</span></code>, the least-significant 32-bits of the result are written into <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>u32  n = (.mode == .clamp) ? min(c, 32) : c &amp; 0x1f;
switch (shf.dir) {  // shift concatenation of [b, a]
    case shf.l:     // extract 32 msbs
           u32  d = (b &lt;&lt; n)      | (a &gt;&gt; (32-n));
    case shf.r:     // extract 32 lsbs
           u32  d = (b &lt;&lt; (32-n)) | (a &gt;&gt; n);
}
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Use funnel shift for multi-word shift operations and for rotate operations. The shift amount is
limited to the range <code class="docutils literal notranslate"><span class="pre">0..32</span></code> in clamp mode and <code class="docutils literal notranslate"><span class="pre">0..31</span></code> in wrap mode, so shifting multi-word
values by distances greater than 32 requires first moving 32-bit words, then using <code class="docutils literal notranslate"><span class="pre">shf</span></code> to shift
the remaining <code class="docutils literal notranslate"><span class="pre">0..31</span></code> distance.</p>
<p>To shift data sizes greater than 64 bits to the right, use repeated <code class="docutils literal notranslate"><span class="pre">shf.r</span></code> instructions applied
to adjacent words, operating from least-significant word towards most-significant word. At each
step, a single word of the shifted result is computed. The most-significant word of the result is
computed using a <code class="docutils literal notranslate"><span class="pre">shr.{u32,s32}</span></code> instruction, which zero or sign fills based on the instruction
type.</p>
<p>To shift data sizes greater than 64 bits to the left, use repeated <code class="docutils literal notranslate"><span class="pre">shf.l</span></code> instructions applied to
adjacent words, operating from most-significant word towards least-significant word. At each step, a
single word of the shifted result is computed. The least-significant word of the result is computed
using a <code class="docutils literal notranslate"><span class="pre">shl</span></code> instruction.</p>
<p>Use funnel shift to perform 32-bit left or right rotate by supplying the same value for source
arguments <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> or higher.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shf.l.clamp.b32  r3,r1,r0,16;

// 128-bit left shift; n &lt; 32
// [r7,r6,r5,r4] = [r3,r2,r1,r0] &lt;&lt; n
shf.l.clamp.b32  r7,r2,r3,n;
shf.l.clamp.b32  r6,r1,r2,n;
shf.l.clamp.b32  r5,r0,r1,n;
shl.b32          r4,r0,n;

// 128-bit right shift, arithmetic; n &lt; 32
// [r7,r6,r5,r4] = [r3,r2,r1,r0] &gt;&gt; n
shf.r.clamp.b32  r4,r0,r1,n;
shf.r.clamp.b32  r5,r1,r2,n;
shf.r.clamp.b32  r6,r2,r3,n;
shr.s32          r7,r3,n;     // result is sign-extended

shf.r.clamp.b32  r1,r0,r0,n;  // rotate right by n; n &lt; 32
shf.l.clamp.b32  r1,r0,r0,n;  // rotate left by n; n &lt; 32

// extract 32-bits from [r1,r0] starting at position n &lt; 32
shf.r.clamp.b32  r0,r0,r1,n;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-shl">
<span id="id248"></span><h4>
<span class="section-number">9.7.8.8. </span><a class="reference internal" href="#logic-and-shift-instructions-shl">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shl</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-shl" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">shl</span></code></p>
<p>Shift bits left, zero-fill on right.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shl.type d, a, b;

.type = { .b16, .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Shift <code class="docutils literal notranslate"><span class="pre">a</span></code> left by the amount specified by unsigned 32-bit value in <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a &lt;&lt; b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Shift amounts greater than the register width <em>N</em> are clamped to <em>N</em>.</p>
<p>The sizes of the destination and first source operand must match, but not necessarily the type. The
<code class="docutils literal notranslate"><span class="pre">b</span></code> operand must be a 32-bit value, regardless of the instruction type.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shl.b32  q,a,2;
</pre></div>
</div>
</section>
<section id="logic-and-shift-instructions-shr">
<span id="id249"></span><h4>
<span class="section-number">9.7.8.9. </span><a class="reference internal" href="#logic-and-shift-instructions-shr">Logic and Shift Instructions: <code class="docutils literal notranslate"><span class="pre">shr</span></code></a><a class="headerlink" href="#logic-and-shift-instructions-shr" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">shr</span></code></p>
<p>Shift bits right, sign or zero-fill on left.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shr.type d, a, b;

.type = { .b16, .b32, .b64,
          .u16, .u32, .u64,
          .s16, .s32, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Shift <code class="docutils literal notranslate"><span class="pre">a</span></code> right by the amount specified by unsigned 32-bit value in <code class="docutils literal notranslate"><span class="pre">b</span></code>. Signed shifts fill with
the sign bit, unsigned and untyped shifts fill with <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a &gt;&gt; b;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Shift amounts greater than the register width <em>N</em> are clamped to <em>N</em>.</p>
<p>The sizes of the destination and first source operand must match, but not necessarily the type. The
<code class="docutils literal notranslate"><span class="pre">b</span></code> operand must be a 32-bit value, regardless of the instruction type.</p>
<p>Bit-size types are included for symmetry with <code class="docutils literal notranslate"><span class="pre">shl</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Example</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shr.u16  c,a,2;
shr.s32  i,i,1;
shr.b16  k,i,j;
</pre></div>
</div>
</section>
</section>
<section id="data-movement-and-conversion-instructions">
<span id="id250"></span><h3>
<span class="section-number">9.7.9. </span><a class="reference internal" href="#data-movement-and-conversion-instructions">Data Movement and Conversion Instructions</a><a class="headerlink" href="#data-movement-and-conversion-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>These instructions copy data from place to place, and from state space to state space, possibly
converting it from one format to another. <code class="docutils literal notranslate"><span class="pre">mov</span></code>, <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ldu</span></code>, and <code class="docutils literal notranslate"><span class="pre">st</span></code> operate on both
scalar and vector types. The <code class="docutils literal notranslate"><span class="pre">isspacep</span></code> instruction is provided to query whether a generic address
falls within a particular state space window. The <code class="docutils literal notranslate"><span class="pre">cvta</span></code> instruction converts addresses between
<code class="docutils literal notranslate"><span class="pre">generic</span></code> and <code class="docutils literal notranslate"><span class="pre">const</span></code>, <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> state spaces.</p>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">suld</span></code>, and <code class="docutils literal notranslate"><span class="pre">sust</span></code> support optional cache operations.</p>
<p>The Data Movement and Conversion Instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mov</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prmt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ld</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ldu</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">st</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">st.async</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">st.bulk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">isspacep</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cvta</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code>, <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></p></li>
</ul>
<section id="cache-operators">
<span id="id251"></span><h4>
<span class="section-number">9.7.9.1. </span><a class="reference internal" href="#cache-operators">Cache Operators</a><a class="headerlink" href="#cache-operators" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX ISA version 2.0 introduced optional cache operators on load and store instructions. The cache
operators require a target architecture of <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Cache operators on load or store instructions are treated as performance hints only. The use of a
cache operator on an <code class="docutils literal notranslate"><span class="pre">ld</span></code> or <code class="docutils literal notranslate"><span class="pre">st</span></code> instruction does not change the memory consistency behavior of
the program.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and higher, the cache operators have the following definitions and behavior.</p>
<table class="table-no-stripes docutils align-default" id="id680">
<caption>
<span class="caption-number">Table 30 </span><span class="caption-text">Cache Operators for Memory Load Instructions</span><a class="headerlink" href="#id680" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Operator</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.ca</span></code></p></td>
<td>
<p>Cache at all levels, likely to be accessed again.</p>
<p>The default load instruction cache operation is ld.ca, which allocates cache lines in all
levels (L1 and L2) with normal eviction policy. Global data is coherent at the L2 level, but
multiple L1 caches are not coherent for global data. If one thread stores to global memory
via one L1 cache, and a second thread loads that address via a second L1 cache with <code class="docutils literal notranslate"><span class="pre">ld.ca</span></code>,
the second thread may get stale L1 cache data, rather than the data stored by the first thread.
The driver must invalidate global L1 cache lines between dependent grids of parallel threads.
Stores by the first grid program are then correctly fetched by the second grid program issuing
default <code class="docutils literal notranslate"><span class="pre">ld.ca</span></code> loads cached in L1.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.cg</span></code></p></td>
<td>
<p>Cache at global level (cache in L2 and below, not L1).</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">ld.cg</span></code> to cache loads only globally, bypassing the L1 cache, and cache only in the L2
cache.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.cs</span></code></p></td>
<td>
<p>Cache streaming, likely to be accessed once.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ld.cs</span></code> load cached streaming operation allocates global lines with evict-first policy in
L1 and L2 to limit cache pollution by temporary streaming data that may be accessed once or
twice. When <code class="docutils literal notranslate"><span class="pre">ld.cs</span></code> is applied to a Local window address, it performs the <code class="docutils literal notranslate"><span class="pre">ld.lu</span></code>
operation.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.lu</span></code></p></td>
<td>
<p>Last use.</p>
<p>The compiler/programmer may use <code class="docutils literal notranslate"><span class="pre">ld.lu</span></code> when restoring spilled registers and popping function
stack frames to avoid needless write-backs of lines that will not be used again. The <code class="docutils literal notranslate"><span class="pre">ld.lu</span></code>
instruction performs a load cached streaming operation (<code class="docutils literal notranslate"><span class="pre">ld.cs</span></code>) on global addresses.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.cv</span></code></p></td>
<td>
<p>Donâ€™t cache and fetch again (consider cached system memory lines stale, fetch again).</p>
<p>The ld.cv load operation applied to a global System Memory address invalidates (discards) a
matching L2 line and re-fetches the line on each new load.</p>
</td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="id681">
<caption>
<span class="caption-number">Table 31 </span><span class="caption-text">Cache Operators for Memory Store Instructions</span><a class="headerlink" href="#id681" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Operator</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.wb</span></code></p></td>
<td>
<p>Cache write-back all coherent levels.</p>
<p>The default store instruction cache operation is <code class="docutils literal notranslate"><span class="pre">st.wb</span></code>, which writes back cache lines of
coherent cache levels with normal eviction policy.</p>
<p>If one thread stores to global memory, bypassing its L1 cache, and a second thread in a
different SM later loads from that address via a different L1 cache with <code class="docutils literal notranslate"><span class="pre">ld.ca</span></code>, the second
thread may get a hit on stale L1 cache data, rather than get the data from L2 or memory stored
by the first thread.</p>
<p>The driver must invalidate global L1 cache lines between dependent grids of thread arrays.
Stores by the first grid program are then correctly missed in L1 and fetched by the second grid
program issuing default <code class="docutils literal notranslate"><span class="pre">ld.ca</span></code> loads.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.cg</span></code></p></td>
<td>
<p>Cache at global level (cache in L2 and below, not L1).</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">st.cg</span></code> to cache global store data only globally, bypassing the L1 cache, and cache only
in the L2 cache.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.cs</span></code></p></td>
<td>
<p>Cache streaming, likely to be accessed once.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">st.cs</span></code> store cached-streaming operation allocates cache lines with evict-first policy to
limit cache pollution by streaming output data.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.wt</span></code></p></td>
<td>
<p>Cache write-through (to system memory).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">st.wt</span></code> store write-through operation applied to a global System Memory address writes
through the L2 cache.</p>
</td>
</tr>
</tbody>
</table>
</section>
<section id="cache-eviction-priority-hints">
<span id="id252"></span><h4>
<span class="section-number">9.7.9.2. </span><a class="reference internal" href="#cache-eviction-priority-hints">Cache Eviction Priority Hints</a><a class="headerlink" href="#cache-eviction-priority-hints" title="Permalink to this headline">ïƒ</a>
</h4>
<p>PTX ISA version 7.4 adds optional cache eviction priority hints on load and store
instructions. Cache eviction priority requires target architecture <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Cache eviction priority on load or store instructions is treated as a performance hint. It is
supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and generic addresses where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code>
state space.</p>
<table class="table-no-stripes docutils align-default" id="id682">
<caption>
<span class="caption-number">Table 32 </span><span class="caption-text">Cache Eviction Priority Hints for Memory Load and Store Instructions</span><a class="headerlink" href="#id682" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Cache Eviction Priority</p></th>
<th class="head"><p>Meaning</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">evict_normal</span></code></p></td>
<td><p>Cache data with normal eviction priority. This is the default eviction priority.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">evict_first</span></code></p></td>
<td><p>Data cached with this priority will be first in the eviction priority order and
will likely be evicted when cache eviction is required. This priority is suitable
for streaming data.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">evict_last</span></code></p></td>
<td><p>Data cached with this priority will be last in the eviction priority order and will
likely be evicted only after other data with <code class="docutils literal notranslate"><span class="pre">evict_normal</span></code> or <code class="docutils literal notranslate"><span class="pre">evict_first</span></code>
eviction priotity is already evicted. This priority is suitable for data that
should remain persistent in cache.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">evict_unchanged</span></code></p></td>
<td><p>Do not change eviction priority order as part of this operation.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">no_allocate</span></code></p></td>
<td><p>Do not allocate data to cache. This priority is suitable for streaming data.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="data-movement-and-conversion-instructions-mov">
<span id="id253"></span><h4>
<span class="section-number">9.7.9.3. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-mov">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mov</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-mov" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mov</span></code></p>
<p>Set a register variable with the value of a register variable or an immediate value. Take the
non-generic address of a variable in global, local, or shared state space.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.type  d, a;
mov.type  d, sreg;
mov.type  d, avar;       // get address of variable
mov.type  d, avar+imm;   // get address of variable with offset
mov.u32   d, fname;      // get address of device function
mov.u64   d, fname;      // get address of device function
mov.u32   d, kernel;     // get address of entry function
mov.u64   d, kernel;     // get address of entry function

.type = { .pred,
          .b16, .b32, .b64,
          .u16, .u32, .u64,
          .s16, .s32, .s64,
                .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Write register <code class="docutils literal notranslate"><span class="pre">d</span></code> with the value of <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> may be a register, special register, variable with optional offset in an addressable
memory space, or function name.</p>
<p>For variables declared in <code class="docutils literal notranslate"><span class="pre">.const</span></code>, <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code>, and <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state spaces, <code class="docutils literal notranslate"><span class="pre">mov</span></code>
places the non-generic address of the variable (i.e., the address of the variable in its state
space) into the destination register. The generic address of a variable in <code class="docutils literal notranslate"><span class="pre">const</span></code>, <code class="docutils literal notranslate"><span class="pre">global</span></code>,
<code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> state space may be generated by first taking the address within the state
space with <code class="docutils literal notranslate"><span class="pre">mov</span></code> and then converting it to a generic address using the <code class="docutils literal notranslate"><span class="pre">cvta</span></code> instruction;
alternately, the generic address of a variable declared in <code class="docutils literal notranslate"><span class="pre">const</span></code>, <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or
<code class="docutils literal notranslate"><span class="pre">shared</span></code> state space may be taken directly using the <code class="docutils literal notranslate"><span class="pre">cvta</span></code> instruction.</p>
<p>Note that if the address of a device function parameter is moved to a register, the parameter will
be copied onto the stack and the address will be in the local state space.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a;
d = sreg;
d = &amp;avar;        // address is non-generic; i.e., within the variable's declared state space
d = &amp;avar+imm;
</pre></div>
</div>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Although only predicate and bit-size types are required, we include the arithmetic types for the
programmerâ€™s convenience: their use enhances program readability and allows additional type
checking.</p></li>
<li><p>When moving address of a kernel or a device function, only <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> instruction types
are allowed. However, if a signed type is used, it is not treated as a compilation error. The
compiler issues a warning in this case.</p></li>
</ul>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Taking the address of kernel entry functions requires PTX ISA version 3.1 or later. Kernel function
addresses should only be used in the context of CUDA Dynamic Parallelism system calls. See the <em>CUDA
Dynamic Parallelism Programming Guide</em> for details.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mov.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Taking the address of kernel entry functions requires <code class="docutils literal notranslate"><span class="pre">sm_35</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.f32  d,a;
mov.u16  u,v;
mov.f32  k,0.1;
mov.u32  ptr, A;        // move address of A into ptr
mov.u32  ptr, A[5];     // move address of A[5] into ptr
mov.u32  ptr, A+20;     // move address with offset into ptr
mov.u32  addr, myFunc;  // get address of device function 'myFunc'
mov.u64  kptr, main;    // get address of entry function 'main'
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-mov-2">
<span id="id254"></span><h4>
<span class="section-number">9.7.9.4. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-mov-2">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mov</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-mov-2" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mov</span></code></p>
<p>Move vector-to-scalar (pack) or scalar-to-vector (unpack).</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.type  d, a;

.type = { .b16, .b32, .b64, .b128 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Write scalar register <code class="docutils literal notranslate"><span class="pre">d</span></code> with the packed value of vector register <code class="docutils literal notranslate"><span class="pre">a</span></code>, or write vector register
<code class="docutils literal notranslate"><span class="pre">d</span></code> with the unpacked values from scalar register <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>When destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is a vector register, the sink symbol <code class="docutils literal notranslate"><span class="pre">'_'</span></code> may be used for one or
more elements provided that at least one element is a scalar register.</p>
<p>For bit-size types, <code class="docutils literal notranslate"><span class="pre">mov</span></code> may be used to pack vector elements into a scalar register or unpack
sub-fields of a scalar register into a vector. Both the overall size of the vector and the size of
the scalar must match the size of the instruction type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// pack two 8-bit elements into .b16
d = a.x | (a.y &lt;&lt; 8)
// pack four 8-bit elements into .b32
d = a.x | (a.y &lt;&lt; 8)  | (a.z &lt;&lt; 16) | (a.w &lt;&lt; 24)
// pack two 16-bit elements into .b32
d = a.x | (a.y &lt;&lt; 16)
// pack four 16-bit elements into .b64
d = a.x | (a.y &lt;&lt; 16)  | (a.z &lt;&lt; 32) | (a.w &lt;&lt; 48)
// pack two 32-bit elements into .b64
d = a.x | (a.y &lt;&lt; 32)
// pack four 32-bit elements into .b128
d = a.x | (a.y &lt;&lt; 32)  | (a.z &lt;&lt; 64) | (a.w &lt;&lt; 96)
// pack two 64-bit elements into .b128
d = a.x | (a.y &lt;&lt; 64)

// unpack 8-bit elements from .b16
{ d.x, d.y } = { a[0..7], a[8..15] }
// unpack 8-bit elements from .b32
{ d.x, d.y, d.z, d.w }
        { a[0..7], a[8..15], a[16..23], a[24..31] }

// unpack 16-bit elements from .b32
{ d.x, d.y }  = { a[0..15], a[16..31] }
// unpack 16-bit elements from .b64
{ d.x, d.y, d.z, d.w } =
        { a[0..15], a[16..31], a[32..47], a[48..63] }

// unpack 32-bit elements from .b64
{ d.x, d.y } = { a[0..31], a[32..63] }

// unpack 32-bit elements from .b128
{ d.x, d.y, d.z, d.w } =
        { a[0..31], a[32..63], a[64..95], a[96..127] }
// unpack 64-bit elements from .b128
{ d.x, d.y } = { a[0..63], a[64..127] }
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.b32 %r1,{a,b};      // a,b have type .u16
mov.b64 {lo,hi}, %x;    // %x is a double; lo,hi are .u32
mov.b32 %r1,{x,y,z,w};  // x,y,z,w have type .b8
mov.b32 {r,g,b,a},%r1;  // r,g,b,a have type .u8
mov.b64 {%r1, _}, %x;   // %x is.b64, %r1 is .b32
mov.b128 {%b1, %b2}, %y;   // %y is.b128, %b1 and % b2 are .b64
mov.b128 %y, {%b1, %b2};   // %y is.b128, %b1 and % b2 are .b64
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-shfl">
<span id="id255"></span><h4>
<span class="section-number">9.7.9.5. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-shfl">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">shfl</span></code> (deprecated)</a><a class="headerlink" href="#data-movement-and-conversion-instructions-shfl" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">shfl</span></code> (deprecated)</p>
<p>Register data shuffle within threads of a warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shfl.mode.b32  d[|p], a, b, c;

.mode = { .up, .down, .bfly, .idx };
</pre></div>
</div>
<p class="rubric">Deprecation Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">shfl</span></code> instruction without a <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier is deprecated in PTX ISA version 6.0.</p>
<ul class="simple">
<li><p>Support for this instruction with <code class="docutils literal notranslate"><span class="pre">.target</span></code> lower than <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> may be removed in a future PTX ISA version.</p></li>
</ul>
<p class="rubric">Removal Note</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">shfl</span></code> instruction without a <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier is removed in PTX ISA version 6.4 for <code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Description</p>
<p>Exchange register data between threads of a warp.</p>
<p>Each thread in the currently executing warp will compute a source lane index <em>j</em> based on input
operands <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> and the <em>mode</em>. If the computed source lane index <em>j</em> is in range, the
thread will copy the input operand <code class="docutils literal notranslate"><span class="pre">a</span></code> from lane <em>j</em> into its own destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>;
otherwise, the thread will simply copy its own input <code class="docutils literal notranslate"><span class="pre">a</span></code> to destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. The optional
destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if the computed source lane is in range, and
otherwise set to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>Note that an out of range value of <code class="docutils literal notranslate"><span class="pre">b</span></code> may still result in a valid computed source lane index
<em>j</em>. In this case, a data transfer occurs and the destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is True.</p>
<p>Note that results are undefined in divergent control flow within a warp, if an active thread sources
a register from an inactive thread.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> specifies a source lane or source lane offset, depending on the mode.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> contains two packed values specifying a mask for logically splitting warps into
sub-segments and an upper bound for clamping the source lane index.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>lane[4:0]  = [Thread].laneid;  // position of thread in warp
bval[4:0] = b[4:0];            // source lane or lane offset (0..31)
cval[4:0] = c[4:0];            // clamp value
mask[4:0] = c[12:8];

// get value of source register a if thread is active and
// guard predicate true, else unpredictable
if (isActive(Thread) &amp;&amp; isGuardPredicateTrue(Thread)) {
    SourceA[lane] = a;
} else {
    // Value of SourceA[lane] is unpredictable for
    // inactive/predicated-off threads in warp
}
maxLane = (lane[4:0] &amp; mask[4:0]) | (cval[4:0] &amp; ~mask[4:0]);
minLane = (lane[4:0] &amp; mask[4:0]);

switch (.mode) {
    case .up:    j = lane - bval; pval = (j &gt;= maxLane); break;
    case .down:  j = lane + bval; pval = (j &lt;= maxLane); break;
    case .bfly:  j = lane ^ bval; pval = (j &lt;= maxLane); break;
    case .idx:   j = minLane  | (bval[4:0] &amp; ~mask[4:0]);
                                 pval = (j &lt;= maxLane); break;
}
if (!pval) j = lane;  // copy from own lane
d = SourceA[j];       // copy input a from lane j
if (dest predicate selected)
    p = pval;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.0.</p>
<p>Deprecated in PTX ISA version 6.0 in favor of <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code>.</p>
<p>Not supported in PTX ISA version 6.4 for .target <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">shfl</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">shfl</span></code> is not supported on <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher starting PTX ISA version 6.4.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    // Warp-level INCLUSIVE PLUS SCAN:
    //
    // Assumes input in following registers:
    //     - Rx  = sequence value for this thread
    //
    shfl.up.b32  Ry|p, Rx, 0x1,  0x0;
@p  add.f32      Rx, Ry, Rx;
    shfl.up.b32  Ry|p, Rx, 0x2,  0x0;
@p  add.f32      Rx, Ry, Rx;
    shfl.up.b32  Ry|p, Rx, 0x4,  0x0;
@p  add.f32      Rx, Ry, Rx;
    shfl.up.b32  Ry|p, Rx, 0x8,  0x0;
@p  add.f32      Rx, Ry, Rx;
    shfl.up.b32  Ry|p, Rx, 0x10, 0x0;
@p  add.f32      Rx, Ry, Rx;


    // Warp-level INCLUSIVE PLUS REVERSE-SCAN:
    //
    // Assumes input in following registers:
    //     - Rx  = sequence value for this thread
    //
    shfl.down.b32  Ry|p, Rx, 0x1,  0x1f;
@p  add.f32        Rx, Ry, Rx;
    shfl.down.b32  Ry|p, Rx, 0x2,  0x1f;
@p  add.f32        Rx, Ry, Rx;
    shfl.down.b32  Ry|p, Rx, 0x4,  0x1f;
@p  add.f32        Rx, Ry, Rx;
    shfl.down.b32  Ry|p, Rx, 0x8,  0x1f;
@p  add.f32        Rx, Ry, Rx;
    shfl.down.b32  Ry|p, Rx, 0x10, 0x1f;
@p  add.f32        Rx, Ry, Rx;


    // BUTTERFLY REDUCTION:
    //
    // Assumes input in following registers:
    //     - Rx  = sequence value for this thread
    //
    shfl.bfly.b32  Ry, Rx, 0x10, 0x1f;   // no predicate dest
    add.f32        Rx, Ry, Rx;
    shfl.bfly.b32  Ry, Rx, 0x8,  0x1f;
    add.f32        Rx, Ry, Rx;
    shfl.bfly.b32  Ry, Rx, 0x4,  0x1f;
    add.f32        Rx, Ry, Rx;
    shfl.bfly.b32  Ry, Rx, 0x2,  0x1f;
    add.f32        Rx, Ry, Rx;
    shfl.bfly.b32  Ry, Rx, 0x1,  0x1f;
    add.f32        Rx, Ry, Rx;
    //
    // All threads now hold sum in Rx
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-shfl-sync">
<span id="id256"></span><h4>
<span class="section-number">9.7.9.6. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-shfl-sync">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-shfl-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code></p>
<p>Register data shuffle within threads of a warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shfl.sync.mode.b32  d[|p], a, b, c, membermask;

.mode = { .up, .down, .bfly, .idx };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Exchange register data between threads of a warp.</p>
<p><code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code> will cause executing thread to wait until all non-exited threads corresponding to
<code class="docutils literal notranslate"><span class="pre">membermask</span></code> have executed <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code> with the same qualifiers and same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> value
before resuming execution.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer which is a mask indicating threads participating
in barrier where the bit position corresponds to threadâ€™s <code class="docutils literal notranslate"><span class="pre">laneid</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code> exchanges register data between threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p>Each thread in the currently executing warp will compute a source lane index <em>j</em> based on input
operands <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> and the <em>mode</em>. If the computed source lane index <em>j</em> is in range, the
thread will copy the input operand <code class="docutils literal notranslate"><span class="pre">a</span></code> from lane <em>j</em> into its own destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>;
otherwise, the thread will simply copy its own input <code class="docutils literal notranslate"><span class="pre">a</span></code> to destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. The optional
destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if the computed source lane is in range, and
otherwise set to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>Note that an out of range value of <code class="docutils literal notranslate"><span class="pre">b</span></code> may still result in a valid computed source lane index
<em>j</em>. In this case, a data transfer occurs and the destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is True.</p>
<p>Note that results are undefined if a thread sources a register from an inactive thread or a thread
that is not in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> specifies a source lane or source lane offset, depending on the mode.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> contains two packed values specifying a mask for logically splitting warps into
sub-segments and an upper bound for clamping the source lane index.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code> is undefined if the executing thread is not in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For .target <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> or below, all threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> must execute the same <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code>
instruction in convergence, and only threads belonging to some <code class="docutils literal notranslate"><span class="pre">membermask</span></code> can be active when
the <code class="docutils literal notranslate"><span class="pre">shfl.sync</span></code> instruction is executed. Otherwise, the behavior is undefined.</p>
</div>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// wait for all threads in membermask to arrive
wait_for_specified_threads(membermask);

lane[4:0]  = [Thread].laneid;  // position of thread in warp
bval[4:0] = b[4:0];            // source lane or lane offset (0..31)
cval[4:0] = c[4:0];            // clamp value
segmask[4:0] = c[12:8];

// get value of source register a if thread is active and
// guard predicate true, else unpredictable
if (isActive(Thread) &amp;&amp; isGuardPredicateTrue(Thread)) {
    SourceA[lane] = a;
} else {
    // Value of SourceA[lane] is unpredictable for
    // inactive/predicated-off threads in warp
}
maxLane = (lane[4:0] &amp; segmask[4:0]) | (cval[4:0] &amp; ~segmask[4:0]);
minLane = (lane[4:0] &amp; segmask[4:0]);

switch (.mode) {
    case .up:    j = lane - bval; pval = (j &gt;= maxLane); break;
    case .down:  j = lane + bval; pval = (j &lt;= maxLane); break;
    case .bfly:  j = lane ^ bval; pval = (j &lt;= maxLane); break;
    case .idx:   j = minLane  | (bval[4:0] &amp; ~segmask[4:0]);
                                 pval = (j &lt;= maxLane); break;
}
if (!pval) j = lane;  // copy from own lane
d = SourceA[j];       // copy input a from lane j
if (dest predicate selected)
    p = pval;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>shfl.sync.up.b32  Ry|p, Rx, 0x1,  0x0, 0xffffffff;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-prmt">
<span id="id257"></span><h4>
<span class="section-number">9.7.9.7. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-prmt">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">prmt</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-prmt" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">prmt</span></code></p>
<p>Permute bytes from register pair.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>prmt.b32{.mode}  d, a, b, c;

.mode = { .f4e, .b4e, .rc8, .ecl, .ecr, .rc16 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Pick four arbitrary bytes from two 32-bit registers, and reassemble them into a 32-bit destination
register.</p>
<p>In the generic form (no mode specified), the permute control consists of four 4-bit selection
values. The bytes in the two source registers are numbered from 0 to 7: <code class="docutils literal notranslate"><span class="pre">{b,</span> <span class="pre">a}</span> <span class="pre">=</span> <span class="pre">{{b7,</span> <span class="pre">b6,</span> <span class="pre">b5,</span>
<span class="pre">b4},</span> <span class="pre">{b3,</span> <span class="pre">b2,</span> <span class="pre">b1,</span> <span class="pre">b0}}</span></code>. For each byte in the target register, a 4-bit selection value is defined.</p>
<p>The 3 lsbs of the selection value specify which of the 8 source bytes should be moved into the
target position. The msb defines if the byte value should be copied, or if the sign (msb of the
byte) should be replicated over all 8 bits of the target position (sign extend of the byte value);
<code class="docutils literal notranslate"><span class="pre">msb=0</span></code> means copy the literal value; <code class="docutils literal notranslate"><span class="pre">msb=1</span></code> means replicate the sign. Note that the sign
extension is only performed as part of generic form.</p>
<p>Thus, the four 4-bit values fully specify an arbitrary byte permute, as a <code class="docutils literal notranslate"><span class="pre">16b</span></code> permute code.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>default mode</p></th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b3</span></code></p>
<p>source select</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b2</span></code></p>
<p>source select</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b1</span></code></p>
<p>source select</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b0</span></code></p>
<p>source select</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>index</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">c[15:12]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">c[11:8]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">c[7:4]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">c[3:0]</span></code></p></td>
</tr>
</tbody>
</table>
<p>The more specialized form of the permute control uses the two lsbâ€™s of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> (which is
typically an address pointer) to control the byte extraction.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 35%">
<col style="width: 14%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>mode</p></th>
<th class="head">
<p>selector</p>
<p><code class="docutils literal notranslate"><span class="pre">c[1:0]</span></code></p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b3</span></code></p>
<p>source</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b2</span></code></p>
<p>source</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b1</span></code></p>
<p>source</p>
</th>
<th class="head">
<p><code class="docutils literal notranslate"><span class="pre">d.b0</span></code></p>
<p>source</p>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">f4e</span></code> (forward 4 extract)</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>4</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>6</p></td>
<td><p>5</p></td>
<td><p>4</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">b4e</span></code> (backward 4 extract)</p></td>
<td><p>0</p></td>
<td><p>5</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>6</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>7</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">rc8</span></code> (replicate 8)</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">ecl</span></code> (edge clamp left)</p></td>
<td><p>0</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">ecr</span></code> (edge clamp right)</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">rc16</span></code> (replicate 16)</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>1</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td></td>
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td></td>
<td><p>3</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tmp64 = (b&lt;&lt;32) | a;  // create 8 byte source

if ( ! mode ) {
   ctl[0] = (c &gt;&gt;  0) &amp; 0xf;
   ctl[1] = (c &gt;&gt;  4) &amp; 0xf;
   ctl[2] = (c &gt;&gt;  8) &amp; 0xf;
   ctl[3] = (c &gt;&gt; 12) &amp; 0xf;
} else {
   ctl[0] = ctl[1] = ctl[2] = ctl[3] = (c &gt;&gt;  0) &amp; 0x3;
}

tmp[07:00] = ReadByte( mode, ctl[0], tmp64 );
tmp[15:08] = ReadByte( mode, ctl[1], tmp64 );
tmp[23:16] = ReadByte( mode, ctl[2], tmp64 );
tmp[31:24] = ReadByte( mode, ctl[3], tmp64 );
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">prmt</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>prmt.b32      r1, r2, r3, r4;
prmt.b32.f4e  r1, r2, r3, r4;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-ld">
<span id="id258"></span><h4>
<span class="section-number">9.7.9.8. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-ld">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ld</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-ld" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ld</span></code></p>
<p>Load a register variable from an addressable state space variable.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld{.weak}{.ss}{.cop}{.level::cache_hint}{.level::prefetch_size}{.vec}.type  d, [a]{.unified}{, cache-policy};

ld{.weak}{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.level::prefetch_size}{.vec}.type  d, [a]{.unified}{, cache-policy};

ld.volatile{.ss}{.level::prefetch_size}{.vec}.type  d, [a];

ld.relaxed.scope{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.level::prefetch_size}{.vec}.type  d, [a]{, cache-policy};

ld.acquire.scope{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.level::prefetch_size}{.vec}.type  d, [a]{, cache-policy};

ld.mmio.relaxed.sys{.global}.type  d, [a];

.ss =                       { .const, .global, .local, .param{::entry, ::func}, .shared{::cta, ::cluster} };
.cop =                      { .ca, .cg, .cs, .lu, .cv };
.level1::eviction_priority = { .L1::evict_normal, .L1::evict_unchanged,
                               .L1::evict_first, .L1::evict_last, .L1::no_allocate };
.level2::eviction_priority = {.L2::evict_normal, .L2::evict_first, .L2::evict_last};
.level::cache_hint =        { .L2::cache_hint };
.level::prefetch_size =     { .L2::64B, .L2::128B, .L2::256B }
.scope =                    { .cta, .cluster, .gpu, .sys };
.vec =                      { .v2, .v4, .v8 };
.type =                     { .b8, .b16, .b32, .b64, .b128,
                              .u8, .u16, .u32, .u64,
                              .s8, .s16, .s32, .s64,
                              .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Load register variable <code class="docutils literal notranslate"><span class="pre">d</span></code> from the location specified by the source address operand <code class="docutils literal notranslate"><span class="pre">a</span></code> in
specified state space. If no state space is given, perform the load using <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>.</p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in
<a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a></p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space, then:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">::func</span></code> is assumed when access is inside a device function.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">::entry</span></code> is assumed when accessing kernel function parameters from entry function. Otherwise, when
accessing device function parameters or any other <code class="docutils literal notranslate"><span class="pre">.param</span></code> variables from entry function <code class="docutils literal notranslate"><span class="pre">::func</span></code>
is assumed by default.</p></li>
</ul>
<p>For <code class="docutils literal notranslate"><span class="pre">ld.param::entry</span></code> instruction, operand a must be a kernel parameter address, otherwise behavior
is undefined. For <code class="docutils literal notranslate"><span class="pre">ld.param::func</span></code> instruction, operand a must be a device function parameter address,
otherwise behavior is undefined.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">ld.param{::func}</span></code> used for reading value returned from device function call cannot be
predicated. See <a class="reference internal" href="#parameter-state-space"><span class="std std-ref">Parameter State Space</span></a> and
<a class="reference internal" href="#function-declarations-and-definitions"><span class="std std-ref">Function Declarations and Definitions</span></a> for descriptions
of the proper use of <code class="docutils literal notranslate"><span class="pre">ld.param</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> qualifiers indicate memory synchronization as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. The <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier
indicates the set of threads with which an <code class="docutils literal notranslate"><span class="pre">ld.relaxed</span></code> or <code class="docutils literal notranslate"><span class="pre">ld.acquire</span></code> instruction can directly
synchronize<sup>1</sup>. The <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifier indicates a memory instruction with no synchronization.
The effects of this instruction become visible to other threads only when synchronization is established
by other means.</p>
<p>The semantic details of <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier are described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
Only <code class="docutils literal notranslate"><span class="pre">.sys</span></code> thread scope is valid for <code class="docutils literal notranslate"><span class="pre">ld.mmio</span></code> operation. The
qualifiers <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> and <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> must be specified together.</p>
<p>The semantic details of <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier are described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.weak</span></code>, <code class="docutils literal notranslate"><span class="pre">.volatile</span></code>, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> qualifiers are mutually exclusive. When
none of these is specified, the <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifier is assumed by default.</p>
<p><code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>:</p>
<ul class="simple">
<li><p>May be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces, or with generic addressing where the address
points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared</span></code> space.</p></li>
<li><p>Cache operations are not allowed.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.volatile</span></code>:</p>
<ul class="simple">
<li><p>May be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code> spaces, or with generic addressing where
the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code>, or <code class="docutils literal notranslate"><span class="pre">.local</span></code> space.</p></li>
<li><p>Cache operations are not allowed.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code>:</p>
<ul class="simple">
<li><p>May be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> space or with generic addressing where the address points to
<code class="docutils literal notranslate"><span class="pre">.global</span></code> space.</p></li>
</ul>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.unified</span></code> must be specified on operand <code class="docutils literal notranslate"><span class="pre">a</span></code> if <code class="docutils literal notranslate"><span class="pre">a</span></code> is the address of a
variable declared with <code class="docutils literal notranslate"><span class="pre">.unified</span></code> attribute as described in <a class="reference internal" href="#variable-and-function-attribute-directive-attribute"><span class="std std-ref">Variable and Function Attribute Directive: .attribute</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.v8</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier is supported if:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> AND</p></li>
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.v4</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier with type <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> is supported if:</p>
<ul class="simple">
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> and <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> specify the eviction policy
for L1 and L2 cache respectively which may be applied during memory access.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> is supported if:</p>
<ul class="simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 8 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
<li>
<p>OR <code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 4 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
</ul>
<p>Optionally, sink symbol â€˜_â€™ can be used in vector expression <code class="docutils literal notranslate"><span class="pre">d</span></code> when:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> OR</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></li>
</ul>
<p>which indicates that data from corresponding memory location is not read.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is a hint to fetch additional data of the specified size
into the respective cache level.The sub-qualifier <code class="docutils literal notranslate"><span class="pre">prefetch_size</span></code> can be set to either of <code class="docutils literal notranslate"><span class="pre">64B</span></code>,
<code class="docutils literal notranslate"><span class="pre">128B</span></code>, <code class="docutils literal notranslate"><span class="pre">256B</span></code> thereby allowing the prefetch size to be 64 Bytes, 128 Bytes or 256 Bytes
respectively.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> may only be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and with
generic addressing where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space. If the generic address does
not fall within the address window of the global memory, then the prefetching behavior is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is treated as a performance hint only.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.unified</span></code> and <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> are only supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state
space and for generic addressing where the address points to the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p><sup>1</sup> This synchronization is further extended to other threads through the transitive nature of
<em>causality order</em>, as described in the memory consistency model.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a;             // named variable a
d = *(&amp;a+immOff)   // variable-plus-offset
d = *a;            // register
d = *(a+immOff);   // register-plus-offset
d = *(immAddr);    // immediate address
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> must be in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space.</p>
<p>A destination register wider than the specified type may be used. The value loaded is sign-extended
to the destination register width for signed integers, and is zero-extended to the destination
register width for unsigned and bit-size types. See
<a class="reference internal" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-destination-operands"><span class="std std-numref">Table 28</span></a>
for a description of these relaxed type-checking rules.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> data may be loaded using <code class="docutils literal notranslate"><span class="pre">ld.b16</span></code>, and then converted to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> using
<code class="docutils literal notranslate"><span class="pre">cvt</span></code> or can be used in half precision floating point instructions.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> data may be loaded using <code class="docutils literal notranslate"><span class="pre">ld.b32</span></code> and then used in half precision floating point
instructions.</p>
<p class="rubric">PTX ISA Notes</p>
<p>ld introduced in PTX ISA version 1.0. <code class="docutils literal notranslate"><span class="pre">ld.volatile</span></code> introduced in PTX ISA version 1.1.</p>
<p>Generic addressing and cache operations introduced in PTX ISA version 2.0.</p>
<p>Support for scope qualifier, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>, <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>, <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifiers introduced in PTX ISA
version 6.0.</p>
<p>Support for generic addressing of .const space added in PTX ISA version 3.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code>, <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code>
qualifiers introduced in PTX ISA version 7.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.unified</span></code> qualifier introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier introduced in PTX ISA version 8.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::entry</span></code> and <code class="docutils literal notranslate"><span class="pre">::func</span></code> sub-qualifiers on <code class="docutils literal notranslate"><span class="pre">.param</span></code> space introduced in PTX ISA
version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scope with <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> introduced in PTX ISA version 8.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier with <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space introduced in PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">ld.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Support for scope qualifier, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>, <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>, <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifiers require <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or
higher.</p>
<p>Generic addressing requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Cache operations require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.L2::256B</span></code> and <code class="docutils literal notranslate"><span class="pre">.L2::cache_hint</span></code> qualifiers requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.unified</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld.global.f32    d,[a];
ld.shared.v4.b32 Q,[p];
ld.const.s32     d,[p+4];
ld.local.b32     x,[p+-8]; // negative offset
ld.local.b64     x,[240];  // immediate address

ld.global.b16    %r,[fs];  // load .f16 data into 32-bit reg
cvt.f32.f16      %r,%r;    // up-convert f16 data to f32

ld.global.b32    %r0, [fs];     // load .f16x2 data in 32-bit reg
ld.global.b32    %r1, [fs + 4]; // load .f16x2 data in 32-bit reg
add.rn.f16x2     %d0, %r0, %r1; // addition of f16x2 data
ld.global.relaxed.gpu.u32 %r0, [gbl];
ld.shared.acquire.gpu.u32 %r1, [sh];
ld.global.relaxed.cluster.u32 %r2, [gbl];
ld.shared::cta.acquire.gpu.u32 %r2, [sh + 4];
ld.shared::cluster.u32 %r3, [sh + 8];
ld.global.mmio.relaxed.sys.u32 %r3, [gbl];
ld.local.volatile.u32 %r4, [lcl];

ld.global.f32    d,[ugbl].unified;
ld.b32           %r0, [%r1].unified;

ld.global.L1::evict_last.u32  d, [p];

ld.global.L2::64B.b32   %r0, [gbl]; // Prefetch 64B to L2
ld.L2::128B.f64         %r1, [gbl]; // Prefetch 128B to L2
ld.global.L2::256B.f64  %r2, [gbl]; // Prefetch 256B to L2

createpolicy.fractional.L2::evict_last.L2::evict_unchanged.b64 cache-policy, 1;
ld.global.L2::cache_hint.b64  x, [p], cache-policy;
ld.param::entry.b32 %rp1, [kparam1];

ld.global.b128   %r0, [gbl];   // 128-bit load

// 256-bit load
ld.global.L2::evict_last.v8.f32 { %reg0, _, %reg2, %reg3, %reg4, %reg5, %reg6, %reg7}, [addr];
ld.global.L2::evict_last.L1::evict_last.v4.u64 { %reg0, %reg1, %reg2, %reg3}, [addr];
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-ld-global-nc">
<span id="id259"></span><h4>
<span class="section-number">9.7.9.9. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-ld-global-nc">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-ld-global-nc" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code></p>
<p>Load a register variable from global state space via non-coherent cache.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld.global{.cop}.nc{.level::cache_hint}{.level::prefetch_size}.type                 d, [a]{, cache-policy};
ld.global{.cop}.nc{.level::cache_hint}{.level::prefetch_size}.vec.type             d, [a]{, cache-policy};

ld.global.nc{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.level::prefetch_size}.type      d, [a]{, cache-policy};
ld.global.nc{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.level::prefetch_size}.vec.type  d, [a]{, cache-policy};

.cop  =                     { .ca, .cg, .cs };     // cache operation
.level1::eviction_priority = { .L1::evict_normal, .L1::evict_unchanged,
                               .L1::evict_first, .L1::evict_last, .L1::no_allocate};
.level2::eviction_priority = {.L2::evict_normal, .L2::evict_first, .L2::evict_last};
.level::cache_hint =        { .L2::cache_hint };
.level::prefetch_size =     { .L2::64B, .L2::128B, .L2::256B }
.vec  =                     { .v2, .v4, .v8 };
.type =                     { .b8, .b16, .b32, .b64, .b128,
                              .u8, .u16, .u32, .u64,
                              .s8, .s16, .s32, .s64,
                              .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Load register variable <code class="docutils literal notranslate"><span class="pre">d</span></code> from the location specified by the source address operand <code class="docutils literal notranslate"><span class="pre">a</span></code> in the
global state space, and optionally cache in non-coherent read-only cache.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>On some architectures, the texture cache is larger, has higher bandwidth, and longer latency than
the global memory cache. For applications with sufficient parallelism to cover the longer
latency, <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code> should offer better performance than <code class="docutils literal notranslate"><span class="pre">ld.global</span></code> on such
architectures.</p>
</div>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">a</span></code> shall contain a global address.
Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are
described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.v8</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier is supported if:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> AND</p></li>
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.v4</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier with type <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> is supported if:</p>
<ul class="simple">
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> and <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> specify the eviction policy
for L1 and L2 cache respectively which may be applied during memory access.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> is supported if:</p>
<ul class="simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 8 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
<li>
<p>OR <code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 4 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
</ul>
<p>Optionally, sink symbol â€˜_â€™ can be used in vector expression <code class="docutils literal notranslate"><span class="pre">d</span></code> when:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> OR</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></li>
</ul>
<p>which indicates that data from corresponding memory location is not read.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is a hint to fetch additional data of the specified size
into the respective cache level.The sub-qualifier <code class="docutils literal notranslate"><span class="pre">prefetch_size</span></code> can be set to either of <code class="docutils literal notranslate"><span class="pre">64B</span></code>,
<code class="docutils literal notranslate"><span class="pre">128B</span></code>, <code class="docutils literal notranslate"><span class="pre">256B</span></code> thereby allowing the prefetch size to be 64 Bytes, 128 Bytes or 256 Bytes
respectively.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is treated as a performance hint only.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a;             // named variable a
d = *(&amp;a+immOff)   // variable-plus-offset
d = *a;            // register
d = *(a+immOff);   // register-plus-offset
d = *(immAddr);    // immediate address
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> must be in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space.</p>
<p>A destination register wider than the specified type may be used. The value loaded is sign-extended
to the destination register width for signed integers, and is zero-extended to the destination
register width for unsigned and bit-size types.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> data may be loaded using <code class="docutils literal notranslate"><span class="pre">ld.b16</span></code>, and then converted to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> using <code class="docutils literal notranslate"><span class="pre">cvt</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code>, <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> and <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code>
qualifiers introduced in PTX ISA version 7.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ld.global.nc.f32           d, [a];
ld.gloal.nc.L1::evict_last.u32 d, [a];

createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.5;
ld.global.nc.L2::cache_hint.f32  d, [a], cache-policy;

ld.global.nc.L2::64B.b32      d,  [a];     // Prefetch 64B to L2
ld.global.nc.L2::256B.f64     d,  [a];     // Prefetch 256B to L2

ld.global.nc.b128             d,  [a];

ld.global.nc.L2::evict_first.v4.f64 {%reg0, %reg1. %reg2, %reg3}. [a]; // 256-bit load
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-ldu">
<span id="id260"></span><h4>
<span class="section-number">9.7.9.10. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-ldu">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">ldu</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-ldu" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ldu</span></code></p>
<p>Load read-only data from an address that is common across threads in the warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ldu{.ss}.type      d, [a];       // load from address
ldu{.ss}.vec.type  d, [a];       // vec load from address

.ss   = { .global };             // state space
.vec  = { .v2, .v4 };
.type = { .b8, .b16, .b32, .b64, .b128,
          .u8, .u16, .u32, .u64,
          .s8, .s16, .s32, .s64,
                     .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Load <em>read-only</em> data into register variable <code class="docutils literal notranslate"><span class="pre">d</span></code> from the location specified by the source address
operand <code class="docutils literal notranslate"><span class="pre">a</span></code> in the global state space, where the address is guaranteed to be the same across all
threads in the warp. If no state space is given, perform the load using <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in
<a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a;             // named variable a
d = *(&amp;a+immOff)   // variable-plus-offset
d = *a;            // register
d = *(a+immOff);   // register-plus-offset
d = *(immAddr);    // immediate address
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> must be in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space.</p>
<p>A destination register wider than the specified type may be used. The value loaded is sign-extended
to the destination register width for signed integers, and is zero-extended to the destination
register width for unsigned and bit-size types. See
<a class="reference internal" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-destination-operands"><span class="std std-numref">Table 28</span></a>
for a description of these relaxed type-checking rules.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> data may be loaded using <code class="docutils literal notranslate"><span class="pre">ldu.b16</span></code>, and then converted to <code class="docutils literal notranslate"><span class="pre">.f32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> using
<code class="docutils literal notranslate"><span class="pre">cvt</span></code> or can be used in half precision floating point instructions.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> data may be loaded using <code class="docutils literal notranslate"><span class="pre">ldu.b32</span></code> and then used in half precision floating point
instructions.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">ldu.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ldu.global.f32    d,[a];
ldu.global.b32    d,[p+4];
ldu.global.v4.f32 Q,[p];
ldu.global.b128   d,[a];
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-st">
<span id="id261"></span><h4>
<span class="section-number">9.7.9.11. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-st">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-st" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">st</span></code></p>
<p>Store data to an addressable state space variable.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st{.weak}{.ss}{.cop}{.level::cache_hint}{.vec}.type   [a], b{, cache-policy};
st{.weak}{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.vec}.type
                                                      [a], b{, cache-policy};
st.volatile{.ss}{.vec}.type                           [a], b;
st.relaxed.scope{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.vec}.type
                                                      [a], b{, cache-policy};
st.release.scope{.ss}{.level1::eviction_priority}{.level2::eviction_priority}{.level::cache_hint}{.vec}.type
                                                      [a], b{, cache-policy};
st.mmio.relaxed.sys{.global}.type         [a], b;

.ss =                       { .global, .local, .param{::func}, .shared{::cta, ::cluster} };
.level1::eviction_priority = { .L1::evict_normal, .L1::evict_unchanged,
                               .L1::evict_first, .L1::evict_last, .L1::no_allocate };
.level2::eviction_priority = { .L2::evict_normal, .L2::evict_first, .L2::evict_last };
.level::cache_hint =        { .L2::cache_hint };
.cop =                      { .wb, .cg, .cs, .wt };
.sem =                      { .relaxed, .release };
.scope =                    { .cta, .cluster, .gpu, .sys };
.vec =                      { .v2, .v4, .v8 };
.type =                     { .b8, .b16, .b32, .b64, .b128,
                              .u8, .u16, .u32, .u64,
                              .s8, .s16, .s32, .s64,
                              .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Store the value of operand <code class="docutils literal notranslate"><span class="pre">b</span></code> in the location specified by the destination address
operand <code class="docutils literal notranslate"><span class="pre">a</span></code> in specified state space. If no state space is given, perform the store using
<a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>. Stores to const memory are illegal.</p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in
<a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.param</span></code> is specified without any sub-qualifiers then it defaults to <code class="docutils literal notranslate"><span class="pre">.param::func</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">st.param{::func}</span></code> used for passing arguments to device function cannot be predicated.
See <a class="reference internal" href="#parameter-state-space"><span class="std std-ref">Parameter State Space</span></a> and <a class="reference internal" href="#function-declarations-and-definitions"><span class="std std-ref">Function Declarations and Definitions</span></a>
for descriptions of the proper use
of <code class="docutils literal notranslate"><span class="pre">st.param</span></code>.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code> indicate memory synchronization as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. The <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier
indicates the set of threads with which an <code class="docutils literal notranslate"><span class="pre">st.relaxed</span></code> or <code class="docutils literal notranslate"><span class="pre">st.release</span></code> instruction can directly
synchronize<sup>1</sup>. The <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifier indicates a memory instruction with no synchronization.
The effects of this instruction become visible to other threads only when synchronization is established
by other means.</p>
<p>The semantic details of <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier are described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
Only <code class="docutils literal notranslate"><span class="pre">.sys</span></code> thread scope is valid for <code class="docutils literal notranslate"><span class="pre">st.mmio</span></code> operation. The
qualifiers <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> and <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> must be specified together.</p>
<p>The semantic details of <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier are described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.weak</span></code>, <code class="docutils literal notranslate"><span class="pre">.volatile</span></code>, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifiers are mutually exclusive. When
none of these is specified, the <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifier is assumed by default.</p>
<p><code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code>:</p>
<ul class="simple">
<li><p>May be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces or with generic addressing where the address points
to <code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared</span></code> space.</p></li>
<li><p>Cache operations are not allowed.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.volatile</span></code>:</p>
<ul class="simple">
<li><p>May be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code> spaces or with generic addressing where the
address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.shared</span></code>, or <code class="docutils literal notranslate"><span class="pre">.local</span></code> space.</p></li>
<li><p>Cache operations are not allowed.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code>:</p>
<ul class="simple">
<li><p>May be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> space or with generic addressing where the address points to
<code class="docutils literal notranslate"><span class="pre">.global</span></code> space.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.v8</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier is supported if:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> AND</p></li>
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.v4</span></code> (<code class="docutils literal notranslate"><span class="pre">.vec</span></code>) qualifier with type <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code> is supported if:</p>
<ul class="simple">
<li><p>State space is <code class="docutils literal notranslate"><span class="pre">.global</span></code> or with generic addressing where address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space</p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> and <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> specify the eviction policy
for L1 and L2 cache respectively which may be applied during memory access.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> is supported if:</p>
<ul class="simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 8 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
<li>
<p>OR <code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p>
<ul>
<li><p>AND Operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is vector of 4 registers with type specified with <code class="docutils literal notranslate"><span class="pre">.type</span></code></p></li>
</ul>
</li>
</ul>
<p>Optionally, sink symbol â€˜_â€™ can be used in vector expression <code class="docutils literal notranslate"><span class="pre">b</span></code> when:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v8</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code> OR</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.vec</span></code> is <code class="docutils literal notranslate"><span class="pre">.v4</span></code> and <code class="docutils literal notranslate"><span class="pre">.type</span></code> is <code class="docutils literal notranslate"><span class="pre">.b64</span></code> or <code class="docutils literal notranslate"><span class="pre">.s64</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></li>
</ul>
<p>which indicates that no data is being written at the corresponding destination address.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and for generic
addressing where the address points to the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p><sup>1</sup> This synchronization is further extended to other threads through the transitive nature of
<em>causality order</em>, as described in the memory consistency model.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = a;                // named variable d
*(&amp;a+immOffset) = b;            // variable-plus-offset
*a = b;               // register
*(a+immOffset) = b;   // register-plus-offset
*(immAddr) = b;       // immediate address
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> must be in the <code class="docutils literal notranslate"><span class="pre">.reg</span></code> state space.</p>
<p>A source register wider than the specified type may be used. The lower <code class="docutils literal notranslate"><span class="pre">n</span></code> bits corresponding to
the instruction-type width are stored to memory. See
<a class="reference internal" href="#operand-size-exceeding-instruction-type-size-relaxed-type-checking-rules-source-operands"><span class="std std-numref">Table 27</span></a>
for a description of these relaxed type-checking rules.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> data resulting from a <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction may be stored using <code class="docutils literal notranslate"><span class="pre">st.b16</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> data may be stored using <code class="docutils literal notranslate"><span class="pre">st.b32</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>st introduced in PTX ISA version 1.0. <code class="docutils literal notranslate"><span class="pre">st.volatile</span></code> introduced in PTX ISA version 1.1.</p>
<p>Generic addressing and cache operations introduced in PTX ISA version 2.0.</p>
<p>Support for scope qualifier, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code>, <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifiers introduced in PTX ISA
version 6.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> and <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifiers introduced in PTX
ISA version 7.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier introduced in PTX ISA version 8.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::func</span></code> sub-qualifier on <code class="docutils literal notranslate"><span class="pre">.param</span></code> space introduced in PTX ISA version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scope with <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> introduced in PTX ISA version 8.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier with <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space introduced in PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">st.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p>Support for scope qualifier, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code>, <code class="docutils literal notranslate"><span class="pre">.weak</span></code> qualifiers require <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or
higher.</p>
<p>Generic addressing requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Cache operations require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level1::eviction_priority</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level2::eviction_priority</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">.v8.b32</span></code>/<code class="docutils literal notranslate"><span class="pre">.v4.b64</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.global.f32    [a],b;
st.local.b32     [q+4],a;
st.global.v4.s32 [p],Q;
st.local.b32     [q+-8],a; // negative offset
st.local.s32     [100],r7; // immediate address

cvt.f16.f32      %r,%r;    // %r is 32-bit register
st.b16           [fs],%r;  // store lower
st.global.relaxed.sys.u32 [gbl], %r0;
st.shared.release.cta.u32 [sh], %r1;
st.global.relaxed.cluster.u32 [gbl], %r2;
st.shared::cta.release.cta.u32 [sh + 4], %r1;
st.shared::cluster.u32 [sh + 8], %r1;
st.global.mmio.relaxed.sys.u32 [gbl], %r1;
st.local.volatile.u32 [lcl], %r2;

st.global.L1::no_allocate.f32 [p], a;

createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.25;
st.global.L2::cache_hint.b32  [a], b, cache-policy;

st.param::func.b64 [param1], %rp1;

st.global.b128  [a], b;  // 128-bit store

// 256-bit store
st.global.L2::evict_last.v8.f32 [addr], { %reg0, _, %reg2, %reg3, %reg4, %reg5, %reg6, %reg7};
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-st-async">
<span id="id262"></span><h4>
<span class="section-number">9.7.9.12. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-st-async">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st.async</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-st-async" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">st.async</span></code></p>
<p>Asynchronous store operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.async{.weak}{.ss}.completion_mechanism{.vec}.type [a], b, [mbar];
st.async{.scope}{.ss}.completion_mechanism{.vec}.type [a], b, [mbar];

.scope =                { .cluster };
.ss   =                 { .shared::cluster };
.type =                 { .b32, .b64,
                          .u32, .u64,
                          .s32, .s64,
                          .f32, .f64 };
.vec  =                 { .v2, .v4 };
.completion_mechanism = { .mbarrier::complete_tx::bytes };

st.async{.mmio}.sem.scope{.ss}.type [a], b;

.sem =                  { .release };
.scope =                { .gpu, .sys };
.ss =                   { .global };
.type =                 { .b8, .b16, .b32, .b64,
                          .u8, .u16, .u32, .u64,
                          .s8, .s16, .s32, .s64,
                                     .f32, .f64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">st.async</span></code> is a non-blocking instruction which initiates an asynchronous store operation that
stores the value specified by source operand <code class="docutils literal notranslate"><span class="pre">b</span></code> to the destination memory location
specified by operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">Operands</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">a</span></code> is a destination address, and must be either a register, or of the form <code class="docutils literal notranslate"><span class="pre">register</span> <span class="pre">+</span> <span class="pre">immOff</span></code>,
as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">b</span></code> is a source value, of the type indicated by qualifier <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbar</span></code> is an mbarrier object address.</p></li>
</ul>
<p class="rubric">Qualifiers</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> indicates whether this is an <a class="reference internal" href="#mmio-operation"><span class="std std-ref">mmio Operation</span></a>.</p></li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> specifies the memory ordering semantics as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.sem</span></code> is not specified, it defaults to <code class="docutils literal notranslate"><span class="pre">.weak</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> specifies the set of threads with which this instruction can directly synchronize.</p></li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.ss</span></code> specifies the state space of the destination operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and the mbarrier
operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used.</p></li>
</ul>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the mechanism for observing the completion of the
asynchronous operation.</p>
<ul>
<li><p>When <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code>: upon completion of the
asynchronous operation, a
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation will be performed on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>, with
<code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to the amount of data stored in bytes.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">.type</span></code> specifies the type of the source operand <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p></li>
</ul>
<p class="rubric">Conditions</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.sem</span></code> is <code class="docutils literal notranslate"><span class="pre">.weak</span></code>:</p>
<ul>
<li><p>This is a weak store to shared memory, which signals its completion through an mbarrier object.</p></li>
<li><p>The store operation is treated as a weak memory operation.</p></li>
<li><p>The complete-tx operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at <code class="docutils literal notranslate"><span class="pre">.cluster</span></code>
scope.</p></li>
<li>
<p>Requires:</p>
<ul class="simple">
<li><p>The shared memory addresses of destination operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and the <em>mbarrier object</em> <code class="docutils literal notranslate"><span class="pre">mbar</span></code> belong
to the same CTA within the same cluster as the executing thread.</p></li>
<li><p>The number of CTAs within the cluster is strictly greater than one; <code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> is true.</p></li>
</ul>
<p>Otherwise, the behavior is undefined.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> must not be specified.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is specified, it must be <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, generic addressing is used for operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.
If the generic addresses specified do not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space, the behavior is undefined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> must be specified and must be <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code>.</p></li>
</ul>
<p>When <code class="docutils literal notranslate"><span class="pre">.sem</span></code> is <code class="docutils literal notranslate"><span class="pre">.release</span></code>:</p>
<ul class="simple">
<li><p>This is a release store to global memory.</p></li>
<li><p>The store operation is a strong memory operation with <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at the
scope specified by <code class="docutils literal notranslate"><span class="pre">.scope</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be <code class="docutils literal notranslate"><span class="pre">.sys</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is specified, it must be <code class="docutils literal notranslate"><span class="pre">.global</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, generic addressing is used for operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.
If the generic address specified does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code>
state space, the behavior is undefined.</p></li>
</ul>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier, <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics, <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space, and
<code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier introduced in PTX ISA version 8.7.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier, <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics, <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space, and
<code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier require <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.async.shared::cluster.mbarrier::complete_tx::bytes.u32 [addr], b, [mbar_addr];

st.async.sys.release.global.u32 [addr], b;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-st-bulk">
<span id="id263"></span><h4>
<span class="section-number">9.7.9.13. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-st-bulk">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">st.bulk</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-st-bulk" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">st.bulk</span></code></p>
<p>Initializes a region of memory as specified by state space.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.bulk{.weak}{.shared::cta}  [a], size, initval; // initval must be zero
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">st.bulk</span></code> instruction initializes a region of shared memory starting from the location specified
by destination address operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>The 32-bit or 64-bit integer operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be initialized in terms of
number of bytes. <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a multiple of 8. If the value is not a multiple of 8, then the
behavior is undefined. The maximum value of <code class="docutils literal notranslate"><span class="pre">size</span></code> operand can be 16777216.</p>
<p>The integer immediate operand <code class="docutils literal notranslate"><span class="pre">initval</span></code> specifies the initialization value for the memory
locations. The only numeric value allowed for operand <code class="docutils literal notranslate"><span class="pre">initval</span></code> is 0.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used. If the
address specified by <code class="docutils literal notranslate"><span class="pre">a</span></code> does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space then
the behavior is undefined.</p>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.weak</span></code> specify the memory synchronizing effect of the <code class="docutils literal notranslate"><span class="pre">st.bulk</span></code>
instruction as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">size</span></code> operand with 32-bit length is introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.bulk.weak.shared::cta  [dst], n, 0;

st.bulk                   [gdst], 4096, 0;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-multimem">
<span id="id264"></span><h4>
<span class="section-number">9.7.9.14. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-multimem">Data Movement and Conversion Instructions:
<code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-multimem" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The multimem.* operations operate on multimem addresses and accesses all of the multiple memory
locations which the multimem address points to.</p>
<p>Multimem addresses can only be accessed only by multimem.* operations. Accessing a multimem address
with <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code> or any other memory operations results in undefined behavior.</p>
<p>Refer to <em>CUDA programming guide</em> for creation and management of the multimem addresses.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code></p>
<p>Perform memory operations on the multimem address.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Integer type:

multimem.ld_reduce{.ldsem}{.scope}{.ss}.op.type      d, [a];
multimem.ld_reduce.weak{.ss}.op.type                 d, [a];

multimem.st{.stsem}{.scope}{.ss}.type                [a], b;
multimem.st.weak{.ss}.type                           [a], b;

multimem.red{.redsem}{.scope}{.ss}.op.type           [a], b;

.ss =       { .global }
.ldsem =    { .relaxed, .acquire }
.stsem =    { .relaxed, .release }
.redsem =   { .relaxed, .release }
.scope =    { .cta, .cluster, .gpu, .sys }
.op  =      { .min, .max, .add, .and, .or, .xor }
.type =     { .b32, .b64,  .u32, .u64, .s32, .s64 }

// Floating point type:

multimem.ld_reduce{.ldsem}{.scope}{.ss}.op{.acc_prec}{.vec}.type    d, [a];
multimem.ld_reduce.weak{.ss}.op{.acc_prec}{.vec}.type               d, [a];

multimem.st{.stsem}{.scope}{.ss}{.vec}.type                         [a], b;
multimem.st.weak{.ss}{.vec}.type                                    [a], b;

multimem.red{.redsem}{.scope}{.ss}.redop{.vec}.redtype              [a], b;

.ss =       { .global }
.ldsem =    { .relaxed, .acquire }
.stsem =    { .relaxed, .release }
.redsem =   { .relaxed, .release }
.scope =    { .cta, .cluster, .gpu, .sys }
.op  =      { .min, .max, .add }
.redop  =   { .add }
.acc_prec = { .acc::f32, .acc::f16 }
.vec =      { .v2, .v4, .v8 }
.type=      { .f16, .f16x2, .bf16, .bf16x2, .f32, .f64, .e5m2, .e5m2x2, .e5m2x4, .e4m3, .e4m3x2, .e4m3x4 }
.redtype =  { .f16, .f16x2, .bf16, .bf16x2, .f32, .f64 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code> performs the following operations:</p>
<ul class="simple">
<li><p>load operation on the multimem address <code class="docutils literal notranslate"><span class="pre">a</span></code>, which involves loading of data from all of the
multiple memory locations pointed to by the multimem address <code class="docutils literal notranslate"><span class="pre">a</span></code>,</p></li>
<li><p>reduction operation specified by <code class="docutils literal notranslate"><span class="pre">.op</span></code> on the multiple data loaded from the multimem address
<code class="docutils literal notranslate"><span class="pre">a</span></code>.</p></li>
</ul>
<p>The result of the reduction operation in returned in register <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code> performs a store operation of the input operand <code class="docutils literal notranslate"><span class="pre">b</span></code> to all the memory
locations pointed to by the multimem address <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> performs a reduction operation on all the memory locations pointed to
by the multimem address <code class="docutils literal notranslate"><span class="pre">a</span></code>, with operand <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code> performs reduction on the values loaded from all the memory
locations that the multimem address points to. In contrast, the <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> perform reduction
on all the memory locations that the multimem address points to.</p>
<p>Address operand <code class="docutils literal notranslate"><span class="pre">a</span></code> must be a multimem address. Otherwise, the behavior is undefined.  Supported
addressing modes for operand a and alignment requirements are described in
<a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">a</span></code> does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code> state
space then the behavior is undefined.</p>
<p>For floating-point type multi- operations, the size of the specified type along with <code class="docutils literal notranslate"><span class="pre">.vec</span></code> must
equal either 32-bits or 64-bits or 128-bits. No other combinations of <code class="docutils literal notranslate"><span class="pre">.vec</span></code> and type are
allowed. Type <code class="docutils literal notranslate"><span class="pre">.f64</span></code> cannot be used with <code class="docutils literal notranslate"><span class="pre">.vec</span></code> qualifier.
The following table describes the valid usage of <code class="docutils literal notranslate"><span class="pre">.vec</span></code> and base floating-point type:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 39%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.vec</p></th>
<th class="head"><p>Base float-type supported</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>No <code class="docutils literal notranslate"><span class="pre">.vec</span></code> specified</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
<code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.v4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
<code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code></p></td>
</tr>
</tbody>
</table>
<p>The following table describes the valid combinations of <code class="docutils literal notranslate"><span class="pre">.op</span></code> and base type:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 39%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>op</p></th>
<th class="head"><p>Base type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>
<code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
<code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f64</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code>
<code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code></p></td>
</tr>
</tbody>
</table>
<p>For <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, the default precision of the intermediate accumulation is same as the
specified type.</p>
<p>Optionally, <code class="docutils literal notranslate"><span class="pre">.acc_prec</span></code> qualifier can be specified to change the precision of intermediate
accumulation as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 38%">
<col style="width: 23%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.type</p></th>
<th class="head"><p>.acc::prec</p></th>
<th class="head"><p>Changes precision to</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.acc::f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.acc::f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
</tr>
</tbody>
</table>
<p>Optional qualifiers <code class="docutils literal notranslate"><span class="pre">.ldsem</span></code>, <code class="docutils literal notranslate"><span class="pre">.stsem</span></code> and <code class="docutils literal notranslate"><span class="pre">.redsem</span></code> specify the memory synchronizing effect
of the <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> respectively, as described in
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If explicit semantics qualifiers
are not specified, then <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code> default to <code class="docutils literal notranslate"><span class="pre">.weak</span></code> and
<code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> defaults to <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier specifies the set of threads that can directly observe the memory
synchronizing effect of this operation, as described in
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is not specified for
<code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> then <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scope is assumed by default.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.acc::f32</span></code> qualifier introduced in PTX ISA version 8.2.</p>
<p>Support for types <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>
introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.acc::f16</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Types <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>
are supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></li>
<li>
<p>And are supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.acc::f16</span></code> is supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>multimem.ld_reduce.and.b32                    val1_b32, [addr1];
multimem.ld_reduce.acquire.gpu.global.add.u32 val2_u32, [addr2];

multimem.st.relaxed.gpu.b32                [addr3], val3_b32;
multimem.st.release.cta.global.u32         [addr4], val4_u32;

multimem.red.relaxed.gpu.max.f64           [addr5], val5_f64;
multimem.red.release.cta.global.add.v4.f32 [addr6], {val6, val7, val8, val9};
multimem.ld_reduce.add.acc::f32.v2.f16x2   {val_10, val_11}, [addr7];

multimem.ld_reduce.relaxed.cta.min.v2.e4m3x2 {val_12, val_13}, [addr8];
multimem.ld_reduce.relaxed.cta.add.v4.e4m3   {val_14, val_15, val_16, val_17}, [addr9];
multimem.ld_reduce.add.acc::f16.v4.e5m2      {val_18, val_19, val_20, val_21}, [addr10];
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-prefetch-prefetchu">
<span id="id265"></span><h4>
<span class="section-number">9.7.9.15. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-prefetch-prefetchu">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-prefetch-prefetchu" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code></p>
<p>Prefetch line containing a generic address at a specified level of memory hierarchy, in specified
state space.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>prefetch{.space}.level                    [a];   // prefetch to data cache
prefetch.global.level::eviction_priority  [a];   // prefetch to data cache

prefetchu.L1  [a];             // prefetch to uniform cache

prefetch{.tensormap_space}.tensormap [a];  // prefetch the tensormap

.space =                    { .global, .local };
.level =                    { .L1, .L2 };
.level::eviction_priority = { .L2::evict_last, .L2::evict_normal };
.tensormap_space =          { .const, .param };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> instruction brings the cache line containing the specified address in global or
local memory state space into the specified cache level.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">.tensormap</span></code> qualifier is specified then the <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> instruction brings the cache line
containing the specified address in the <code class="docutils literal notranslate"><span class="pre">.const</span></code> or <code class="docutils literal notranslate"><span class="pre">.param</span></code> memory state space for subsequent
use by the <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> instruction.</p>
<p>If no state space is given, the <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> uses <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>.</p>
<p>Optionally, the eviction priority to be applied on the prefetched cache line can be specified by the
modifier <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code>.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in
<a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a></p>
<p>The <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code> instruction brings the cache line containing the specified generic address into
the specified uniform cache level.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> to a shared memory location performs no operation.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> into the uniform cache requires a generic address, and no operation occurs if the
address maps to a <code class="docutils literal notranslate"><span class="pre">const</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> memory location.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code> qualifier introduced in PTX ISA version 7.4.</p>
<p>Support for the <code class="docutils literal notranslate"><span class="pre">.tensormap</span></code> qualifier is introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">prefetch</span></code> and <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for the <code class="docutils literal notranslate"><span class="pre">.tensormap</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>prefetch.global.L1             [ptr];
prefetch.global.L2::evict_last [ptr];
prefetchu.L1  [addr];
prefetch.const.tensormap       [ptr];
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-applypriority">
<span id="id266"></span><h4>
<span class="section-number">9.7.9.16. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-applypriority">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">applypriority</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-applypriority" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">applypriority</span></code></p>
<p>Apply the cache eviction priority to the specified address in the specified cache level.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>applypriority{.global}.level::eviction_priority  [a], size;

.level::eviction_priority = { .L2::evict_normal };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">applypriority</span></code> instruction applies the cache eviction priority specified by the
<code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code> qualifier to the address range <code class="docutils literal notranslate"><span class="pre">[a..a+size)</span></code> in the specified cache
level.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the specified address does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space
then the behavior is undefined.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">size</span></code> is an integer constant that specifies the amount of data, in bytes, in the
specified cache level on which the priority is to be applied. The only supported value for the
<code class="docutils literal notranslate"><span class="pre">size</span></code> operand is 128.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
<code class="docutils literal notranslate"><span class="pre">a</span></code> must be aligned to 128 bytes.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>applypriority.global.L2::evict_normal [ptr], 128;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-discard">
<span id="id267"></span><h4>
<span class="section-number">9.7.9.17. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-discard">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">discard</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-discard" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">discard</span></code></p>
<p>Discard the data at the specified address range and cache level.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>discard{.global}.level  [a], size;

.level = { .L2 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Semantically, this behaves like a weak write of an <em>unstable indeterminate value</em>:
reads of memory locations with <em>unstable indeterminate values</em> may return different
bit patterns each time until the memory is overwritten.
This operation <em>hints</em> to the implementation that data in the specified cache <code class="docutils literal notranslate"><span class="pre">.level</span></code>
can be destructively discarded without writing it back to memory.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">size</span></code> is an integer constant that specifies the length in bytes of the
address range <code class="docutils literal notranslate"><span class="pre">[a,</span> <span class="pre">a</span> <span class="pre">+</span> <span class="pre">size)</span></code> to write <em>unstable indeterminate values</em> into.
The only supported value for the <code class="docutils literal notranslate"><span class="pre">size</span></code> operand is <code class="docutils literal notranslate"><span class="pre">128</span></code>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used.
If the specified address does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space
then the behavior is undefined.</p>
<p>Supported addressing modes for address operand <code class="docutils literal notranslate"><span class="pre">a</span></code> are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
<code class="docutils literal notranslate"><span class="pre">a</span></code> must be aligned to 128 bytes.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>discard.global.L2 [ptr], 128;
ld.weak.u32 r0, [ptr];
ld.weak.u32 r1, [ptr];
// The values in r0 and r1 may differ!
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-createpolicy">
<span id="id268"></span><h4>
<span class="section-number">9.7.9.18. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-createpolicy">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">createpolicy</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-createpolicy" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">createpolicy</span></code></p>
<p>Create a cache eviction policy for the specified cache level.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Range-based policy
createpolicy.range{.global}.level::primary_priority{.level::secondary_priority}.b64
                                   cache-policy, [a], primary-size, total-size;

// Fraction-based policy
createpolicy.fractional.level::primary_priority{.level::secondary_priority}.b64
                                   cache-policy{, fraction};

// Converting the access property from CUDA APIs
createpolicy.cvt.L2.b64            cache-policy, access-property;

.level::primary_priority =   { .L2::evict_last, .L2::evict_normal,
                               .L2::evict_first, .L2::evict_unchanged };
.level::secondary_priority = { .L2::evict_first, .L2::evict_unchanged };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">createpolicy</span></code> instruction creates a cache eviction policy for the specified cache level in an
opaque 64-bit register specified by the destination operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code>. The cache eviction
policy specifies how cache eviction priorities are applied to global memory addresses used in memory
operations with <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier.</p>
<p>There are two types of cache eviction policies:</p>
<ul>
<li>
<p>Range-based policy</p>
<p>The cache eviction policy created using <code class="docutils literal notranslate"><span class="pre">createpolicy.range</span></code> specifies the cache eviction
behaviors for the following three address ranges:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[a</span> <span class="pre">..</span> <span class="pre">a</span> <span class="pre">+</span> <span class="pre">(primary-size</span> <span class="pre">-</span> <span class="pre">1)]</span></code> referred to as primary range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[a</span> <span class="pre">+</span> <span class="pre">primary-size</span> <span class="pre">..</span> <span class="pre">a</span> <span class="pre">+</span> <span class="pre">(total-size</span> <span class="pre">-</span> <span class="pre">1)]</span></code> referred to as trailing secondary range.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[a</span> <span class="pre">-</span> <span class="pre">(total-size</span> <span class="pre">-</span> <span class="pre">primary-size)</span> <span class="pre">..</span> <span class="pre">(a</span> <span class="pre">-</span> <span class="pre">1)]</span></code> referred to as preceding secondary range.</p></li>
</ul>
<p>When a range-based cache eviction policy is used in a memory operation with
<code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier, the eviction priorities are applied as follows:</p>
<ul class="simple">
<li><p>If the memory address falls in the primary range, the eviction priority specified by
<code class="docutils literal notranslate"><span class="pre">.L2::primary_priority</span></code> is applied.</p></li>
<li><p>If the memory address falls in any of the secondary ranges, the eviction priority specified by
<code class="docutils literal notranslate"><span class="pre">.L2::secondary_priority</span></code> is applied.</p></li>
<li><p>If the memory address does not fall in either of the above ranges, then the applied eviction
priority is unspecified.</p></li>
</ul>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">primary-size</span></code> specifies the size, in bytes, of the primary range. The
32-bit operand <code class="docutils literal notranslate"><span class="pre">total-size</span></code> specifies the combined size, in bytes, of the address range
including primary and secondary ranges. The value of <code class="docutils literal notranslate"><span class="pre">primary-size</span></code> must be less than or equal
to the value of <code class="docutils literal notranslate"><span class="pre">total-size</span></code>. Maximum allowed value of <code class="docutils literal notranslate"><span class="pre">total-size</span></code> is 4GB.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.L2::secondary_priority</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.L2::evict_unchanged</span></code>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the specified address does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space
then the behavior is undefined.</p>
</li>
<li>
<p>Fraction-based policy</p>
<p>A memory operation with <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier can use the fraction-based cache
eviction policy to request the cache eviction priority specified by <code class="docutils literal notranslate"><span class="pre">.L2:primary_priority</span></code> to
be applied to a fraction of cache accesses specified by the 32-bit floating point operand
<code class="docutils literal notranslate"><span class="pre">fraction</span></code>. The remainder of the cache accesses get the eviction priority specified by
<code class="docutils literal notranslate"><span class="pre">.L2::secondary_priority</span></code>. This implies that in a memory operation that uses a fraction-based
cache policy, the memory access has a probability specified by the operand <code class="docutils literal notranslate"><span class="pre">fraction</span></code> of
getting the cache eviction priority specified by <code class="docutils literal notranslate"><span class="pre">.L2::primary_priority</span></code>.</p>
<p>The valid range of values for the operand <code class="docutils literal notranslate"><span class="pre">fraction</span></code> is <code class="docutils literal notranslate"><span class="pre">(0.0,..,</span> <span class="pre">1.0]</span></code>. If the operand
<code class="docutils literal notranslate"><span class="pre">fraction</span></code> is not specified, it defaults to 1.0.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.L2::secondary_priority</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.L2::evict_unchanged</span></code>.</p>
</li>
</ul>
<p>The access property created using the CUDA APIs can be converted into cache eviction policy by the
instruction <code class="docutils literal notranslate"><span class="pre">createpolicy.cvt</span></code>. The source operand <code class="docutils literal notranslate"><span class="pre">access-property</span></code> is a 64-bit opaque
register. Refer to <em>CUDA programming guide</em> for more details.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>createpolicy.fractional.L2::evict_last.b64                      policy, 1.0;
createpolicy.fractional.L2::evict_last.L2::evict_unchanged.b64  policy, 0.5;

createpolicy.range.L2::evict_last.L2::evict_first.b64
                                            policy, [ptr], 0x100000, 0x200000;

// access-prop is created by CUDA APIs.
createpolicy.cvt.L2.b64 policy, access-prop;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-isspacep">
<span id="id269"></span><h4>
<span class="section-number">9.7.9.19. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-isspacep">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">isspacep</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-isspacep" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">isspacep</span></code></p>
<p>Query whether a generic address falls within a specified state space window.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>isspacep.space  p, a;    // result is .pred

.space = { const, .global, .local, .shared{::cta, ::cluster}, .param{::entry} };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Write predicate register <code class="docutils literal notranslate"><span class="pre">p</span></code> with <code class="docutils literal notranslate"><span class="pre">1</span></code> if generic address a falls within the specified state
space window and with <code class="docutils literal notranslate"><span class="pre">0</span></code> otherwise. Destination <code class="docutils literal notranslate"><span class="pre">p</span></code> has type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>; the source address
operand must be of type <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.u64</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep.param{::entry}</span></code> returns <code class="docutils literal notranslate"><span class="pre">1</span></code> if the generic address falls within the window of
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a>, otherwise returns <code class="docutils literal notranslate"><span class="pre">0</span></code>. If <code class="docutils literal notranslate"><span class="pre">.param</span></code>
is specified without any sub-qualifiers then it defaults to <code class="docutils literal notranslate"><span class="pre">.param::entry</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep.global</span></code> returns <code class="docutils literal notranslate"><span class="pre">1</span></code> for <a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a>
as <code class="docutils literal notranslate"><span class="pre">.param</span></code> window is contained within the <code class="docutils literal notranslate"><span class="pre">.global</span></code>
window.</p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">ispacep.shared::cluster</span></code> will return 1 for every shared memory address that is accessible to
the threads in the cluster, whereas <code class="docutils literal notranslate"><span class="pre">ispacep.shared::cta</span></code> will return 1 only if the address is
of a variable declared in the executing CTA.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep.const</span></code> introduced in PTX ISA version 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep.param</span></code> introduced in PTX ISA version 7.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::entry</span></code> on <code class="docutils literal notranslate"><span class="pre">.param</span></code> space introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">isspacep.param{::entry}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>isspacep.const           iscnst, cptr;
isspacep.global          isglbl, gptr;
isspacep.local           islcl,  lptr;
isspacep.shared          isshrd, sptr;
isspacep.param::entry    isparam, pptr;
isspacep.shared::cta     isshrdcta, sptr;
isspacep.shared::cluster ishrdany sptr;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cvta">
<span id="id270"></span><h4>
<span class="section-number">9.7.9.20. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cvta">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvta</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cvta" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cvta</span></code></p>
<p>Convert address from <code class="docutils literal notranslate"><span class="pre">.const</span></code>,
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code>, or <code class="docutils literal notranslate"><span class="pre">.shared</span></code>
state space to generic, or vice-versa. Take the generic address of a variable declared in
<code class="docutils literal notranslate"><span class="pre">.const</span></code>, <a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>),
<code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code>, or <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// convert const, global, local, or shared address to generic address
cvta.space.size  p, a;        // source address in register a
cvta.space.size  p, var;      // get generic address of var
cvta.space.size  p, var+imm;  // generic address of var+offset

// convert generic address to const, global, local, or shared address
cvta.to.space.size  p, a;

.space = { .const, .global, .local, .shared{::cta, ::cluster}, .param{::entry} };
.size  = { .u32, .u64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Convert a <code class="docutils literal notranslate"><span class="pre">const</span></code>, <a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a>
(<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> address to a generic address, or vice-versa. The
source and destination addresses must be the same size. Use <code class="docutils literal notranslate"><span class="pre">cvt.u32.u64</span></code> or <code class="docutils literal notranslate"><span class="pre">cvt.u64.u32</span></code> to
truncate or zero-extend addresses.</p>
<p>For variables declared in <code class="docutils literal notranslate"><span class="pre">.const</span></code>,
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">.global</span></code>, <code class="docutils literal notranslate"><span class="pre">.local</span></code>, or <code class="docutils literal notranslate"><span class="pre">.shared</span></code>
state space, the generic address of the variable may be taken using <code class="docutils literal notranslate"><span class="pre">cvta</span></code>. The source is either a
register or a variable defined in <code class="docutils literal notranslate"><span class="pre">const</span></code>,
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code> memory
with an optional offset.</p>
<p>When converting a generic address into a <code class="docutils literal notranslate"><span class="pre">const</span></code>,
<a class="reference internal" href="#kernel-function-parameters"><span class="std std-ref">Kernel Function Parameters</span></a> (<code class="docutils literal notranslate"><span class="pre">.param</span></code>), <code class="docutils literal notranslate"><span class="pre">global</span></code>, <code class="docutils literal notranslate"><span class="pre">local</span></code>, or <code class="docutils literal notranslate"><span class="pre">shared</span></code>
address, the resulting address is undefined in cases where the generic address does not fall within
the address window of the specified state space. A program may use <code class="docutils literal notranslate"><span class="pre">isspacep</span></code> to guard against
such incorrect behavior.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">cvta</span></code> with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, the address must belong to the space specified by
<code class="docutils literal notranslate"><span class="pre">::cta</span></code> or <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifier, otherwise the behavior is undefined. If no sub-qualifier
is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.param</span></code> is specified without any sub-qualifiers then it defaults to <code class="docutils literal notranslate"><span class="pre">.param::entry</span></code>. For
<code class="docutils literal notranslate"><span class="pre">.param{::entry}</span></code> state space, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> must be a kernel parameter address, otherwise
behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvta.const</span></code> and <code class="docutils literal notranslate"><span class="pre">cvta.to.const</span></code> introduced in PTX ISA version 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvta.param</span></code> and <code class="docutils literal notranslate"><span class="pre">cvta.to.param</span></code> introduced in PTX ISA version 7.7.</p>
<p><strong>Note:</strong> The current implementation does not allow generic pointers to <code class="docutils literal notranslate"><span class="pre">const</span></code> space variables in
programs that contain pointers to constant buffers passed as kernel parameters.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::entry</span></code> on <code class="docutils literal notranslate"><span class="pre">.param</span></code> space introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">cvta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvta.param{::entry}</span></code> and <code class="docutils literal notranslate"><span class="pre">cvta.to.param{::entry}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cvta.const.u32   ptr,cvar;
cvta.local.u32   ptr,lptr;
cvta.shared::cta.u32  p,As+4;
cvta.shared::cluster.u32 ptr, As;
cvta.to.global.u32  p,gptr;
cvta.param.u64   ptr,pvar;
cvta.to.param::entry.u64  epptr, ptr;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cvt">
<span id="id271"></span><h4>
<span class="section-number">9.7.9.21. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cvt">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvt</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cvt" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cvt</span></code></p>
<p>Convert a value from one type to another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cvt{.irnd}{.ftz}{.sat}.dtype.atype         d, a;  // integer rounding
cvt{.frnd}{.ftz}{.sat}.dtype.atype         d, a;  // fp rounding

cvt.frnd2{.relu}{.satfinite}.f16.f32       d, a;
cvt.frnd2{.relu}{.satfinite}.f16x2.f32     d, a, b;
cvt.rs{.relu}{.satfinite}.f16x2.f32        d, a, b, rbits;

cvt.frnd2{.relu}{.satfinite}.bf16.f32      d, a;
cvt.frnd2{.relu}{.satfinite}.bf16x2.f32    d, a, b;
cvt.rs{.relu}{.satfinite}.bf16x2.f32       d, a, b, rbits;

cvt.rna{.satfinite}.tf32.f32               d, a;
cvt.frnd2{.satfinite}{.relu}.tf32.f32      d, a;

cvt.rn.satfinite{.relu}.f8x2type.f32       d, a, b;
cvt.rn.satfinite{.relu}.f8x2type.fp16x2    d, a;
cvt.rn.{.relu}.f16x2.f8x2type              d, a;
cvt.rs{.relu}.satfinite.f8x4type.f32       d, {a, b, e, f}, rbits;

cvt.rn.satfinite{.relu}.f4x2type.f32        d, a, b;
cvt.rn.satfinite{.relu}.f4x2type.fp16x2type d, a;
cvt.rn{.relu}.f16x2.f4x2type                d, a;
cvt.rs{.relu}.satfinite.f4x4type.f32        d, {a, b, e, f}, rbits;

cvt.rn.satfinite{.relu}.f6x2type.f32        d, a, b;
cvt.rn.satfinite{.relu}.f6x2type.fp16x2type d, a;
cvt.rn{.relu}.f16x2.f6x2type                d, a;
cvt.rs{.relu}.satfinite.f6x4type.f32        d, {a, b, e, f}, rbits;

cvt.frnd3{.satfinite}.ue8m0x2.f32          d, a, b;
cvt.frnd3{.satfinite}.ue8m0x2.bf16x2       d, a;
cvt.rn.bf16x2.ue8m0x2                      d, a;

cvt.rn.satfinite{.relu}{.scaled::n2::ue8m0}.s2f6x2.f32      d, a, b{, scale-factor};
cvt.rn.satfinite{.relu}{.scaled::n2::ue8m0}.s2f6x2.bf16x2   d, a{, scale-factor};
cvt.rn{.satfinite}{.relu}{.scaled::n2::ue8m0}.bf16x2.s2f6x2 d, a{, scale-factor};

.irnd   = { .rni, .rzi, .rmi, .rpi };
.frnd   = { .rn,  .rz,  .rm,  .rp  };
.frnd2  = { .rn,  .rz };
.frnd3  = { .rz,  .rp };
.dtype = .atype = { .u8,   .u16, .u32, .u64,
                    .s8,   .s16, .s32, .s64,
                    .bf16, .f16, .f32, .f64 };
.f8x2type = { .e4m3x2, .e5m2x2 };
.f4x2type = { .e2m1x2 };
.f6x2type = { .e2m3x2, .e3m2x2 };
.f4x4type = { .e2m1x4 };
.f8x4type = { .e4m3x4, .e5m2x4 };
.f6x4type = { .e2m3x4, .e3m2x4 };
.fp16x2type = { .f16x2, .bf16x2 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Convert between different types and sizes.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type, two inputs <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> of <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type are
converted into <code class="docutils literal notranslate"><span class="pre">.f16</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type and the converted values are packed in the destination
register <code class="docutils literal notranslate"><span class="pre">d</span></code>, such that the value converted from input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper half of <code class="docutils literal notranslate"><span class="pre">d</span></code>
and the value converted from input <code class="docutils literal notranslate"><span class="pre">b</span></code> is stored in the lower half of <code class="docutils literal notranslate"><span class="pre">d</span></code></p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> instruction type, destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> instruction type, operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> instruction type,
operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. For <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> instruction type, operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code> data formats, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code>
type. When converting two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, each input is converted to the
specified format, and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the
value converted from input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from
input <code class="docutils literal notranslate"><span class="pre">b</span></code> is stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>. When converting an <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> input to
<code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, each <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> input from operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to the specified
format. The converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value
converted from the upper 16 bits of input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value
converted from the lower 16 bits of input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting from <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, source operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code>
type. Each 8-bit input value in operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type. The converted values
are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from the upper 8 bits of
<code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code>
is stored in the lower 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code> data formats, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type.
When converting two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, each input is converted to the specified format,
and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted
from input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 4 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from input <code class="docutils literal notranslate"><span class="pre">b</span></code> is
stored in the lower 4 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>. When converting an <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> input to
<code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, each <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> input from operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to the specified format.
The converted values are packed in <code class="docutils literal notranslate"><span class="pre">d</span></code> so that the value from the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored
in the upper 4 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>, and the value from the lower 16 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the lower 4
bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting from <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, source operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type. Each 4-bit
input value in operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type. The converted values are packed in the
destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from the upper 4 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in
the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from the lower 4 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the
lower 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code> data format, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. When
converting four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, each input is converted to the specified format,
and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted
from inputs <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">e</span></code>, <code class="docutils literal notranslate"><span class="pre">f</span></code> are stored in each 4 bits starting from upper bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code> data formats, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code>
type. When converting two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, each input is converted to the
specified format, and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the
value converted from input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> with 2 MSB bits padded with
zeros and the value converted from input <code class="docutils literal notranslate"><span class="pre">b</span></code> is stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> with 2 MSB bits
padded with zeros. When converting an <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> input to <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, each
<code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> input from operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to the specified format. The converted
values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> so that the value from the upper 16 bits of input
<code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> with 2 MSB bits padded with zeros, and the value from
the lower 16 bits of input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> with 2 MSB bits padded with
zeros.</p>
<p>When converting from <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, source operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type.
Each 8-bit input value with 2 MSB bits 0 in operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type. The converted
values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from the upper 8 bits
of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code>
is stored in the lower 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code> data format, the destination
operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type. When converting four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, each input is converted to the specified format,
and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted
from inputs <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">e</span></code>, <code class="docutils literal notranslate"><span class="pre">f</span></code> are stored in each 8 bits starting from upper bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.
For <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, each 8-bit output will have 2 MSB bits padded with zeros.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> data formats, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. When
converting two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> or two packed <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code>, each input is converted to the
specified format, and the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the
value converted from input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from
input <code class="docutils literal notranslate"><span class="pre">b</span></code> is stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting from <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, source operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. Each 8-bit
input value in operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type. The converted values are packed in the
destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in
the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the
lower 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> data formats, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. When
converting two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> inputs to <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code>, each input is converted to the <code class="docutils literal notranslate"><span class="pre">.s2f6</span></code> value, and
the converted values are packed in the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from
input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from input <code class="docutils literal notranslate"><span class="pre">b</span></code> is
stored in the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>. When converting from <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, each input packed in operand
<code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.s2f6</span></code> value and converted values are packed in the destination operand
<code class="docutils literal notranslate"><span class="pre">d</span></code> such that value converted from upper 8 bits of input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in upper 8 bits of
operand <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from lower 8 bits of input <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in lower 8 bits of
operand <code class="docutils literal notranslate"><span class="pre">d</span></code>. Optional operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> has type <code class="docutils literal notranslate"><span class="pre">.b16</span></code> and stores two packed scaling
factors of type <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code>. For down conversion, inputs are divided by <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> and then
conversion is performed. The scaling factor of input <code class="docutils literal notranslate"><span class="pre">a</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> input from upper 16 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code>
is stored in the upper 8 bits of operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> and the scaling factor of input <code class="docutils literal notranslate"><span class="pre">b</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
input from lower 16 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the lower 8 bits of operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code>.
If not specified explicitly, value of <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> will be assumed to be <code class="docutils literal notranslate"><span class="pre">0x7f7f</span></code>,
that is, assumed as value <code class="docutils literal notranslate"><span class="pre">1</span></code> for both input scale factors.</p>
<p>When converting from <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, source operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has <code class="docutils literal notranslate"><span class="pre">.b16</span></code> type. Each 8-bit
input value in operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is converted to <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type. The converted values are packed in the
destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> such that the value converted from the upper 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in
the upper 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> and the value converted from the lower 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the
lower 16 bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>. Optional operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> has type <code class="docutils literal notranslate"><span class="pre">.b16</span></code> and stores two packed
scaling factors of type <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code>. For up-conversion, inputs are converted to destination type and
then multiplied by <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code>. The scaling factor of <code class="docutils literal notranslate"><span class="pre">.s2f6</span></code> input from upper 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code>
is stored in the upper 8 bits of operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> and the scaling factor of <code class="docutils literal notranslate"><span class="pre">.s2f6</span></code> input
from lower 8 bits of <code class="docutils literal notranslate"><span class="pre">a</span></code> is stored in the lower 8 bits of operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code>.
If not specified explicitly, value of <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> will be assumed to
be <code class="docutils literal notranslate"><span class="pre">0x7f7f</span></code>, that is, assumed as value <code class="docutils literal notranslate"><span class="pre">1</span></code> for both input scale factors.</p>
<p>Optional qualifier <code class="docutils literal notranslate"><span class="pre">.scaled::n2::ue8m0</span></code> specifies that the instruction uses packed
scale-factor with 2 scale values of <code class="docutils literal notranslate"><span class="pre">ue8m0</span></code> type. Operand <code class="docutils literal notranslate"><span class="pre">scale-factor</span></code> and qualifier
<code class="docutils literal notranslate"><span class="pre">.scaled::n2::ue8m0</span></code> must be used together.</p>
<p><code class="docutils literal notranslate"><span class="pre">rbits</span></code> is a <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type register operand used for providing random bits for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding mode.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, two 16-bit values are provided from <code class="docutils literal notranslate"><span class="pre">rbits</span></code> where 13 LSBs from
upper 16-bits are used as random bits for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> with 3 MSBs are 0 and 13 LSBs from lower
16-bits are used as random bits for operand <code class="docutils literal notranslate"><span class="pre">b</span></code> with 3 MSBs are 0.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, two 16-bit values are provided from <code class="docutils literal notranslate"><span class="pre">rbits</span></code> where upper 16-bits
are used as random bits for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and lower 16-bits are used as random bits for operand <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, two 16-bit values are provided
from <code class="docutils literal notranslate"><span class="pre">rbits</span></code> where lower 16-bits are used for operands <code class="docutils literal notranslate"><span class="pre">e</span></code>, <code class="docutils literal notranslate"><span class="pre">f</span></code> and upper 16 bits are used
for operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>When converting to <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, two 16-bit values are provided from <code class="docutils literal notranslate"><span class="pre">rbits</span></code> where lower 8-bits
from both 16-bits half of <code class="docutils literal notranslate"><span class="pre">rbits</span></code> are used for operands <code class="docutils literal notranslate"><span class="pre">e</span></code>, <code class="docutils literal notranslate"><span class="pre">f</span></code> and upper 8-bits from both
16-bits half of <code class="docutils literal notranslate"><span class="pre">rbits</span></code> are used for operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p>
<p>Rounding modifier is mandatory in all of the following cases:</p>
<ul class="simple">
<li><p>float-to-float conversions, when destination type is smaller than source type</p></li>
<li><p>All float-to-int conversions</p></li>
<li><p>All int-to-float conversions</p></li>
<li><p>All conversions involving <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2,</span> <span class="pre">.e5m2x2,</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> instruction types.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> modifier is only supported for conversions involving the following types:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> destination types.
<code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> modifier is mandatory for such conversions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>, <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> as destination types.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (/* inst type is .f16x2 or .bf16x2 */) {
    d[31:16] = convert(a);
    d[15:0]  = convert(b);
} else if (/* inst destination type is .e5m2x2 or .e4m3x2 or .ue8m0x2 */) {
    if (/* inst source type is .f32 */) {
        d[15:8] = convert(a);
        d[7:0]  = convert(b);
    } else {
        d[15:8] = convert(a[31:16]);
        d[7:0]  = convert(a[15:0]);
    }
} else if (/* inst destination type is .s2f6x2 */) {
    if (/* inst source type is .f32 */) {
        d[15:8] = convert(a / scale-factor[15:8]);
        d[7:0]  = convert(b / scale-factor[7:0]);
    } else {
        d[15:8] = convert(a[15:8] / scale-factor[15:8]);
        d[7:0]  = convert(a[7:0] / scale-factor[7:0]);
    }
} else if (/* inst source type is .s2f6x2 */) {
        d[31:16] = convert(a[15:8]) * scale-factor[15:8];
        d[15:0]  = convert(a[7:0]) * scale-factor[7:0];
} else if (/* inst destination type is .e2m1x2 */) {
    if (/* inst source type is .f32 */) {
        d[7:4] = convert(a);
        d[3:0] = convert(b);
    } else {
        d[7:4] = convert(a[31:16]);
        d[3:0]  = convert(a[15:0]);
    }
} else if (/* inst destination type is .e2m3x2 or .e3m2x2 */) {
    if (/* inst source type is .f32 */) {
        d[15:14] = 0;
        d[13:8] = convert(a);
        d[7:6] = 0;
        d[5:0] = convert(b);
    } else {
        d[15:14] = 0;
        d[13:8] = convert(a[31:16]);
        d[7:6] = 0;
        d[5:0] = convert(a[15:0]);
    }
} else if (/* inst destination type is .e2m1x4 */) {
    d[15:12] = convert(a);
    d[11:8] = convert(b);
    d[7:4] = convert(e);
    d[3:0] = convert(f);
} else if (/* inst destination type is .e4m3x4 or .e5m2x4 */) {
    d[31:24] = convert(a);
    d[23:16] = convert(b);
    d[15:8] = convert(e);
    d[7:0] = convert(f);
} else if (/* inst destination type is .e2m3x4 or .e3m2x4 */) {
    d[31:30] = 0;
    d[29:24] = convert(a);
    d[23:22] = 0;
    d[21:16] = convert(b);
    d[15:14] = 0;
    d[13:8] = convert(e);
    d[7:6] = 0;
    d[5:0] = convert(f);
} else {
    d = convert(a);
}
</pre></div>
</div>
<p>// Random bits <code class="docutils literal notranslate"><span class="pre">rbits</span></code> semantics for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding:</p>
<ol class="arabic">
<li>
<p>Destination type <code class="docutils literal notranslate"><span class="pre">.f16</span></code>:
Refer <a class="reference internal" href="#cvt-rs-rbits-layout-f16"><span class="std std-numref">Figure 38</span></a> for random bits layout details.</p>
<figure class="align-center" id="cvt-rs-rbits-layout-f16">
<img alt="_images/cvt-rs-rbits-layout-f16.png" class="image" src="_images/cvt-rs-rbits-layout-f16.png">
<figcaption>
<p><span class="caption-number">Figure 38 </span><span class="caption-text">Random bits layout for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> destination type</span><a class="headerlink" href="#cvt-rs-rbits-layout-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Destination type <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>:
Refer <a class="reference internal" href="#cvt-rs-rbits-layout-bf16"><span class="std std-numref">Figure 39</span></a> for random bits layout details.</p>
<figure class="align-center" id="cvt-rs-rbits-layout-bf16">
<img alt="_images/cvt-rs-rbits-layout-bf16.png" class="image" src="_images/cvt-rs-rbits-layout-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 39 </span><span class="caption-text">Random bits layout for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding with <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> destination type</span><a class="headerlink" href="#cvt-rs-rbits-layout-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Destination type <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>:
Refer <a class="reference internal" href="#cvt-rs-rbits-layout-f4"><span class="std std-numref">Figure 40</span></a> for random bits layout details.</p>
<figure class="align-center" id="cvt-rs-rbits-layout-f4">
<img alt="_images/cvt-rs-rbits-layout-f4.png" class="image" src="_images/cvt-rs-rbits-layout-f4.png">
<figcaption>
<p><span class="caption-number">Figure 40 </span><span class="caption-text">Random bits layout for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding with <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code> destination type</span><a class="headerlink" href="#cvt-rs-rbits-layout-f4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Destination type <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>:
Refer <a class="reference internal" href="#cvt-rs-rbits-layout-f8-f6"><span class="std std-numref">Figure 41</span></a> for random bits layout details.</p>
<figure class="align-center" id="cvt-rs-rbits-layout-f8-f6">
<img alt="_images/cvt-rs-rbits-layout-f8-f6.png" class="image" src="_images/cvt-rs-rbits-layout-f8-f6.png">
<figcaption>
<p><span class="caption-number">Figure 41 </span><span class="caption-text">Random bits layout for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding with <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code> destination type</span><a class="headerlink" href="#cvt-rs-rbits-layout-f8-f6" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ol>
<p class="rubric">Integer Notes</p>
<p>Integer rounding is required for float-to-integer conversions, and for same-size float-to-float
conversions where the value is rounded to an integer. Integer rounding is illegal in all other
instances.</p>
<p>Integer rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rni</span></code></dt>
<dd>
<p>round to nearest integer, choosing even integer if source is equidistant between two integers</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rzi</span></code></dt>
<dd>
<p>round to nearest integer in the direction of zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rmi</span></code></dt>
<dd>
<p>round to nearest integer in direction of negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rpi</span></code></dt>
<dd>
<p>round to nearest integer in direction of positive infinity</p>
</dd>
</dl>
<p>In float-to-integer conversions, depending upon conversion types, <code class="docutils literal notranslate"><span class="pre">NaN</span></code> input results in following
value:</p>
<ol class="arabic simple">
<li><p>Zero if source is not <code class="docutils literal notranslate"><span class="pre">.f64</span></code> and destination is not <code class="docutils literal notranslate"><span class="pre">.s64</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>.</p></li>
<li><p>Otherwise 1 &lt;&lt; (BitWidth(dst) - 1) corresponding to the value of (<code class="docutils literal notranslate"><span class="pre">MAXINT</span></code> &gt;&gt; 1) + 1 for unsigned type
or <code class="docutils literal notranslate"><span class="pre">MININT</span></code> for signed type.</p></li>
</ol>
<p>Subnormal numbers:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">cvt.ftz.dtype.f32</span></code> float-to-integer conversions and <code class="docutils literal notranslate"><span class="pre">cvt.ftz.f32.f32</span></code> float-to-float
conversions with integer rounding, subnormal inputs are flushed to sign-preserving zero. Modifier
<code class="docutils literal notranslate"><span class="pre">.ftz</span></code> can only be specified when either <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> or <code class="docutils literal notranslate"><span class="pre">.atype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> and applies only
to single precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) inputs and results.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>For <code class="docutils literal notranslate"><span class="pre">cvt.ftz.dtype.f32</span></code> float-to-integer conversions and <code class="docutils literal notranslate"><span class="pre">cvt.ftz.f32.f32</span></code>
float-to-float conversions with integer rounding, subnormal inputs are flushed to sign-preserving
zero. The optional <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier may be specified in these cases for clarity.</p>
<p><strong>Note:</strong> In PTX ISA versions 1.4 and earlier, the <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction did not flush single-precision
subnormal inputs or results to zero if the destination type size was 64-bits. The compiler will
preserve this behavior for legacy PTX code.</p>
</dd>
</dl>
<p>Saturation modifier:</p>
<dl>
<dt><code class="docutils literal notranslate"><span class="pre">.sat</span></code></dt>
<dd>
<p>For integer destination types, <code class="docutils literal notranslate"><span class="pre">.sat</span></code> limits the result to <code class="docutils literal notranslate"><span class="pre">MININT..MAXINT</span></code> for the size of
the operation. Note that saturation applies to both signed and unsigned integer types.</p>
<p>The saturation modifier is allowed only in cases where the destination typeâ€™s value range is not
a superset of the source typeâ€™s value range; i.e., the <code class="docutils literal notranslate"><span class="pre">.sat</span></code> modifier is illegal in cases
where saturation is not possible based on the source and destination types.</p>
<p>For float-to-integer conversions, the result is clamped to the destination range by default; i.e,
<code class="docutils literal notranslate"><span class="pre">.sat</span></code> is redundant.</p>
</dd>
</dl>
<p class="rubric">Floating Point Notes</p>
<p>Floating-point rounding is required for float-to-float conversions that result in loss of precision,
and for integer-to-float conversions. Floating-point rounding is illegal in all other instances.</p>
<p>Floating-point rounding modifiers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>rounding to nearest, with ties to even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rna</span></code></dt>
<dd>
<p>rounding to nearest, with ties away from zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>rounding toward zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>rounding toward negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>rounding toward positive infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rs</span></code></dt>
<dd>
<p>Stochastic rounding is achieved through the use of the supplied random bits. Operationâ€™s result
is rounded in the direction toward zero or away from zero based on the carry out of the integer
addition of the supplied random bits (<code class="docutils literal notranslate"><span class="pre">rbits</span></code>) to the truncated off (discarded) bits of
mantissa from the input.</p>
</dd>
</dl>
<p>A floating-point value may be rounded to an integral value using the integer rounding modifiers (see
Integer Notes). The operands must be of the same size. The result is an integral value, stored in
floating-point format.</p>
<p>Subnormal numbers:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">sm_20+</span></code></dt>
<dd>
<p>By default, subnormal numbers are supported. Modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> may be specified to flush
single-precision subnormal inputs and results to sign-preserving zero. Modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> can only
be specified when either <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> or <code class="docutils literal notranslate"><span class="pre">.atype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> and applies only to single
precision (<code class="docutils literal notranslate"><span class="pre">.f32</span></code>) inputs and results.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></dt>
<dd>
<p>Single-precision subnormal inputs and results are flushed to sign-preserving zero. The optional
<code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier may be specified in these cases for clarity.</p>
</dd>
</dl>
<p><strong>Note:</strong> In PTX ISA versions 1.4 and earlier, the <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction did not flush
single-precision subnormal inputs or results to zero if either source or destination type was
<code class="docutils literal notranslate"><span class="pre">.f64</span></code>. The compiler will preserve this behavior for legacy PTX code. Specifically, if the PTX
ISA version is 1.4 or earlier, single-precision subnormal inputs and results are flushed to
sign-preserving zero only for <code class="docutils literal notranslate"><span class="pre">cvt.f32.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">cvt.f16.f32</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt.f32.f32</span></code> instructions.</p>
<p>Saturation modifier:</p>
<dl class="simple">
<dt>
<code class="docutils literal notranslate"><span class="pre">.sat</span></code>:</dt>
<dd>
<p>For floating-point destination types, <code class="docutils literal notranslate"><span class="pre">.sat</span></code> limits the result to the range [0.0, 1.0]. <code class="docutils literal notranslate"><span class="pre">NaN</span></code>
results are flushed to positive zero. Applies to <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, and <code class="docutils literal notranslate"><span class="pre">.f64</span></code> types.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.relu</span></code>:</dt>
<dd>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>
destination types, <code class="docutils literal notranslate"><span class="pre">.relu</span></code> clamps the result to 0 if negative. <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are converted
to canonical <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.satfinite</span></code>:</dt>
<dd>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> destination formats, if the input value is <code class="docutils literal notranslate"><span class="pre">NaN</span></code>, then the result is
<code class="docutils literal notranslate"><span class="pre">NaN</span></code> in the specified destination format. For <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> destination formats <code class="docutils literal notranslate"><span class="pre">NaN</span></code> results are converted to positive <em>MAX_NORM</em>.
If the absolute value of input (ignoring sign) is greater than <em>MAX_NORM</em> of the specified destination
format, then the result is sign-preserved <em>MAX_NORM</em> of the destination format and a positive
<em>MAX_NORM</em> in <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> for which the destination sign is not supported.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>A source register wider than the specified type may be used, except when the source operand has
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> or <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> format. The lower <code class="docutils literal notranslate"><span class="pre">n</span></code> bits corresponding to the instruction-type width
are used in the conversion. See
<a class="reference internal" href="#operand-size-exceeding-instruction-type-size"><span class="std std-ref">Operand Size Exceeding Instruction-Type Size</span></a> for a description of these relaxed
type-checking rules.</p>
<p>A destination register wider than the specified type may be used, except when the destination
operand has <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> or <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> format. The result of conversion is sign-extended to
the destination register width for signed integers, and is zero-extended to the destination register
width for unsigned, bit-size, and floating-point types. See
<a class="reference internal" href="#operand-size-exceeding-instruction-type-size"><span class="std std-ref">Operand Size Exceeding Instruction-Type Size</span></a> for a description of these relaxed
type-checking rules.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">cvt.f32.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">NaN</span></code> input yields unspecified <code class="docutils literal notranslate"><span class="pre">NaN</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.relu</span></code> modifier and {<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>} destination formats
introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.f32.bf16</span></code> introduced in PTX ISA version 7.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.bf16.{u8/s8/u16/s16/u32/s32/u64/s64/f16/f64/bf16}</span></code>,
<code class="docutils literal notranslate"><span class="pre">cvt.{u8/s8/u16/s16/u32/s32/u64/s64/f16/f64}.bf16</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt.tf32.f32.{relu}.{rn/rz}</span></code> introduced
in PTX ISA version 7.8.</p>
<p><code class="docutils literal notranslate"><span class="pre">.ftz</span></code> qualifier for <code class="docutils literal notranslate"><span class="pre">cvt.f32.bf16</span></code> introduced in PTX ISA version 7.8.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code> for <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher introduced in PTX ISA version 7.8.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.satfinite.{e4m3x2,</span> <span class="pre">e5m2x2}.{f32,</span> <span class="pre">f16x2}</span></code> for <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher introduced in PTX ISA version 7.8.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code> for <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> introduced in PTX ISA version 8.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.satfinite.{e4m3x2,</span> <span class="pre">e5m2x2}.{f32,</span> <span class="pre">f16x2}</span></code> for <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> introduced in PTX ISA version 8.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.satfinite.{f16,</span> <span class="pre">bf16,</span> <span class="pre">f16x2,</span> <span class="pre">bf16x2,</span> <span class="pre">tf32}.f32</span></code> introduced in PTX ISA version 8.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rn/rz}.satfinite.tf32.f32</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}.{e2m1x2/e2m3x2/e3m2x2/ue8m0x2}.f32</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn{.relu}.f16x2.{e2m1x2/e2m3x2/e3m2x2}</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rp/rz}{.satfinite}{.relu}.ue8m0x2.bf16x2</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rz/rp}.satfinite.ue8m0x2.f32</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.bf16x2.ue8m0x2</span></code> introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding mode introduced in PTX ISA version 8.7.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rs{.e2m1x4/.e4m3x4/.e5m2x4/.e3m2x4/.e2m3x4}.f32</span></code> introduced in PTX ISA version 8.7.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}{.e5m2x2/.e4m3x2}{.bf16x2}</span></code> introduced in PTX ISA version 9.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}{.e2m3x2/.e3m2x2/.e2m1x2}{.f16x2/.bf16x2}</span></code> introduced in PTX ISA
version 9.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> instruction type introduced in PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> to or from <code class="docutils literal notranslate"><span class="pre">.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.relu</span></code> modifier and {<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>} destination formats require
<code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.f32.bf16</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.bf16.{u8/s8/u16/s16/u32/s32/u64/s64/f16/f64/bf16}</span></code>,
<code class="docutils literal notranslate"><span class="pre">cvt.{u8/s8/u16/s16/u32/s32/u64/s64/f16/f64}.bf16</span></code>, and <code class="docutils literal notranslate"><span class="pre">cvt.tf32.f32.{relu}.{rn/rz}</span></code> require
<code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.ftz</span></code> qualifier for <code class="docutils literal notranslate"><span class="pre">cvt.f32.bf16</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm89</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.satfinite.{e4m3x2,</span> <span class="pre">e5m2x2}.{f32,</span> <span class="pre">f16x2}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rn/rz}.satfinite.tf32.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}.{e2m1x2/e2m3x2/e3m2x2/ue8m0x2}.f32</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn{.relu}.f16x2.{e2m1x2/e2m3x2/e3m2x2}</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rz/rp}{.satfinite}{.relu}.ue8m0x2.bf16x2</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.{rz/rp}.satfinite.ue8m0x2.f32</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.bf16x2.ue8m0x2</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding mode is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rs{.e2m1x4/.e4m3x4/.e5m2x4/.e3m2x4/.e2m3x4}.f32</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}{.e5m2x2/.e4m3x2}{.bf16x2}</span></code> is supported on following family-specific
architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt.rn.satfinite{.relu}{.e2m3x2/.e3m2x2/.e2m1x2}{.f16x2/.bf16x2}</span></code> is supported on following
family-specific architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> instruction type is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cvt.f32.s32 f,i;
cvt.s32.f64 j,r;     // float-to-int saturates by default
cvt.rni.f32.f32 x,y; // round to nearest int, result is fp
cvt.f32.f32 x,y;     // note .ftz behavior for sm_1x targets
cvt.rn.relu.f16.f32      b, f;        // result is saturated with .relu saturation mode
cvt.rz.f16x2.f32         b1, f, f1;   // convert two fp32 values to packed fp16 outputs
cvt.rn.relu.satfinite.f16x2.f32    b1, f, f1;   // convert two fp32 values to packed fp16 outputs with .relu saturation on each output
cvt.rn.bf16.f32          b, f;        // convert fp32 to bf16
cvt.rz.relu.satfinite.bf16.f3 2    b, f;        // convert fp32 to bf16 with .relu and .satfinite saturation
cvt.rz.satfinite.bf16x2.f32        b1, f, f1;   // convert two fp32 values to packed bf16 outputs
cvt.rn.relu.bf16x2.f32   b1, f, f1;   // convert two fp32 values to packed bf16 outputs with .relu saturation on each output
cvt.rna.satfinite.tf32.f32         b1, f;       // convert fp32 to tf32 format
cvt.rn.relu.tf32.f32     d, a;        // convert fp32 to tf32 format
cvt.f64.bf16.rp          f, b;        // convert bf16 to f64 format
cvt.bf16.f16.rz          b, f         // convert f16 to bf16 format
cvt.bf16.u64.rz          b, u         // convert u64 to bf16 format
cvt.s8.bf16.rpi          s, b         // convert bf16 to s8 format
cvt.bf16.bf16.rpi        b1, b2       // convert bf16 to corresponding int represented in bf16 format
cvt.rn.satfinite.e4m3x2.f32 d, a, b;  // convert a, b to .e4m3 and pack as .e4m3x2 output
cvt.rn.relu.satfinite.e5m2x2.f16x2 d, a; // unpack a and convert the values to .e5m2 outputs with .relu
                                         // saturation on each output and pack as .e5m2x2
cvt.rn.f16x2.e4m3x2 d, a;             // unpack a, convert two .e4m3 values to packed f16x2 output
cvt.rn.satfinite.tf32.f32 d, a;       // convert fp32 to tf32 format
cvt.rn.relu.f16x2.e2m1x2 d, a;        // unpack a, convert two .e2m1 values to packed f16x2 output
cvt.rn.satfinite.e2m3x2.f32 d, a, b;  // convert a, b to .e2m3 and pack as .e2m3x2 output
cvt.rn.relu.f16x2.e3m2x2 d, a;        // unpack a, convert two .e3m2 values to packed f16x2 output

cvt.rs.f16x2.f32    d, a, b, rbits;  // convert 2 fp32 values to packed fp16 with applying .rs rounding
cvt.rs.satfinite.e2m1x4.f32  d, {a, b, e, f}, rbits; // convert 4 fp32 values to packed 4 e2m1 values with applying .rs rounding

cvt.rn.satfinite.relu.e2m1x2type.f16x2  d, a; // unpack a and covert to two .e2m1 values
cvt.rn.satfinite.e2m3x2type.bf16x2  d, a; // unpack a and covert to two .e2m3 values

// Convert 2 f32 values to s2f6 after applying scale factor for dividing the value
cvt.rn.satfinite.scaled::n2::ue8m0.s2f6x2.f32 d, a, b, scale-factor;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cvt-pack">
<span id="id272"></span><h4>
<span class="section-number">9.7.9.22. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cvt-pack">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cvt-pack" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code></p>
<p>Convert two integer values from one integer type to another and pack the results.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cvt.pack.sat.convertType.abType  d, a, b;
    .convertType  = { .u16, .s16 }
    .abType       = { .s32 }

cvt.pack.sat.convertType.abType.cType  d, a, b, c;
    .convertType  = { .u2, .s2, .u4, .s4, .u8, .s8 }
    .abType       = { .s32 }
    .cType        = { .b32 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Convert two 32-bit integers <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> into specified type and pack the results into <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is an unsigned 32-bit integer. Source operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are integers of
type <code class="docutils literal notranslate"><span class="pre">.abType</span></code> and the source operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is an integer of type <code class="docutils literal notranslate"><span class="pre">.cType</span></code>.</p>
<p>The inputs <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are converted to values of type specified by <code class="docutils literal notranslate"><span class="pre">.convertType</span></code> with
saturation and the results after conversion are packed into lower bits of <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>If operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is specified then remaining bits of <code class="docutils literal notranslate"><span class="pre">d</span></code> are copied from lower bits of <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ta = a &lt; MIN(convertType) ? MIN(convertType) : a;
ta = a &gt; MAX(convertType) ? MAX(convertType) : a;
tb = b &lt; MIN(convertType) ? MIN(convertType) : b;
tb = b &gt; MAX(convertType) ? MAX(convertType) : b;

size = sizeInBits(convertType);
td = tb ;
for (i = size; i &lt;= 2 * size - 1; i++) {
    td[i] = ta[i - size];
}

if (isU16(convertType) || isS16(convertType)) {
    d = td;
} else {
    for (i = 0; i &lt; 2 * size; i++) {
        d[i] = td[i];
    }
    for (i = 2 * size; i &lt;= 31; i++) {
        d[i] = c[i - 2 * size];
    }
}
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">.sat</span></code> modifier limits the converted values to <code class="docutils literal notranslate"><span class="pre">MIN(convertType)</span></code>.. <code class="docutils literal notranslate"><span class="pre">MAX(convertedType)</span></code> (no
overflow) if the corresponding inputs are not in the range of datatype specified as
<code class="docutils literal notranslate"><span class="pre">.convertType</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.5.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> or higher.</p>
<p>Sub byte types (<code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> and <code class="docutils literal notranslate"><span class="pre">.u2</span></code>/<code class="docutils literal notranslate"><span class="pre">.s2</span></code>) requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cvt.pack.sat.s16.s32      %r1, %r2, %r3;           // 32-bit to 16-bit conversion
cvt.pack.sat.u8.s32.b32   %r4, %r5, %r6, 0;        // 32-bit to 8-bit conversion
cvt.pack.sat.u8.s32.b32   %r7, %r8, %r9, %r4;      // %r7 = { %r5, %r6, %r8, %r9 }
cvt.pack.sat.u4.s32.b32   %r10, %r12, %r13, %r14;  // 32-bit to 4-bit conversion
cvt.pack.sat.s2.s32.b32   %r15, %r16, %r17, %r18;  // 32-bits to 2-bit conversion
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-mapa">
<span id="id273"></span><h4>
<span class="section-number">9.7.9.23. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-mapa">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">mapa</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-mapa" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mapa</span></code></p>
<p>Map the address of the shared variable in the target CTA.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mapa{.space}.type          d, a, b;

// Maps shared memory address in register a into CTA b.
mapa.shared::cluster.type  d, a, b;

// Maps shared memory variable into CTA b.
mapa.shared::cluster.type  d, sh, b;

// Maps shared memory variable into CTA b.
mapa.shared::cluster.type  d, sh + imm, b;

// Maps generic address in register a into CTA b.
mapa.type                  d, a, b;

.space = { .shared::cluster }
.type  = { .u32, .u64 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Get address in the CTA specified by operand <code class="docutils literal notranslate"><span class="pre">b</span></code> which corresponds to the address specified by
operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>Instruction type <code class="docutils literal notranslate"><span class="pre">.type</span></code> indicates the type of the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> and the source
operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>When space is <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>, source <code class="docutils literal notranslate"><span class="pre">a</span></code> is either a shared memory variable or a register
containing a valid shared memory address and register <code class="docutils literal notranslate"><span class="pre">d</span></code> contains a shared memory address. When
the optional qualifier <code class="docutils literal notranslate"><span class="pre">.space</span></code> is not specified, both <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> are registers containing
generic addresses pointing to shared memory.</p>
<p><code class="docutils literal notranslate"><span class="pre">b</span></code> is a 32-bit integer operand representing the rank of the target CTA.</p>
<p>Destination register <code class="docutils literal notranslate"><span class="pre">d</span></code> will hold an address in CTA <code class="docutils literal notranslate"><span class="pre">b</span></code> corresponding to operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mapa.shared::cluster.u64 d1, %reg1, cta;
mapa.shared::cluster.u32 d2, sh, 3;
mapa.u64                 d3, %reg2, cta;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-getctarank">
<span id="id274"></span><h4>
<span class="section-number">9.7.9.24. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-getctarank">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">getctarank</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-getctarank" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">getctarank</span></code></p>
<p>Generate the CTA rank of the address.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>getctarank{.space}.type d, a;

// Get cta rank from source shared memory address in register a.
getctarank.shared::cluster.type d, a;

// Get cta rank from shared memory variable.
getctarank.shared::cluster.type d, var;

// Get cta rank from shared memory variable+offset.
getctarank.shared::cluster.type d, var + imm;

// Get cta rank from generic address of shared memory variable in register a.
getctarank.type d, a;

.space = { .shared::cluster }
.type  = { .u32, .u64 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Write the destination register <code class="docutils literal notranslate"><span class="pre">d</span></code> with the rank of the CTA which contains the address specified
in operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>Instruction type <code class="docutils literal notranslate"><span class="pre">.type</span></code> indicates the type of source operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>When space is <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>, source <code class="docutils literal notranslate"><span class="pre">a</span></code> is either a shared memory variable or a register
containing a valid shared memory address. When the optional qualifier <code class="docutils literal notranslate"><span class="pre">.space</span></code> is not specified,
<code class="docutils literal notranslate"><span class="pre">a</span></code> is a register containing a generic addresses pointing to shared memory. Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is
always a 32-bit register which holds the rank of the CTA.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>getctarank.shared::cluster.u32 d1, addr;
getctarank.shared::cluster.u64 d2, sh + 4;
getctarank.u64                 d3, src;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-asynchronous-copy">
<span id="id275"></span><h4>
<span class="section-number">9.7.9.25. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy">Data Movement and Conversion Instructions: Asynchronous copy</a><a class="headerlink" href="#data-movement-and-conversion-instructions-asynchronous-copy" title="Permalink to this headline">ïƒ</a>
</h4>
<p>An asynchronous copy operation performs the underlying operation asynchronously in the background,
thus allowing the issuing threads to perform subsequent tasks.</p>
<p>An asynchronous copy operation can be a <em>bulk</em> operation that operates on a large amount of data, or
a <em>non-bulk</em> operation that operates on smaller sized data. The amount of data handled by a bulk
asynchronous operation must be a multiple of 16 bytes.</p>
<p>An asynchronous copy operation typically includes the following sequence:</p>
<ul class="simple">
<li><p>Optionally, reading from the tensormap.</p></li>
<li><p>Reading data from the source location(s).</p></li>
<li><p>Writing data to the destination location(s).</p></li>
<li><p>Writes being made visible to the executing thread or other threads.</p></li>
</ul>
<section id="data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms">
<span id="id276"></span><h5>
<span class="section-number">9.7.9.25.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms">Completion Mechanisms for Asynchronous Copy Operations</a><a class="headerlink" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A thread must explicitly wait for the completion of an asynchronous copy operation in order to
access the result of the operation. Once an asynchronous copy operation is initiated, modifying the
source memory location or tensor descriptor or reading from the destination memory location before
the asynchronous operation completes, exhibits undefined behavior.</p>
<p>This section describes two asynchronous copy operation completion mechanisms supported in PTX:
Async-group mechanism and mbarrier-based mechanism.</p>
<p>Asynchronous operations may be tracked by either of the completion mechanisms or both mechanisms.
The tracking mechanism is instruction/instruction-variant specific.</p>
<section id="data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-async-group">
<span id="id277"></span><h6>
<span class="section-number">9.7.9.25.1.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-async-group">Async-group mechanism</a><a class="headerlink" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-async-group" title="Permalink to this headline">ïƒ</a>
</h6>
<p>When using the async-group completion mechanism, the issuing thread specifies a group of
asynchronous operations, called <em>async-group</em>, using a <em>commit</em> operation and tracks the completion
of this group using a <em>wait</em> operation. The thread issuing the asynchronous operation must create
separate <em>async-groups</em> for bulk and non-bulk asynchronous operations.</p>
<p>A <em>commit</em> operation creates a per-thread <em>async-group</em> containing all prior asynchronous operations
tracked by <em>async-group</em> completion and initiated by the executing thread but none of the asynchronous
operations following the commit operation. A committed asynchronous operation belongs to a single
<em>async-group</em>.</p>
<p>When an <em>async-group</em> completes, all the asynchronous operations belonging to that group are
complete and the executing thread that initiated the asynchronous operations can read the result of
the asynchronous operations. All <em>async-groups</em> committed by an executing thread always complete in
the order in which they were committed. There is no ordering between asynchronous operations within
an <em>async-group</em>.</p>
<p>A typical pattern of using <em>async-group</em> as the completion mechanism is as follows:</p>
<ul class="simple">
<li><p>Initiate the asynchronous operations.</p></li>
<li><p>Group the asynchronous operations into an <em>async-group</em> using a <em>commit</em> operation.</p></li>
<li><p>Wait for the completion of the async-group using the wait operation.</p></li>
<li><p>Once the <em>async-group</em> completes, access the results of all asynchronous operations in that
<em>async-group</em>.</p></li>
</ul>
</section>
<section id="data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-mbarrier">
<span id="id278"></span><h6>
<span class="section-number">9.7.9.25.1.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-mbarrier">Mbarrier-based mechanism</a><a class="headerlink" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-mbarrier" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A thread can track the completion of one or more asynchronous operations using the current phase of
an <em>mbarrier object</em>. When the current phase of the <em>mbarrier object</em> is complete, it implies that
all asynchronous operations tracked by this phase are complete, and all threads participating in
that <em>mbarrier object</em> can access the result of the asynchronous operations.</p>
<p>The <em>mbarrier object</em> to be used for tracking the completion of an asynchronous operation can be
either specified along with the asynchronous operation as part of its syntax, or as a separate
operation. For a bulk asynchronous operation, the <em>mbarrier object</em> must be specified in the
asynchronous operation, whereas for non-bulk operations, it can be specified after the asynchronous
operation.</p>
<p>A typical pattern of using mbarrier-based completion mechanism is as follows:</p>
<ul class="simple">
<li><p>Initiate the asynchronous operations.</p></li>
<li><p>Set up an <em>mbarrier object</em> to track the asynchronous operations in its current phase, either as
part of the asynchronous operation or as a separate operation.</p></li>
<li><p>Wait for the <em>mbarrier object</em> to complete its current phase using <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> or
<code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code>.</p></li>
<li><p>Once the <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> operation returns <code class="docutils literal notranslate"><span class="pre">True</span></code>, access the
results of the asynchronous operations tracked by the <em>mbarrier object</em>.</p></li>
</ul>
</section>
</section>
<section id="async-proxy">
<span id="id279"></span><h5>
<span class="section-number">9.7.9.25.2. </span><a class="reference internal" href="#async-proxy">Async Proxy</a><a class="headerlink" href="#async-proxy" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk</span></code> operations are performed in the <em>asynchronous proxy</em> (or <em>async
proxy</em>).</p>
<p>Accessing the same memory location across multiple proxies needs a cross-proxy fence. For the
<em>async proxy</em>, <code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> should be used to synchronize memory between <em>generic
proxy</em> and the <em>async proxy</em>.</p>
<p>The completion of a <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk</span></code> operation is followed by an implicit <em>generic-async</em>
proxy fence. So the result of the asynchronous operation is made visible to the generic proxy as
soon as its completion is observed. <em>Async-group</em> OR <em>mbarrier-based</em> completion mechanism must
be used to wait for the completion of the <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk</span></code> instructions.</p>
</section>
<section id="data-movement-and-conversion-instructions-non-bulk-copy">
<span id="id280"></span><h5>
<span class="section-number">9.7.9.25.3. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-non-bulk-copy">Data Movement and Conversion Instructions: Non-bulk copy</a><a class="headerlink" href="#data-movement-and-conversion-instructions-non-bulk-copy" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="data-movement-and-conversion-instructions-cp-async">
<span id="id281"></span><h6>
<span class="section-number">9.7.9.25.3.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async</span></code></p>
<p>Initiates an asynchronous copy operation from one state space to another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.ca.shared{::cta}.global{.level::cache_hint}{.level::prefetch_size}
                         [dst], [src], cp-size{, src-size}{, cache-policy} ;
cp.async.cg.shared{::cta}.global{.level::cache_hint}{.level::prefetch_size}
                         [dst], [src], 16{, src-size}{, cache-policy} ;
cp.async.ca.shared{::cta}.global{.level::cache_hint}{.level::prefetch_size}
                         [dst], [src], cp-size{, ignore-src}{, cache-policy} ;
cp.async.cg.shared{::cta}.global{.level::cache_hint}{.level::prefetch_size}
                         [dst], [src], 16{, ignore-src}{, cache-policy} ;

.level::cache_hint =     { .L2::cache_hint }
.level::prefetch_size =  { .L2::64B, .L2::128B, .L2::256B }
cp-size =                { 4, 8, 16 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async</span></code> is a non-blocking instruction which initiates an asynchronous copy operation of data
from the location specified by source address operand <code class="docutils literal notranslate"><span class="pre">src</span></code> to the location specified by
destination address operand <code class="docutils literal notranslate"><span class="pre">dst</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">src</span></code> specifies a location in the global state space
and <code class="docutils literal notranslate"><span class="pre">dst</span></code> specifies a location in the shared state space.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">cp-size</span></code> is an integer constant which specifies the size of data in bytes to be copied to
the destination <code class="docutils literal notranslate"><span class="pre">dst</span></code>. <code class="docutils literal notranslate"><span class="pre">cp-size</span></code> can only be 4, 8 and 16.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> allows optionally specifying a 32-bit integer operand <code class="docutils literal notranslate"><span class="pre">src-size</span></code>. Operand
<code class="docutils literal notranslate"><span class="pre">src-size</span></code> represents the size of the data in bytes to be copied from <code class="docutils literal notranslate"><span class="pre">src</span></code> to <code class="docutils literal notranslate"><span class="pre">dst</span></code> and must
be less than <code class="docutils literal notranslate"><span class="pre">cp-size</span></code>. In such case, remaining bytes in destination <code class="docutils literal notranslate"><span class="pre">dst</span></code> are filled with
zeros. Specifying <code class="docutils literal notranslate"><span class="pre">src-size</span></code> larger than <code class="docutils literal notranslate"><span class="pre">cp-size</span></code> results in undefined behavior.</p>
<p>The optional and non-immediate predicate argument <code class="docutils literal notranslate"><span class="pre">ignore-src</span></code> specifies whether the data from the
source location <code class="docutils literal notranslate"><span class="pre">src</span></code> should be ignored completely. If the source data is ignored then zeros will
be copied to destination <code class="docutils literal notranslate"><span class="pre">dst</span></code>. If the argument <code class="docutils literal notranslate"><span class="pre">ignore-src</span></code> is not specified then it defaults
to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<p>Supported alignment requirements and addressing modes for operand <code class="docutils literal notranslate"><span class="pre">src</span></code> and <code class="docutils literal notranslate"><span class="pre">dst</span></code> are described
in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.async</span></code> qualifier indicates that the <code class="docutils literal notranslate"><span class="pre">cp</span></code> instruction will initiate the memory
copy operation asynchronously and control will return to the executing thread before the copy
operation is complete. The executing thread can then use
<a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-async-group"><span class="std std-ref">async-group based completion mechanism</span></a>
or the <a class="reference internal" href="#data-movement-and-conversion-instructions-asynchronous-copy-completion-mechanisms-mbarrier"><span class="std std-ref">mbarrier based completion mechanism</span></a>
to wait for completion of the asynchronous copy operation.
No other synchronization mechanism guarantees the completion of the asynchronous
copy operations.</p>
<p>There is no ordering guarantee between two <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations if they are not explicitly
synchronized using <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code> or <code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> or <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier"><span class="std std-ref">mbarrier instructions</span></a>.</p>
<p>As described in <a class="reference internal" href="#cache-operators"><span class="std std-ref">Cache Operators</span></a>, the <code class="docutils literal notranslate"><span class="pre">.cg</span></code> qualifier indicates
caching of data only at global level cache L2 and not at L1 whereas <code class="docutils literal notranslate"><span class="pre">.ca</span></code> qualifier indicates
caching of data at all levels including L1 cache. Cache operator are treated as performance hints
only.</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async</span></code> is treated as a weak memory operation in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is a hint to fetch additional data of the specified size
into the respective cache level.The sub-qualifier <code class="docutils literal notranslate"><span class="pre">prefetch_size</span></code> can be set to either of <code class="docutils literal notranslate"><span class="pre">64B</span></code>,
<code class="docutils literal notranslate"><span class="pre">128B</span></code>, <code class="docutils literal notranslate"><span class="pre">256B</span></code> thereby allowing the prefetch size to be 64 Bytes, 128 Bytes or 256 Bytes
respectively.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> may only be used with <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and with
generic addressing where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space. If the generic address does
not fall within the address window of the global memory, then the prefetching behavior is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier is treated as a performance hint only.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and for generic
addressing where the address points to the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> and <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifiers introduced in PTX ISA
version 7.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">ignore-src</span></code> operand introduced in PTX ISA version 7.5.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.ca.shared.global  [shrd],    [gbl + 4], 4;
cp.async.ca.shared::cta.global  [%r0 + 8], [%r1],     8;
cp.async.cg.shared.global  [%r2],     [%r3],     16;

cp.async.cg.shared.global.L2::64B   [%r2],      [%r3],     16;
cp.async.cg.shared.global.L2::128B  [%r0 + 16], [%r1],     16;
cp.async.cg.shared.global.L2::256B  [%r2 + 32], [%r3],     16;

createpolicy.fractional.L2::evict_last.L2::evict_unchanged.b64 cache-policy, 0.25;
cp.async.ca.shared.global.L2::cache_hint [%r2], [%r1], 4, cache-policy;

cp.async.ca.shared.global                   [shrd], [gbl], 4, p;
cp.async.cg.shared.global.L2::cache_hint   [%r0], [%r2], 16, q, cache-policy;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-commit-group">
<span id="id282"></span><h6>
<span class="section-number">9.7.9.25.3.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-commit-group">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-commit-group" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code></p>
<p>Commits all prior initiated but uncommitted <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instructions into a <em>cp.async-group</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.commit_group ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code> instruction creates a new <em>cp.async-group</em> per thread and batches all
prior <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instructions initiated by the executing thread but not committed to any
<em>cp.async-group</em> into the new <em>cp.async-group</em>. If there are no uncommitted <code class="docutils literal notranslate"><span class="pre">cp.async</span></code>
instructions then <code class="docutils literal notranslate"><span class="pre">cp.async.commit_group</span></code> results in an empty <em>cp.async-group.</em></p>
<p>An executing thread can wait for the completion of all <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations in a <em>cp.async-group</em>
using <code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code>.</p>
<p>There is no memory ordering guarantee provided between any two <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations within the
same <em>cp.async-group</em>. So two or more <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations within a <em>cp.async-group</em> copying data
to the same location results in undefined behavior.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example 1:
cp.async.ca.shared.global [shrd], [gbl], 4;
cp.async.commit_group ; // Marks the end of a cp.async group

// Example 2:
cp.async.ca.shared.global [shrd1],   [gbl1],   8;
cp.async.ca.shared.global [shrd1+8], [gbl1+8], 8;
cp.async.commit_group ; // Marks the end of cp.async group 1

cp.async.ca.shared.global [shrd2],    [gbl2],    16;
cp.async.cg.shared.global [shrd2+16], [gbl2+16], 16;
cp.async.commit_group ; // Marks the end of cp.async group 2
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-wait-group">
<span id="id283"></span><h6>
<span class="section-number">9.7.9.25.3.3. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-wait-group">Data Movement and Conversion Instructions:
<code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> / <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-wait-group" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code>, <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code></p>
<p>Wait for completion of prior asynchronous copy operations.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.wait_group N;
cp.async.wait_all ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> instruction will cause executing thread to wait till only <code class="docutils literal notranslate"><span class="pre">N</span></code> or fewer of
the most recent <em>cp.async-group</em>s are pending and all the prior <em>cp.async-group</em>s committed by
the executing threads are complete. For example, when <code class="docutils literal notranslate"><span class="pre">N</span></code> is 0, the executing thread waits on all
the prior <em>cp.async-group</em>s to complete. Operand <code class="docutils literal notranslate"><span class="pre">N</span></code> is an integer constant.</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code> is equivalent to :</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.commit_group;
cp.async.wait_group 0;
</pre></div>
</div>
<p>An empty <em>cp.async-group</em> is considered to be trivially complete.</p>
<p>Writes performed by <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations are made visible to the executing thread only after:</p>
<ol class="arabic simple">
<li><p>The completion of <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code> or</p></li>
<li><p>The completion of <code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> on the <em>cp.async-group</em> in which the <code class="docutils literal notranslate"><span class="pre">cp.async</span></code>
belongs to or</p></li>
<li><p><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait"><span class="std std-ref">mbarrier.test_wait</span></a>
returns <code class="docutils literal notranslate"><span class="pre">True</span></code> on an <em>mbarrier object</em> which is tracking the completion of the <code class="docutils literal notranslate"><span class="pre">cp.async</span></code>
operation.</p></li>
</ol>
<p>There is no ordering between two <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> operations that are not synchronized with
<code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code> or <code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> or <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier"><span class="std std-ref">mbarrier objects</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.wait_group</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async.wait_all</span></code> does not provide any ordering and visibility
guarantees for any other memory operation apart from <code class="docutils literal notranslate"><span class="pre">cp.async</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example of .wait_all:
cp.async.ca.shared.global [shrd1], [gbl1], 4;
cp.async.cg.shared.global [shrd2], [gbl2], 16;
cp.async.wait_all;  // waits for all prior cp.async to complete

// Example of .wait_group :
cp.async.ca.shared.global [shrd3], [gbl3], 8;
cp.async.commit_group;  // End of group 1

cp.async.cg.shared.global [shrd4], [gbl4], 16;
cp.async.commit_group;  // End of group 2

cp.async.cg.shared.global [shrd5], [gbl5], 16;
cp.async.commit_group;  // End of group 3

cp.async.wait_group 1;  // waits for group 1 and group 2 to complete
</pre></div>
</div>
</section>
</section>
<section id="data-movement-and-conversion-instructions-bulk-copy">
<span id="id284"></span><h5>
<span class="section-number">9.7.9.25.4. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-bulk-copy">Data Movement and Conversion Instructions: Bulk copy</a><a class="headerlink" href="#data-movement-and-conversion-instructions-bulk-copy" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="data-movement-and-conversion-instructions-cp-async-bulk">
<span id="id285"></span><h6>
<span class="section-number">9.7.9.25.4.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code></p>
<p>Initiates an asynchronous copy operation from one state space to another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// global -&gt; shared::cta
cp.async.bulk.dst.src.completion_mechanism{.level::cache_hint}
                      [dstMem], [srcMem], size, [mbar] {, cache-policy}

.dst =                  { .shared::cta }
.src =                  { .global }
.completion_mechanism = { .mbarrier::complete_tx::bytes }
.level::cache_hint =    { .L2::cache_hint }


// global -&gt; shared::cluster
cp.async.bulk.dst.src.completion_mechanism{.multicast}{.level::cache_hint}
                      [dstMem], [srcMem], size, [mbar] {, ctaMask} {, cache-policy}

.dst =                  { .shared::cluster }
.src =                  { .global }
.completion_mechanism = { .mbarrier::complete_tx::bytes }
.level::cache_hint =    { .L2::cache_hint }
.multicast =            { .multicast::cluster  }


// shared::cta -&gt; shared::cluster
cp.async.bulk.dst.src.completion_mechanism [dstMem], [srcMem], size, [mbar]

.dst =                  { .shared::cluster }
.src =                  { .shared::cta }
.completion_mechanism = { .mbarrier::complete_tx::bytes }


// shared::cta -&gt; global
cp.async.bulk.dst.src.completion_mechanism{.level::cache_hint}{.cp_mask}
                      [dstMem], [srcMem], size {, cache-policy} {, byteMask}

.dst =                  { .global }
.src =                  { .shared::cta }
.completion_mechanism = { .bulk_group }
.level::cache_hint =    { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> is a non-blocking instruction which initiates an asynchronous bulk-copy operation
from the location specified by source address operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> to the location specified by
destination address operand <code class="docutils literal notranslate"><span class="pre">dstMem</span></code>.</p>
<p>The direction of bulk-copy is from the state space specified by the <code class="docutils literal notranslate"><span class="pre">.src</span></code> modifier to the state
space specified by the <code class="docutils literal notranslate"><span class="pre">.dst</span></code> modifiers.</p>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be copied, in terms of number of
bytes. <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a multiple of 16. If the value is not a multiple of 16, then the behavior is
undefined. The memory range <code class="docutils literal notranslate"><span class="pre">[dstMem,</span> <span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size</span> <span class="pre">-</span> <span class="pre">1]</span></code> must not overflow the destination memory
space and the memory range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span> <span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size</span> <span class="pre">-</span> <span class="pre">1]</span></code> must not overflow the source memory
space. Otherwise, the behavior is undefined. The addresses <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> and <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> must be aligned
to 16 bytes.</p>
<p>When the destination of the copy is <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> the destination address has to be in the shared
memory of the executing CTA within the cluster, otherwise the behavior is undefined.</p>
<p>When the source of the copy is <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> and the destination is <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>, the
destination has to be in the shared memory of a different CTA within the cluster.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported on the
instruction variant. The completion mechanisms that are supported for different variants are
summarized in the following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 27%">
<col style="width: 26%">
<col style="width: 21%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.completion-mechanism</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.dst</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.src</span></code></p></th>
<th class="head"><p>Completion mechanism</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.mbarrier::...</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td rowspan="3"><p>mbarrier based</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
<td><p><em>Bulk async-group</em>
based</p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> variant uses
mbarrier based completion mechanism. The <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation, with <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to amount of data copied in bytes, will be
performed on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> variant uses <em>bulk async-group</em>
based completion mechanism.</p>
<p>The optional modifier <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> allows copying of data from global memory to shared
memory of multiple CTAs in the cluster. Operand <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> specifies the destination CTAs in the
cluster such that each bit position in the 16-bit <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> operand corresponds to the <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code>
of the destination CTA. The source data is multicast to the same CTA-relative offset as <code class="docutils literal notranslate"><span class="pre">dstMem</span></code>
in the shared memory of each destination CTA. The mbarrier signal is also multicast to the same
CTA-relative offset as <code class="docutils literal notranslate"><span class="pre">mbar</span></code> in the shared memory of the destination CTA.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program. The
qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported when at least one of the <code class="docutils literal notranslate"><span class="pre">.src</span></code> or <code class="docutils literal notranslate"><span class="pre">.dst</span></code>
statespaces is <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p>When the optional qualifier <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> is specified, the argument <code class="docutils literal notranslate"><span class="pre">byteMask</span></code> is required.
The i-th bit in the 16-bit wide <code class="docutils literal notranslate"><span class="pre">byteMask</span></code> operand specifies whether the i-th byte of each 16-byte
wide chunk of source data is copied to the destination. If the bit is set, the byte is copied.</p>
<p>The copy operation in <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> is treated as a weak memory operation and the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at the <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> qualifier is optimized for target architecture <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>/
<code class="docutils literal notranslate"><span class="pre">sm_103f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> and may have substantially reduced performance on other
targets and hence <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> is advised to be used with <code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>/
<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> as destination state space is introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> qualifier advised to be used with <code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or
<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// .global -&gt; .shared::cta (strictly non-remote):
cp.async.bulk.shared::cta.global.mbarrier::complete_tx::bytes [dstMem], [srcMem], size, [mbar];

cp.async.bulk.shared::cta.global.mbarrier::complete_tx::bytes.L2::cache_hint
                                             [dstMem], [srcMem], size, [mbar], cache-policy;

// .global -&gt; .shared::cluster:
cp.async.bulk.shared::cluster.global.mbarrier::complete_tx::bytes [dstMem], [srcMem], size, [mbar];

cp.async.bulk.shared::cluster.global.mbarrier::complete_tx::bytes.multicast::cluster
                                             [dstMem], [srcMem], size, [mbar], ctaMask;

cp.async.bulk.shared::cluster.global.mbarrier::complete_tx::bytes.L2::cache_hint
                                             [dstMem], [srcMem], size, [mbar], cache-policy;


// .shared::cta -&gt; .shared::cluster (strictly remote):
cp.async.bulk.shared::cluster.shared::cta.mbarrier::complete_tx::bytes [dstMem], [srcMem], size, [mbar];

// .shared::cta -&gt; .global:
cp.async.bulk.global.shared::cta.bulk_group [dstMem], [srcMem], size;

cp.async.bulk.global.shared::cta.bulk_group.L2::cache_hint} [dstMem], [srcMem], size, cache-policy;

// .shared::cta -&gt; .global with .cp_mask:
cp.async.bulk.global.shared::cta.bulk_group.L2::cache_hint.cp_mask [dstMem], [srcMem], size, cache-policy, byteMask;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-reduce-async-bulk">
<span id="id286"></span><h6>
<span class="section-number">9.7.9.25.4.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code></p>
<p>Initiates an asynchronous reduction operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.reduce.async.bulk.dst.src.completion_mechanism.redOp.type
              [dstMem], [srcMem], size, [mbar]

.dst =                  { .shared::cluster }
.src =                  { .shared::cta }
.completion_mechanism = { .mbarrier::complete_tx::bytes }
.redOp=                 { .and, .or, .xor,
                          .add, .inc, .dec,
                          .min, .max }
.type =                 { .b32, .u32, .s32, .b64, .u64 }


cp.reduce.async.bulk.dst.src.completion_mechanism{.level::cache_hint}.redOp.type
               [dstMem], [srcMem], size{, cache-policy}

.dst =                  { .global      }
.src =                  { .shared::cta }
.completion_mechanism = { .bulk_group }
.level::cache_hint    = { .L2::cache_hint }
.redOp=                 { .and, .or, .xor,
                          .add, .inc, .dec,
                          .min, .max }
.type =                 { .f16, .bf16, .b32, .u32, .s32, .b64, .u64, .s64, .f32, .f64 }


cp.reduce.async.bulk.dst.src.completion_mechanism{.level::cache_hint}.add.noftz.type
               [dstMem], [srcMem], size{, cache-policy}
.dst  =                 { .global }
.src  =                 { .shared::cta }
.completion_mechanism = { .bulk_group }
.type =                 { .f16, .bf16 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> is a non-blocking instruction which initiates an asynchronous reduction
operation on an array of memory locations specified by the destination address operand <code class="docutils literal notranslate"><span class="pre">dstMem</span></code>
with the source array whose location is specified by the source address operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code>. The size
of the source and the destination array must be the same and is specified by the operand <code class="docutils literal notranslate"><span class="pre">size</span></code>.</p>
<p>Each data element in the destination array is reduced inline with the corresponding data element in
the source array with the reduction operation specified by the modifier <code class="docutils literal notranslate"><span class="pre">.redOp</span></code>. The type of each
data element in the source and the destination array is specified by the modifier <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p>
<p>The source address operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> is located in the state space specified by <code class="docutils literal notranslate"><span class="pre">.src</span></code> and the
destination address operand <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> is located in the state specified by the <code class="docutils literal notranslate"><span class="pre">.dst</span></code>.</p>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be copied from the source location and
used in the reduction operation, in terms of number of bytes. <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a multiple of 16. If
the value is not a multiple of 16, then the behavior is undefined. The memory range <code class="docutils literal notranslate"><span class="pre">[dstMem,</span>
<span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size</span> <span class="pre">-</span> <span class="pre">1]</span></code> must not overflow the destination memory space and the memory range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span>
<span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size</span> <span class="pre">-</span> <span class="pre">1]</span></code> must not overflow the source memory space. Otherwise, the behavior is
undefined. The addresses <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> and <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> must be aligned to 16 bytes.</p>
<p>The operations supported by <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> are classified as follows:</p>
<ul class="simple">
<li><p>The bit-size operations are <code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, and <code class="docutils literal notranslate"><span class="pre">.xor</span></code>.</p></li>
<li><p>The integer operations are <code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, and <code class="docutils literal notranslate"><span class="pre">.max</span></code>. The <code class="docutils literal notranslate"><span class="pre">.inc</span></code> and
<code class="docutils literal notranslate"><span class="pre">.dec</span></code> operations return a result in the range <code class="docutils literal notranslate"><span class="pre">[0..x]</span></code> where <code class="docutils literal notranslate"><span class="pre">x</span></code> is the value at the source
state space.</p></li>
<li><p>The floating point operation <code class="docutils literal notranslate"><span class="pre">.add</span></code> rounds to the nearest even. The current implementation of
<code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.add.f32</span></code> flushes subnormal inputs and results to sign-preserving zero. The
<code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.add.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.add.bf16</span></code> operations require
<code class="docutils literal notranslate"><span class="pre">.noftz</span></code> qualifier. It preserves input and result subnormals, and does not flush them to zero.</p></li>
</ul>
<p>The following table describes the valid combinations of <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> and element type:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 24%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.dst</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.redOp</span></code></p></th>
<th class="head"><p>Element type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f64</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported on the
instruction variant. The completion mechanisms that are supported for different variants are
summarized in the following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 26%">
<col style="width: 25%">
<col style="width: 21%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.completion-mechanism</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.dst</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.src</span></code></p></th>
<th class="head"><p>Completion mechanism</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.mbarrier::...</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td rowspan="2"><p>mbarrier based</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
<td><p><em>Bulk async-group</em>
based</p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> variant
uses mbarrier based completion mechanism. The <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation, with <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to amount of data copied in bytes, will be
performed on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> variant uses <em>bulk
async-group</em> based completion mechanism.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program. The
qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported when at least one of the <code class="docutils literal notranslate"><span class="pre">.src</span></code> or <code class="docutils literal notranslate"><span class="pre">.dst</span></code>
statespaces is <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p>Each reduction operation performed by the <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> has individually <code class="docutils literal notranslate"><span class="pre">.relaxed.gpu</span></code>
memory ordering semantics. The load operations in <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> are treated as weak
memory operation and the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at the <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.reduce.async.bulk.shared::cluster.shared::cta.mbarrier::complete_tx::bytes.add.u64
                                                                  [dstMem], [srcMem], size, [mbar];

cp.reduce.async.bulk.shared::cluster.shared::cta.mbarrier::complete_tx::bytes.min.s32
                                                                  [dstMem], [srcMem], size, [mbar];

cp.reduce.async.bulk.global.shared::cta.bulk_group.min.f16 [dstMem], [srcMem], size;

cp.reduce.async.bulk.global.shared::cta.bulk_group.L2::cache_hint.xor.s32 [dstMem], [srcMem], size, policy;

cp.reduce.async.bulk.global.shared::cta.bulk_group.add.noftz.f16 [dstMem], [srcMem], size;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-bulk-prefetch">
<span id="id287"></span><h6>
<span class="section-number">9.7.9.25.4.3. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code></p>
<p>Provides a hint to the system to initiate the asynchronous prefetch of data to the cache.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.prefetch.L2.src{.level::cache_hint}   [srcMem], size {, cache-policy}

.src =                { .global }
.level::cache_hint =  { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code> is a non-blocking instruction which may initiate an asynchronous prefetch
of data from the location specified by source address operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code>, in <code class="docutils literal notranslate"><span class="pre">.src</span></code> statespace, to
the L2 cache.</p>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be prefetched in terms of number of
bytes. <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a multiple of 16. If the value is not a multiple of 16, then the behavior is
undefined.  The address <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> must be aligned to 16 bytes.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch</span></code> is treated as a weak memory operation in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.prefetch.L2.global                 [srcMem], size;

cp.async.bulk.prefetch.L2.global.L2::cache_hint  [srcMem], size, policy;
</pre></div>
</div>
</section>
</section>
</section>
<section id="data-movement-and-conversion-instructions-multimem-cp-async-bulk">
<span id="id288"></span><h4>
<span class="section-number">9.7.9.26. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-multimem-cp-async-bulk">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-multimem-cp-async-bulk" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code></p>
<p>Initiates an asynchronous copy operation to a multimem address range.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>multimem.cp.async.bulk.dst.src.completion_mechanism{.cp_mask}
    [dstMem], [srcMem], size{, byteMask};

    .dst                  = { .global }
    .src                  = { .shared::cta }
    .completion_mechanism = { .bulk_group }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code> initiates an asynchronous bulk-copy operation from source
address range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span> <span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size)</span></code> to memory locations residing on each GPUâ€™s memory referred
to by the destination multimem address range <code class="docutils literal notranslate"><span class="pre">[dstMem,</span> <span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size)</span></code>. The direction of
bulk-copy is from the state space specified by the <code class="docutils literal notranslate"><span class="pre">.src</span></code> modifier to the state space specified
by the <code class="docutils literal notranslate"><span class="pre">.dst</span></code> modifiers.</p>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be copied, in terms of number of
bytes. Operand <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a multiple of <code class="docutils literal notranslate"><span class="pre">16</span></code>. The memory range <code class="docutils literal notranslate"><span class="pre">[dstMem,</span> <span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size)</span></code>
must not overflow the destination multimem memory space. The memory range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span> <span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size)</span></code>
must not overflow the source memory space. The addresses <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> and <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> must be aligned
to <code class="docutils literal notranslate"><span class="pre">16</span></code> bytes. If any of these pre-conditions is not met, the behavior is undefined.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported by the
instruction. The modifier <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code> instruction
uses bulk async-group based completion mechanism.</p>
<p>When the optional modifier <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> is specified, the argument <code class="docutils literal notranslate"><span class="pre">byteMask</span></code> is required. The
i-th bit in the 16-bit wide <code class="docutils literal notranslate"><span class="pre">byteMask</span></code> operand specifies whether the i-th byte of each 16-byte
wide chunk of source data is copied to the destination. If the bit is set, the byte is copied.</p>
<p>The reads and writes of the copy operation in <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code> are weak memory operations
as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>multimem.cp.async.bulk.global.shared::cta.bulk_group [dstMem], [srcMem], size;

multimem.cp.async.bulk.global.shared::cta.bulk_group [dstMem], [srcMem], 512;

multimem.cp.async.bulk.global.shared::cta.bulk_group.cp_mask [dstMem], [srcMem], size, byteMask;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-multimem-cp-reduce-async-bulk">
<span id="id289"></span><h4>
<span class="section-number">9.7.9.27. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-multimem-cp-reduce-async-bulk">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-multimem-cp-reduce-async-bulk" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code></p>
<p>Initiates an asynchronous reduction operation to a multimem address range.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>multimem.cp.reduce.async.bulk.dst.src.completion_mechanism.redOp.type  [dstMem], [srcMem], size;

    .dst                  = { .global }
    .src                  = { .shared::cta }
    .completion_mechanism = { .bulk_group }
    .redOp                = { .and, .or, .xor,
                              .add, .inc, .dec,
                              .min, .max }
    .type                 = { .f16, .bf16,
                              .b32, .u32, .s32,
                              .b64, .u64, .s64,
                              .f32, .f64 }

multimem.cp.reduce.async.bulk.dst.src.completion_mechanism.add.noftz.type  [dstMem], [srcMem], size;

    .dst                  = { .global }
    .src                  = { .shared::cta }
    .completion_mechanism = { .bulk_group }
    .type                 = { .f16, .bf16 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code> initiates an element-wise asynchronous reduction
operation with elements from source memory address range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span> <span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size)</span></code> to memory
locations residing on each GPUâ€™s memory referred to by the multimem destination address range
<code class="docutils literal notranslate"><span class="pre">[dstMem,</span> <span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size)</span></code>.</p>
<p>Each data element in the destination array is reduced inline with the corresponding data element in
the source array with the reduction operation specified by the modifier <code class="docutils literal notranslate"><span class="pre">.redOp</span></code>. The type of each
data element in the source and the destination array is specified by the modifier <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p>
<p>The source address operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> is in the state space specified by <code class="docutils literal notranslate"><span class="pre">.src</span></code> and the
destination address operand <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> is in the state specified by the <code class="docutils literal notranslate"><span class="pre">.dst</span></code>.</p>
<p>The 32-bit operand <code class="docutils literal notranslate"><span class="pre">size</span></code> specifies the amount of memory to be copied from the source location
and used in the reduction operation, in terms of number of bytes. Operand <code class="docutils literal notranslate"><span class="pre">size</span></code> must be a
multiple of 16. The memory range <code class="docutils literal notranslate"><span class="pre">[dstMem,</span> <span class="pre">dstMem</span> <span class="pre">+</span> <span class="pre">size)</span></code> must not overflow the destination
multimem memory space. The memory range <code class="docutils literal notranslate"><span class="pre">[srcMem,</span> <span class="pre">srcMem</span> <span class="pre">+</span> <span class="pre">size)</span></code> must not overflow the source
memory space. The addresses <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> and <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> must be aligned to 16 bytes. If any of these
preconditions is not met, the behavior is undefined.</p>
<p>The operations supported by <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> are classified as follows:</p>
<p>The bit-size operations are <code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, and <code class="docutils literal notranslate"><span class="pre">.xor</span></code>.</p>
<p>The integer operations are <code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, and <code class="docutils literal notranslate"><span class="pre">.max</span></code>. The <code class="docutils literal notranslate"><span class="pre">.inc</span></code> and
<code class="docutils literal notranslate"><span class="pre">.dec</span></code> operations return a result in the range <code class="docutils literal notranslate"><span class="pre">[0..x]</span></code> where <code class="docutils literal notranslate"><span class="pre">x</span></code> is the value at the source
state space.</p>
<p>The floating point operation <code class="docutils literal notranslate"><span class="pre">.add</span></code> rounds to the nearest even, preserve input and result
subnormals, and does not flush them to zero, except for the current implementation of
<code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk.add.f32</span></code> which flushes subnormal inputs and results to
sign-preserving zero. The <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk.add.f16</span></code> and
<code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk.add.bf16</span></code> operations require <code class="docutils literal notranslate"><span class="pre">.noftz</span></code> qualifier. It preserves
input and result subnormals, and does not flush them to zero.</p>
<p>The following table describes the valid combinations of <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> and element type:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 23%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.redOp</p></th>
<th class="head"><p>element type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>.add</p></td>
<td><p>.u32, .s32, .u64, .f32, .f64,
.f16, .bf16</p></td>
</tr>
<tr class="row-odd">
<td><p>.min,
.max</p></td>
<td><p>.u32, .s32, .u64, .s64, .f16,
.bf16</p></td>
</tr>
<tr class="row-even">
<td><p>.inc,
.dec</p></td>
<td><p>.u32</p></td>
</tr>
<tr class="row-odd">
<td><p>.and,
.or,
.xor</p></td>
<td><p>.b32, .b64</p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported by the
instruction. The modifier <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code> uses
bulk async-group based completion mechanism.</p>
<p>Each reduction operation performed by the <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code> has individually
<code class="docutils literal notranslate"><span class="pre">.relaxed.sys</span></code> memory ordering semantics. The load operations in <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code>
are treated as weak memory operations as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.add.u32 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.xor.b64 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.inc.u32 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.dec.u32 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.max.s32 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.add.noftz.f16 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.min.bf16 [dstMem], [srcMem], size;

multimem.cp.reduce.async.bulk.global.shared::cta.bulk_group.add.noftz.bf16 [dstMem], [srcMem], size;
</pre></div>
</div>
<section id="data-movement-and-conversion-instructions-tensor-copy">
<span id="id290"></span><h5>
<span class="section-number">9.7.9.27.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-tensor-copy">Data Movement and Conversion Instructions: Tensor copy</a><a class="headerlink" href="#data-movement-and-conversion-instructions-tensor-copy" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="data-movement-and-conversion-instructions-tensor-copy-restrictions">
<span id="id291"></span><h6>
<span class="section-number">9.7.9.27.1.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions">Restriction on Tensor Copy instructions</a><a class="headerlink" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Following are the restrictions on the types <code class="docutils literal notranslate"><span class="pre">.b4x16</span></code>, <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and
<code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk</span></code> doesnâ€™t support the types <code class="docutils literal notranslate"><span class="pre">.b4x16</span></code>, <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>
and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> with the direction <code class="docutils literal notranslate"><span class="pre">.global.shared::cta</span></code> doesnâ€™t support the
type <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> with the direction <code class="docutils literal notranslate"><span class="pre">.shared::cluster.global</span></code> doesnâ€™t support
the sub-byte types on <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>.</p></li>
<li><p>OOB-NaN fill mode doesnâ€™t support the types <code class="docutils literal notranslate"><span class="pre">.b4x16</span></code>, <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>
and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>.</p></li>
<li>
<p>Box-Size[0] must be exactly:</p>
<ol class="arabic simple">
<li><p>96B for <code class="docutils literal notranslate"><span class="pre">b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>.</p></li>
<li><p>64B for <code class="docutils literal notranslate"><span class="pre">b4x16_p64</span></code>.</p></li>
</ol>
</li>
<li>
<p>Tensor-Size[0] must be a multiple of:</p>
<ol class="arabic simple">
<li><p>96B for <code class="docutils literal notranslate"><span class="pre">b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>.</p></li>
<li><p>64B for <code class="docutils literal notranslate"><span class="pre">b4x16_p64</span></code>.</p></li>
</ol>
</li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>, the first coordinate in the tensorCoords
argument vector must be a multiple of 128.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>, the global memory address must be 32B aligned.
Additionally, tensor stride in every dimension must be 32B aligned.</p></li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code> supports the following swizzling modes:</p>
<ol class="arabic simple">
<li><p>None.</p></li>
<li><p>128B (With all potential swizzle atomicity values except: 32B with 8B flip)</p></li>
</ol>
</li>
</ol>
<p>Following are the restrictions on the 96B swizzle mode:</p>
<ol class="arabic simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">.swizzle_atomicity</span></code> must be 16B.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">.interleave_layout</span></code> must not be set.</p></li>
<li><p>Box-Size[0] must be less than or equal to 96B.</p></li>
<li><p>The type must not be among following: <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code>, <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> and <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> must not be set to <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code>.</p></li>
</ol>
<p>Following are the restrictions on the <code class="docutils literal notranslate"><span class="pre">.global.shared::cta</span></code> direction:</p>
<ol class="arabic simple">
<li><p>Starting co-ordinates for Bounding Box (<code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code>) must be non-negative.</p></li>
<li>
<p>The bounding box along the D, W and H dimensions must stay within the tensor boundaries.
This implies:</p>
<ol class="arabic simple">
<li><p>Bounding-Box Lower-Corner must be non-negative.</p></li>
<li><p>Bounding-Box Upper-Corner must be non-positive.</p></li>
</ol>
</li>
</ol>
<p>Following are the restrictions for <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>:</p>
<ol class="arabic simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> with the direction <code class="docutils literal notranslate"><span class="pre">.shared::cluster.global</span></code> doesnâ€™t support:</p>
<ol class="arabic simple">
<li><p>the sub-byte types</p></li>
<li><p>the qualifier <code class="docutils literal notranslate"><span class="pre">.swizzle_atomicity</span></code></p></li>
</ol>
</li>
</ol>
<p>Following are the restrictions for <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> while using type <code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code> on
<code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> with the direction <code class="docutils literal notranslate"><span class="pre">.global.shared::cta</span></code>:</p>
<ol class="arabic simple">
<li><p>Box-Size[0] must be exactly either of 48B or 96B.</p></li>
<li><p>The global memory address must be 16B aligned.</p></li>
<li><p>Tensor Stride in every dimension must be 16B aligned.</p></li>
<li><p>The first coordinate in the tensorCoords argument vector must be a multiple of 64.</p></li>
<li><p>Tensor-Size[0] must be a multiple of 48B.</p></li>
<li>
<p>The following swizzle modes are supported:</p>
<ol class="arabic simple">
<li><p>None.</p></li>
<li><p>128B (With all potential swizzle atomicity values except: 32B with 8B flip)</p></li>
<li><p>64B swizzle with 16B swizzle atomicity</p></li>
</ol>
</li>
</ol>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-bulk-tensor">
<span id="id292"></span><h6>
<span class="section-number">9.7.9.27.1.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-tensor">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk-tensor" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code></p>
<p>Initiates an asynchronous copy operation on the tensor data from one state space to another.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// global -&gt; shared::cta
cp.async.bulk.tensor.dim.dst.src{.load_mode}.completion_mechanism{.cta_group}{.level::cache_hint}
                                   [dstMem], [tensorMap, tensorCoords], [mbar]{, im2colInfo} {, cache-policy}

.dst =                  { .shared::cta }
.src =                  { .global }
.dim =                  { .1d, .2d, .3d, .4d, .5d }
.completion_mechanism = { .mbarrier::complete_tx::bytes }
.cta_group =            { .cta_group::1, .cta_group::2 }
.load_mode =            { .tile, .tile::gather4, .im2col, .im2col::w, .im2col::w::128 }
.level::cache_hint =    { .L2::cache_hint }


// global -&gt; shared::cluster
cp.async.bulk.tensor.dim.dst.src{.load_mode}.completion_mechanism{.multicast}{.cta_group}{.level::cache_hint}
                                   [dstMem], [tensorMap, tensorCoords], [mbar]{, im2colInfo}
                                   {, ctaMask} {, cache-policy}

.dst =                  { .shared::cluster }
.src =                  { .global }
.dim =                  { .1d, .2d, .3d, .4d, .5d }
.completion_mechanism = { .mbarrier::complete_tx::bytes }
.cta_group =            { .cta_group::1, .cta_group::2 }
.load_mode =            { .tile, .tile::gather4, .im2col, .im2col::w, .im2col::w::128 }
.level::cache_hint =    { .L2::cache_hint }
.multicast =            { .multicast::cluster  }


// shared::cta -&gt; global
cp.async.bulk.tensor.dim.dst.src{.load_mode}.completion_mechanism{.level::cache_hint}
                                   [tensorMap, tensorCoords], [srcMem] {, cache-policy}

.dst =                  { .global }
.src =                  { .shared::cta }
.dim =                  { .1d, .2d, .3d, .4d, .5d }
.completion_mechanism = { .bulk_group }
.load_mode =            { .tile, .tile::scatter4, .im2col_no_offs }
.level::cache_hint =    { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> is a non-blocking instruction which initiates an asynchronous copy
operation of tensor data from the location in <code class="docutils literal notranslate"><span class="pre">.src</span></code> state space to the location in the <code class="docutils literal notranslate"><span class="pre">.dst</span></code>
state space.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> specifies the location in the <code class="docutils literal notranslate"><span class="pre">.dst</span></code> state space into which the tensor data
has to be copied and <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> specifies the location in the <code class="docutils literal notranslate"><span class="pre">.src</span></code> state space from which the
tensor data has to be copied.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.dst</span></code> is specified as <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code>, the address <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> must be in the shared memory
of the executing CTA within the cluster, otherwise the behavior is undefined.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.dst</span></code> is specified as <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>, the address <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> can be in the shared memory
of any of the CTAs within the current cluster.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is the generic address of the opaque tensor-map object which resides
in <code class="docutils literal notranslate"><span class="pre">.param</span></code> space or <code class="docutils literal notranslate"><span class="pre">.const</span></code> space or <code class="docutils literal notranslate"><span class="pre">.global</span></code> space. The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> specifies
the properties of the tensor copy operation, as described in <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">Tensor-map</span></a>.
The <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is accessed in tensormap proxy. Refer to the <em>CUDA programming guide</em> for creating
the tensor-map objects on the host side.</p>
<p>The dimension of the tensor data is specified by the <code class="docutils literal notranslate"><span class="pre">.dim</span></code> modifier.</p>
<p>The vector operand <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> specifies the starting coordinates in the tensor data in the
global memory from or to which the copy operation has to be performed. The individual tensor
coordinates in <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> are of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. The format of vector argument <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code>
is dependent on <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> specified and is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 42%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.load_mode</p></th>
<th class="head"><p>tensorCoords</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code></p></td>
<td rowspan="2"><p>{col_idx, row_idx0, row_idx1, row_idx2, row_idx3}</p></td>
<td rowspan="2"><p>Fixed length vector of size 5.
The five elements together specify the start
co-ordinates of the four rows.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Rest all</p></td>
<td><p>{d0, .., dn}
for n = .dim</p></td>
<td><p>Vector of n elements where n = .dim.
The elements indicate the offset in each of the
dimension.</p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported on the
instruction variant. The completion mechanisms that are supported for different variants are
summarized in the following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 13%">
<col style="width: 19%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>.completion-mechanism</p></th>
<th class="head" rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.dst</span></code></p></th>
<th class="head" rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.src</span></code></p></th>
<th class="head" colspan="2"><p>Completion mechanism</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>Needed for completion of
entire Async operation</p></th>
<th class="head"><p>optionally can be used for the completion of
reading of the tensormap object</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.mbarrier::...</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td rowspan="2"><p>mbarrier based</p></td>
<td rowspan="3"><p><em>Bulk async-group</em> based</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.global</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></td>
<td><p><em>Bulk async-group</em>
based</p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> variant
uses mbarrier based completion mechanism. Upon the completion of the asynchronous copy operation, the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation, with <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to amount of data copied in bytes, will be
performed on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> can only be specified with the mbarrier based completion mechanism. The
modifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> is used to signal either the odd numbered CTA or the even numbered CTA among
the <a class="reference internal" href="#tcgen05-cta-pair"><span class="std std-ref">CTA-Pair</span></a>. When <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> is specified, the mbarrier object <code class="docutils literal notranslate"><span class="pre">mbar</span></code>
that is specified must be in the shared memory of the same CTA as the shared memory destination <code class="docutils literal notranslate"><span class="pre">dstMem</span></code>.
When <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified, the mbarrier object <code class="docutils literal notranslate"><span class="pre">mbar</span></code> can be in shared memory of either the
same CTA as the shared memory destination <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> or in its <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer-CTA</span></a>. If
<code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code>.</p>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> specifies that the <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> variant uses <em>bulk
async-group</em> based completion mechanism.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> specifies how the data in the source location is copied into the
destination location. If <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> is not specified, it defaults to <code class="docutils literal notranslate"><span class="pre">.tile</span></code>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">.tile</span></code> mode, the multi-dimensional layout of the source tensor is preserved at the destination.
In <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> mode, four rows in 2-dimnesional source tensor are combined to form a single 2-dimensional
destination tensor. In <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> mode, single 2-dimensional source tensor is divided into four rows
in 2-dimensional destination tensor. Details of <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code>/<code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> modes are described
in <a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes"><span class="std std-ref">.tile::scatter4 and .tile::gather4 modes</span></a>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes, some dimensions of the source tensors are unrolled in a single
dimensional column at the destination. Details of the <code class="docutils literal notranslate"><span class="pre">im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes are described
in <a class="reference internal" href="#tensor-im2col-mode"><span class="std std-ref">im2col mode</span></a> and <a class="reference internal" href="#tensor-im2col-w-w128-modes"><span class="std std-ref">im2col::w and im2col::w::128 modes</span></a>
respectively. In <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes, the tensor has to be at least 3-dimensional. The vector
operand <code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> can be specified only when <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> is <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> or <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> or
<code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code>. The format of the vector argument <code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> is dependent on the exact im2col mode
and is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 32%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Exact im2col mode</p></th>
<th class="head"><p>im2colInfo argument</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col</span></code></p></td>
<td><p>{ i2cOffW , i2cOffH , i2cOffD }
for <code class="docutils literal notranslate"><span class="pre">.dim</span></code> = <code class="docutils literal notranslate"><span class="pre">.5d</span></code></p></td>
<td><p>A vector of im2col offsets whose vector size is two
less than number of dimensions .dim.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code></p></td>
<td rowspan="2"><p>{ wHalo, wOffset }</p></td>
<td rowspan="2"><p>A vector of 2 arguments containing
<a class="reference internal" href="#tensor-im2col-w-w128-modes-whalo"><span class="std std-ref">wHalo</span></a> and
<a class="reference internal" href="#tensor-im2col-w-w128-modes-woffset"><span class="std std-ref">wOffset</span></a>
arguments.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col_no_offs</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> is not applicable.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> is not applicable.</p></td>
</tr>
</tbody>
</table>
<p>Argument <code class="docutils literal notranslate"><span class="pre">wHalo</span></code> is a 16bit unsigned integer whose valid set of values differs on the load-mode and is as follows:
- Im2col::w mode : valid range is [0, 512).
- Im2col::w::128 mode : valid range is [0, 32).</p>
<p>Argument <code class="docutils literal notranslate"><span class="pre">wOffset</span></code> is a 16bit unsigned integer whose valid range of values is [0, 32).</p>
<p>The optional modifier <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> allows copying of data from global memory to shared
memory of multiple CTAs in the cluster. Operand <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> specifies the destination CTAs in the
cluster such that each bit position in the 16-bit <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> operand corresponds to the <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code>
of the destination CTA. The source data is multicast to the same offset as <code class="docutils literal notranslate"><span class="pre">dstMem</span></code> in the shared
memory of each destination CTA. When <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> is specified as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> : The mbarrier signal is also multicasted to the same offset as <code class="docutils literal notranslate"><span class="pre">mbar</span></code> in
the shared memory of the destination CTA.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> : The mbarrier signal is multicasted either to all the odd numbered CTAs or the
even numbered CTAs within the corresponding <a class="reference internal" href="#tcgen05-cta-pair"><span class="std std-ref">CTA-Pair</span></a>. For each destination
CTA specified in the <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code>, the mbarrier signal is sent either to the destination CTA or its
<a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer-CTA</span></a> based on CTAs <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code> parity of shared memory where
the mbarrier object <code class="docutils literal notranslate"><span class="pre">mbar</span></code> resides.</p></li>
</ul>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p>The copy operation in <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> is treated as a weak memory operation and the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at the <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> qualifier is optimized for target architecture <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>/
<code class="docutils literal notranslate"><span class="pre">sm_103f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> and may have substantially reduced performance on other
targets and hence <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> is advised to be used with <code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>/
<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> as destination state space is introduced in PTX ISA version 8.6.</p>
<p>Support for qualifiers <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> introduced in PTX ISA version 8.6.</p>
<p>Support for qualifiers <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> introduced in PTX ISA version 8.6.</p>
<p>Support for qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> qualifier advised to be used with <code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or
<code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> require:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> when destination state space is <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> and is supported on <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> from PTX ISA version 8.8.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher when destination state space is <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code>.</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b16 ctaMask;
.reg .u16 i2cOffW, i2cOffH, i2cOffD;
.reg .b64 l2CachePolicy;

cp.async.bulk.tensor.1d.shared::cta.global.mbarrier::complete_tx::bytes.tile  [sMem0], [tensorMap0, {tc0}], [mbar0];

@p cp.async.bulk.tensor.5d.shared::cta.global.im2col.mbarrier::complete_tx::bytes
                     [sMem2], [tensorMap2, {tc0, tc1, tc2, tc3, tc4}], [mbar2], {i2cOffW, i2cOffH, i2cOffD};

cp.async.bulk.tensor.1d.shared::cluster.global.mbarrier::complete_tx::bytes.tile  [sMem0], [tensorMap0, {tc0}], [mbar0];

@p cp.async.bulk.tensor.2d.shared::cluster.global.mbarrier::complete_tx::bytes.multicast::cluster
                     [sMem1], [tensorMap1, {tc0, tc1}], [mbar2], ctaMask;

@p cp.async.bulk.tensor.5d.shared::cluster.global.im2col.mbarrier::complete_tx::bytes
                     [sMem2], [tensorMap2, {tc0, tc1, tc2, tc3, tc4}], [mbar2], {i2cOffW, i2cOffH, i2cOffD};

@p cp.async.bulk.tensor.3d.im2col.shared::cluster.global.mbarrier::complete_tx::bytes.L2::cache_hint
                     [sMem3], [tensorMap3, {tc0, tc1, tc2}], [mbar3], {i2cOffW}, policy;

@p cp.async.bulk.tensor.1d.global.shared::cta.bulk_group  [tensorMap3, {tc0}], [sMem3];

cp.async.bulk.tensor.2d.tile::gather4.shared::cluster.global.mbarrier::complete_tx::bytes
                     [sMem5], [tensorMap6, {x0, y0, y1, y2, y3}], [mbar5];

cp.async.bulk.tensor.3d.im2col::w.shared::cluster.global.mbarrier::complete_tx::bytes
                     [sMem4], [tensorMap5, {t0, t1, t2}], [mbar4], {im2colwHalo, im2colOff};

cp.async.bulk.tensor.1d.shared::cluster.global.tile.cta_group::2
                     [sMem6], [tensorMap7, {tc0}], [peerMbar];
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor">
<span id="id293"></span><h6>
<span class="section-number">9.7.9.27.1.3. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-reduce-async-bulk-tensor" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code></p>
<p>Initiates an asynchronous reduction operation on the tensor data.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// shared::cta -&gt; global:
cp.reduce.async.bulk.tensor.dim.dst.src.redOp{.load_mode}.completion_mechanism{.level::cache_hint}
                                          [tensorMap, tensorCoords], [srcMem] {,cache-policy}

.dst =                  { .global }
.src =                  { .shared::cta }
.dim =                  { .1d, .2d, .3d, .4d, .5d }
.completion_mechanism = { .bulk_group }
.load_mode =            { .tile, .im2col_no_offs }
.redOp =                { .add, .min, .max, .inc, .dec, .and, .or, .xor}
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code> is a non-blocking instruction which initiates an asynchronous
reduction operation of tensor data in the <code class="docutils literal notranslate"><span class="pre">.dst</span></code> state space with tensor data in the <code class="docutils literal notranslate"><span class="pre">.src</span></code>
state space.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">srcMem</span></code> specifies the location of the tensor data in the <code class="docutils literal notranslate"><span class="pre">.src</span></code> state space using
which the reduction operation has to be performed.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is the generic address of the opaque tensor-map object which resides
in <code class="docutils literal notranslate"><span class="pre">.param</span></code> space or <code class="docutils literal notranslate"><span class="pre">.const</span></code> space or <code class="docutils literal notranslate"><span class="pre">.global</span></code> space. The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> specifies
the properties of the tensor copy operation, as described in <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">Tensor-map</span></a>.
The <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is accessed in tensormap proxy. Refer to the <em>CUDA programming guide</em> for creating
the tensor-map objects on the host side.</p>
<p>Each element of the tensor data in the <code class="docutils literal notranslate"><span class="pre">.dst</span></code> state space is reduced inline with the corresponding
element from the tensor data in the <code class="docutils literal notranslate"><span class="pre">.src</span></code> state space. The modifier <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> specifies the
reduction operation used for the inline reduction. The type of each tensor data element in the
source and the destination tensor is specified in <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">Tensor-map</span></a>.</p>
<p>The dimension of the tensor is specified by the <code class="docutils literal notranslate"><span class="pre">.dim</span></code> modifier.</p>
<p>The vector operand <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> specifies the starting coordinates of the tensor data in the
global memory on which the reduce operation is to be performed. The number of tensor coordinates in
the vector argument <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> should be equal to the dimension specified by the modifier
<code class="docutils literal notranslate"><span class="pre">.dim</span></code>. The individual tensor coordinates are of the type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p>The following table describes the valid combinations of <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> and element type:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 32%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.redOp</span></code></p></th>
<th class="head"><p>Element type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, <code class="docutils literal notranslate"><span class="pre">.s64</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></td>
</tr>
</tbody>
</table>
<p>The modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the completion mechanism that is supported on the
instruction variant. Value <code class="docutils literal notranslate"><span class="pre">.bulk_group</span></code> of the modifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies that
<code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code> instruction uses <em>bulk async-group</em> based completion mechanism.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> specifies how the data in the source location is copied into the
destination location. If <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> is not specified, it defaults to <code class="docutils literal notranslate"><span class="pre">.tile</span></code>. In <code class="docutils literal notranslate"><span class="pre">.tile</span></code>
mode, the multi-dimensional layout of the source tensor is preserved at the destination. In
<code class="docutils literal notranslate"><span class="pre">.im2col_no_offs</span></code> mode, some dimensions of the source tensors are unrolled in a single dimensional
column at the destination. Details of the <code class="docutils literal notranslate"><span class="pre">im2col</span></code> mode are described in
<a class="reference internal" href="#tensor-im2col-mode"><span class="std std-ref">im2col mode</span></a>. In <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> mode, the tensor has to be at least
3-dimensional.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program. The
qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported when at least one of the <code class="docutils literal notranslate"><span class="pre">.src</span></code> or <code class="docutils literal notranslate"><span class="pre">.dst</span></code>
statespaces is <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p>Each reduction operation performed by <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code> has individually
<code class="docutils literal notranslate"><span class="pre">.relaxed.gpu</span></code> memory ordering semantics. The load operations in <code class="docutils literal notranslate"><span class="pre">cp.reduce.async.bulk.tensor</span></code>
are treated as weak memory operations and the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics at the <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.reduce.async.bulk.tensor.1d.global.shared::cta.add.tile.bulk_group
                                             [tensorMap0, {tc0}], [sMem0];

cp.reduce.async.bulk.tensor.2d.global.shared::cta.and.bulk_group.L2::cache_hint
                                             [tensorMap1, {tc0, tc1}], [sMem1] , policy;

cp.reduce.async.bulk.tensor.3d.global.shared::cta.xor.im2col.bulk_group
                                             [tensorMap2, {tc0, tc1, tc2}], [sMem2]
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-bulk-prefetch-tensor">
<span id="id294"></span><h6>
<span class="section-number">9.7.9.27.1.4. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch-tensor">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk-prefetch-tensor" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code></p>
<p>Provides a hint to the system to initiate the asynchronous prefetch of tensor data to the cache.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// global -&gt; shared::cluster:
cp.async.bulk.prefetch.tensor.dim.L2.src{.load_mode}{.level::cache_hint} [tensorMap, tensorCoords]
                                                             {, im2colInfo } {, cache-policy}

.src =                { .global }
.dim =                { .1d, .2d, .3d, .4d, .5d }
.load_mode =          { .tile, .tile::gather4, .im2col, .im2col::w, .im2col::w::128 }
.level::cache_hint =  { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code> is a non-blocking instruction which may initiate an asynchronous
prefetch of tensor data from the location in <code class="docutils literal notranslate"><span class="pre">.src</span></code> statespace to the L2 cache.</p>
<p>The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is the generic address of the opaque tensor-map object which resides
in <code class="docutils literal notranslate"><span class="pre">.param</span></code> space or <code class="docutils literal notranslate"><span class="pre">.const</span></code> space or <code class="docutils literal notranslate"><span class="pre">.global</span></code> space. The operand <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> specifies
the properties of the tensor copy operation, as described in <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">Tensor-map</span></a>.
The <code class="docutils literal notranslate"><span class="pre">tensorMap</span></code> is accessed in tensormap proxy. Refer to the <em>CUDA programming guide</em> for creating
the tensor-map objects on the host side.</p>
<p>The dimension of the tensor data is specified by the <code class="docutils literal notranslate"><span class="pre">.dim</span></code> modifier.</p>
<p>The vector operand <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> specifies the starting coordinates in the tensor data in the
global memory from which the copy operation has to be performed. The individual tensor
coordinates in <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code> are of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. The format of vector argument <code class="docutils literal notranslate"><span class="pre">tensorCoords</span></code>
is dependent on <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> specified and is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 42%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.load_mode</p></th>
<th class="head"><p>tensorCoords</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code></p></td>
<td><p>{col_idx, row_idx0, row_idx1, row_idx2, row_idx3}</p></td>
<td><p>Fixed length vector of size 5.
The five elements together specify the start
co-ordinates of the four rows.</p></td>
</tr>
<tr class="row-odd">
<td><p>Rest all</p></td>
<td><p>{d0, .., dn}
for n = .dim</p></td>
<td><p>Vector of n elements where n = .dim.
The elements indicate the offset in each of the
dimension.</p></td>
</tr>
</tbody>
</table>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> specifies how the data in the source location is copied into the
destination location. If <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> is not specified, it defaults to <code class="docutils literal notranslate"><span class="pre">.tile</span></code>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">.tile</span></code> mode, the multi-dimensional layout of the source tensor is preserved at the destination.
In <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> mode, four rows in the 2-dimnesional source tensor are fetched to L2 cache.
Details of <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> modes are described
in <a class="reference internal" href="#tensor-tiled-scatter4-gather4-modes"><span class="std std-ref">.tile::scatter4 and .tile::gather4 modes</span></a>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes, some dimensions of the source tensors are unrolled in a single
dimensional column at the destination. Details of the <code class="docutils literal notranslate"><span class="pre">im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes are described in
<a class="reference internal" href="#tensor-im2col-mode"><span class="std std-ref">im2col mode</span></a> and <a class="reference internal" href="#tensor-im2col-w-w128-modes"><span class="std std-ref">im2col::w and im2col::w::128 modes</span></a>
respectively. In <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::*</span></code> modes, the tensor has to be at least 3-dimensional. The vector
operand <code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> can be specified only when <code class="docutils literal notranslate"><span class="pre">.load_mode</span></code> is <code class="docutils literal notranslate"><span class="pre">.im2col</span></code> or <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> or
<code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code>. The format of the vector argument <code class="docutils literal notranslate"><span class="pre">im2colInfo</span></code> is dependent on the exact im2col mode
and is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 32%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Exact im2col mode</p></th>
<th class="head"><p>im2colInfo argument</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col</span></code></p></td>
<td><p>{ i2cOffW , i2cOffH , i2cOffD }
for <code class="docutils literal notranslate"><span class="pre">.dim</span></code> = <code class="docutils literal notranslate"><span class="pre">.5d</span></code></p></td>
<td><p>A vector of im2col offsets whose vector size is two
less than number of dimensions .dim.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code></p></td>
<td rowspan="2"><p>{ wHalo, wOffset }</p></td>
<td rowspan="2"><p>A vector of 2 arguments containing
<a class="reference internal" href="#tensor-im2col-w-w128-modes-whalo"><span class="std std-ref">wHalo</span></a> and
<a class="reference internal" href="#tensor-im2col-w-w128-modes-woffset"><span class="std std-ref">wOffset</span></a>
arguments.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code></p></td>
</tr>
</tbody>
</table>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code> is treated as a weak memory operation in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p>Support for qualifier <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> introduced in PTX ISA version 8.6.</p>
<p>Support for qualifiers <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code> are supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And are supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b16 ctaMask, im2colwHalo, im2colOff;
.reg .u16 i2cOffW, i2cOffH, i2cOffD;
.reg .b64 l2CachePolicy;

cp.async.bulk.prefetch.tensor.1d.L2.global.tile  [tensorMap0, {tc0}];

@p cp.async.bulk.prefetch.tensor.2d.L2.global    [tensorMap1, {tc0, tc1}];

@p cp.async.bulk.prefetch.tensor.5d.L2.global.im2col
                      [tensorMap2, {tc0, tc1, tc2, tc3, tc4}], {i2cOffW, i2cOffH, i2cOffD};

@p cp.async.bulk.prefetch.tensor.3d.L2.global.im2col.L2::cache_hint
                      [tensorMap3, {tc0, tc1, tc2}], {i2cOffW}, policy;

cp.async.bulk.prefetch.tensor.2d.L2.global.tile::gather4 [tensorMap5, {col_idx, row_idx0, row_idx1, row_idx2, row_idx3}];

cp.async.bulk.prefetch.tensor.4d.L2.global.im2col::w::128
                      [tensorMap4, {t0, t1, t2, t3}], {im2colwHalo, im2colOff};
</pre></div>
</div>
</section>
</section>
<section id="data-movement-and-conversion-instructions-bulk-tensor-copy-completion">
<span id="id295"></span><h5>
<span class="section-number">9.7.9.27.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-bulk-tensor-copy-completion">Data Movement and Conversion Instructions: Bulk and Tensor copy completion instructions</a><a class="headerlink" href="#data-movement-and-conversion-instructions-bulk-tensor-copy-completion" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="data-movement-and-conversion-instructions-cp-async-bulk-commit-group">
<span id="id296"></span><h6>
<span class="section-number">9.7.9.27.2.1. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-commit-group">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk-commit-group" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code></p>
<p>Commits all prior initiated but uncommitted <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> instructions into a
<em>cp.async.bulk-group</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.commit_group;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code> instruction creates a new per-thread <em>bulk async-group</em> and batches
all prior <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk.{.prefetch}{.tensor}</span></code> instructions satisfying the following
conditions into the new <em>bulk async-group</em>:</p>
<ul class="simple">
<li><p>The prior <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk.{.prefetch}{.tensor}</span></code> instructions use <em>bulk_group</em> based
completion mechanism, and</p></li>
<li><p>They are initiated by the executing thread but not committed to any <em>bulk async-group</em>.</p></li>
</ul>
<p>If there are no uncommitted <code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk.{.prefetch}{.tensor}</span></code> instructions then
<code class="docutils literal notranslate"><span class="pre">cp.async.bulk.commit_group</span></code> results in an empty <em>bulk async-group</em>.</p>
<p>An executing thread can wait for the completion of all
<code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk.{.prefetch}{.tensor}</span></code> operations in a <em>bulk async-group</em> using
<code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code>.</p>
<p>There is no memory ordering guarantee provided between any two
<code class="docutils literal notranslate"><span class="pre">cp{.reduce}.async.bulk.{.prefetch}{.tensor}</span></code> operations within the same <em>bulk async-group</em>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.commit_group;
</pre></div>
</div>
</section>
<section id="data-movement-and-conversion-instructions-cp-async-bulk-wait-group">
<span id="id297"></span><h6>
<span class="section-number">9.7.9.27.2.2. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async-bulk-wait-group">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-cp-async-bulk-wait-group" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code></p>
<p>Wait for completion of <em>bulk async-groups</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.wait_group{.read} N;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code> instruction will cause the executing thread to wait until only N or
fewer of the most recent <em>bulk async-groups</em> are pending and all the prior <em>bulk async-groups</em>
committed by the executing threads are complete. For example, when N is 0, the executing thread
waits on all the prior <em>bulk async-groups</em> to complete. Operand N is an integer constant.</p>
<p>By default, <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.wait_group</span></code> instruction will cause the executing thread to wait until
completion of all the bulk async operations in the specified <em>bulk async-group</em>. A bulk async
operation includes the following:</p>
<ul class="simple">
<li><p>Optionally, reading from the tensormap.</p></li>
<li><p>Reading from the source locations.</p></li>
<li><p>Writing to their respective destination locations.</p></li>
<li><p>Writes being made visible to the executing thread.</p></li>
</ul>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.read</span></code> modifier indicates that the waiting has to be done until all the bulk
async operations in the specified <em>bulk async-group</em> have completed:</p>
<ol class="arabic simple">
<li><p>reading from the tensormap</p></li>
<li><p>the reading from their source locations.</p></li>
</ol>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.bulk.wait_group.read   0;
cp.async.bulk.wait_group        2;
</pre></div>
</div>
</section>
</section>
</section>
<section id="data-movement-and-conversion-instructions-tensormap-replace">
<span id="id298"></span><h4>
<span class="section-number">9.7.9.28. </span><a class="reference internal" href="#data-movement-and-conversion-instructions-tensormap-replace">Data Movement and Conversion Instructions: <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></a><a class="headerlink" href="#data-movement-and-conversion-instructions-tensormap-replace" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></p>
<p>Modifies the field of a tensor-map object.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tensormap.replace.mode.field1{.ss}.b1024.type  [addr], new_val;
tensormap.replace.mode.field2{.ss}.b1024.type  [addr], ord, new_val;
tensormap.replace.mode.field3{.ss}.b1024.type  [addr], new_val;

.mode    = { .tile }
.field1  = { .global_address, .rank }
.field2  = { .box_dim, .global_dim, .global_stride, .element_stride  }
.field3  = { .elemtype,  .interleave_layout, .swizzle_mode, .swizzle_atomicity, .fill_mode }
.ss      = { .global, .shared::cta }
.type    = { .b32, .b64 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code> instruction replaces the field, specified by <code class="docutils literal notranslate"><span class="pre">.field</span></code> qualifier,
of the tensor-map object at the location specified by the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> with a
new value. The new value is specified by the argument <code class="docutils literal notranslate"><span class="pre">new_val</span></code>.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.mode</span></code> specifies the mode of the <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">tensor-map</span></a> object
located at the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>.</p>
<p>Instruction type <code class="docutils literal notranslate"><span class="pre">.b1024</span></code> indicates the size of the <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">tensor-map</span></a>
object, which is 1024 bits.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">new_val</span></code> has the type <code class="docutils literal notranslate"><span class="pre">.type</span></code>. When <code class="docutils literal notranslate"><span class="pre">.field</span></code> is specified as <code class="docutils literal notranslate"><span class="pre">.global_address</span></code>
or <code class="docutils literal notranslate"><span class="pre">.global_stride</span></code>, <code class="docutils literal notranslate"><span class="pre">.type</span></code> must be <code class="docutils literal notranslate"><span class="pre">.b64</span></code>. Otherwise, <code class="docutils literal notranslate"><span class="pre">.type</span></code> must be <code class="docutils literal notranslate"><span class="pre">.b32</span></code>.</p>
<p>The immediate integer operand <code class="docutils literal notranslate"><span class="pre">ord</span></code> specifies the ordinal of the field across the rank of the
tensor which needs to be replaced in the <a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">tensor-map</span></a> object.</p>
<p>For field <code class="docutils literal notranslate"><span class="pre">.rank</span></code>, the operand <code class="docutils literal notranslate"><span class="pre">new_val</span></code> must be ones less than the desired tensor rank as
this field uses zero-based numbering.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.field3</span></code> is specified, the operand <code class="docutils literal notranslate"><span class="pre">new_val</span></code> must be an immediate and the
<a class="reference internal" href="#tensormap-new-val-validity"><span class="std std-numref">Table 33</span></a> shows the mapping of the operand <code class="docutils literal notranslate"><span class="pre">new_val</span></code> across various fields.</p>
<table class="table-no-stripes docutils align-default" id="tensormap-new-val-validity">
<caption>
<span class="caption-number">Table 33 </span><span class="caption-text">Tensormap new_val validity</span><a class="headerlink" href="#tensormap-new-val-validity" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 13%">
<col style="width: 20%">
<col style="width: 16%">
<col style="width: 20%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p><strong>new_val</strong></p></th>
<th class="head" colspan="5"><p><strong>.field3</strong></p></th>
</tr>
<tr class="row-even">
<th class="head"><p><strong>.elemtype</strong></p></th>
<th class="head"><p><strong>.interleave_layout</strong></p></th>
<th class="head"><p><strong>.swizzle_mode</strong></p></th>
<th class="head"><p><strong>.swizzle_atomicity</strong></p></th>
<th class="head"><p><strong>.fill_mode</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p>0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>No interleave</p></td>
<td><p>No swizzling</p></td>
<td><p>16B</p></td>
<td><p>Zero fill</p></td>
</tr>
<tr class="row-even">
<td><p>1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u16</span></code></p></td>
<td><p>16B interleave</p></td>
<td><p>32B swizzling</p></td>
<td><p>32B</p></td>
<td><p>OOB-NaN fill</p></td>
</tr>
<tr class="row-odd">
<td><p>2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u32</span></code></p></td>
<td><p>32B interleave</p></td>
<td><p>64B swizzling</p></td>
<td><p>32B + 8B flip</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>x</p></td>
<td><p>128B swizzling</p></td>
<td><p>64B</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>4</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u64</span></code></p></td>
<td><p>x</p></td>
<td><p>96B swizzling</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>5</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32.ftz</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>9</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>10</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>11</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>12</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32.ftz</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>13</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b4x16</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-odd">
<td><p>14</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
<tr class="row-even">
<td><p>15</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>
or
<code class="docutils literal notranslate"><span class="pre">.b6p2x16</span></code></p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
<td><p>x</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The values of <code class="docutils literal notranslate"><span class="pre">.elemtype</span></code> do not correspond to the values of the <code class="docutils literal notranslate"><span class="pre">CUtensorMapDataType</span></code> enum used in the driver API.</p>
</div>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used.
If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.global</span></code>
or <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p><code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code> is treated as a weak memory operation, on the entire 1024-bit opaque
<a class="reference internal" href="#tensor-tensormap"><span class="std std-ref">tensor-map</span></a> object, in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.3.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.swizzle_atomicity</span></code> introduced in PTX ISA version 8.6.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.elemtype</span></code> with values from <code class="docutils literal notranslate"><span class="pre">13</span></code> to <code class="docutils literal notranslate"><span class="pre">15</span></code>, both inclusive, is
supported in PTX ISA version 8.7 onwards.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.swizzle_mode</span></code> with value <code class="docutils literal notranslate"><span class="pre">4</span></code> is supported from PTX ISA version 8.8 onwards.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.swizzle_atomicity</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> (refer to <a class="reference external" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions">section</a>
for restrictions on sm_120a)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.field3</span></code> variant <code class="docutils literal notranslate"><span class="pre">.elemtype</span></code> corresponding to <code class="docutils literal notranslate"><span class="pre">new_val</span></code> values <code class="docutils literal notranslate"><span class="pre">13</span></code>, <code class="docutils literal notranslate"><span class="pre">14</span></code>
and <code class="docutils literal notranslate"><span class="pre">15</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> (refer to <a class="reference external" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions">section</a>
for restrictions on sm_120a)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">.field3</span></code> variant <code class="docutils literal notranslate"><span class="pre">.swizzle_mode</span></code> corresponding to <code class="docutils literal notranslate"><span class="pre">new_val</span></code> value <code class="docutils literal notranslate"><span class="pre">4</span></code> is supported on
following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> (refer to <a class="reference external" href="#data-movement-and-conversion-instructions-tensor-copy-restrictions">section</a>
for restrictions on sm_103a)</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tensormap.replace.tile.global_address.shared::cta.b1024.b64   [sMem], new_val;
</pre></div>
</div>
</section>
</section>
<section id="texture-instructions">
<span id="id299"></span><h3>
<span class="section-number">9.7.10. </span><a class="reference internal" href="#texture-instructions">Texture Instructions</a><a class="headerlink" href="#texture-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>This section describes PTX instructions for accessing textures and samplers. PTX supports the
following operations on texture and sampler descriptors:</p>
<ul class="simple">
<li><p>Static initialization of texture and sampler descriptors.</p></li>
<li><p>Module-scope and per-entry scope definitions of texture and sampler descriptors.</p></li>
<li><p>Ability to query fields within texture and sampler descriptors.</p></li>
</ul>
<section id="texturing-modes">
<span id="id300"></span><h4>
<span class="section-number">9.7.10.1. </span><a class="reference internal" href="#texturing-modes">Texturing Modes</a><a class="headerlink" href="#texturing-modes" title="Permalink to this headline">ïƒ</a>
</h4>
<p>For working with textures and samplers, PTX has two modes of operation. In the <em>unified mode,</em>
texture and sampler information is accessed through a single <code class="docutils literal notranslate"><span class="pre">.texref</span></code> handle. In the <em>independent
mode</em>, texture and sampler information each have their own handle, allowing them to be defined
separately and combined at the site of usage in the program.</p>
<p>The advantage of unified mode is that it allows 256 samplers per kernel (128 for architectures prior
to <code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>), with the restriction that they correspond 1-to-1 with the 256 possible textures per
kernel (128 for architectures prior to <code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>). The advantage of independent mode is that
textures and samplers can be mixed and matched, but the number of samplers is greatly restricted to
32 per kernel (16 for architectures prior to <code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>).</p>
<p><a class="reference internal" href="#texturing-modes-textures-samplers-surfaces"><span class="std std-numref">Table 34</span></a> summarizes the number of textures, samplers and
surfaces available in different texturing modes.</p>
<table class="table-no-stripes docutils align-default" id="texturing-modes-textures-samplers-surfaces">
<caption>
<span class="caption-number">Table 34 </span><span class="caption-text">Texture, sampler and surface limits</span><a class="headerlink" href="#texturing-modes-textures-samplers-surfaces" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 29%">
<col style="width: 16%">
<col style="width: 35%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Texturing mode</p></th>
<th class="head"><p>Resource</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_2x</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">sm_3x+</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="3"><p>Unified mode</p></td>
<td><p>Textures</p></td>
<td><p>128</p></td>
<td><p>256</p></td>
</tr>
<tr class="row-odd">
<td><p>Samplers</p></td>
<td><p>128</p></td>
<td><p>256</p></td>
</tr>
<tr class="row-even">
<td><p>Surfaces</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p>Independent mode</p></td>
<td><p>Textures</p></td>
<td><p>128</p></td>
<td><p>256</p></td>
</tr>
<tr class="row-even">
<td><p>Samplers</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
</tr>
<tr class="row-odd">
<td><p>Surfaces</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
</tr>
</tbody>
</table>
<p>The texturing mode is selected using <code class="docutils literal notranslate"><span class="pre">.target</span></code> options <code class="docutils literal notranslate"><span class="pre">texmode_unified</span></code> and
<code class="docutils literal notranslate"><span class="pre">texmode_independent</span></code>. A PTX module may declare only one texturing mode. If no texturing mode is
declared, the module is assumed to use unified mode.</p>
<p><strong>Example</strong>: calculate an elementâ€™s power contribution as elementâ€™s power/total number of elements.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.target texmode_independent
.global .samplerref tsamp1 = { addr_mode_0 = clamp_to_border,
                               filter_mode = nearest
                             };
...
.entry compute_power
  ( .param .texref tex1 )
{
  txq.width.b32  r6, [tex1]; // get tex1's width
  txq.height.b32 r5, [tex1]; // get tex1's height
  tex.2d.v4.f32.f32  {r1,r2,r3,r4}, [tex1, tsamp1, {f1,f2}];
  mul.u32 r5, r5, r6;
  add.f32 r1, r1, r2;
  add.f32 r3, r3, r4;
  add.f32 r1, r1, r3;
  cvt.f32.u32 r5, r5;
  div.f32 r1, r1, r5;
}
</pre></div>
</div>
</section>
<section id="mipmaps">
<span id="id301"></span><h4>
<span class="section-number">9.7.10.2. </span><a class="reference internal" href="#mipmaps">Mipmaps</a><a class="headerlink" href="#mipmaps" title="Permalink to this headline">ïƒ</a>
</h4>
<p>A <em>mipmap</em> is a sequence of textures, each of which is a progressively lower resolution
representation of the same image. The height and width of each image, or level of detail (LOD), in
the mipmap is a power of two smaller than the previous level. Mipmaps are used in graphics
applications to improve rendering speed and reduce aliasing artifacts. For example, a
high-resolution mipmap image is used for objects that are close to the user; lower-resolution images
are used as the object appears farther away. Mipmap filtering modes are provided when switching
between two levels of detail (LODs) in order to avoid abrupt changes in visual fidelity.</p>
<p><strong>Example:</strong> If the texture has a basic size of 256 by 256 pixels, then the associated mipmap set
may contain a series of eight images, each one-fourth the total area of the previous one: 128x128
pixels, 64x64, 32x32, 16x16, 8x8, 4x4, 2x2, 1x1 (a single pixel). If, for example, a scene is
rendering this texture in a space of 40x40 pixels, then either a scaled up version of the 32x32
(without trilinear interpolation) or an interpolation of the 64x64 and the 32x32 mipmaps (with
trilinear interpolation) would be used.</p>
<p>The total number of LODs in a complete mipmap pyramid is calculated through the following equation:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>numLODs = 1 + floor(log2(max(w, h, d)))
</pre></div>
</div>
<p>The finest LOD is called the base level and is the 0th level. The next (coarser) level is the 1st
level, and so on. The coarsest level is the level of size (1 x 1 x 1). Each successively smaller
mipmap level has half the {width, height, depth} of the previous level, but if this half value is a
fractional value, itâ€™s rounded down to the next largest integer. Essentially, the size of a mipmap
level can be specified as:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>max(1, floor(w_b / 2^i)) x
max(1, floor(h_b / 2^i)) x
max(1, floor(d_b / 2^i))
</pre></div>
</div>
<p>where <em>i</em> is the ith level beyond the 0th level (the base level). And <em>w_b</em>, <em>h_b</em> and <em>d_b</em> are the
width, height and depth of the base level respectively.</p>
<p class="rubric">PTX support for mipmaps</p>
<p>The PTX <code class="docutils literal notranslate"><span class="pre">tex</span></code> instruction supports three modes for specifying the LOD: <em>base</em>, <em>level</em>, and
<em>grad</em>ient. In base mode, the instruction always picks level 0. In level mode, an additional
argument is provided to specify the LOD to fetch from. In gradmode, two floating-point vector
arguments provide <em>partials</em> (e.g., <code class="docutils literal notranslate"><span class="pre">{ds/dx,</span> <span class="pre">dt/dx}</span></code> and <code class="docutils literal notranslate"><span class="pre">{ds/dy,</span> <span class="pre">dt/dy}</span></code> for a 2d texture),
which the <code class="docutils literal notranslate"><span class="pre">tex</span></code> instruction uses to compute the LOD.</p>
<p>These instructions provide access to texture memory.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tex</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tld4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq</span></code></p></li>
</ul>
</section>
<section id="texture-instructions-tex">
<span id="id302"></span><h4>
<span class="section-number">9.7.10.3. </span><a class="reference internal" href="#texture-instructions-tex">Texture Instructions: <code class="docutils literal notranslate"><span class="pre">tex</span></code></a><a class="headerlink" href="#texture-instructions-tex" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tex</span></code></p>
<p>Perform a texture memory lookup.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tex.geom.v4.dtype.ctype  d, [a, c] {, e} {, f};
tex.geom.v4.dtype.ctype  d[|p], [a, b, c] {, e} {, f};  // explicit sampler

tex.geom.v2.f16x2.ctype  d[|p], [a, c] {, e} {, f};
tex.geom.v2.f16x2.ctype  d[|p], [a, b, c] {, e} {, f};  // explicit sampler

// mipmaps
tex.base.geom.v4.dtype.ctype   d[|p], [a, {b,} c] {, e} {, f};
tex.level.geom.v4.dtype.ctype  d[|p], [a, {b,} c], lod {, e} {, f};
tex.grad.geom.v4.dtype.ctype   d[|p], [a, {b,} c], dPdx, dPdy {, e} {, f};

tex.base.geom.v2.f16x2.ctype   d[|p], [a, {b,} c] {, e} {, f};
tex.level.geom.v2.f16x2.ctype  d[|p], [a, {b,} c], lod {, e} {, f};
tex.grad.geom.v2.f16x2.ctype   d[|p], [a, {b,} c], dPdx, dPdy {, e} {, f};

.geom  = { .1d, .2d, .3d, .a1d, .a2d, .cube, .acube, .2dms, .a2dms };
.dtype = { .u32, .s32, .f16,  .f32 };
.ctype = {       .s32, .f32 };          // .cube, .acube require .f32
                                        // .2dms, .a2dms require .s32
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.{1d,2d,3d}</span></code></p>
<p>Texture lookup using a texture coordinate vector. The instruction loads data from the texture named
by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> at coordinates given by operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is a
scalar or singleton tuple for 1d textures; is a two-element vector for 2d textures; and is a
four-element vector for 3d textures, where the fourth element is ignored. An optional texture
sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior is a property of
the named texture. The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture
at specified coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination
predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data
at specified coordinates is dependent on execution environment setup using Driver API calls, prior
to kernel launch. Refer to Driver API documentation for more details including any
system/implementation specific behavior.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of <code class="docutils literal notranslate"><span class="pre">.s32</span></code> values that
specifies coordinate offset. Offset is applied to coordinates before doing texture lookup. Offset
value is in the range of -8 to +7. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a singleton tuple for 1d textures; is a two
element vector 2d textures; and is four-element vector for 3d textures, where the fourth element is
ignored.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for <code class="docutils literal notranslate"><span class="pre">depth</span> <span class="pre">textures</span></code>. Depth textures are special type
of textures which hold data from the depth buffer. Depth buffer contains depth information of each
pixel. Operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> scalar value that specifies depth compare value for depth
textures. Each element fetched from texture is compared against value given in <code class="docutils literal notranslate"><span class="pre">f</span></code> operand. If
comparison passes, result is 1.0; otherwise result is 0.0. These per-element comparison results are
used for the filtering. When using depth compare operand, the elements in texture coordinate vector
<code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</p>
<p>Depth compare operand is not supported for <code class="docutils literal notranslate"><span class="pre">3d</span></code> textures.</p>
<p>The instruction returns a two-element vector for destination type <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>. For all other
destination types, the instruction returns a four-element vector. Coordinates may be given in either
signed 32-bit integer or 32-bit floating point form.</p>
<p>A texture base address is assumed to be aligned to a 16 byte boundary, and the address given by the
coordinate vector must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined; i.e., the access may proceed by silently
masking off low-order address bits to achieve proper rounding, or the instruction may fault.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.{a1d,a2d}</span></code></p>
<p>Texture array selection, followed by texture lookup. The instruction first selects a texture from
the texture array named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> using the index given by the first element of the array
coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code>. The instruction then loads data from the selected texture at coordinates
given by the remaining elements of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is a bit-size
type vector or tuple containing an index into the array of textures followed by coordinates within
the selected texture, as follows:</p>
<ul class="simple">
<li><p>For 1d texture arrays, operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v2.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the texture array, and the second element is interpreted as
a 1d texture coordinate of type <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>.</p></li>
<li><p>For 2d texture arrays, operand <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the texture array, and the next two elements are
interpreted as 2d texture coordinates of type <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>. The fourth element is ignored.</p></li>
</ul>
<p>An optional texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior
is a property of the named texture.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of <code class="docutils literal notranslate"><span class="pre">.s32</span></code> values that
specifies coordinate offset. Offset is applied to coordinates before doing texture lookup. Offset
value is in the range of -8 to +7. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a singleton tuple for 1d texture arrays; and is
a two element vector 2d texture arrays.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for depth textures arrays. Operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>
scalar value that specifies depth compare value for depth textures. When using depth compare
operand, the coordinates in texture coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</p>
<p>The instruction returns a two-element vector for destination type <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>. For all other
destination types, the instruction returns a four-element vector. The texture array index is a
32-bit unsigned integer, and texture coordinate elements are 32-bit signed integer or floating point
values.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.cube</span></code></p>
<p><em>Cubemap</em> texture lookup. The instruction loads data from the cubemap texture named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code>
at coordinates given by operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. Cubemap textures are special
two-dimensional layered textures consisting of six layers that represent the faces of a cube. All
layers in a cubemap are of the same size and are square (i.e., width equals height).</p>
<p>When accessing a cubemap, the texture coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v4.f32</span></code>, and comprises
three floating-point coordinates (<code class="docutils literal notranslate"><span class="pre">s</span></code>, <code class="docutils literal notranslate"><span class="pre">t</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>) and a fourth padding argument which is
ignored. Coordinates (<code class="docutils literal notranslate"><span class="pre">s</span></code>, <code class="docutils literal notranslate"><span class="pre">t</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>) are projected onto one of the six cube faces. The (<code class="docutils literal notranslate"><span class="pre">s</span></code>,
<code class="docutils literal notranslate"><span class="pre">t</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>) coordinates can be thought of as a direction vector emanating from the center of the
cube. Of the three coordinates (<code class="docutils literal notranslate"><span class="pre">s</span></code>, <code class="docutils literal notranslate"><span class="pre">t</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>), the coordinate of the largest magnitude (the
major axis) selects the cube face. Then, the other two coordinates (the minor axes) are divided by
the absolute value of the major axis to produce a new (<code class="docutils literal notranslate"><span class="pre">s</span></code>, <code class="docutils literal notranslate"><span class="pre">t</span></code>) coordinate pair to lookup into
the selected cube face.</p>
<p>An optional texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior
is a property of the named texture.</p>
<p>Offset vector operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is not supported for cubemap textures.</p>
<p>an optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for cubemap depth textures. operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>
scalar value that specifies depth compare value for cubemap depth textures.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.acube</span></code></p>
<p>Cubemap array selection, followed by cubemap lookup. The instruction first selects a cubemap texture
from the cubemap array named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> using the index given by the first element of the
array coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code>. The instruction then loads data from the selected cubemap texture at
coordinates given by the remaining elements of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p><em>Cubemap array</em> textures consist of an array of cubemaps, i.e., the total number of layers is a
multiple of six. When accessing a cubemap array texture, the coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> has type
<code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element is interpreted as an unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the
cubemap array, and the remaining three elements are interpreted as floating-point cubemap
coordinates (<code class="docutils literal notranslate"><span class="pre">s</span></code>, <code class="docutils literal notranslate"><span class="pre">t</span></code>, <code class="docutils literal notranslate"><span class="pre">r</span></code>), used to lookup in the selected cubemap as described above.</p>
<p>An optional texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior
is a property of the named texture.</p>
<p>Offset vector operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is not supported for cubemap texture arrays.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for cubemap depth texture arrays. Operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is
<code class="docutils literal notranslate"><span class="pre">.f32</span></code> scalar value that specifies depth compare value for cubemap depth textures.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.2dms</span></code></p>
<p>Multi-sample texture lookup using a texture coordinate vector. Multi-sample textures consist of
multiple samples per data element. The instruction loads data from the texture named by operand
<code class="docutils literal notranslate"><span class="pre">a</span></code> from sample number given by first element of the operand <code class="docutils literal notranslate"><span class="pre">c</span></code>, at coordinates given by
remaining elements of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. When accessing a multi-sample texture,
texture coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element in operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is
interpreted as unsigned integer sample number (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>), and the next two elements are interpreted
as signed integer (<code class="docutils literal notranslate"><span class="pre">.s32</span></code>) 2d texture coordinates. The fourth element is ignored. An optional
texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior is a
property of the named texture.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of type <code class="docutils literal notranslate"><span class="pre">.v2.s32</span></code> that
specifies coordinate offset. Offset is applied to coordinates before doing texture lookup. Offset
value is in the range of -8 to +7.</p>
<p>Depth compare operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is not supported for multi-sample textures.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.a2dms</span></code></p>
<p>Multi-sample texture array selection, followed by multi-sample texture lookup. The instruction first
selects a multi-sample texture from the multi-sample texture array named by operand a using the
index given by the first element of the array coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code>. The instruction then loads
data from the selected multi-sample texture from sample number given by second element of the
operand <code class="docutils literal notranslate"><span class="pre">c</span></code>, at coordinates given by remaining elements of operand <code class="docutils literal notranslate"><span class="pre">c</span></code> into destination
<code class="docutils literal notranslate"><span class="pre">d</span></code>. When accessing a multi-sample texture array, texture coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> has type
<code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element in operand c is interpreted as unsigned integer sampler number, the
second element is interpreted as unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the multi-sample texture
array and the next two elements are interpreted as signed integer (<code class="docutils literal notranslate"><span class="pre">.s32</span></code>) 2d texture
coordinates. An optional texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the
sampler behavior is a property of the named texture.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of type <code class="docutils literal notranslate"><span class="pre">.v2.s32</span></code> values
that specifies coordinate offset. Offset is applied to coordinates before doing texture
lookup. Offset value is in the range of -8 to +7.</p>
<p>Depth compare operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is not supported for multi-sample texture arrays.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p class="rubric">Mipmaps</p>
<dl class="simple">
<dt>
<code class="docutils literal notranslate"><span class="pre">.base</span></code> (lod zero)</dt>
<dd>
<p>Pick level 0 (base level). This is the default if no mipmap mode is specified. No additional arguments.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.level</span></code> (lod explicit)</dt>
<dd>
<p>Requires an additional 32-bit scalar argument, <code class="docutils literal notranslate"><span class="pre">lod</span></code>, which contains the LOD to fetch from. The
type of <code class="docutils literal notranslate"><span class="pre">lod</span></code> follows <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> (either <code class="docutils literal notranslate"><span class="pre">.s32</span></code> or <code class="docutils literal notranslate"><span class="pre">.f32</span></code>). Geometries <code class="docutils literal notranslate"><span class="pre">.2dms</span></code> and
<code class="docutils literal notranslate"><span class="pre">.a2dms</span></code> are not supported in this mode.</p>
</dd>
<dt>
<code class="docutils literal notranslate"><span class="pre">.grad</span></code> (lod gradient)</dt>
<dd>
<p>Requires two <code class="docutils literal notranslate"><span class="pre">.f32</span></code> vectors, <code class="docutils literal notranslate"><span class="pre">dPdx</span></code> and <code class="docutils literal notranslate"><span class="pre">dPdy</span></code>, that specify the partials. The vectors are
singletons for 1d and a1d textures; are two-element vectors for 2d and a2d textures; and are
four-element vectors for 3d, cube and acube textures, where the fourth element is ignored for 3d
and cube geometries. Geometries <code class="docutils literal notranslate"><span class="pre">.2dms</span></code> and <code class="docutils literal notranslate"><span class="pre">.a2dms</span></code> are not supported in this mode.</p>
</dd>
</dl>
<p>For mipmap texture lookup, an optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> that specifies coordinate offset. Offset is applied to coordinates before doing texture
lookup. Offset value is in the range of -8 to +7. Offset vector operand is not supported for cube
and cubemap geometries.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for mipmap textures. Operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> scalar
value that specifies depth compare value for depth textures. When using depth compare operand, the
coordinates in texture coordinate vector <code class="docutils literal notranslate"><span class="pre">c</span></code> have <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p>Depth compare operand is not supported for <code class="docutils literal notranslate"><span class="pre">3d</span></code> textures.</p>
<p class="rubric">Indirect texture access</p>
<p>Beginning with PTX ISA version 3.1, indirect texture access is supported in unified mode for target
architecture <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding
the address of a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variable.</p>
<p class="rubric">Notes</p>
<p>For compatibility with prior versions of PTX, the square brackets are not required and <code class="docutils literal notranslate"><span class="pre">.v4</span></code>
coordinate vectors are allowed for any geometry, with the extra elements being ignored.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Unified mode texturing introduced in PTX ISA version 1.0. Extension using opaque <code class="docutils literal notranslate"><span class="pre">.texref</span></code> and
<code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> types and independent mode texturing introduced in PTX ISA version 1.5.</p>
<p>Texture arrays <code class="docutils literal notranslate"><span class="pre">tex.{a1d,a2d}</span></code> introduced in PTX ISA version 2.3.</p>
<p>Cubemaps and cubemap arrays introduced in PTX ISA version 3.0.</p>
<p>Support for mipmaps introduced in PTX ISA version 3.1.</p>
<p>Indirect texture access introduced in PTX ISA version 3.1.</p>
<p>Multi-sample textures and multi-sample texture arrays introduced in PTX ISA version 3.2.</p>
<p>Support for textures returning <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> data introduced in PTX ISA version 4.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">tex.grad.{cube,</span> <span class="pre">acube}</span></code> introduced in PTX ISA version 4.3.</p>
<p>Offset vector operand introduced in PTX ISA version 4.3.</p>
<p>Depth compare operand introduced in PTX ISA version 4.3.</p>
<p>Support for optional destination predicate introduced in PTX ISA version 7.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p>The cubemap array geometry (<code class="docutils literal notranslate"><span class="pre">.acube</span></code>) requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Mipmaps require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Indirect texture access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Multi-sample textures and multi-sample texture arrays require <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Texture fetch returning <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> data require <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">tex.grad.{cube,</span> <span class="pre">acube}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Offset vector operand requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Depth compare operand requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Support for optional destination predicate requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> // Example of unified mode texturing
 // - f4 is required to pad four-element tuple and is ignored
 tex.3d.v4.s32.s32  {r1,r2,r3,r4}, [tex_a,{f1,f2,f3,f4}];

 // Example of independent mode texturing
 tex.1d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a,smpl_x,{f1}];

 // Example of 1D texture array, independent texturing mode
 tex.a1d.v4.s32.s32 {r1,r2,r3,r4}, [tex_a,smpl_x,{idx,s1}];

 // Example of 2D texture array, unified texturing mode
 // - f3 is required to pad four-element tuple and is ignored
 tex.a2d.v4.s32.f32 {r1,r2,r3,r4}, [tex_a,{idx,f1,f2,f3}];

 // Example of cubemap array, unified textureing mode
 tex.acube.v4.f32.f32 {r0,r1,r2,r3}, [tex_cuarray,{idx,f1,f2,f3}];

 // Example of multi-sample texture, unified texturing mode
 tex.2dms.v4.s32.s32 {r0,r1,r2,r3}, [tex_ms,{sample,r6,r7,r8}];

 // Example of multi-sample texture, independent texturing mode
 tex.2dms.v4.s32.s32 {r0,r1,r2,r3}, [tex_ms, smpl_x,{sample,r6,r7,r8}];

 // Example of multi-sample texture array, unified texturing mode
 tex.a2dms.v4.s32.s32 {r0,r1,r2,r3}, [tex_ams,{idx,sample,r6,r7}];

 // Example of texture returning .f16 data
 tex.1d.v4.f16.f32  {h1,h2,h3,h4}, [tex_a,smpl_x,{f1}];

 // Example of texture returning .f16x2 data
 tex.1d.v2.f16x2.f32  {h1,h2}, [tex_a,smpl_x,{f1}];

 // Example of 3d texture array access with tex.grad,unified texturing mode
 tex.grad.3d.v4.f32.f32 {%f4,%f5,%f6,%f7},[tex_3d,{%f0,%f0,%f0,%f0}],
                 {fl0,fl1,fl2,fl3},{fl0,fl1,fl2,fl3};

// Example of cube texture array access with tex.grad,unified texturing mode
 tex.grad.cube.v4.f32.f32{%f4,%f5,%f6,%f7},[tex_cube,{%f0,%f0,%f0,%f0}],
                 {fl0,fl1,fl2,fl3},{fl0,fl1,fl2,fl3};

 // Example of 1d texture lookup with offset, unified texturing mode
 tex.1d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a, {f1}], {r5};

 // Example of 2d texture array lookup with offset, unified texturing mode
 tex.a2d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a,{idx,f1,f2}], {f5,f6};

 // Example of 2d mipmap texture lookup with offset, unified texturing mode
 tex.level.2d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a,{f1,f2}],
                          flvl, {r7, r8};

 // Example of 2d depth texture lookup with compare, unified texturing mode
 tex.1d.v4.f32.f32  {f1,f2,f3,f4}, [tex_a, {f1}], f0;

 // Example of depth 2d texture array lookup with offset, compare
 tex.a2d.v4.s32.f32  {f0,f1,f2,f3}, [tex_a,{idx,f4,f5}], {r5,r6}, f6;

 // Example of destination predicate use
 tex.3d.v4.s32.s32 {r1,r2,r3,r4}|p, [tex_a,{f1,f2,f3,f4}];
</pre></div>
</div>
</section>
<section id="texture-instructions-tld4">
<span id="id303"></span><h4>
<span class="section-number">9.7.10.4. </span><a class="reference internal" href="#texture-instructions-tld4">Texture Instructions: <code class="docutils literal notranslate"><span class="pre">tld4</span></code></a><a class="headerlink" href="#texture-instructions-tld4" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tld4</span></code></p>
<p>Perform a texture fetch of the 4-texel bilerp footprint.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tld4.comp.2d.v4.dtype.f32    d[|p], [a, c] {, e} {, f};
tld4.comp.geom.v4.dtype.f32  d[|p], [a, b, c] {, e} {, f};  // explicit sampler

.comp  = { .r, .g, .b, .a };
.geom  = { .2d, .a2d, .cube, .acube };
.dtype = { .u32, .s32, .f32 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Texture fetch of the 4-texel bilerp footprint using a texture coordinate vector. The instruction
loads the bilerp footprint from the texture named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> at coordinates given by operand
<code class="docutils literal notranslate"><span class="pre">c</span></code> into vector destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. The texture component fetched for each texel sample is
specified by <code class="docutils literal notranslate"><span class="pre">.comp</span></code>. The four texel samples are placed into destination vector <code class="docutils literal notranslate"><span class="pre">d</span></code> in
counter-clockwise order starting at lower left.</p>
<p>An optional texture sampler <code class="docutils literal notranslate"><span class="pre">b</span></code> may be specified. If no sampler is specified, the sampler behavior
is a property of the named texture.</p>
<p>The optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> if data from texture at specified
coordinates is resident in memory, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise. When optional destination predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is
set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, data loaded will be all zeros. Memory residency of Texture Data at specified
coordinates is dependent on execution environment setup using Driver API calls, prior to kernel
launch. Refer to Driver API documentation for more details including any system/implementation
specific behavior.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">f</span></code> may be specified for <em>depth textures</em>. Depth textures are special type of
textures which hold data from the depth buffer. Depth buffer contains depth information of each
pixel. Operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> scalar value that specifies depth compare value for depth
textures. Each element fetched from texture is compared against value given in <code class="docutils literal notranslate"><span class="pre">f</span></code> operand. If
comparison passes, result is 1.0; otherwise result is 0.0. These per-element comparison results are
used for the filtering.</p>
<p>A texture base address is assumed to be aligned to a 16 byte boundary, and the address given by the
coordinate vector must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined; i.e., the access may proceed by silently
masking off low-order address bits to achieve proper rounding, or the instruction may fault.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.2d</span></code></p>
<p>For 2D textures, operand <code class="docutils literal notranslate"><span class="pre">c</span></code> specifies coordinates as a two-element, 32-bit floating-point vector.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of type <code class="docutils literal notranslate"><span class="pre">.v2.s32</span></code> that
specifies coordinate offset. Offset is applied to coordinates before doing texture fetch. Offset
value is in the range of -8 to +7.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.a2d</span></code></p>
<p>Texture array selection, followed by <code class="docutils literal notranslate"><span class="pre">tld4</span></code> texture fetch of 2d texture. For 2d texture arrays
operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is a four element, 32-bit vector. The first element in operand c is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the texture array, and the next two elements are interpreted
as 32-bit floating point coordinates of 2d texture. The fourth element is ignored.</p>
<p>An optional operand <code class="docutils literal notranslate"><span class="pre">e</span></code> may be specified. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a vector of type <code class="docutils literal notranslate"><span class="pre">.v2.s32</span></code> that
specifies coordinate offset. Offset is applied to coordinates before doing texture fetch. Offset
value is in the range of -8 to +7.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.cube</span></code></p>
<p>For cubemap textures, operand <code class="docutils literal notranslate"><span class="pre">c</span></code> specifies four-element vector which comprises three
floating-point coordinates (s, t, r) and a fourth padding argument which is ignored.</p>
<p>Cubemap textures are special two-dimensional layered textures consisting of six layers that
represent the faces of a cube. All layers in a cubemap are of the same size and are square (i.e.,
width equals height).</p>
<p>Coordinates (s, t, r) are projected onto one of the six cube faces. The (s, t, r) coordinates can be
thought of as a direction vector emanating from the center of the cube. Of the three coordinates (s,
t, r), the coordinate of the largest magnitude (the major axis) selects the cube face. Then, the
other two coordinates (the minor axes) are divided by the absolute value of the major axis to
produce a new (s, t) coordinate pair to lookup into the selected cube face.</p>
<p>Offset vector operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is not supported for cubemap textures.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.acube</span></code></p>
<p>Cubemap array selection, followed by <code class="docutils literal notranslate"><span class="pre">tld4</span></code> texture fetch of cubemap texture. The first element in
operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is interpreted as an unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the cubemap texture array,
and the remaining three elements are interpreted as floating-point cubemap coordinates (s, t, r),
used to lookup in the selected cubemap.</p>
<p>Offset vector operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is not supported for cubemap texture arrays.</p>
<p class="rubric">Indirect texture access</p>
<p>Beginning with PTX ISA version 3.1, indirect texture access is supported in unified mode for target
architecture <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding
the address of a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.2.</p>
<p>Indirect texture access introduced in PTX ISA version 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.{a2d,cube,acube}</span></code> introduced in PTX ISA version 4.3.</p>
<p>Offset vector operand introduced in PTX ISA version 4.3.</p>
<p>Depth compare operand introduced in PTX ISA version 4.3.</p>
<p>Support for optional destination predicate introduced in PTX ISA version 7.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Indirect texture access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">tld4.{a2d,cube,acube}</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Offset vector operand requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Depth compare operand requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Support for optional destination predicate requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>//Example of unified mode texturing
tld4.r.2d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a,{f1,f2}];

// Example of independent mode texturing
tld4.r.2d.v4.u32.f32  {u1,u2,u3,u4}, [tex_a,smpl_x,{f1,f2}];

// Example of unified mode texturing using offset
tld4.r.2d.v4.s32.f32  {r1,r2,r3,r4}, [tex_a,{f1,f2}], {r5, r6};

// Example of unified mode texturing using compare
tld4.r.2d.v4.f32.f32  {f1,f2,f3,f4}, [tex_a,{f5,f6}], f7;

// Example of optional destination predicate
tld4.r.2d.v4.f32.f32 {f1,f2,f3,f4}|p, [tex_a,{f5,f6}], f7;
</pre></div>
</div>
</section>
<section id="texture-instructions-txq">
<span id="id304"></span><h4>
<span class="section-number">9.7.10.5. </span><a class="reference internal" href="#texture-instructions-txq">Texture Instructions: <code class="docutils literal notranslate"><span class="pre">txq</span></code></a><a class="headerlink" href="#texture-instructions-txq" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">txq</span></code></p>
<p>Query texture and sampler attributes.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>txq.tquery.b32         d, [a];       // texture attributes
txq.level.tlquery.b32  d, [a], lod;  // texture attributes
txq.squery.b32         d, [a];       // sampler attributes

.tquery  = { .width, .height, .depth,
             .channel_data_type, .channel_order,
             .normalized_coords, .array_size,
             .num_mipmap_levels, .num_samples};

.tlquery = { .width, .height, .depth };

.squery  = { .force_unnormalized_coords, .filter_mode,
             .addr_mode_0, addr_mode_1, addr_mode_2 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Query an attribute of a texture or sampler. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is either a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> or <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> variable, or a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 31%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Query</p></th>
<th class="head"><p>Returns</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<p><code class="docutils literal notranslate"><span class="pre">.width</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.height</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.depth</span></code></p>
</td>
<td><p>value in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.channel_data_type</span></code></p></td>
<td><p>Unsigned integer corresponding to source languageâ€™s channel data type
enumeration. If the source language combines channel data type and channel
order into a single enumeration type, that value is returned for both
<code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and channel_order queries.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.channel_order</span></code></p></td>
<td><p>Unsigned integer corresponding to source languageâ€™s channel order
enumeration. If the source language combines channel data type and channel
order into a single enumeration type, that value is returned for both
<code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">channel_order</span></code> queries.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.normalized_coords</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code> (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or <code class="docutils literal notranslate"><span class="pre">0</span></code> (<code class="docutils literal notranslate"><span class="pre">False</span></code>).</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.force_unnormalized_coords</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code> (<code class="docutils literal notranslate"><span class="pre">True)</span></code> or <code class="docutils literal notranslate"><span class="pre">0</span></code> (<code class="docutils literal notranslate"><span class="pre">False).</span></code> Defined only for <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code>
variables in independent texture mode. Overrides the <code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code>
field of a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variable used with a <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> in a <code class="docutils literal notranslate"><span class="pre">tex</span></code>
instruction.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.filter_mode</span></code></p></td>
<td><p>Integer from <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">{</span> <span class="pre">nearest,</span> <span class="pre">linear</span> <span class="pre">}</span></code></p></td>
</tr>
<tr class="row-even">
<td>
<p><code class="docutils literal notranslate"><span class="pre">.addr_mode_0</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.addr_mode_1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.addr_mode_2</span></code></p>
</td>
<td><p>Integer from
<code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">{</span> <span class="pre">wrap,</span> <span class="pre">mirror,</span> <span class="pre">clamp_ogl,</span> <span class="pre">clamp_to_edge,</span> <span class="pre">clamp_to_border</span> <span class="pre">}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.array_size</span></code></p></td>
<td><p>For a texture array, number of textures in array, 0 otherwise.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.num_mipmap_levels</span></code></p></td>
<td><p>For a mipmapped texture, number of levels of details (LOD), 0 otherwise.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.num_samples</span></code></p></td>
<td><p>For a multi-sample texture, number of samples, 0 otherwise.</p></td>
</tr>
</tbody>
</table>
<p>Texture attributes are queried by supplying a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> argument to <code class="docutils literal notranslate"><span class="pre">txq</span></code>. In unified mode,
sampler attributes are also accessed via a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> argument, and in independent mode sampler
attributes are accessed via a separate <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> argument.</p>
<p><code class="docutils literal notranslate"><span class="pre">txq.level</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">txq.level</span></code> requires an additional 32bit integer argument, <code class="docutils literal notranslate"><span class="pre">lod</span></code>, which specifies LOD and
queries requested attribute for the specified LOD.</p>
<p class="rubric">Indirect texture access</p>
<p>Beginning with PTX ISA version 3.1, indirect texture access is supported in unified mode for target
architecture <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding
the address of a <code class="docutils literal notranslate"><span class="pre">.texref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.5.</p>
<p>Channel data type and channel order queries were added in PTX ISA version 2.1.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.force_unnormalized_coords</span></code> query was added in PTX ISA version 2.2.</p>
<p>Indirect texture access introduced in PTX ISA version 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">.array_size</span></code>, <code class="docutils literal notranslate"><span class="pre">.num_mipmap_levels</span></code>, <code class="docutils literal notranslate"><span class="pre">.num_samples</span></code> samples queries were added in PTX ISA
version 4.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">txq.level</span></code> introduced in PTX ISA version 4.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p>Indirect texture access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Querying the number of mipmap levels requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Querying the number of samples requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">txq.level</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>txq.width.b32       %r1, [tex_A];
txq.filter_mode.b32 %r1, [tex_A];   // unified mode
txq.addr_mode_0.b32 %r1, [smpl_B];  // independent mode
txq.level.width.b32 %r1, [tex_A], %r_lod;
</pre></div>
</div>
</section>
<section id="texture-instructions-istypep">
<span id="id305"></span><h4>
<span class="section-number">9.7.10.6. </span><a class="reference internal" href="#texture-instructions-istypep">Texture Instructions: <code class="docutils literal notranslate"><span class="pre">istypep</span></code></a><a class="headerlink" href="#texture-instructions-istypep" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">istypep</span></code></p>
<p>Query whether a register points to an opaque variable of a specified type.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>istypep.type   p, a;  // result is .pred

.type = { .texref, .samplerref, .surfref };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Write predicate register <code class="docutils literal notranslate"><span class="pre">p</span></code> with 1 if register <code class="docutils literal notranslate"><span class="pre">a</span></code> points to an opaque variable of the
specified type, and with 0 otherwise. Destination <code class="docutils literal notranslate"><span class="pre">p</span></code> has type <code class="docutils literal notranslate"><span class="pre">.pred</span></code>; the source address
operand must be of type <code class="docutils literal notranslate"><span class="pre">.u64</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>istypep requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>istypep.texref istex, tptr;
istypep.samplerref issampler, sptr;
istypep.surfref issurface, surfptr;
</pre></div>
</div>
</section>
</section>
<section id="surface-instructions">
<span id="id306"></span><h3>
<span class="section-number">9.7.11. </span><a class="reference internal" href="#surface-instructions">Surface Instructions</a><a class="headerlink" href="#surface-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>This section describes PTX instructions for accessing surfaces. PTX supports the following
operations on surface descriptors:</p>
<ul class="simple">
<li><p>Static initialization of surface descriptors.</p></li>
<li><p>Module-scope and per-entry scope definitions of surface descriptors.</p></li>
<li><p>Ability to query fields within surface descriptors.</p></li>
</ul>
<p>These instructions provide access to surface memory.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">suld</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sust</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sured</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">suq</span></code></p></li>
</ul>
<section id="surface-instructions-suld">
<span id="id307"></span><h4>
<span class="section-number">9.7.11.1. </span><a class="reference internal" href="#surface-instructions-suld">Surface Instructions: <code class="docutils literal notranslate"><span class="pre">suld</span></code></a><a class="headerlink" href="#surface-instructions-suld" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">suld</span></code></p>
<p>Load from surface memory.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>suld.b.geom{.cop}.vec.dtype.clamp  d, [a, b];  // unformatted

.geom  = { .1d, .2d, .3d, .a1d, .a2d };
.cop   = { .ca, .cg, .cs, .cv };               // cache operation
.vec   = { none, .v2, .v4 };
.dtype = { .b8 , .b16, .b32, .b64 };
.clamp = { .trap, .clamp, .zero };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b.{1d,2d,3d}</span></code></p>
<p>Load from surface memory using a surface coordinate vector. The instruction loads data from the
surface named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> at coordinates given by operand <code class="docutils literal notranslate"><span class="pre">b</span></code> into destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand
<code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is a scalar or singleton tuple
for 1d surfaces; is a two-element vector for 2d surfaces; and is a four-element vector for 3d
surfaces, where the fourth element is ignored. Coordinate elements are of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b</span></code> performs an unformatted load of binary data. The lowest dimension coordinate represents a
byte offset into the surface and is not scaled, and the size of the data transfer matches the size
of destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b.{a1d,a2d}</span></code></p>
<p>Surface layer selection, followed by a load from the selected surface. The instruction first selects
a surface layer from the surface array named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> using the index given by the first
element of the array coordinate vector <code class="docutils literal notranslate"><span class="pre">b</span></code>. The instruction then loads data from the selected
surface at coordinates given by the remaining elements of operand <code class="docutils literal notranslate"><span class="pre">b</span></code> into destination
<code class="docutils literal notranslate"><span class="pre">d</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is a bit-size
type vector or tuple containing an index into the array of surfaces followed by coordinates within
the selected surface, as follows:</p>
<p>For 1d surface arrays, operand <code class="docutils literal notranslate"><span class="pre">b</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v2.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the surface array, and the second element is interpreted as a
1d surface coordinate of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p>For 2d surface arrays, operand <code class="docutils literal notranslate"><span class="pre">b</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the surface array, and the next two elements are interpreted
as 2d surface coordinates of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. The fourth element is ignored.</p>
<p>A surface base address is assumed to be aligned to a 16 byte boundary, and the address given by the
coordinate vector must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined; i.e., the access may proceed by silently
masking off low-order address bits to achieve proper rounding, or the instruction may fault.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> field specifies how to handle out-of-bounds addresses:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.trap</span></code></dt>
<dd>
<p>causes an execution trap on out-of-bounds addresses</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.clamp</span></code></dt>
<dd>
<p>loads data at the nearest surface location (sized appropriately)</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.zero</span></code></dt>
<dd>
<p>loads zero for out-of-bounds addresses</p>
</dd>
</dl>
<p class="rubric">Indirect surface access</p>
<p>Beginning with PTX ISA version 3.1, indirect surface access is supported for target architecture
<code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding the address of
a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b.trap</span></code> introduced in PTX ISA version 1.5.</p>
<p>Additional clamp modifiers and cache operations introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b.3d</span></code> and <code class="docutils literal notranslate"><span class="pre">suld.b.{a1d,a2d}</span></code> introduced in PTX ISA version 3.0.</p>
<p>Indirect surface access introduced in PTX ISA version 3.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.b</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets support only the <code class="docutils literal notranslate"><span class="pre">.trap</span></code> clamping modifier.</p>
<p><code class="docutils literal notranslate"><span class="pre">suld.3d</span></code> and <code class="docutils literal notranslate"><span class="pre">suld.{a1d,a2d}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Indirect surface access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Cache operations require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>suld.b.1d.v4.b32.trap  {s1,s2,s3,s4}, [surf_B, {x}];
suld.b.3d.v2.b64.trap  {r1,r2}, [surf_A, {x,y,z,w}];
suld.b.a1d.v2.b32      {r0,r1}, [surf_C, {idx,x}];
suld.b.a2d.b32         r0, [surf_D, {idx,x,y,z}];  // z ignored
</pre></div>
</div>
</section>
<section id="surface-instructions-sust">
<span id="id308"></span><h4>
<span class="section-number">9.7.11.2. </span><a class="reference internal" href="#surface-instructions-sust">Surface Instructions: <code class="docutils literal notranslate"><span class="pre">sust</span></code></a><a class="headerlink" href="#surface-instructions-sust" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sust</span></code></p>
<p>Store to surface memory.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sust.b.{1d,2d,3d}{.cop}.vec.ctype.clamp  [a, b], c;  // unformatted
sust.p.{1d,2d,3d}.vec.b32.clamp          [a, b], c;  // formatted

sust.b.{a1d,a2d}{.cop}.vec.ctype.clamp   [a, b], c;  // unformatted

.cop   = { .wb, .cg, .cs, .wt };                     // cache operation
.vec   = { none, .v2, .v4 };
.ctype = { .b8 , .b16, .b32, .b64 };
.clamp = { .trap, .clamp, .zero };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.{1d,2d,3d}</span></code></p>
<p>Store to surface memory using a surface coordinate vector. The instruction stores data from operand
<code class="docutils literal notranslate"><span class="pre">c</span></code> to the surface named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> at coordinates given by operand <code class="docutils literal notranslate"><span class="pre">b</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is
a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is a scalar or singleton tuple for 1d
surfaces; is a two-element vector for 2d surfaces; and is a four-element vector for 3d surfaces,
where the fourth element is ignored. Coordinate elements are of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.b</span></code> performs an unformatted store of binary data. The lowest dimension coordinate represents
a byte offset into the surface and is not scaled. The size of the data transfer matches the size of
source operand <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.p</span></code> performs a formatted store of a vector of 32-bit data values to a surface sample. The
source vector elements are interpreted left-to-right as <code class="docutils literal notranslate"><span class="pre">R</span></code>, <code class="docutils literal notranslate"><span class="pre">G</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code>, and <code class="docutils literal notranslate"><span class="pre">A</span></code> surface
components. These elements are written to the corresponding surface sample components. Source
elements that do not occur in the surface sample are ignored. Surface sample components that do not
occur in the source vector will be written with an unpredictable value. The lowest dimension
coordinate represents a sample offset rather than a byte offset.</p>
<p>The source data interpretation is based on the surface sample format as follows: If the surface
format contains <code class="docutils literal notranslate"><span class="pre">UNORM</span></code>, <code class="docutils literal notranslate"><span class="pre">SNORM</span></code>, or <code class="docutils literal notranslate"><span class="pre">FLOAT</span></code> data, then <code class="docutils literal notranslate"><span class="pre">.f32</span></code> is assumed; if the surface
format contains <code class="docutils literal notranslate"><span class="pre">UINT</span></code> data, then <code class="docutils literal notranslate"><span class="pre">.u32</span></code> is assumed; if the surface format contains <code class="docutils literal notranslate"><span class="pre">SINT</span></code>
data, then <code class="docutils literal notranslate"><span class="pre">.s32</span></code> is assumed. The source data is then converted from this type to the surface
sample format.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.b.{a1d,a2d}</span></code></p>
<p>Surface layer selection, followed by an unformatted store to the selected surface. The instruction
first selects a surface layer from the surface array named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> using the index given by
the first element of the array coordinate vector <code class="docutils literal notranslate"><span class="pre">b</span></code>. The instruction then stores the data in
operand <code class="docutils literal notranslate"><span class="pre">c</span></code> to the selected surface at coordinates given by the remaining elements of operand
<code class="docutils literal notranslate"><span class="pre">b</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a .surfref variable or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is a bit-size type
vector or tuple containing an index into the array of surfaces followed by coordinates within the
selected surface, as follows:</p>
<ul class="simple">
<li><p>For 1d surface arrays, operand <code class="docutils literal notranslate"><span class="pre">b</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v2.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the surface array, and the second element is interpreted as
a 1d surface coordinate of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p></li>
<li><p>For 2d surface arrays, operand <code class="docutils literal notranslate"><span class="pre">b</span></code> has type <code class="docutils literal notranslate"><span class="pre">.v4.b32</span></code>. The first element is interpreted as an
unsigned integer index (<code class="docutils literal notranslate"><span class="pre">.u32</span></code>) into the surface array, and the next two elements are
interpreted as 2d surface coordinates of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. The fourth element is ignored.</p></li>
</ul>
<p>A surface base address is assumed to be aligned to a 16 byte boundary, and the address given by the
coordinate vector must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined; i.e., the access may proceed by silently
masking off low-order address bits to achieve proper rounding, or the instruction may fault.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> field specifies how to handle out-of-bounds addresses:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.trap</span></code></dt>
<dd>
<p>causes an execution trap on out-of-bounds addresses</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.clamp</span></code></dt>
<dd>
<p>stores data at the nearest surface location (sized appropriately)</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.zero</span></code></dt>
<dd>
<p>drops stores to out-of-bounds addresses</p>
</dd>
</dl>
<p class="rubric">Indirect surface access</p>
<p>Beginning with PTX ISA version 3.1, indirect surface access is supported for target architecture
<code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding the address of
a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.b.trap</span></code> introduced in PTX ISA version 1.5. <code class="docutils literal notranslate"><span class="pre">sust.p</span></code>, additional clamp modifiers, and
cache operations introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.b.3d</span></code> and <code class="docutils literal notranslate"><span class="pre">sust.b.{a1d,a2d}</span></code> introduced in PTX ISA version 3.0.</p>
<p>Indirect surface access introduced in PTX ISA version 3.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.b</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets support only the <code class="docutils literal notranslate"><span class="pre">.trap</span></code> clamping modifier.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.3d</span></code> and <code class="docutils literal notranslate"><span class="pre">sust.{a1d,a2d}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">sust.p</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Indirect surface access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Cache operations require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sust.p.1d.v4.b32.trap  [surf_B, {x}], {f1,f2,f3,f4};
sust.b.3d.v2.b64.trap  [surf_A, {x,y,z,w}], {r1,r2};
sust.b.a1d.v2.b64      [surf_C, {idx,x}], {r1,r2};
sust.b.a2d.b32         [surf_D, {idx,x,y,z}], r0;  // z ignored
</pre></div>
</div>
</section>
<section id="surface-instructions-sured">
<span id="id309"></span><h4>
<span class="section-number">9.7.11.3. </span><a class="reference internal" href="#surface-instructions-sured">Surface Instructions: <code class="docutils literal notranslate"><span class="pre">sured</span></code></a><a class="headerlink" href="#surface-instructions-sured" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">sured</span></code></p>
<p>Reduce surface memory.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sured.b.op.geom.ctype.clamp  [a,b],c; // byte addressing
sured.p.op.geom.ctype.clamp  [a,b],c; // sample addressing

.op    = { .add, .min, .max, .and, .or };
.geom  = { .1d, .2d, .3d };
.ctype = { .u32, .u64, .s32, .b32, .s64 };  // for sured.b
.ctype = { .b32, .b64 };                    // for sured.p
.clamp = { .trap, .clamp, .zero };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Reduction to surface memory using a surface coordinate vector. The instruction performs a reduction
operation with data from operand <code class="docutils literal notranslate"><span class="pre">c</span></code> to the surface named by operand <code class="docutils literal notranslate"><span class="pre">a</span></code> at coordinates given by
operand <code class="docutils literal notranslate"><span class="pre">b</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable or <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is a
scalar or singleton tuple for 1d surfaces; is a two-element vector for 2d surfaces; and is a
four-element vector for 3d surfaces, where the fourth element is ignored. Coordinate elements are of
type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">sured.b</span></code> performs an unformatted reduction on <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, or <code class="docutils literal notranslate"><span class="pre">.s64</span></code>
data. The lowest dimension coordinate represents a byte offset into the surface and is not
scaled. Operation <code class="docutils literal notranslate"><span class="pre">add</span></code> applies to <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code>, and <code class="docutils literal notranslate"><span class="pre">.s32</span></code> types; <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code>
apply to <code class="docutils literal notranslate"><span class="pre">.u32</span></code>, <code class="docutils literal notranslate"><span class="pre">.s32</span></code>, <code class="docutils literal notranslate"><span class="pre">.u64</span></code> and <code class="docutils literal notranslate"><span class="pre">.s64</span></code> types; operations <code class="docutils literal notranslate"><span class="pre">and</span></code> and <code class="docutils literal notranslate"><span class="pre">or</span></code> apply to
<code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p><code class="docutils literal notranslate"><span class="pre">sured.p</span></code> performs an unformatted reduction on sample-addressed data. The lowest dimension coordinate
represents a sample offset rather than a byte offset and is scaled by the data-size given by <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>.
The instruction type <code class="docutils literal notranslate"><span class="pre">.b64</span></code> is restricted to <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> operations. For type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>,
the data is interpreted as <code class="docutils literal notranslate"><span class="pre">.u32</span></code> or <code class="docutils literal notranslate"><span class="pre">.s32</span></code> based on the surface sample format as follows:
if the surface format contains <code class="docutils literal notranslate"><span class="pre">UINT</span></code> data, then <code class="docutils literal notranslate"><span class="pre">.u32</span></code> is assumed; if the surface format contains
<code class="docutils literal notranslate"><span class="pre">SINT</span></code> data, then <code class="docutils literal notranslate"><span class="pre">.s32</span></code> is assumed. For type <code class="docutils literal notranslate"><span class="pre">.b64</span></code>, if the surface format contains <code class="docutils literal notranslate"><span class="pre">UINT</span></code> data,
then <code class="docutils literal notranslate"><span class="pre">.u64</span></code> is assumed; if the surface format contains <code class="docutils literal notranslate"><span class="pre">SINT</span></code> data, then <code class="docutils literal notranslate"><span class="pre">.s64</span></code> is assumed.</p>
<p>A surface base address is assumed to be aligned to a 16 byte boundary, and the address given by the
coordinate vector must be naturally aligned to a multiple of the access size. If an address is not
properly aligned, the resulting behavior is undefined; i.e., the access may proceed by silently
masking off low-order address bits to achieve proper rounding, or the instruction may fault.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> field specifies how to handle out-of-bounds addresses:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.trap</span></code></dt>
<dd>
<p>causes an execution trap on out-of-bounds addresses</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.clamp</span></code></dt>
<dd>
<p>stores data at the nearest surface location (sized appropriately)</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.zero</span></code></dt>
<dd>
<p>drops stores to out-of-bounds addresses</p>
</dd>
</dl>
<p class="rubric">Indirect surface access</p>
<p>Beginning with PTX ISA version 3.1, indirect surface access is supported for target architecture
<code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding the address of
a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p>Indirect surface access introduced in PTX ISA version 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u64</span></code>/<code class="docutils literal notranslate"><span class="pre">.s64</span></code>/<code class="docutils literal notranslate"><span class="pre">.b64</span></code> types with <code class="docutils literal notranslate"><span class="pre">.min</span></code>/<code class="docutils literal notranslate"><span class="pre">.max</span></code> operations introduced in PTX ISA version
8.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>sured requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Indirect surface access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u64</span></code>/<code class="docutils literal notranslate"><span class="pre">.s64</span></code>/<code class="docutils literal notranslate"><span class="pre">.b64</span></code> types with <code class="docutils literal notranslate"><span class="pre">.min</span></code>/<code class="docutils literal notranslate"><span class="pre">.max</span></code> operations requires <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>sured.b.add.2d.u32.trap  [surf_A, {x,y}], r1;
sured.p.min.1d.u32.trap  [surf_B, {x}], r1;
sured.b.max.1d.u64.trap  [surf_C, {x}], r1;
sured.p.min.1d.b64.trap  [surf_D, {x}], r1;
</pre></div>
</div>
</section>
<section id="surface-instructions-suq">
<span id="id310"></span><h4>
<span class="section-number">9.7.11.4. </span><a class="reference internal" href="#surface-instructions-suq">Surface Instructions: <code class="docutils literal notranslate"><span class="pre">suq</span></code></a><a class="headerlink" href="#surface-instructions-suq" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">suq</span></code></p>
<p>Query a surface attribute.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>suq.query.b32   d, [a];

.query = { .width, .height, .depth,
           .channel_data_type, .channel_order,
           .array_size, .memory_layout };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Query an attribute of a surface. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable or a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 34%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Query</p></th>
<th class="head"><p>Returns</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<p><code class="docutils literal notranslate"><span class="pre">.width</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.height</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.depth</span></code></p>
</td>
<td><p>value in elements</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.channel_data_type</span></code></p></td>
<td><p>Unsigned integer corresponding to source languageâ€™s channel data
type enumeration. If the source language combines channel data
type and channel order into a single enumeration type, that value
is returned for both <code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">channel_order</span></code>
queries.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.channel_order</span></code></p></td>
<td><p>Unsigned integer corresponding to source languageâ€™s channel order
enumeration. If the source language combines channel data type and
channel order into a single enumeration type, that value is
returned for both <code class="docutils literal notranslate"><span class="pre">channel_data_type</span></code> and <code class="docutils literal notranslate"><span class="pre">channel_order</span></code>
queries.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.array_size</span></code></p></td>
<td><p>For a surface array, number of surfaces in array, 0 otherwise.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.memory_layout</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1</span></code> for surface with linear memory layout; <code class="docutils literal notranslate"><span class="pre">0</span></code> otherwise</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Indirect surface access</p>
<p>Beginning with PTX ISA version 3.1, indirect surface access is supported for target architecture
<code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. In indirect access, operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a <code class="docutils literal notranslate"><span class="pre">.u64</span></code> register holding the address of
a <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variable.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.5.</p>
<p>Channel data type and channel order queries added in PTX ISA version 2.1.</p>
<p>Indirect surface access introduced in PTX ISA version 3.1.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.array_size</span></code> query was added in PTX ISA version 4.1.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.memory_layout</span></code> query was added in PTX ISA version 4.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p>Indirect surface access requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>suq.width.b32       %r1, [surf_A];
</pre></div>
</div>
</section>
</section>
<section id="control-flow-instructions">
<span id="id311"></span><h3>
<span class="section-number">9.7.12. </span><a class="reference internal" href="#control-flow-instructions">Control Flow Instructions</a><a class="headerlink" href="#control-flow-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The following PTX instructions and syntax are for controlling execution in a PTX program:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">{}</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">@</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bra</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ret</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">exit</span></code></p></li>
</ul>
<section id="control-flow-instructions-curly-braces">
<span id="id312"></span><h4>
<span class="section-number">9.7.12.1. </span><a class="reference internal" href="#control-flow-instructions-curly-braces">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">{}</span></code></a><a class="headerlink" href="#control-flow-instructions-curly-braces" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">{}</span></code></p>
<p>Instruction grouping.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>{ instructionList }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The curly braces create a group of instructions, used primarily for defining a function body. The
curly braces also provide a mechanism for determining the scope of a variable: any variable declared
within a scope is not available outside the scope.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>{ add.s32  a,b,c; mov.s32  d,a; }
</pre></div>
</div>
</section>
<section id="control-flow-instructions-at">
<span id="id313"></span><h4>
<span class="section-number">9.7.12.2. </span><a class="reference internal" href="#control-flow-instructions-at">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">@</span></code></a><a class="headerlink" href="#control-flow-instructions-at" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">@</span></code></p>
<p>Predicated execution.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@{!}p    instruction;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Execute an instruction or instruction block for threads that have the guard predicate
<code class="docutils literal notranslate"><span class="pre">True</span></code>. Threads with a <code class="docutils literal notranslate"><span class="pre">False</span></code> guard predicate do nothing.</p>
<p class="rubric">Semantics</p>
<p>If <code class="docutils literal notranslate"><span class="pre">{!}p</span></code> then instruction</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    setp.eq.f32  p,y,0;     // is y zero?
@!p div.f32      ratio,x,y  // avoid division by zero

@q  bra L23;                // conditional branch
</pre></div>
</div>
</section>
<section id="control-flow-instructions-bra">
<span id="id314"></span><h4>
<span class="section-number">9.7.12.3. </span><a class="reference internal" href="#control-flow-instructions-bra">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">bra</span></code></a><a class="headerlink" href="#control-flow-instructions-bra" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bra</span></code></p>
<p>Branch to a target and continue execution there.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p   bra{.uni}  tgt;           // tgt is a label
     bra{.uni}  tgt;           // unconditional branch
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Continue execution at the target. Conditional branches are specified by using a guard predicate. The
branch target must be a label.</p>
<p><code class="docutils literal notranslate"><span class="pre">bra.uni</span></code> is guaranteed to be non-divergent, i.e. all active threads in a warp that are currently
executing this instruction have identical values for the guard predicate and branch target.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (p) {
    pc = tgt;
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Unimplemented indirect branch introduced in PTX ISA version 2.1 has been removed from the spec.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bra.uni  L_exit;    // uniform unconditional jump
@q  bra      L23;   // conditional branch
</pre></div>
</div>
</section>
<section id="control-flow-instructions-brx-idx">
<span id="id315"></span><h4>
<span class="section-number">9.7.12.4. </span><a class="reference internal" href="#control-flow-instructions-brx-idx">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code></a><a class="headerlink" href="#control-flow-instructions-brx-idx" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">brx.idx</span></code></p>
<p>Branch to a label indexed from a list of potential branch targets.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@p    brx.idx{.uni} index, tlist;
      brx.idx{.uni} index, tlist;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Index into a list of possible destination labels, and continue execution from the chosen
label. Conditional branches are specified by using a guard predicate.</p>
<p><code class="docutils literal notranslate"><span class="pre">brx.idx.uni</span></code> guarantees that the branch is non-divergent, i.e. all active threads in a warp that
are currently executing this instruction have identical values for the guard predicate and the
<code class="docutils literal notranslate"><span class="pre">index</span></code> argument.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">index</span></code> operand is a <code class="docutils literal notranslate"><span class="pre">.u32</span></code> register. The <code class="docutils literal notranslate"><span class="pre">tlist</span></code> operand must be the label of a
<code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code> directive. It is accessed as a zero-based sequence using <code class="docutils literal notranslate"><span class="pre">index</span></code>. Behaviour is
undefined if the value of <code class="docutils literal notranslate"><span class="pre">index</span></code> is greater than or equal to the length of <code class="docutils literal notranslate"><span class="pre">tlist</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code> directive must be defined in the local function scope before it is used. It
must refer to labels within the current function.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>if (p) {
    if (index &lt; length(tlist)) {
      pc = tlist[index];
    } else {
      pc = undefined;
    }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.function foo () {
    .reg .u32 %r0;
    ...
    L1:
    ...
    L2:
    ...
    L3:
    ...
    ts: .branchtargets L1, L2, L3;
    @p brx.idx %r0, ts;
    ...
}
</pre></div>
</div>
</section>
<section id="control-flow-instructions-call">
<span id="id316"></span><h4>
<span class="section-number">9.7.12.5. </span><a class="reference internal" href="#control-flow-instructions-call">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">call</span></code></a><a class="headerlink" href="#control-flow-instructions-call" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">call</span></code></p>
<p>Call a function, recording the return location.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// direct call to named function, func is a symbol
call{.uni} (ret-param), func, (param-list);
call{.uni} func, (param-list);
call{.uni} func;

// indirect call via pointer, with full list of call targets
call{.uni} (ret-param), fptr, (param-list), flist;
call{.uni} fptr, (param-list), flist;
call{.uni} fptr, flist;

// indirect call via pointer, with no knowledge of call targets
call{.uni} (ret-param), fptr, (param-list), fproto;
call{.uni} fptr, (param-list), fproto;
call{.uni} fptr, fproto;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">call</span></code> instruction stores the address of the next instruction, so execution can resume at that
point after executing a <code class="docutils literal notranslate"><span class="pre">ret</span></code> instruction. A <code class="docutils literal notranslate"><span class="pre">call</span></code> is assumed to be divergent unless the
<code class="docutils literal notranslate"><span class="pre">.uni</span></code> suffix is present. The <code class="docutils literal notranslate"><span class="pre">.uni</span></code> suffix indicates that the <code class="docutils literal notranslate"><span class="pre">call</span></code> is guaranteed to be
non-divergent, i.e. all active threads in a warp that are currently executing this instruction have
identical values for the guard predicate and <code class="docutils literal notranslate"><span class="pre">call</span></code> target.</p>
<p>For direct calls, the called location <code class="docutils literal notranslate"><span class="pre">func</span></code> must be a symbolic function name; for indirect calls,
the called location <code class="docutils literal notranslate"><span class="pre">fptr</span></code> must be an address of a function held in a register. Input arguments
and return values are optional. Arguments may be registers, immediate constants, or variables in
<code class="docutils literal notranslate"><span class="pre">.param</span></code> space. Arguments are pass-by-value.</p>
<p>Indirect calls require an additional operand, <code class="docutils literal notranslate"><span class="pre">flist</span></code> or <code class="docutils literal notranslate"><span class="pre">fproto</span></code>, to communicate the list of
potential <code class="docutils literal notranslate"><span class="pre">call</span></code> targets or the common function prototype of all <code class="docutils literal notranslate"><span class="pre">call</span></code> targets,
respectively. In the first case, <code class="docutils literal notranslate"><span class="pre">flist</span></code> gives a complete list of potential <code class="docutils literal notranslate"><span class="pre">call</span></code> targets and
the optimizing backend is free to optimize the calling convention. In the second case, where the
complete list of potential <code class="docutils literal notranslate"><span class="pre">call</span></code> targets may not be known, the common function prototype is given
and the <code class="docutils literal notranslate"><span class="pre">call</span></code> must obey the ABIâ€™s calling convention.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">flist</span></code> operand is either the name of an array (call table) initialized to a list of function
names; or a label associated with a <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code> directive, which declares a list of potential
<code class="docutils literal notranslate"><span class="pre">call</span></code> targets. In both cases the fptr register holds the address of a function listed in the call
table or <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code> list, and the <code class="docutils literal notranslate"><span class="pre">call</span></code> operands are type-checked against the type
signature of the functions indicated by <code class="docutils literal notranslate"><span class="pre">flist</span></code>.</p>
<p>The fproto operand is the name of a label associated with a <code class="docutils literal notranslate"><span class="pre">.callprototype</span></code> directive. This
operand is used when a complete list of potential targets is not known. The <code class="docutils literal notranslate"><span class="pre">call</span></code> operands are
type-checked against the prototype, and code generation will follow the ABI calling convention. If a
function that doesnâ€™t match the prototype is called, the behavior is undefined.</p>
<p>Call tables may be declared at module scope or local scope, in either the constant or global state
space. The <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code> and <code class="docutils literal notranslate"><span class="pre">.callprototype</span></code> directives must be declared within a function
body. All functions must be declared prior to being referenced in a <code class="docutils literal notranslate"><span class="pre">call</span></code> table initializer or
<code class="docutils literal notranslate"><span class="pre">.calltargets</span></code> directive.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Direct <code class="docutils literal notranslate"><span class="pre">call</span></code> introduced in PTX ISA version 1.0. Indirect <code class="docutils literal notranslate"><span class="pre">call</span></code> introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Direct <code class="docutils literal notranslate"><span class="pre">call</span></code> supported on all target architectures. Indirect <code class="docutils literal notranslate"><span class="pre">call</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// examples of direct call
    call     init;    // call function 'init'
    call.uni g, (a);  // call function 'g' with parameter 'a'
@p  call     (d), h, (a, b);  // return value into register d

// call-via-pointer using jump table
.func (.reg .u32 rv) foo (.reg .u32 a, .reg .u32 b) ...
.func (.reg .u32 rv) bar (.reg .u32 a, .reg .u32 b) ...
.func (.reg .u32 rv) baz (.reg .u32 a, .reg .u32 b) ...

.global .u32 jmptbl[5] = { foo, bar, baz };
      ...
@p    ld.global.u32  %r0, [jmptbl+4];
@p    ld.global.u32  %r0, [jmptbl+8];
      call  (retval), %r0, (x, y), jmptbl;

// call-via-pointer using .calltargets directive
.func (.reg .u32 rv) foo (.reg .u32 a, .reg .u32 b) ...
.func (.reg .u32 rv) bar (.reg .u32 a, .reg .u32 b) ...
.func (.reg .u32 rv) baz (.reg .u32 a, .reg .u32 b) ...
      ...
@p    mov.u32  %r0, foo;
@q    mov.u32  %r0, baz;
Ftgt: .calltargets foo, bar, baz;
      call  (retval), %r0, (x, y), Ftgt;

// call-via-pointer using .callprototype directive
.func dispatch (.reg .u32 fptr, .reg .u32 idx)
{
...
Fproto: .callprototype _ (.param .u32 _, .param .u32 _);
      call  %fptr, (x, y), Fproto;
...
</pre></div>
</div>
</section>
<section id="control-flow-instructions-ret">
<span id="id317"></span><h4>
<span class="section-number">9.7.12.6. </span><a class="reference internal" href="#control-flow-instructions-ret">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">ret</span></code></a><a class="headerlink" href="#control-flow-instructions-ret" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ret</span></code></p>
<p>Return from function to instruction after call.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ret{.uni};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Return execution to callerâ€™s environment. A divergent return suspends threads until all threads are
ready to return to the caller. This allows multiple divergent <code class="docutils literal notranslate"><span class="pre">ret</span></code> instructions.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">ret</span></code> is assumed to be divergent unless the <code class="docutils literal notranslate"><span class="pre">.uni</span></code> suffix is present, indicating that the
return is guaranteed to be non-divergent.</p>
<p>Any values returned from a function should be moved into the return parameter variables prior to
executing the <code class="docutils literal notranslate"><span class="pre">ret</span></code> instruction.</p>
<p>A return instruction executed in a top-level entry routine will terminate thread execution.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    ret;
@p  ret;
</pre></div>
</div>
</section>
<section id="control-flow-instructions-exit">
<span id="id318"></span><h4>
<span class="section-number">9.7.12.7. </span><a class="reference internal" href="#control-flow-instructions-exit">Control Flow Instructions: <code class="docutils literal notranslate"><span class="pre">exit</span></code></a><a class="headerlink" href="#control-flow-instructions-exit" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">exit</span></code></p>
<p>Terminate a thread.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>exit;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Ends execution of a thread.</p>
<p>Barriers exclusively waiting on arrivals from exited threads are always released.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    exit;
@p  exit;
</pre></div>
</div>
</section>
</section>
<section id="parallel-synchronization-and-communication-instructions">
<span id="id319"></span><h3>
<span class="section-number">9.7.13. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions">Parallel Synchronization and Communication Instructions</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>These instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">bar{.cta}</span></code>, <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">membar</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">atom</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">red</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">red.async</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vote</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">match.sync</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">activemask</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">redux.sync</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">elect.sync</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code></p></li>
</ul>
<section id="parallel-synchronization-and-communication-instructions-bar">
<span id="id320"></span><h4>
<span class="section-number">9.7.13.1. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-bar">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">bar</span></code>, <code class="docutils literal notranslate"><span class="pre">barrier</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-bar" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bar</span></code>, <code class="docutils literal notranslate"><span class="pre">bar.cta</span></code>, <code class="docutils literal notranslate"><span class="pre">barrier</span></code>, <code class="docutils literal notranslate"><span class="pre">barrier.cta</span></code></p>
<p>Barrier synchronization.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>barrier{.cta}.sync{.aligned}      a{, b};
barrier{.cta}.arrive{.aligned}    a, b;

barrier{.cta}.red.popc{.aligned}.u32  d, a{, b}, {!}c;
barrier{.cta}.red.op{.aligned}.pred   p, a{, b}, {!}c;

bar{.cta}.sync      a{, b};
bar{.cta}.arrive    a, b;

bar{.cta}.red.popc.u32  d, a{, b}, {!}c;
bar{.cta}.red.op.pred   p, a{, b}, {!}c;

.op = { .and, .or };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs barrier synchronization and communication within a CTA. Each CTA instance has sixteen
barriers numbered <code class="docutils literal notranslate"><span class="pre">0..15</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instructions can be used by the threads within the CTA for synchronization and
communication.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, and <code class="docutils literal notranslate"><span class="pre">d</span></code> have type <code class="docutils literal notranslate"><span class="pre">.u32</span></code>; operands <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> are predicates. Source
operand <code class="docutils literal notranslate"><span class="pre">a</span></code> specifies a logical barrier resource as an immediate constant or register with value
<code class="docutils literal notranslate"><span class="pre">0</span></code> through <code class="docutils literal notranslate"><span class="pre">15</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">b</span></code> specifies the number of threads participating in the barrier. If
no thread count is specified, all threads in the CTA participate in the barrier. When specifying a
thread count, the value must be a multiple of the warp size. Note that a non-zero thread count is
required for <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code>.</p>
<p>Depending on operand <code class="docutils literal notranslate"><span class="pre">b</span></code>, either specified number of threads (in multiple of warp size) or all
threads in the CTA participate in <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction. The <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instructions
signal the arrival of the executing threads at the named barrier.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction causes executing thread to wait for all non-exited threads from its
warp and marks warpsâ€™ arrival at barrier. In addition to signaling its arrival at the barrier, the
<code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> and <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> instructions causes executing thread to wait for
non-exited threads of all other warps participating in the barrier to
arrive. <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code> does not cause executing thread to wait for threads of other
participating warps.</p>
<p>When a barrier completes, the waiting threads are restarted without delay, and the barrier is
reinitialized so that it can be immediately reused.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> or <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code> instruction
guarantees that when the barrier completes, prior memory accesses requested by this thread are
performed relative to all threads participating in the barrier. The <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> and
<code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> instruction further guarantees that no new memory access is requested by this
thread before the barrier completes.</p>
<p>A memory read (e.g., by <code class="docutils literal notranslate"><span class="pre">ld</span></code> or <code class="docutils literal notranslate"><span class="pre">atom</span></code>) has been performed when the value read has been
transmitted from memory and cannot be modified by another thread participating in the barrier. A
memory write (e.g., by <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">red</span></code> or <code class="docutils literal notranslate"><span class="pre">atom</span></code>) has been performed when the value written has
become visible to other threads participating in the barrier, that is, when the previous value can
no longer be read.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> performs a reduction operation across threads. The <code class="docutils literal notranslate"><span class="pre">c</span></code> predicate (or its
complement) from all threads in the CTA are combined using the specified reduction operator. Once
the barrier count is reached, the final value is written to the destination register in all threads
waiting at the barrier.</p>
<p>The reduction operations for <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> are population-count (<code class="docutils literal notranslate"><span class="pre">.popc</span></code>),
all-threads-True (<code class="docutils literal notranslate"><span class="pre">.and</span></code>), and any-thread-True (<code class="docutils literal notranslate"><span class="pre">.or</span></code>). The result of <code class="docutils literal notranslate"><span class="pre">.popc</span></code> is the number of
threads with a <code class="docutils literal notranslate"><span class="pre">True</span></code> predicate, while <code class="docutils literal notranslate"><span class="pre">.and</span></code> and <code class="docutils literal notranslate"><span class="pre">.or</span></code> indicate if all the threads had a
<code class="docutils literal notranslate"><span class="pre">True</span></code> predicate or if any of the threads had a <code class="docutils literal notranslate"><span class="pre">True</span></code> predicate.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> has optional <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> modifier. When specified, it indicates that
all threads in CTA will execute the same <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction. In conditionally executed
code, an aligned <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction should only be used if it is known that all threads
in CTA evaluate the condition identically, otherwise behavior is undefined.</p>
<p>Different warps may execute different forms of the <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction using the same
barrier name and thread count. One example mixes <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> and <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code>
to implement producer/consumer models. The producer threads execute <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code> to
announce their arrival at the barrier and continue execution without delay to produce the next
value, while the consumer threads execute the <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> to wait for a resource to be
produced. The roles are then reversed, using a different barrier, where the producer threads execute
a <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> to wait for a resource to consumed, while the consumer threads announce
that the resource has been consumed with <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code>. Care must be taken to keep a warp
from executing more <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instructions than intended (<code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code> followed
by any other <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction to the same barrier) prior to the reset of the
barrier. <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red</span></code> should not be intermixed with <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync</span></code> or
<code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive</span></code> using the same active barrier. Execution in this case is unpredictable.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.cta</span></code> qualifier simply indicates CTA-level applicability of the barrier and it
doesnâ€™t change the semantics of the instruction.</p>
<p><code class="docutils literal notranslate"><span class="pre">bar{.cta}.sync</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.sync.aligned</span></code>. <code class="docutils literal notranslate"><span class="pre">bar{.cta}.arrive</span></code> is
equivalent to <code class="docutils literal notranslate"><span class="pre">barrier{.cta}.arrive.aligned</span></code>. <code class="docutils literal notranslate"><span class="pre">bar{.cta}.red</span></code> is equivalent to
<code class="docutils literal notranslate"><span class="pre">barrier{.cta}.red.aligned</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For .target <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> or below,</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction without <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> modifier is equivalent to <code class="docutils literal notranslate"><span class="pre">.aligned</span></code>
variant and has the same restrictions as of <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> variant.</p></li>
<li><p>All threads in warp (except for those have exited) must execute <code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction
in convergence.</p></li>
</ol>
</div>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">bar.sync</span></code> without a thread count introduced in PTX ISA version 1.0.</p>
<p>Register operands, thread count, and <code class="docutils literal notranslate"><span class="pre">bar.{arrive,red}</span></code> introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier</span></code> instruction introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.cta</span></code> qualifier introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Register operands, thread count, and <code class="docutils literal notranslate"><span class="pre">bar{.cta}.{arrive,red}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>Only <code class="docutils literal notranslate"><span class="pre">bar{.cta}.sync</span></code> with an immediate barrier number is supported for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instruction requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Use bar.sync to arrive at a pre-computed barrier number and
// wait for all threads in CTA to also arrive:
    st.shared [r0],r1;  // write my result to shared memory
    bar.cta.sync  1;    // arrive, wait for others to arrive
    ld.shared r2,[r3];  // use shared results from other threads

// Use bar.sync to arrive at a pre-computed barrier number and
// wait for fixed number of cooperating threads to arrive:
    #define CNT1 (8*12) // Number of cooperating threads

    st.shared [r0],r1;     // write my result to shared memory
    bar.cta.sync  1, CNT1; // arrive, wait for others to arrive
    ld.shared r2,[r3];     // use shared results from other threads

// Use bar.red.and to compare results across the entire CTA:
    setp.eq.u32 p,r1,r2;         // p is True if r1==r2
    bar.cta.red.and.pred r3,1,p; // r3=AND(p) forall threads in CTA

// Use bar.red.popc to compute the size of a group of threads
// that have a specific condition True:
    setp.eq.u32 p,r1,r2;         // p is True if r1==r2
    bar.cta.red.popc.u32 r3,1,p; // r3=SUM(p) forall threads in CTA

// Examples of barrier.cta.sync
    st.shared         [r0],r1;
    barrier.cta.sync  0;
    ld.shared         r1, [r0];

/* Producer/consumer model. The producer deposits a value in
 * shared memory, signals that it is complete but does not wait
 * using bar.arrive, and begins fetching more data from memory.
 * Once the data returns from memory, the producer must wait
 * until the consumer signals that it has read the value from
 * the shared memory location. In the meantime, a consumer
 * thread waits until the data is stored by the producer, reads
 * it, and then signals that it is done (without waiting).
 */
    // Producer code places produced value in shared memory.
    st.shared   [r0],r1;
    bar.arrive  0,64;
    ld.global   r1,[r2];
    bar.sync    1,64;
    ...

    // Consumer code, reads value from shared memory
    bar.sync   0,64;
    ld.shared  r1,[r0];
    bar.arrive 1,64;
    ...
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-bar-warp-sync">
<span id="id321"></span><h4>
<span class="section-number">9.7.13.2. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-bar-warp-sync">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-bar-warp-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code></p>
<p>Barrier synchronization for threads in a warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>bar.warp.sync      membermask;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> will cause executing thread to wait until all threads corresponding to
<code class="docutils literal notranslate"><span class="pre">membermask</span></code> have executed a <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> with the same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> value before resuming
execution.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer which is a mask indicating threads participating
in barrier where the bit position corresponds to threadâ€™s <code class="docutils literal notranslate"><span class="pre">laneid</span></code>.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> is undefined if the executing thread is not in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> also guarantee memory ordering among threads participating in barrier. Thus,
threads within warp that wish to communicate via memory can store to memory, execute
<code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code>, and then safely read values stored by other threads in warp.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For .target <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> or below, all threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> must execute the same
<code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> instruction in convergence, and only threads belonging to some <code class="docutils literal notranslate"><span class="pre">membermask</span></code>
can be active when the <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> instruction is executed. Otherwise, the behavior is
undefined.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>st.shared.u32 [r0],r1;         // write my result to shared memory
bar.warp.sync  0xffffffff;     // arrive, wait for others to arrive
ld.shared.u32 r2,[r3];         // read results written by other threads
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-barrier-cluster">
<span id="id322"></span><h4>
<span class="section-number">9.7.13.3. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-barrier-cluster">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-barrier-cluster" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code></p>
<p>Barrier synchronization within a cluster.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>barrier.cluster.arrive{.sem}{.aligned};
barrier.cluster.wait{.acquire}{.aligned};

.sem = {.release, .relaxed}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs barrier synchronization and communication within a cluster.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code> instructions can be used by the threads within the cluster for synchronization
and communication.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> instruction marks warpsâ€™ arrival at barrier without causing executing
thread to wait for threads of other participating warps.</p>
<p><code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code> instruction causes the executing thread to wait for all non-exited threads
of the cluster to perform <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code>.</p>
<p>In addition, <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code> instructions cause the executing thread to wait for all non-exited
threads from its warp.</p>
<p>When all non-exited threads in the cluster have executed <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code>, the barrier
completes and is automatically reinitialized. After using <code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code> to detect completion
of the barrier, a thread may immediately arrive at the barrier once again.
Each thread must arrive at the barrier only once before the barrier completes.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code> instruction guarantees that when it completes the execution, memory
accesses (except asynchronous operations) requested, in program order, prior to the preceding
<code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> by all threads in the cluster are complete and visible to the executing
thread.</p>
<p>There is no memory ordering and visibility guarantee for memory accesses requested by the executing
thread, in program order, after <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> and prior to <code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier on <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> specifies that there are no memory
ordering and visibility guarantees provided for the memory accesses performed prior to
<code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> qualifiers on instructions <code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code> and
<code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code> specify the memory synchronization as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent for
<code class="docutils literal notranslate"><span class="pre">barrier.cluster.arrive</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code> is assumed by default. If the optional <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>
qualifier is absent for <code class="docutils literal notranslate"><span class="pre">barrier.cluster.wait</span></code>, <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> is assumed by default.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code> instruction. In conditionally executed code, an aligned <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code>
instruction should only be used if it is known that all threads in the warp evaluate the condition
identically, otherwise behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>, <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifiers introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// use of arrive followed by wait
ld.shared::cluster.u32 r0, [addr];
barrier.cluster.arrive.aligned;
...
barrier.cluster.wait.aligned;
st.shared::cluster.u32 [addr], r1;

// use memory fence prior to arrive for relaxed barrier
@cta0 ld.shared::cluster.u32 r0, [addr];
fence.cluster.acq_rel;
barrier.cluster.arrive.relaxed.aligned;
...
barrier.cluster.wait.aligned;
@cta1 st.shared::cluster.u32 [addr], r1;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-membar">
<span id="id323"></span><h4>
<span class="section-number">9.7.13.4. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-membar">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">membar</span></code> / <code class="docutils literal notranslate"><span class="pre">fence</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-membar" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">membar</span></code>, <code class="docutils literal notranslate"><span class="pre">fence</span></code></p>
<p>Enforce an ordering of memory operations.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Thread fence:
fence{.sem}.scope;

// Thread fence:
fence.acquire.sync_restrict::shared::cluster.cluster;
fence.release.sync_restrict::shared::cta.cluster;

// Operation fence:
fence.op_restrict.release.cluster;

// Proxy fence (bi-directional):
fence.proxy.proxykind;

// Proxy fence (uni-directional):
fence.proxy.to_proxykind::from_proxykind.release.scope;
fence.proxy.to_proxykind::from_proxykind.acquire.scope  [addr], size;
fence.proxy.async::generic.acquire.sync_restrict::shared::cluster.cluster;
fence.proxy.async::generic.release.sync_restrict::shared::cta.cluster;

// Old style membar:
membar.level;
membar.proxy.proxykind;

.sem       = { .sc, .acq_rel, .acquire, .release };
.scope     = { .cta, .cluster, .gpu, .sys };
.level     = { .cta, .gl, .sys };
.proxykind = { .alias, .async, .async.global, .async.shared::{cta, cluster} };
.op_restrict = { .mbarrier_init };
.to_proxykind::from_proxykind = {.tensormap::generic};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">membar</span></code> instruction guarantees that prior memory accesses requested by this thread (<code class="docutils literal notranslate"><span class="pre">ld</span></code>,
<code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code> and <code class="docutils literal notranslate"><span class="pre">red</span></code> instructions) are performed at the specified <code class="docutils literal notranslate"><span class="pre">level</span></code>, before later
memory operations requested by this thread following the <code class="docutils literal notranslate"><span class="pre">membar</span></code> instruction. The <code class="docutils literal notranslate"><span class="pre">level</span></code>
qualifier specifies the set of threads that may observe the ordering effect of this operation.</p>
<p>A memory read (e.g., by <code class="docutils literal notranslate"><span class="pre">ld</span></code> or <code class="docutils literal notranslate"><span class="pre">atom</span></code>) has been performed when the value read has been
transmitted from memory and cannot be modified by another thread at the indicated level. A memory
write (e.g., by <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">red</span></code> or <code class="docutils literal notranslate"><span class="pre">atom</span></code>) has been performed when the value written has become
visible to other threads at the specified level, that is, when the previous value can no longer be
read.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction establishes an ordering between memory accesses requested by this thread
(<code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code> and <code class="docutils literal notranslate"><span class="pre">red</span></code> instructions) as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. The scope qualifier specifies the set of threads that may
observe the ordering effect of this operation.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence.acq_rel</span></code> is a light-weight fence that is sufficient for memory synchronization in most
programs. Instances of <code class="docutils literal notranslate"><span class="pre">fence.acq_rel</span></code> synchronize when combined with additional memory operations
as described in <code class="docutils literal notranslate"><span class="pre">acquire</span></code> and <code class="docutils literal notranslate"><span class="pre">release</span></code> patterns in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
If the optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent, <code class="docutils literal notranslate"><span class="pre">.acq_rel</span></code>
is assumed by default.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> is a slower fence that can restore <em>sequential consistency</em> when used in sufficient
places, at the cost of performance. Instances of <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> with sufficient scope always
synchronize by forming a total order per scope, determined at runtime. This total order can be
constrained further by other synchronization in the program.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.op_restrict</span></code> and <code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code> restrict the class of memory operations
for which the <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction provides the memory ordering guarantees. When <code class="docutils literal notranslate"><span class="pre">.op_restrict</span></code>
is <code class="docutils literal notranslate"><span class="pre">.mbarrier_init</span></code>, the synchronizing effect of the fence only applies to the prior
<code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> operations executed by the same thread on <em>mbarrier objects</em> in <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code>
state space. When <code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code> is <code class="docutils literal notranslate"><span class="pre">.sync_restrict::shared::cta</span></code>, <code class="docutils literal notranslate"><span class="pre">.sem</span></code> must be
<code class="docutils literal notranslate"><span class="pre">.release</span></code>, and the effect of the fence only applies to operations performed on objects in
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space. Likewise, when <code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code> is <code class="docutils literal notranslate"><span class="pre">.sync_restrict::shared::cluster</span></code>,
<code class="docutils literal notranslate"><span class="pre">.sem</span></code> must be <code class="docutils literal notranslate"><span class="pre">.acquire</span></code>, and the effect of the fence only applies to operations performed on
objects in <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space. When either <code class="docutils literal notranslate"><span class="pre">.sync_restrict::shared::cta</span></code> or
<code class="docutils literal notranslate"><span class="pre">.sync_restrict::shared::cluster</span></code> is present, the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified as <code class="docutils literal notranslate"><span class="pre">.cluster</span></code>.</p>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> and the operand <code class="docutils literal notranslate"><span class="pre">size</span></code> together specify the memory range
<code class="docutils literal notranslate"><span class="pre">[addr,</span> <span class="pre">addr+size-1]</span></code> on which the ordering guarantees on the memory accesses across the proxies is to be
provided. The only supported value for the <code class="docutils literal notranslate"><span class="pre">size</span></code> operand is 128, which must be a constant integer literal.
<a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used unconditionally, and the address specified by
the operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> must fall within the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space. Otherwise, the behavior is undefined.</p>
<p>On <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and higher <code class="docutils literal notranslate"><span class="pre">membar</span></code> is a synonym for <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code><sup>1</sup>, and the <code class="docutils literal notranslate"><span class="pre">membar</span></code>
levels <code class="docutils literal notranslate"><span class="pre">cta</span></code>, <code class="docutils literal notranslate"><span class="pre">gl</span></code> and <code class="docutils literal notranslate"><span class="pre">sys</span></code> are synonymous with the <code class="docutils literal notranslate"><span class="pre">fence</span></code> scopes <code class="docutils literal notranslate"><span class="pre">cta</span></code>, <code class="docutils literal notranslate"><span class="pre">gpu</span></code> and
<code class="docutils literal notranslate"><span class="pre">sys</span></code> respectively.</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> and <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> instructions establish an ordering between memory accesses that
may happen through different <em>proxies</em>.</p>
<p>A <em>uni-directional</em> proxy ordering from the <em>from-proxykind</em> to the <em>to-proxykind</em> establishes
ordering between a prior memory access performed via the <em>from-proxykind</em> and a subsequent memory access
performed via the <em>to-proxykind</em>.</p>
<p>A <em>bi-directional</em> proxy ordering between two proxykinds establishes two <em>uni-directional</em> proxy orderings
: one from the first proxykind to the second proxykind and the other from the second proxykind to the first
proxykind.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.proxykind</span></code> qualifier indicates the <em>bi-directional</em> proxy ordering that is established between the memory
accesses done between the generic proxy and the proxy specified by <code class="docutils literal notranslate"><span class="pre">.proxykind</span></code>.</p>
<p>Value <code class="docutils literal notranslate"><span class="pre">.alias</span></code> of the <code class="docutils literal notranslate"><span class="pre">.proxykind</span></code> qualifier refers to memory accesses performed using virtually
aliased addresses to the same memory location. Value <code class="docutils literal notranslate"><span class="pre">.async</span></code> of the <code class="docutils literal notranslate"><span class="pre">.proxykind</span></code> qualifier specifies
that the memory ordering is established between the async proxy and the generic proxy. The memory
ordering is limited only to operations performed on objects in the state space specified. If no state space
is specified, then the memory ordering applies on all state spaces.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">.release</span></code> proxy fence can form a release sequence that synchronizes with an acquire
sequence that contains a <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> proxy fence. The <code class="docutils literal notranslate"><span class="pre">.to_proxykind</span></code> and
<code class="docutils literal notranslate"><span class="pre">.from_proxykind</span></code> qualifiers indicate the <em>uni-directional</em> proxy ordering that is established.</p>
<p>On <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and higher, <code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> is a synonym for <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code>.</p>
<p><sup>1</sup> The semantics of <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code> introduced with <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> is a superset of the semantics of
<code class="docutils literal notranslate"><span class="pre">membar</span></code> and the two are compatible; when executing on <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or later architectures,
<code class="docutils literal notranslate"><span class="pre">membar</span></code> acquires the full semantics of <code class="docutils literal notranslate"><span class="pre">fence.sc</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.{cta,gl}</span></code> introduced in PTX ISA version 1.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.sys</span></code> introduced in PTX ISA version 2.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence</span></code> introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> and <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> introduced in PTX ISA version 7.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier introduced in PTX ISA version 7.8.</p>
<p><code class="docutils literal notranslate"><span class="pre">.op_restrict</span></code> qualifier introduced in PTX ISA version 8.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> is introduced in PTX ISA version 8.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.to_proxykind::from_proxykind</span></code> qualifier introduced in PTX ISA version 8.3.</p>
<p><code class="docutils literal notranslate"><span class="pre">.acquire</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifiers for <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.{cta,gl}</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.sys</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.op_restrict</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.to_proxykind::from_proxykind</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.acquire</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifiers for <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher..</p>
<p><code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher..</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>membar.gl;
membar.cta;
membar.sys;
fence.sc.cta;
fence.sc.cluster;
fence.proxy.alias;
membar.proxy.alias;
fence.mbarrier_init.release.cluster;
fence.proxy.async;
fence.proxy.async.shared::cta;
fence.proxy.async.shared::cluster;
fence.proxy.async.global;

tensormap.replace.tile.global_address.global.b1024.b64   [gbl], new_addr;
fence.proxy.tensormap::generic.release.gpu;
cvta.global.u64  tmap, gbl;
fence.proxy.tensormap::generic.acquire.gpu [tmap], 128;
cp.async.bulk.tensor.1d.shared::cluster.global.tile  [addr0], [tmap, {tc0}], [mbar0];

// Acquire remote barrier state via async proxy.
barrier.cluster.wait.acquire;
fence.proxy.async::generic.acquire.sync_restrict::shared::cluster.cluster;

// Release local barrier state via generic proxy.
mbarrier.init [bar];
fence.mbarrier_init.release.cluster;
barrier.cluster.arrive.relaxed;

// Acquire local shared memory via generic proxy.
mbarrier.try_wait.relaxed.cluster.shared::cta.b64 complete, [addr], parity;
fence.acquire.sync_restrict::shared::cluster.cluster;

// Release local shared memory via generic proxy.
fence.release.sync_restrict::shared::cta.cluster;
mbarrier.arrive.relaxed.cluster.shared::cluster.b64 state, [bar];
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-atom">
<span id="id324"></span><h4>
<span class="section-number">9.7.13.5. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-atom">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">atom</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-atom" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">atom</span></code></p>
<p>Atomic reduction operations for thread-to-thread communication.</p>
<p class="rubric">Syntax</p>
<p>Atomic operation with scalar type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>atom{.sem}{.scope}{.space}.op{.level::cache_hint}.type d, [a], b{, cache-policy};
atom{.sem}{.scope}{.space}.op.type d, [a], b, c;

atom{.sem}{.scope}{.space}.cas.b16 d, [a], b, c;

atom{.sem}{.scope}{.space}.cas.b128 d, [a], b, c;
atom{.sem}{.scope}{.space}.exch{.level::cache_hint}.b128 d, [a], b {, cache-policy};

atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16     d, [a], b{, cache-policy};
atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16x2   d, [a], b{, cache-policy};

atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16    d, [a], b{, cache-policy};
atom{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16x2  d, [a], b{, cache-policy};

.space =              { .global, .shared{::cta, ::cluster} };
.sem =                { .relaxed, .acquire, .release, .acq_rel };
.scope =              { .cta, .cluster, .gpu, .sys };

.op =                 { .and, .or, .xor,
                        .cas, .exch,
                        .add, .inc, .dec,
                        .min, .max };
.level::cache_hint =  { .L2::cache_hint };
.type =               { .b32, .b64, .u32, .u64, .s32, .s64, .f32, .f64 };
</pre></div>
</div>
<p>Atomic operation with vector type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>atom{.sem}{.scope}{.global}.add{.level::cache_hint}.vec_32_bit.f32                  d, [a], b{, cache-policy};
atom{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_16_bit.half_word_type  d, [a], b{, cache-policy};
atom{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_32_bit.packed_type     d, [a], b{, cache-policy};

.sem =               { .relaxed, .acquire, .release, .acq_rel };
.scope =             { .cta, .cluster, .gpu, .sys };
.op =                { .add, .min, .max };
.half_word_type =    { .f16, .bf16 };
.packed_type =       { .f16x2, .bf16x2 };
.vec_16_bit =        { .v2, .v4, .v8 }
.vec_32_bit =        { .v2, .v4 };
.level::cache_hint = { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Atomically loads the original value at location <code class="docutils literal notranslate"><span class="pre">a</span></code> into destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>, performs a
reduction operation with operand <code class="docutils literal notranslate"><span class="pre">b</span></code> and the value in location <code class="docutils literal notranslate"><span class="pre">a</span></code>, and stores the result of the
specified operation at location <code class="docutils literal notranslate"><span class="pre">a</span></code>, overwriting the original value. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> specifies a
location in the specified state space. If no state space is given, perform the memory accesses using
<a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>. <code class="docutils literal notranslate"><span class="pre">atom</span></code> with scalar type may be used only
with <code class="docutils literal notranslate"><span class="pre">.global</span></code> and <code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces and with generic addressing, where the address points to
<code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared</span></code> space. <code class="docutils literal notranslate"><span class="pre">atom</span></code> with vector type may be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> space
and with generic addressing where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> space.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">atom</span></code> with vector type, operands <code class="docutils literal notranslate"><span class="pre">d</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> are brace-enclosed vector expressions, size
of which is equal to the size of vector qualifier.</p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent,
<code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> is assumed by default.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier specifies the set of threads that can directly observe the memory
synchronizing effect of this operation, as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is absent, <code class="docutils literal notranslate"><span class="pre">.gpu</span></code> scope is
assumed by default.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">atom</span></code> with vector type, the supported combinations of vector qualifier and types, and atomic
operations supported on these combinations are depicted in the following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 32%">
<col style="width: 32%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Vector qualifier</p></th>
<th class="head" colspan="3"><p>Types</p></th>
</tr>
<tr class="row-even">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>/ <code class="docutils literal notranslate"><span class="pre">bf16</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/ <code class="docutils literal notranslate"><span class="pre">bf16x2</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.v4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p>Not supported</p></td>
<td><p>Not Supported</p></td>
</tr>
</tbody>
</table>
<p>Two atomic operations (<code class="docutils literal notranslate"><span class="pre">atom</span></code> or <code class="docutils literal notranslate"><span class="pre">red</span></code>) are performed atomically with respect to each other only
if each operation specifies a scope that includes the other. When this condition is not met, each
operation observes the other operation being performed as if it were split into a read followed by a
dependent write.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom</span></code> instruction on packed type or vector type, accesses adjacent scalar elements in memory. In
such cases, the atomicity is guaranteed separately for each of the individual scalar elements; the
entire <code class="docutils literal notranslate"><span class="pre">atom</span></code> is not guaranteed to be atomic as a single access.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> and earlier architectures, <code class="docutils literal notranslate"><span class="pre">atom</span></code> operations on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space do not
guarantee atomicity with respect to normal store instructions to the same address. It is the
programmerâ€™s responsibility to guarantee correctness of programs that use shared memory atomic
instructions, e.g., by inserting barriers between normal stores and atomic operations to a common
address, or by using atom.exch to store to locations accessed by other atomic operations.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a></p>
<p>The bit-size operations are <code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code>, <code class="docutils literal notranslate"><span class="pre">.cas</span></code> (compare-and-swap), and <code class="docutils literal notranslate"><span class="pre">.exch</span></code>
(exchange).</p>
<p>The integer operations are <code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code>. The <code class="docutils literal notranslate"><span class="pre">.inc</span></code> and
<code class="docutils literal notranslate"><span class="pre">.dec</span></code> operations return a result in the range <code class="docutils literal notranslate"><span class="pre">[0..b]</span></code>.</p>
<p>The floating-point operation <code class="docutils literal notranslate"><span class="pre">.add</span></code> operation rounds to nearest even. Current implementation of
<code class="docutils literal notranslate"><span class="pre">atom.add.f32</span></code> on global memory flushes subnormal inputs and results to sign-preserving zero;
whereas <code class="docutils literal notranslate"><span class="pre">atom.add.f32</span></code> on shared memory supports subnormal inputs and results and doesnâ€™t flush
them to zero.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">atom.add.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">atom.add.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">atom.add.bf16x2</span></code> operation requires
the <code class="docutils literal notranslate"><span class="pre">.noftz</span></code> qualifier; it preserves subnormal inputs and results, and does not flush them to
zero.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and for generic
addressing where the address points to the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>atomic {
    d = *a;
    *a = (operation == cas) ? operation(*a, b, c)
                            : operation(*a, b);
}
where
    inc(r, s)  = (r &gt;= s) ? 0 : r+1;
    dec(r, s)  = (r==0 || r &gt; s)  ? s : r-1;
    exch(r, s) =  s;
    cas(r,s,t) = (r == s) ? t : r;
</pre></div>
</div>
<p class="rubric">Notes</p>
<p>Simple reductions may be specified by using the <em>bit bucket</em> destination operand <code class="docutils literal notranslate"><span class="pre">_</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>32-bit atom.global introduced in PTX ISA version 1.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.shared</span></code> and 64-bit <code class="docutils literal notranslate"><span class="pre">atom.global.{add,cas,exch}</span></code> introduced in PTX ISA 1.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.f32</span></code> and 64-bit <code class="docutils literal notranslate"><span class="pre">atom.shared.{add,cas,exch}</span></code> introduced in PTX ISA 2.0.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">atom.{and,or,xor,min,max}</span></code> introduced in PTX ISA 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.f64</span></code> introduced in PTX ISA 5.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier introduced in PTX ISA 5.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.f16x2</span></code> introduced in PTX ISA 6.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">atom.cas.b16</span></code> introduced in PTX ISA 6.3.</p>
<p>Per-element atomicity of <code class="docutils literal notranslate"><span class="pre">atom.f16x2</span></code> clarified in PTX ISA version 6.3, with retrospective effect
from PTX ISA version 6.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier introduced in PTX ISA version 7.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">atom.add.noftz.bf16x2</span></code> introduced in PTX ISA 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for vector types introduced in PTX ISA version 8.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scope with <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type introduced in PTX ISA version 8.4.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.global</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_11</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.shared</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> or higher.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">atom.global.{add,cas,exch}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> or higher.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">atom.shared.{add,cas,exch}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">atom.{and,or,xor,min,max}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Use of generic addressing requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.f16x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">atom.cas.b16</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">atom.add.noftz.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">atom.add.noftz.bf16x2</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for vector types requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>atom.global.add.s32  d,[a],1;
atom.shared::cta.max.u32  d,[x+4],0;
@p  atom.global.cas.b32  d,[p],my_val,my_new_val;
atom.global.sys.add.u32 d, [a], 1;
atom.global.acquire.sys.inc.u32 ans, [gbl], %r0;
atom.add.noftz.f16x2 d, [a], b;
atom.add.noftz.f16   hd, [ha], hb;
atom.global.cas.b16  hd, [ha], hb, hc;
atom.add.noftz.bf16   hd, [a], hb;
atom.add.noftz.bf16x2 bd, [b], bb;
atom.add.shared::cluster.noftz.f16   hd, [ha], hb;
atom.shared.b128.cas d, a, b, c; // 128-bit atom
atom.global.b128.exch d, a, b;   // 128-bit atom

atom.global.cluster.relaxed.add.u32 d, [a], 1;

createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.25;
atom.global.add.L2::cache_hint.s32  d, [a], 1, cache-policy;

atom.global.v8.f16.max.noftz  {%hd0, %hd1, %hd2, %hd3, %hd4, %hd5, %hd6, %hd7}, [gbl],
                                              {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};
atom.global.v8.bf16.add.noftz  {%hd0, %hd1, %hd2, %hd3, %hd4, %hd5, %hd6, %hd7}, [gbl],
                                              {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};
atom.global.v2.f16.add.noftz  {%hd0, %hd1}, [gbl], {%h0, %h1};
atom.global.v2.bf16.add.noftz  {%hd0, %hd1}, [gbl], {%h0, %h1};
atom.global.v4.b16x2.min.noftz  {%hd0, %hd1, %hd2, %hd3}, [gbl], {%h0, %h1, %h2, %h3};
atom.global.v4.f32.add  {%f0, %f1, %f2, %f3}, [gbl], {%f0, %f1, %f2, %f3};
atom.global.v2.f16x2.min.noftz  {%bd0, %bd1}, [g], {%b0, %b1};
atom.global.v2.bf16x2.max.noftz  {%bd0, %bd1}, [g], {%b0, %b1};
atom.global.v2.f32.add  {%f0, %f1}, [g], {%f0, %f1};
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-red">
<span id="id325"></span><h4>
<span class="section-number">9.7.13.6. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-red">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">red</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-red" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">red</span></code></p>
<p>Reduction operations on global and shared memory.</p>
<p class="rubric">Syntax</p>
<p>Reduction operation with scalar type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>red{.sem}{.scope}{.space}.op{.level::cache_hint}.type          [a], b{, cache-policy};

red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16    [a], b{, cache-policy};

red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.f16x2  [a], b{, cache-policy};

red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16
                                                      [a], b {, cache-policy};

red{.sem}{.scope}{.space}.add.noftz{.level::cache_hint}.bf16x2
                                                      [a], b {, cache-policy};

.space =              { .global, .shared{::cta, ::cluster} };
.sem =                {.relaxed, .release};
.scope =              {.cta, .cluster, .gpu, .sys};

.op =                 { .and, .or, .xor,
                        .add, .inc, .dec,
                        .min, .max };
.level::cache_hint =  { .L2::cache_hint };
.type =               { .b32, .b64, .u32, .u64, .s32, .s64, .f32, .f64 };
</pre></div>
</div>
<p>Reduction operation with vector type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>red{.sem}{.scope}{.global}.add{.level::cache_hint}.vec_32_bit.f32 [a], b{, cache-policy};
red{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}. vec_16_bit.half_word_type [a], b{, cache-policy};
red{.sem}{.scope}{.global}.op.noftz{.level::cache_hint}.vec_32_bit.packed_type [a], b {, cache-policy};

.sem =                { .relaxed, .release };
.scope =              { .cta, .cluster, .gpu, .sys };
.op =                 { .add, .min, .max };
.half_word_type =     { .f16, .bf16 };
.packed_type =        { .f16x2,.bf16x2 };
.vec_16_bit =         { .v2, .v4, .v8 }
.vec_32_bit =         { .v2, .v4 };
.level::cache_hint =  { .L2::cache_hint }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Performs a reduction operation with operand <code class="docutils literal notranslate"><span class="pre">b</span></code> and the value in location <code class="docutils literal notranslate"><span class="pre">a</span></code>, and stores the
result of the specified operation at location <code class="docutils literal notranslate"><span class="pre">a</span></code>, overwriting the original value. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code>
specifies a location in the specified state space. If no state space is given, perform the memory
accesses using <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>. <code class="docutils literal notranslate"><span class="pre">red</span></code> with scalar type may
be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> and <code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces and with generic addressing, where the address
points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared</span></code> space. <code class="docutils literal notranslate"><span class="pre">red</span></code> with vector type may be used only with
<code class="docutils literal notranslate"><span class="pre">.global</span></code> space and with generic addressing where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> space.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">red</span></code> with vector type, operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is brace-enclosed vector expressions, size of which is
equal to the size of vector qualifier.</p>
<p>If no sub-qualifier is specified with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then <code class="docutils literal notranslate"><span class="pre">::cta</span></code> is assumed by default.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent,
<code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> is assumed by default.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier specifies the set of threads that can directly observe the memory
synchronizing effect of this operation, as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is absent, <code class="docutils literal notranslate"><span class="pre">.gpu</span></code> scope is
assumed by default.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">red</span></code> with vector type, the supported combinations of vector qualifier, types and reduction
operations supported on these combinations are depicted in following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 32%">
<col style="width: 32%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Vector qualifier</p></th>
<th class="head" colspan="3"><p>Types</p></th>
</tr>
<tr class="row-even">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>/ <code class="docutils literal notranslate"><span class="pre">bf16</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/ <code class="docutils literal notranslate"><span class="pre">bf16x2</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.v4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.v8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code></p></td>
<td><p>Not supported</p></td>
<td><p>Not Supported</p></td>
</tr>
</tbody>
</table>
<p>Two atomic operations (<code class="docutils literal notranslate"><span class="pre">atom</span></code> or <code class="docutils literal notranslate"><span class="pre">red</span></code>) are performed atomically with respect to each other only
if each operation specifies a scope that includes the other. When this condition is not met, each
operation observes the other operation being performed as if it were split into a read followed by a
dependent write.</p>
<p><code class="docutils literal notranslate"><span class="pre">red</span></code> instruction on packed type or vector type, accesses adjacent scalar elements in memory. In
such case, the atomicity is guaranteed separately for each of the individual scalar elements; the
entire <code class="docutils literal notranslate"><span class="pre">red</span></code> is not guaranteed to be atomic as a single access.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> and earlier architectures, <code class="docutils literal notranslate"><span class="pre">red</span></code> operations on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space do not
guarantee atomicity with respect to normal store instructions to the same address. It is the
programmerâ€™s responsibility to guarantee correctness of programs that use shared memory reduction
instructions, e.g., by inserting barriers between normal stores and reduction operations to a common
address, or by using <code class="docutils literal notranslate"><span class="pre">atom.exch</span></code> to store to locations accessed by other reduction operations.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and alignment requirements are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a></p>
<p>The bit-size operations are <code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, and <code class="docutils literal notranslate"><span class="pre">.xor</span></code>.</p>
<p>The integer operations are <code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.inc</span></code>, <code class="docutils literal notranslate"><span class="pre">.dec</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code>, <code class="docutils literal notranslate"><span class="pre">.max</span></code>. The <code class="docutils literal notranslate"><span class="pre">.inc</span></code> and
<code class="docutils literal notranslate"><span class="pre">.dec</span></code> operations return a result in the range <code class="docutils literal notranslate"><span class="pre">[0..b]</span></code>.</p>
<p>The floating-point operation <code class="docutils literal notranslate"><span class="pre">.add</span></code> operation rounds to nearest even. Current implementation of
<code class="docutils literal notranslate"><span class="pre">red.add.f32</span></code> on global memory flushes subnormal inputs and results to sign-preserving zero;
whereas <code class="docutils literal notranslate"><span class="pre">red.add.f32</span></code> on shared memory supports subnormal inputs and results and doesnâ€™t flush
them to zero.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">red.add.f16x2</span></code>, <code class="docutils literal notranslate"><span class="pre">red.add.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">red.add.bf16x2</span></code> operation requires the
<code class="docutils literal notranslate"><span class="pre">.noftz</span></code> qualifier; it preserves subnormal inputs and results, and does not flush them to zero.</p>
<p>When the optional argument <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is specified, the qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is
required. The 64-bit operand <code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> specifies the cache eviction policy that may be used
during the memory access.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> is only supported for <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space and for generic
addressing where the address points to the <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space.</p>
<p><code class="docutils literal notranslate"><span class="pre">cache-policy</span></code> is a hint to the cache subsystem and may not always be respected. It is treated as
a performance hint only, and does not change the memory consistency behavior of the program.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>*a = operation(*a, b);

where
    inc(r, s) = (r &gt;= s) ? 0 : r+1;
    dec(r, s) = (r==0 || r &gt; s)  ? s : r-1;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">red.shared.add.u64</span></code> introduced in PTX ISA 2.0.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">red.{and,or,xor,min,max}</span></code> introduced in PTX ISA 3.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.f64</span></code> introduced in PTX ISA 5.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier introduced in PTX ISA 5.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.f16x2</span></code> introduced in PTX ISA 6.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.f16</span></code> introduced in PTX ISA 6.3.</p>
<p>Per-element atomicity of <code class="docutils literal notranslate"><span class="pre">red.f16x2</span></code> clarified in PTX ISA version 6.3, with retrospective effect
from PTX ISA version 6.2</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier introduced in PTX ISA version 7.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">red.add.noftz.bf16x2</span></code> introduced in PTX ISA 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifiers introduced in PTX ISA version 7.8.</p>
<p>Support for vector types introduced in PTX ISA version 8.1.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">red.global</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_11</span></code> or higher</p>
<p><code class="docutils literal notranslate"><span class="pre">red.shared</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.global.add.u64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.shared.add.u64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p>64-bit <code class="docutils literal notranslate"><span class="pre">red.{and,or,xor,min,max}</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.f64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Use of generic addressing requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.f16x2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.f16</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">red.add.noftz.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">red.add.noftz.bf16x2</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for vector types requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>red.global.add.s32  [a],1;
red.shared::cluster.max.u32  [x+4],0;
@p  red.global.and.b32  [p],my_val;
red.global.sys.add.u32 [a], 1;
red.global.acquire.sys.add.u32 [gbl], 1;
red.add.noftz.f16x2 [a], b;
red.add.noftz.bf16   [a], hb;
red.add.noftz.bf16x2 [b], bb;
red.global.cluster.relaxed.add.u32 [a], 1;
red.shared::cta.min.u32  [x+4],0;

createpolicy.fractional.L2::evict_last.b64 cache-policy, 0.25;
red.global.and.L2::cache_hint.b32 [a], 1, cache-policy;

red.global.v8.f16.add.noftz  [gbl], {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};
red.global.v8.bf16.min.noftz [gbl], {%h0, %h1, %h2, %h3, %h4, %h5, %h6, %h7};
red.global.v2.f16.add.noftz [gbl], {%h0, %h1};
red.global.v2.bf16.add.noftz [gbl], {%h0, %h1};
red.global.v4.f16x2.max.noftz [gbl], {%h0, %h1, %h2, %h3};
red.global.v4.f32.add  [gbl], {%f0, %f1, %f2, %f3};
red.global.v2.f16x2.max.noftz {%bd0, %bd1}, [g], {%b0, %b1};
red.global.v2.bf16x2.add.noftz {%bd0, %bd1}, [g], {%b0, %b1};
red.global.v2.f32.add  {%f0, %f1}, [g], {%f0, %f1};
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-red-async">
<span id="id326"></span><h4>
<span class="section-number">9.7.13.7. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-red-async">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">red.async</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-red-async" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">red.async</span></code></p>
<p>Asynchronous reduction operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Increment and Decrement reductions
red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];

.sem  =                 { .relaxed };
.scope =                { .cluster };
.ss   =                 { .shared::cluster };
.op   =                 { .inc, .dec };
.type =                 { .u32 };
.completion_mechanism = { .mbarrier::complete_tx::bytes };


// MIN and MAX reductions
red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];

.sem  = { .relaxed };
.scope = { .cluster };
.ss   = { .shared::cluster };
.op   = { .min, .max };
.type = { .u32, .s32 };
.completion_mechanism = { .mbarrier::complete_tx::bytes };

// Bitwise AND, OR and XOR reductions
red.async.sem.scope{.ss}.completion_mechanism.op.type [a], b, [mbar];

.sem  = { .relaxed };
.scope = { .cluster };
.ss   = { .shared::cluster };
.op   = { .and, .or, .xor };
.type = { .b32 };
.completion_mechanism = { .mbarrier::complete_tx::bytes };

// ADD reductions
red.async.sem.scope{.ss}.completion_mechanism.add.type [a], b, [mbar];

.sem  = { .relaxed };
.scope = { .cluster };
.ss   = { .shared::cluster };
.type = { .u32, .s32, .u64 };
.completion_mechanism = { .mbarrier::complete_tx::bytes };

red.async{.mmio}.sem.scope{.ss}.add.type [a], b;

.sem  = { .release };
.scope = { .gpu, .cluster };
.ss   = { .global };
.type = { .u32, .s32, .u64, .s64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">red.async</span></code> is a non-blocking instruction which initiates an asynchronous reduction operation
specified by <code class="docutils literal notranslate"><span class="pre">.op</span></code>, with the operand <code class="docutils literal notranslate"><span class="pre">b</span></code> and the value at destination shared memory location
specified by operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p class="rubric">Operands</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">a</span></code> is a destination address, and must be either a register, or of the form
<code class="docutils literal notranslate"><span class="pre">register</span> <span class="pre">+</span> <span class="pre">immOff</span></code>, as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">b</span></code> is a source value, of the type indicated by qualifier <code class="docutils literal notranslate"><span class="pre">.type</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbar</span></code> is an mbarrier object address.</p></li>
</ul>
<p class="rubric">Qualifiers</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> indicates whether this is an <a class="reference internal" href="#mmio-operation"><span class="std std-ref">mmio Operation</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.sem</span></code> specifies the memory ordering semantics as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.scope</span></code> specifies the set of threads with which this instruction can
directly synchronize.</p></li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.ss</span></code> specifies the state space of the destination operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and the
mbarrier operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.</p>
<ul>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>
is used.</p></li>
</ul>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies the mechanism for observing the
completion of the asynchronous operation.</p>
<ul>
<li><p>When <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code>: upon
completion of the asynchronous operation, a
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation will be performed on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>,
with <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to the amount of data stored in bytes.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is not specified: the completion of the store
synchronizes with the end of the CTA.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p></li>
</ul>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.op</span></code> specifies the reduction operation.</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">.inc</span></code> and <code class="docutils literal notranslate"><span class="pre">.dec</span></code> operations return a result in the range <code class="docutils literal notranslate"><span class="pre">[0..b]</span></code>.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">.type</span></code> specifies the type of the source operand <code class="docutils literal notranslate"><span class="pre">b</span></code>.</p></li>
</ul>
<p class="rubric">Conditions</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.sem</span></code> is <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code>:</p>
<ul>
<li><p>The reduce operation is a relaxed memory operation.</p></li>
<li><p>The complete-tx operation on the mbarrier has <code class="docutils literal notranslate"><span class="pre">.release</span></code>
semantics at <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope.</p></li>
<li>
<p>The shared-memory addresses of the destination operand <code class="docutils literal notranslate"><span class="pre">a</span></code> and the
mbarrier operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code> must meet all of the following conditions:</p>
<ul class="simple">
<li><p>They belong to the same CTA.</p></li>
<li><p>The CTA to which they belong is different from the CTA of the executing thread,
but must be within the same cluster.</p></li>
</ul>
<p>Otherwise, the behavior is undefined.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> must not be specified.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is specified, it must be <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, generic addressing is used for operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.
If the generic addresses specified do not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space, the behavior is undefined.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is specified, it must be <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is not specified, it defaults to <code class="docutils literal notranslate"><span class="pre">.mbarrier::complete_tx::bytes</span></code>.</p></li>
</ul>
<p>When <code class="docutils literal notranslate"><span class="pre">.sem</span></code> is <code class="docutils literal notranslate"><span class="pre">.release</span></code>:</p>
<ul class="simple">
<li><p>The reduce operation is a strong memory operation with <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics
at the scope specified by <code class="docutils literal notranslate"><span class="pre">.scope</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> is specified, <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be <code class="docutils literal notranslate"><span class="pre">.sys</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is specified, it must be <code class="docutils literal notranslate"><span class="pre">.global</span></code>.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.ss</span></code> is not specified, generic addressing is used for operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.
If the generic address specified does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.global</span></code> state space, the behavior is undefined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> must not be specified.</p></li>
</ul>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier, <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics, <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space,
and <code class="docutils literal notranslate"><span class="pre">.gpu</span></code> and <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scopes introduced in PTX ISA version 8.7.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier, <code class="docutils literal notranslate"><span class="pre">.release</span></code> semantics, <code class="docutils literal notranslate"><span class="pre">.global</span></code> state space,
and <code class="docutils literal notranslate"><span class="pre">.gpu</span></code> and <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scopes require <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>red.async.relaxed.cluster.shared::cluster.mbarrier::complete_tx::bytes.min.u32 [addr], b, [mbar_addr];

red.async.release.sys.global.add.u32 [addr], b;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-vote">
<span id="id327"></span><h4>
<span class="section-number">9.7.13.8. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-vote">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">vote</span></code> (deprecated)</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-vote" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vote</span></code> (deprecated)</p>
<p>Vote across thread group.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vote.mode.pred  d, {!}a;
vote.ballot.b32 d, {!}a;  // 'ballot' form, returns bitmask

.mode = { .all, .any, .uni };
</pre></div>
</div>
<p class="rubric">Deprecation Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">vote</span></code> instruction without a <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier is deprecated in PTX ISA version 6.0.</p>
<ul class="simple">
<li><p>Support for this instruction with <code class="docutils literal notranslate"><span class="pre">.target</span></code> lower than <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> may be removed in a future PTX
ISA version.</p></li>
</ul>
<p class="rubric">Removal Note</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">vote</span></code> instruction without a <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier is removed in PTX ISA version 6.4 for
<code class="docutils literal notranslate"><span class="pre">.target</span></code> <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Description</p>
<p>Performs a reduction of the source predicate across all active threads in a warp. The destination
predicate value is the same across all threads in the warp.</p>
<p>The reduction modes are:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.all</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate is <code class="docutils literal notranslate"><span class="pre">True</span></code> for all active threads in warp. Negate the source
predicate to compute <code class="docutils literal notranslate"><span class="pre">.none</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.any</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate is <code class="docutils literal notranslate"><span class="pre">True</span></code> for some active thread in warp. Negate the source
predicate to compute <code class="docutils literal notranslate"><span class="pre">.not_all</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.uni</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate has the same value in all active threads in warp. Negating the
source predicate also computes <code class="docutils literal notranslate"><span class="pre">.uni</span></code>.</p>
</dd>
</dl>
<p>In the <em>ballot</em> form, <code class="docutils literal notranslate"><span class="pre">vote.ballot.b32</span></code> simply copies the predicate from each thread in a warp
into the corresponding bit position of destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>, where the bit position
corresponds to the threadâ€™s lane id.</p>
<p>An inactive thread in warp will contribute a 0 for its entry when participating in
<code class="docutils literal notranslate"><span class="pre">vote.ballot.b32</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.2.</p>
<p>Deprecated in PTX ISA version 6.0 in favor of <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code>.</p>
<p>Not supported in PTX ISA version 6.4 for .target <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vote</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">vote.ballot.b32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">vote</span></code> is not supported on <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher starting PTX ISA version 6.4.</p>
<p class="rubric">Release Notes</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">vote</span></code> applies to threads in a single warp, not across an entire CTA.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vote.all.pred    p,q;
vote.uni.pred    p,q;
vote.ballot.b32  r1,p;  // get 'ballot' across warp
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-vote-sync">
<span id="id328"></span><h4>
<span class="section-number">9.7.13.9. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-vote-sync">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-vote-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vote.sync</span></code></p>
<p>Vote across thread group.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vote.sync.mode.pred  d, {!}a, membermask;
vote.sync.ballot.b32 d, {!}a, membermask;  // 'ballot' form, returns bitmask

.mode = { .all, .any, .uni };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">vote.sync</span></code> will cause executing thread to wait until all non-exited threads corresponding to
<code class="docutils literal notranslate"><span class="pre">membermask</span></code> have executed <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code> with the same qualifiers and same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> value
before resuming execution.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to threadâ€™s <code class="docutils literal notranslate"><span class="pre">laneid</span></code>. Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> is a
predicate register.</p>
<p>In the <em>mode</em> form, <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code> performs a reduction of the source predicate across all non-exited
threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>. The destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is a predicate register and its value is
the same across all threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p>The reduction modes are:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.all</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate is <code class="docutils literal notranslate"><span class="pre">True</span></code> for all non-exited threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>. Negate the
source predicate to compute <code class="docutils literal notranslate"><span class="pre">.none</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.any</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate is <code class="docutils literal notranslate"><span class="pre">True</span></code> for some thread in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>. Negate the source
predicate to compute <code class="docutils literal notranslate"><span class="pre">.not_all</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.uni</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">True</span></code> if source predicate has the same value in all non-exited threads in
<code class="docutils literal notranslate"><span class="pre">membermask</span></code>. Negating the source predicate also computes <code class="docutils literal notranslate"><span class="pre">.uni</span></code>.</p>
</dd>
</dl>
<p>In the <em>ballot</em> form, the destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is a <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register. In this form,
<code class="docutils literal notranslate"><span class="pre">vote.sync.ballot.b32</span></code> simply copies the predicate from each thread in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> into the
corresponding bit position of destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>, where the bit position corresponds to the
threadâ€™s lane id.</p>
<p>A thread not specified in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> will contribute a 0 for its entry in
<code class="docutils literal notranslate"><span class="pre">vote.sync.ballot.b32</span></code>.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code> is undefined if the executing thread is not in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For .target <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code> or below, all threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> must execute the same <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code>
instruction in convergence, and only threads belonging to some <code class="docutils literal notranslate"><span class="pre">membermask</span></code> can be active when
the <code class="docutils literal notranslate"><span class="pre">vote.sync</span></code> instruction is executed. Otherwise, the behavior is undefined.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vote.sync.all.pred    p,q,0xffffffff;
vote.sync.ballot.b32  r1,p,0xffffffff;  // get 'ballot' across warp
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-match-sync">
<span id="id329"></span><h4>
<span class="section-number">9.7.13.10. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-match-sync">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">match.sync</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-match-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">match.sync</span></code></p>
<p>Broadcast and compare a value across threads in warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>match.any.sync.type  d, a, membermask;
match.all.sync.type  d[|p], a, membermask;

.type = { .b32, .b64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">match.sync</span></code> will cause executing thread to wait until all non-exited threads from <code class="docutils literal notranslate"><span class="pre">membermask</span></code>
have executed <code class="docutils literal notranslate"><span class="pre">match.sync</span></code> with the same qualifiers and same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> value before resuming
execution.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to threadâ€™s laneid.</p>
<p><code class="docutils literal notranslate"><span class="pre">match.sync</span></code> performs broadcast and compare of operand <code class="docutils literal notranslate"><span class="pre">a</span></code> across all non-exited threads in
<code class="docutils literal notranslate"><span class="pre">membermask</span></code> and sets destination <code class="docutils literal notranslate"><span class="pre">d</span></code> and optional predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> based on mode.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has instruction type and <code class="docutils literal notranslate"><span class="pre">d</span></code> has <code class="docutils literal notranslate"><span class="pre">.b32</span></code> type.</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is a 32-bit mask where bit position in mask corresponds to threadâ€™s laneid.</p>
<p>The matching operation modes are:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.all</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">d</span></code> is set to mask corresponding to non-exited threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> if all non-exited
threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> have same value of operand <code class="docutils literal notranslate"><span class="pre">a</span></code>; otherwise <code class="docutils literal notranslate"><span class="pre">d</span></code> is set
to 0. Optionally predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to true if all non-exited threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> have
same value of operand <code class="docutils literal notranslate"><span class="pre">a</span></code>; otherwise <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to false. The sink symbol â€˜_â€™ may be used in
place of any one of the destination operands.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.any</span></code></dt>
<dd>
<p><code class="docutils literal notranslate"><span class="pre">d</span></code> is set to mask of non-exited threads in <code class="docutils literal notranslate"><span class="pre">membermask</span></code> that have same value of operand
<code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
</dd>
</dl>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">match.sync</span></code> is undefined if the executing thread is not in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Release Notes</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">match.sync</span></code> applies to threads in a single warp, not across an entire CTA.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>match.any.sync.b32    d, a, 0xffffffff;
match.all.sync.b64    d|p, a, mask;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-activemask">
<span id="id330"></span><h4>
<span class="section-number">9.7.13.11. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-activemask">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">activemask</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-activemask" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">activemask</span></code></p>
<p>Queries the active threads within a warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>activemask.b32 d;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">activemask</span></code> queries predicated-on active threads from the executing warp and sets the destination
<code class="docutils literal notranslate"><span class="pre">d</span></code> with 32-bit integer mask where bit position in the mask corresponds to the threadâ€™s
<code class="docutils literal notranslate"><span class="pre">laneid</span></code>.</p>
<p>Destination <code class="docutils literal notranslate"><span class="pre">d</span></code> is a 32-bit destination register.</p>
<p>An active thread will contribute 1 for its entry in the result and exited or inactive or
predicated-off thread will contribute 0 for its entry in the result.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>activemask.b32  %r1;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-redux-sync">
<span id="id331"></span><h4>
<span class="section-number">9.7.13.12. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-redux-sync">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-redux-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">redux.sync</span></code></p>
<p>Perform reduction operation on the data from each predicated active thread in the thread group.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>redux.sync.op.type dst, src, membermask;
.op   = {.add, .min, .max}
.type = {.u32, .s32}

redux.sync.op.b32 dst, src, membermask;
.op   = {.and, .or, .xor}

redux.sync.op{.abs.}{.NaN}.f32 dst, src, membermask;
.op   = { .min, .max }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> will cause the executing thread to wait until all non-exited threads corresponding to
<code class="docutils literal notranslate"><span class="pre">membermask</span></code> have executed <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> with the same qualifiers and same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> value
before resuming execution.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer which is a mask indicating threads participating
in this instruction where the bit position corresponds to threadâ€™s <code class="docutils literal notranslate"><span class="pre">laneid</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> performs a reduction operation <code class="docutils literal notranslate"><span class="pre">.op</span></code> of the 32 bit source register <code class="docutils literal notranslate"><span class="pre">src</span></code> across
all non-exited threads in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>. The result of the reduction operation is written to
the 32 bit destination register <code class="docutils literal notranslate"><span class="pre">dst</span></code>.</p>
<p>Reduction operation can be one of the bitwise operation in <code class="docutils literal notranslate"><span class="pre">.and</span></code>, <code class="docutils literal notranslate"><span class="pre">.or</span></code>, <code class="docutils literal notranslate"><span class="pre">.xor</span></code> or arithmetic
operation in <code class="docutils literal notranslate"><span class="pre">.add</span></code>, <code class="docutils literal notranslate"><span class="pre">.min</span></code> , <code class="docutils literal notranslate"><span class="pre">.max</span></code>.</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">.add</span></code> operation result is truncated to 32 bits.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f32</span></code> instruction type, if the input value is 0.0 then +0.0 &gt; -0.0.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.abs</span></code> qualifier is specified, then the absolute value of the input is considered for the
reduction operation.</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> qualifier is specified, then the result of the reduction operation is canonical NaN
if the input to the reduction operation from any participating thread is NaN.</p>
<p>In the absence of <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> qualifier, only non-NaN values are considered for the reduction operation
and the result will be canonical NaN when all inputs are NaNs.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> is undefined if the executing thread is not in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type is introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.abs</span></code> and <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> qualifiers is introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f32</span></code> type requires <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> and is supported on <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> from PTX ISA version 8.8.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.abs</span></code> and <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> and are supported on <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or
higher in the same family from PTX ISA version 8.8.</p>
<p class="rubric">Release Notes</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> applies to threads in a single warp, not across an entire CTA.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 dst, src, init, mask;
redux.sync.add.s32 dst, src, 0xff;
redux.sync.xor.b32 dst, src, mask;

redux.sync.min.abs.NaN.f32 dst, src, mask;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-griddepcontrol">
<span id="id332"></span><h4>
<span class="section-number">9.7.13.13. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-griddepcontrol">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-griddepcontrol" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code></p>
<p>Control execution of dependent grids.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>griddepcontrol.action;

.action   = { .launch_dependents, .wait }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code> instruction allows the dependent grids and prerequisite grids as defined by
the runtime, to control execution in the following way:</p>
<p><code class="docutils literal notranslate"><span class="pre">.launch_dependents</span></code> modifier signals that specific dependents the runtime system designated to
react to this instruction can be scheduled as soon as all other CTAs in the grid issue the same
instruction or have completed. The dependent may launch before the completion of the current
grid. There is no guarantee that the dependent will launch before the completion of the current
grid. Repeated invocations of this instruction by threads in the current CTA will have no additional
side effects past that of the first invocation.</p>
<p><code class="docutils literal notranslate"><span class="pre">.wait</span></code> modifier causes the executing thread to wait until all prerequisite grids in flight have
completed and all the memory operations from the prerequisite grids are performed and made visible
to the current grid.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the prerequisite grid is using <code class="docutils literal notranslate"><span class="pre">griddepcontrol.launch_dependents</span></code>, then the dependent grid
must use <code class="docutils literal notranslate"><span class="pre">griddepcontrol.wait</span></code> to ensure correct functional execution.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>griddepcontrol.launch_dependents;
griddepcontrol.wait;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-elect-sync">
<span id="id333"></span><h4>
<span class="section-number">9.7.13.14. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-elect-sync">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">elect.sync</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-elect-sync" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">elect.sync</span></code></p>
<p>Elect a leader thread from a set of threads.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>elect.sync d|p, membermask;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">elect.sync</span></code> elects one predicated active leader thread from among a set of threads specified by
<code class="docutils literal notranslate"><span class="pre">membermask</span></code>. <code class="docutils literal notranslate"><span class="pre">laneid</span></code> of the elected thread is returned in the 32-bit destination operand
<code class="docutils literal notranslate"><span class="pre">d</span></code>. The sink symbol â€˜_â€™ can be used for destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code>. The predicate destination
<code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code> for the leader thread, and <code class="docutils literal notranslate"><span class="pre">False</span></code> for all other threads.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">membermask</span></code> specifies a 32-bit integer indicating the set of threads from which a leader
is to be elected. The behavior is undefined if the executing thread is not in <code class="docutils literal notranslate"><span class="pre">membermask</span></code>.</p>
<p>Election of a leader thread happens deterministically, i.e. the same leader thread is elected for
the same <code class="docutils literal notranslate"><span class="pre">membermask</span></code> every time.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">elect</span></code> causes the executing thread to wait until
all threads in the <code class="docutils literal notranslate"><span class="pre">membermask</span></code> execute the <code class="docutils literal notranslate"><span class="pre">elect</span></code> instruction before resuming execution.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>elect.sync    %r0|%p0, 0xffffffff;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier">
<span id="id334"></span><h4>
<span class="section-number">9.7.13.15. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier" title="Permalink to this headline">ïƒ</a>
</h4>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> is a barrier created in shared memory that supports :</p>
<ul class="simple">
<li><p>Synchronizing any subset of threads within a CTA</p></li>
<li><p>One-way synchronization of threads across CTAs of a cluster. As noted in
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-smem"><span class="std std-ref">mbarrier support with shared memory</span></a>, threads can
perform only <em>arrive</em> operations but not <em>*_wait</em> on an mbarrier located in <code class="docutils literal notranslate"><span class="pre">shared::cluster</span></code>
space.</p></li>
<li><p>Waiting for completion of asynchronous memory operations initiated by a thread and making them
visible to other threads.</p></li>
</ul>
<p>An <em>mbarrier object</em> is an opaque object in memory which can be initialized and invalidated using :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code></p></li>
</ul>
<p>Operations supported on <em>mbarrier object</em>s are :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code></p></li>
</ul>
<p>Performing any <em>mbarrier</em> operation except <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> on an uninitialized <em>mbarrier object</em>
results in undefined behavior.
Performing any <em>non-mbarrier</em> or <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> operations on an initialized <em>mbarrier object</em>
results in undefined behavior.</p>
<p>Unlike <code class="docutils literal notranslate"><span class="pre">bar{.cta}</span></code>/<code class="docutils literal notranslate"><span class="pre">barrier{.cta}</span></code> instructions which can access a limited number of barriers
per CTA, <em>mbarrier objects</em> are user defined and are only limited by the total shared memory size
available.</p>
<p><em>mbarrier</em> operations enable threads to perform useful work after the arrival at the <em>mbarrier</em> and
before waiting for the <em>mbarrier</em> to complete.</p>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-size-alignment">
<span id="id335"></span><h5>
<span class="section-number">9.7.13.15.1. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment">Size and alignment of mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment" title="Permalink to this headline">ïƒ</a>
</h5>
<p>An mbarrier object is an opaque object with the following type and alignment requirements :</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 23%">
<col style="width: 44%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Type</p></th>
<th class="head"><p>Alignment (bytes)</p></th>
<th class="head"><p>Memory space</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b64</span></code></p></td>
<td><p>8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shared</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-contents">
<span id="id336"></span><h5>
<span class="section-number">9.7.13.15.2. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents">Contents of the mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents" title="Permalink to this headline">ïƒ</a>
</h5>
<p>An opaque <em>mbarrier object</em> keeps track of the following information :</p>
<ul class="simple">
<li><p>Current phase of the <em>mbarrier object</em></p></li>
<li><p>Count of pending arrivals for the current phase of the <em>mbarrier object</em></p></li>
<li><p>Count of expected arrivals for the next phase of the <em>mbarrier object</em></p></li>
<li><p>Count of pending asynchronous memory operations (or transactions) tracked by the current phase of
the <em>mbarrier object</em>. This is also referred to as <em>tx-count</em>.</p></li>
</ul>
<p>An <em>mbarrier object</em> progresses through a sequence of phases where each phase is defined by threads
performing an expected number of
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a>
operations.</p>
<p>The valid range of each of the counts is as shown below:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 38%">
<col style="width: 33%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Count name</p></th>
<th class="head"><p>Minimum value</p></th>
<th class="head"><p>Maximum value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Expected arrival count</p></td>
<td><p>1</p></td>
<td><p>2<sup>20</sup> - 1</p></td>
</tr>
<tr class="row-odd">
<td><p>Pending arrival count</p></td>
<td><p>0</p></td>
<td><p>2<sup>20</sup> - 1</p></td>
</tr>
<tr class="row-even">
<td><p>tx-count</p></td>
<td><p>-(2<sup>20</sup> - 1)</p></td>
<td><p>2<sup>20</sup> - 1</p></td>
</tr>
</tbody>
</table>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-lifecycle">
<span id="id337"></span><h5>
<span class="section-number">9.7.13.15.3. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-lifecycle">Lifecycle of the mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-lifecycle" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The <em>mbarrier object</em> must be initialized prior to use.</p>
<p>An <em>mbarrier object</em> is used to synchronize threads and asynchronous memory operations.</p>
<p>An <em>mbarrier object</em> may be used to perform a sequence of such synchronizations.</p>
<p>An <em>mbarrier object</em> must be invalidated to repurpose its memory for any purpose,
including repurposing it for another mbarrier object.</p>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-phase">
<span id="id338"></span><h5>
<span class="section-number">9.7.13.15.4. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase">Phase of the mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The phase of an <em>mbarrier object</em> is the number of times the <em>mbarrier object</em> has been used to
synchronize threads and <a class="reference internal" href="#program-order-async-operations"><span class="std std-ref">asynchronous</span></a>
operations. In each phase {0, 1, 2, â€¦}, threads perform in program order :</p>
<ul class="simple">
<li><p><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a>
operations to complete the current phase and</p></li>
<li><p><em>test_wait</em> / <em>try_wait</em> operations to check for the completion of the current phase.</p></li>
</ul>
<p>An <em>mbarrier object</em> is automatically reinitialized upon completion of the current phase for
immediate use in the next phase. The current phase is incomplete and all prior phases are complete.</p>
<p>For each phase of the mbarrier object, at least one <em>test_wait</em> or <em>try_wait</em> operation must be
performed which returns <code class="docutils literal notranslate"><span class="pre">True</span></code> for <code class="docutils literal notranslate"><span class="pre">waitComplete</span></code> before an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a> operation
in the subsequent phase.</p>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations">
<span id="id339"></span><h5>
<span class="section-number">9.7.13.15.5. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations">Tracking asynchronous operations by the mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-tracking-async-operations" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Starting with the Hopper architecture (<code class="docutils literal notranslate"><span class="pre">sm_9x</span></code>), <em>mbarrier object</em> supports a new count, called
<em>tx-count</em>, which is used for tracking the completion of asynchronous memory operations or
transactions. <em>tx-count</em> tracks the number of asynchronous transactions, in units specified by the
asynchronous memory operation, that are outstanding and yet to be complete.</p>
<p>The <em>tx-count</em> of an <em>mbarrier object</em> must be set to the total amount of asynchronous memory
operations, in units as specified by the asynchronous operations, to be tracked by the current
phase. Upon completion of each of the asynchronous operations, the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation will be performed on the <em>mbarrier object</em> and thus progress the mbarrier towards the
completion of the current phase.</p>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation">
<span id="id340"></span><h6>
<span class="section-number">9.7.13.15.5.1. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation">expect-tx operation</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The <em>expect-tx</em> operation, with an <code class="docutils literal notranslate"><span class="pre">expectCount</span></code> argument, increases the <em>tx-count</em> of an
<em>mbarrier object</em> by the value specified by <code class="docutils literal notranslate"><span class="pre">expectCount</span></code>. This sets the current phase of the
<em>mbarrier object</em> to expect and track the completion of additional asynchronous transactions.</p>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation">
<span id="id341"></span><h6>
<span class="section-number">9.7.13.15.5.2. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation">complete-tx operation</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The <em>complete-tx</em> operation, with an <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument, on an <em>mbarrier object</em> consists of the following:</p>
<dl class="simple">
<dt>mbarrier signaling</dt>
<dd>
<p>Signals the completion of asynchronous transactions that were tracked by the current phase. As a
result of this, <em>tx-count</em> is decremented by <code class="docutils literal notranslate"><span class="pre">completeCount</span></code>.</p>
</dd>
<dt>mbarrier potentially completing the current phase</dt>
<dd>
<p>If the current phase has been completed then the mbarrier transitions to the next phase. Refer to
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion"><span class="std std-ref">Phase Completion of the mbarrier object</span></a>
for details on phase completion requirements and phase transition process.</p>
</dd>
</dl>
</section>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-phase-completion">
<span id="id342"></span><h5>
<span class="section-number">9.7.13.15.6. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion">Phase Completion of the mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The requirements for completion of the current phase are described below. Upon completion of the
current phase, the phase transitions to the subsequent phase as described below.</p>
<dl class="simple">
<dt>Current phase completion requirements</dt>
<dd>
<p>An <em>mbarrier object</em> completes the current phase when all of the following conditions are met:</p>
<ul class="simple">
<li><p>The count of the pending arrivals has reached zero.</p></li>
<li><p>The <em>tx-count</em> has reached zero.</p></li>
</ul>
</dd>
<dt>Phase transition</dt>
<dd>
<p>When an <em>mbarrier</em> object completes the current phase, the following actions are performed
atomically:</p>
<ul class="simple">
<li><p>The <em>mbarrier object</em> transitions to the next phase.</p></li>
<li><p>The pending arrival count is reinitialized to the expected arrival count.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-arrive-on">
<span id="id343"></span><h5>
<span class="section-number">9.7.13.15.7. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on">Arrive-on operation on mbarrier object</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on" title="Permalink to this headline">ïƒ</a>
</h5>
<p>An <em>arrive-on</em> operation, with an optional <em>count</em> argument, on an <em>mbarrier object</em> consists of the
following 2 steps :</p>
<ul>
<li>
<p>mbarrier signalling:</p>
<p>Signals the arrival of the executing thread OR completion of the asynchronous instruction which
signals the arrive-on operation initiated by the executing thread on the <em>mbarrier object</em>. As a
result of this, the pending arrival count is decremented by <em>count</em>. If the <em>count</em> argument is
not specified, then it defaults to 1.</p>
</li>
<li>
<p>mbarrier potentially completing the current phase:</p>
<p>If the current phase has been completed then the mbarrier transitions to the next phase. Refer to
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion"><span class="std std-ref">Phase Completion of the mbarrier object</span></a>
for details on phase completion requirements and phase transition process.</p>
</li>
</ul>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-smem">
<span id="id344"></span><h5>
<span class="section-number">9.7.13.15.8. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-smem">mbarrier support with shared memory</a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-smem" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The following table summarizes the support of various mbarrier operations on <em>mbarrier objects</em>
located at different shared memory locations:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 35%">
<col style="width: 23%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>mbarrier operations</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></p></td>
<td><p>Supported</p></td>
<td><p>Supported, cannot return result</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code></p></td>
<td><p>Supported</p></td>
<td><p>Supported</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code></p></td>
<td><p>Supported</p></td>
<td><p>Supported</p></td>
</tr>
<tr class="row-odd">
<td><p>Other mbarrier operations</p></td>
<td><p>Supported</p></td>
<td><p>Not supported</p></td>
</tr>
</tbody>
</table>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-init">
<span id="id345"></span><h5>
<span class="section-number">9.7.13.15.9. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-init">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-init" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code></p>
<p>Initialize the <em>mbarrier object</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.init{.shared{::cta}}.b64 [addr], count;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> initializes the <em>mbarrier object</em> at the location specified by the address operand
<code class="docutils literal notranslate"><span class="pre">addr</span></code> with the unsigned 32-bit integer <code class="docutils literal notranslate"><span class="pre">count</span></code>. The value of operand count must be in the range
as specified in <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents"><span class="std std-ref">Contents of the mbarrier object</span></a>.</p>
<p>Initialization of the <em>mbarrier object</em> involves :</p>
<ul class="simple">
<li><p>Initializing the current phase to 0.</p></li>
<li><p>Initializing the expected arrival count to <code class="docutils literal notranslate"><span class="pre">count</span></code>.</p></li>
<li><p>Initializing the pending arrival count to <code class="docutils literal notranslate"><span class="pre">count</span></code>.</p></li>
<li><p>Initializing the <em>tx-count</em> to 0.</p></li>
</ul>
<p>The valid range of values for the operand <code class="docutils literal notranslate"><span class="pre">count</span></code> is [1, â€¦, 2<sup>20</sup> - 1].
Refer <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents"><span class="std std-ref">Contents of the mbarrier object</span></a> for the
valid range of values for the various constituents of the mbarrier.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>The behavior of performing an <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> operation on a memory location containing a
valid <em>mbarrier object</em> is undefined; invalidate the <em>mbarrier object</em> using <code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code>
first, before repurposing the memory location for any other purpose, including another <em>mbarrier object</em>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.shared .b64 shMem, shMem2;
.reg    .b64 addr;
.reg    .b32 %r1;

cvta.shared.u64          addr, shMem2;
mbarrier.init.b64        [addr],   %r1;
bar.cta.sync             0;
// ... other mbarrier operations on addr

mbarrier.init.shared::cta.b64 [shMem], 12;
bar.sync                 0;
// ... other mbarrier operations on shMem
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-inval">
<span id="id346"></span><h5>
<span class="section-number">9.7.13.15.10. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-inval">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-inval" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code></p>
<p>Invalidates the <em>mbarrier object</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.inval{.shared{::cta}}.b64 [addr];
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.inval</span></code> invalidates the <em>mbarrier object</em> at the location specified by the address
operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>.</p>
<p>An <em>mbarrier object</em> must be invalidated before using its memory location for any other purpose.</p>
<p>Performing any <em>mbarrier</em> operation except <code class="docutils literal notranslate"><span class="pre">mbarrier.init</span></code> on a memory location that does not
contain a valid <em>mbarrier object</em>, results in undefined behaviour.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.shared .b64 shmem;
.reg    .b64 addr;
.reg    .b32 %r1;
.reg    .pred t0;

// Example 1 :
bar.sync                      0;
@t0 mbarrier.init.b64     [addr], %r1;
// ... other mbarrier operations on addr
bar.sync                      0;
@t0 mbarrier.inval.b64    [addr];


// Example 2 :
bar.cta.sync                  0;
mbarrier.init.shared.b64           [shmem], 12;
// ... other mbarrier operations on shmem
bar.cta.sync                  0;
@t0 mbarrier.inval.shared.b64      [shmem];

// shmem can be reused here for unrelated use :
bar.cta.sync                  0;
st.shared.b64                      [shmem], ...;

// shmem can be re-initialized as mbarrier object :
bar.cta.sync                  0;
@t0 mbarrier.init.shared.b64       [shmem], 24;
// ... other mbarrier operations on shmem
bar.cta.sync                  0;
@t0 mbarrier.inval.shared::cta.b64 [shmem];
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-expect-tx">
<span id="id347"></span><h5>
<span class="section-number">9.7.13.15.11. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code></p>
<p>Perfoms
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation"><span class="std std-ref">expect-tx</span></a>
operation on the <em>mbarrier object</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.expect_tx{.sem.scope}{.space}.b64 [addr], txCount;

.sem   = { .relaxed }
.scope = { .cta, .cluster }
.space = { .shared{::cta}, .shared::cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A thread executing <code class="docutils literal notranslate"><span class="pre">mbarrier.expect_tx</span></code> performs an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation"><span class="std std-ref">expect-tx</span></a>
operation on the <em>mbarrier object</em> at the location specified by the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>. The
32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">txCount</span></code> specifies the <code class="docutils literal notranslate"><span class="pre">expectCount</span></code> argument to the
<em>expect-tx</em> operation.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> are as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier does not provide any memory ordering semantics and visibility
guarantees.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier indicates the set of threads that directly observe the memory
synchronizing effect of this operation, as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified together.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.expect_tx.b64                       [addr], 32;
mbarrier.expect_tx.relaxed.cta.shared.b64    [mbarObj1], 512;
mbarrier.expect_tx.relaxed.cta.shared.b64    [mbarObj2], 512;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-complete-tx">
<span id="id348"></span><h5>
<span class="section-number">9.7.13.15.12. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code></p>
<p>Perfoms
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the <em>mbarrier object</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.complete_tx{.sem.scope}{.space}.b64 [addr], txCount;

.sem   = { .relaxed }
.scope = { .cta, .cluster }
.space = { .shared{::cta}, .shared::cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A thread executing <code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code> performs a <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation on the <em>mbarrier object</em> at the location specified by the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>. The
32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">txCount</span></code> specifies the <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument to the
<em>complete-tx</em> operation.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.complete_tx</span></code> does not involve any asynchronous memory operations and only simulates the
completion of an asynchronous memory operation and its side effect of signaling to the <em>mbarrier
object</em>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> are as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier does not provide any memory ordering semantics and visibility
guarantees.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier indicates the set of threads that directly observe the memory
synchronizing effect of this operation, as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified together.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.complete_tx.b64             [addr],     32;
mbarrier.complete_tx.shared.b64      [mbarObj1], 512;
mbarrier.complete_tx.relaxed.cta.b64 [addr2],    32;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-arrive">
<span id="id349"></span><h5>
<span class="section-number">9.7.13.15.13. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code></p>
<p>Performs <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> on the
<em>mbarrier object</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.arrive{.sem.scope}{.shared{::cta}}.b64           state, [addr]{, count};
mbarrier.arrive{.sem.scope}{.shared::cluster}.b64         _, [addr] {,count}
mbarrier.arrive.expect_tx{.sem.scope}{.shared{::cta}}.b64 state, [addr], txCount;
mbarrier.arrive.expect_tx{.sem.scope}{.shared::cluster}.b64   _, [addr], txCount;
mbarrier.arrive.noComplete{.release.cta}{.shared{::cta}}.b64  state, [addr], count;

.sem   = { .release, .relaxed }
.scope = { .cta, .cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A thread executing <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> performs an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a> operation
on the <em>mbarrier object</em> at the location specified by the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>. The 32-bit
unsigned integer operand <code class="docutils literal notranslate"><span class="pre">count</span></code> specifies the <em>count</em> argument to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a>
operation.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> specifies that an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation"><span class="std std-ref">expect-tx</span></a>
operation is performed prior to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a>
operation. The 32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">txCount</span></code> specifies the <em>expectCount</em> argument to
the <em>expect-tx</em> operation. When both qualifiers <code class="docutils literal notranslate"><span class="pre">.arrive</span></code> and <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> are specified, then
the count argument of the <em>arrive-on</em> operation is assumed to be 1.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> qualifier must not cause the <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> to
complete its current phase, otherwise the behavior is undefined.</p>
<p>The value of the operand <code class="docutils literal notranslate"><span class="pre">count</span></code> must be in the range as specified in
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents"><span class="std std-ref">Contents of the mbarrier object</span></a>.</p>
<p>Note: for <code class="docutils literal notranslate"><span class="pre">sm_8x</span></code>, when the argument <code class="docutils literal notranslate"><span class="pre">count</span></code> is specified, the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> is
required.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> operation on an <em>mbarrier object</em> located in <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> returns an opaque
64-bit register capturing the phase of the <em>mbarrier object</em> prior to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> in the
destination operand <code class="docutils literal notranslate"><span class="pre">state.</span></code> Contents of the <code class="docutils literal notranslate"><span class="pre">state</span></code> operand are implementation
specific. Optionally, sink symbol <code class="docutils literal notranslate"><span class="pre">'_'</span></code> can be used for the <code class="docutils literal notranslate"><span class="pre">state</span></code> argument.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> operation on an <em>mbarrier object</em> located in <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> but not in
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> cannot return a value. Sink symbol â€˜_â€™ is mandatory for the destination operand for
such cases.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent,
<code class="docutils literal notranslate"><span class="pre">.release</span></code> is assumed by default.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier does not provide any memory ordering semantics and visibility
guarantees.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier indicates the set of threads that directly observe the memory
synchronizing effect of this operation, as described in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.
If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is not specified then it
defaults to <code class="docutils literal notranslate"><span class="pre">.cta</span></code>. In contrast, the <code class="docutils literal notranslate"><span class="pre">.shared::&lt;scope&gt;</span></code> indicates the state space where the
mbarrier resides.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified together.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for sink symbol â€˜_â€™ as the destination operand is introduced in PTX ISA version 7.1.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">count</span></code> argument without the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> introduced in PTX ISA version
7.8.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> introduced in PTX ISA version 8.0.</p>
<p>Support for qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> is introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.scope</span></code> and <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifiers introduced in PTX ISA version 8.0</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">count</span></code> argument without the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 cnt, remoteAddr32, remoteCTAId, addr32;
.reg .b64 %r&lt;5&gt;, addr, remoteAddr64;
.shared .b64 shMem, shMem2;

cvta.shared.u64            addr, shMem2;
mov.b32                    addr32, shMem2;
mapa.shared::cluster.u32   remoteAddr32, addr32, remoteCTAId;
mapa.u64                   remoteAddr64, addr,   remoteCTAId;

cvta.shared.u64          addr, shMem2;

mbarrier.arrive.shared.b64                       %r0, [shMem];
mbarrier.arrive.shared::cta.b64                  %r0, [shMem2];
mbarrier.arrive.release.cta.shared::cluster.b64  _, [remoteAddr32];
mbarrier.arrive.release.cluster.b64              _, [remoteAddr64], cnt;
mbarrier.arrive.expect_tx.release.cluster.b64    _, [remoteAddr64], tx_count;
mbarrier.arrive.noComplete.b64                   %r1, [addr], 2;
mbarrier.arrive.relaxed.cta.b64                  %r2, [addr], 4;
mbarrier.arrive.b64                              %r2, [addr], cnt;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop">
<span id="id350"></span><h5>
<span class="section-number">9.7.13.15.14. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-drop" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code></p>
<p>Decrements the expected count of the <em>mbarrier object</em> and performs <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.arrive_drop{.sem.scope}{.shared{::cta}}.b64 state,           [addr]{, count};
mbarrier.arrive_drop{.sem.scope}{.shared::cluster}.b64           _,   [addr] {,count};
mbarrier.arrive_drop.expect_tx{.sem.scope}{.shared{::cta}}.b64 state, [addr], tx_count;
mbarrier.arrive_drop.expect_tx{.sem.scope}{.shared::cluster}.b64   _, [addr], tx_count;
mbarrier.arrive_drop.noComplete{.release.cta}{.shared{::cta}}.b64 state,  [addr], count;

.sem   = { .release, .relaxed }
.scope = { .cta, .cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A thread executing <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> on the <em>mbarrier object</em> at the location specified by
the address operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> performs the following steps:</p>
<ul class="simple">
<li><p>Decrements the expected arrival count of the <em>mbarrier object</em> by the value specified by the
32-bit integer operand <code class="docutils literal notranslate"><span class="pre">count</span></code>. If <code class="docutils literal notranslate"><span class="pre">count</span></code> operand is not specified, it defaults to 1.</p></li>
<li><p>Performs an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> on the
<em>mbarrier object</em>. The operand <code class="docutils literal notranslate"><span class="pre">count</span></code> specifies the <em>count</em> argument to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a>.</p></li>
</ul>
<p>The decrement done in the expected arrivals count of the <em>mbarrier object</em> will be for all the
subsequent phases of the <em>mbarrier object</em>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> or <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> specifies that an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation"><span class="std std-ref">expect-tx</span></a>
operation is performed prior to the <code class="docutils literal notranslate"><span class="pre">arrive_drop</span></code> operation, i.e. the decrement of arrival count and
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a>
operation. The 32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">txCount</span></code> specifies the <em>expectCount</em> argument to
the <em>expect-tx</em> operation. When both qualifiers <code class="docutils literal notranslate"><span class="pre">.arrive_drop</span></code> and <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> are specified, then
the count argument of the <em>arrive-on</em> operation is assumed to be 1.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifier forms the <em>release</em> pattern as
described in the Memory Consistency Model and synchronizes with the <em>acquire</em> patterns.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent,
<code class="docutils literal notranslate"><span class="pre">.release</span></code> is assumed by default.  The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier does not provide any memory
ordering semantics and visibility guarantees.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier indicates the set of threads that an <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code>
instruction can directly synchronize. If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is not specified then it defaults
to <code class="docutils literal notranslate"><span class="pre">.cta</span></code>. In contrast, the <code class="docutils literal notranslate"><span class="pre">.shared::&lt;scope&gt;</span></code> indicates the state space where the mbarrier
resides.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> with <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> qualifier must not complete the <code class="docutils literal notranslate"><span class="pre">mbarrier,</span></code>
otherwise the behavior is undefined.</p>
<p>The value of the operand <code class="docutils literal notranslate"><span class="pre">count</span></code> must be in the range as specified in
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents"><span class="std std-ref">Contents of the mbarrier object</span></a>.</p>
<p>Note: for <code class="docutils literal notranslate"><span class="pre">sm_8x</span></code>, when the argument <code class="docutils literal notranslate"><span class="pre">count</span></code> is specified, the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> is
required.</p>
<p>A thread that wants to either exit or opt out of participating in the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> can use
<code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> to drop itself from the <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> operation on an <em>mbarrier object</em> located in <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> returns an
opaque 64-bit register capturing the phase of the <em>mbarrier object</em> prior to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on
operation</span></a>
in the destination operand <code class="docutils literal notranslate"><span class="pre">state</span></code>. Contents of the returned state are implementation
specific. Optionally, sink symbol <code class="docutils literal notranslate"><span class="pre">'_'</span></code> can be used for the <code class="docutils literal notranslate"><span class="pre">state</span></code> argument.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code> operation on an <em>mbarrier</em> object located in <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> but not
in <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> cannot return a value. Sink symbol â€˜_â€™ is mandatory for the destination operand
for such cases.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified together.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">count</span></code> argument without the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> introduced in PTX ISA version
7.8.</p>
<p>Support for qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> is introduced in PTX ISA version 8.0.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.scope</span></code> and <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifiers introduced in PTX ISA version 8.0</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">count</span></code> argument without the modifier <code class="docutils literal notranslate"><span class="pre">.noComplete</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 cnt;
.reg .b64 %r1;
.shared .b64 shMem;

// Example 1
@p mbarrier.arrive_drop.shared.b64 _, [shMem];
@p exit;
@p2 mbarrier.arrive_drop.noComplete.shared.b64 _, [shMem], %a;
@p2 exit;
..
@!p mbarrier.arrive.shared.b64   %r1, [shMem];
@!p mbarrier.test_wait.shared.b64  q, [shMem], %r1;

// Example 2
mbarrier.arrive_drop.shared::cluster.b64 _, [addr];
mbarrier.arrive_drop.shared::cta.release.cluster.b64     _, [addr], cnt;

// Example 3
mbarrier.arrive_drop.expect_tx.shared::cta.relaxed.cluster.b64 state, [addr], tx_count;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive">
<span id="id351"></span><h5>
<span class="section-number">9.7.13.15.15. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-cp-async-mbarrier-arrive" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code></p>
<p>Makes the <em>mbarrier object</em> track all prior <a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async"><span class="std std-ref">cp.async</span></a>
operations initiated by the
executing thread.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>cp.async.mbarrier.arrive{.noinc}{.shared{::cta}}.b64 [addr];
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Causes an <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> to be
triggered by the system on the <em>mbarrier object</em> upon the completion of all prior <a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async"><span class="std std-ref">cp.async</span></a>
operations initiated by the
executing thread. The <em>mbarrier object</em> is at the location specified by the operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>. The
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> is
asynchronous to execution of <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.noinc</span></code> modifier is not specified, the pending count of the mbarrier object is incremented
by 1 prior to the asynchronous <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a>. This
results in a zero-net change for the pending count from the asynchronous <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on</span></a> operation
during the current phase. The pending count of the <em>mbarrier object</em> after the increment should not
exceed the limit as mentioned in
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-contents"><span class="std std-ref">Contents of the mbarrier object</span></a>. Otherwise,
the behavior is undefined.</p>
<p>When the <code class="docutils literal notranslate"><span class="pre">.noinc</span></code> modifier is specified, the increment to the pending count of the <em>mbarrier
object</em> is not performed. Hence the decrement of the pending count done by the asynchronous
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> must be
accounted for in the initialization of the <em>mbarrier object</em>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example 1: no .noinc
mbarrier.init.shared.b64 [shMem], threadCount;
....
cp.async.ca.shared.global [shard1], [gbl1], 4;
cp.async.cg.shared.global [shard2], [gbl2], 16;
....
// Absence of .noinc accounts for arrive-on from completion of prior cp.async operations.
// So mbarrier.init must only account for arrive-on from mbarrier.arrive.
cp.async.mbarrier.arrive.shared.b64 [shMem];
....
mbarrier.arrive.shared.b64 state, [shMem];

waitLoop:
mbarrier.test_wait.shared.b64 p, [shMem], state;
@!p bra waitLoop;



// Example 2: with .noinc

// Tracks arrive-on from mbarrier.arrive and cp.async.mbarrier.arrive.

// All threads participating in the mbarrier perform cp.async
mov.b32 copyOperationCnt, threadCount;

// 3 arrive-on operations will be triggered per-thread
mul.lo.u32 copyArrivalCnt, copyOperationCnt, 3;

add.u32 totalCount, threadCount, copyArrivalCnt;

mbarrier.init.shared.b64 [shMem], totalCount;
....
cp.async.ca.shared.global [shard1], [gbl1], 4;
cp.async.cg.shared.global [shard2], [gbl2], 16;
...
// Presence of .noinc requires mbarrier initalization to have accounted for arrive-on from cp.async
cp.async.mbarrier.arrive.noinc.shared.b64 [shMem]; // 1st instance
....
cp.async.ca.shared.global [shard3], [gbl3], 4;
cp.async.ca.shared.global [shard4], [gbl4], 16;
cp.async.mbarrier.arrive.noinc.shared::cta.b64 [shMem]; // 2nd instance
....
cp.async.ca.shared.global [shard5], [gbl5], 4;
cp.async.cg.shared.global [shard6], [gbl6], 16;
cp.async.mbarrier.arrive.noinc.shared.b64 [shMem]; // 3rd and last instance
....
mbarrier.arrive.shared.b64 state, [shMem];

waitLoop:
mbarrier.test_wait.shared.b64 p, [shMem], state;
@!p bra waitLoop;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait">
<span id="id352"></span><h5>
<span class="section-number">9.7.13.15.16. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> / <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-test-wait-try-wait" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code>, <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code></p>
<p>Checks whether the <em>mbarrier object</em> has completed the phase.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.test_wait{.sem.scope}{.shared{::cta}}.b64        waitComplete, [addr], state;
mbarrier.test_wait.parity{.sem.scope}{.shared{::cta}}.b64 waitComplete, [addr], phaseParity;

mbarrier.try_wait{.sem.scope}{.shared{::cta}}.b64         waitComplete, [addr], state
                                                            {, suspendTimeHint};

mbarrier.try_wait.parity{.sem.scope}{.shared{::cta}}.b64  waitComplete, [addr], phaseParity
                                                            {, suspendTimeHint};

.sem   = { .acquire, .relaxed }
.scope = { .cta, .cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <em>test_wait</em> and <em>try_wait</em> operations test for the completion of the current or the immediately
preceding phase of an <em>mbarrier object</em> at the location specified by the operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> is a non-blocking instruction which tests for the completion of the phase.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> is a potentially blocking instruction which tests for the completion of the
phase. If the phase is not complete, the executing thread may be suspended. Suspended thread resumes
execution when the specified phase completes OR before the phase completes following a
system-dependent time limit. The optional 32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">suspendTimeHint</span></code>
specifies the time limit, in nanoseconds, that may be used for the time limit instead of the
system-dependent limit.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> and <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> test for completion of the phase :</p>
<ul class="simple">
<li><p>Specified by the 64-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">state</span></code>, which was returned by an
<code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> instruction on the same <em>mbarrier object</em> during the current or the
immediately preceding phase. Or</p></li>
<li><p>Indicated by the 32-bit unsigned integer operand <code class="docutils literal notranslate"><span class="pre">phaseParity</span></code>, which is the integer parity
of either the current phase or the immediately preceding phase of the <em>mbarrier object</em>.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.parity</span></code> variant of the instructions test for the completion of the phase indicated by the
operand <code class="docutils literal notranslate"><span class="pre">phaseParity</span></code>, which is the integer parity of either the current phase or the immediately
preceding phase of the <em>mbarrier object</em>. An even phase has integer parity 0 and an odd phase has
integer parity of 1. So the valid values of <code class="docutils literal notranslate"><span class="pre">phaseParity</span></code> operand are 0 and 1.</p>
<p>Note: the use of the <code class="docutils literal notranslate"><span class="pre">.parity</span></code> variants of the instructions requires tracking the phase of an
<em>mbarrier object</em> throughout its lifetime.</p>
<p>The <em>test_wait</em> and <em>try_wait</em> operations are valid only for :</p>
<ul class="simple">
<li><p>the current incomplete phase, for which <code class="docutils literal notranslate"><span class="pre">waitComplete</span></code> returns <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p>the immediately preceding phase, for which <code class="docutils literal notranslate"><span class="pre">waitComplete</span></code> returns <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is
used. If the address specified by <code class="docutils literal notranslate"><span class="pre">addr</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Supported addressing modes for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.
Alignment for operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> is as described in the
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-size-alignment"><span class="std std-ref">Size and alignment of mbarrier object</span></a>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> and <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> operations with <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> qualifier
returns <code class="docutils literal notranslate"><span class="pre">True</span></code>, they form the <em>acquire</em> pattern as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier specifies a memory synchronizing effect as described in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>. If the <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier is absent,
<code class="docutils literal notranslate"><span class="pre">.acquire</span></code> is assumed by default.  The <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier does not provide any memory
ordering semantics and visibility guarantees.</p>
<p>The optional <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier indicates the set of threads that the <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> and
<code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> instructions can directly synchronize. If the <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier is not
specified then it defaults to <code class="docutils literal notranslate"><span class="pre">.cta</span></code>. In contrast, the <code class="docutils literal notranslate"><span class="pre">.shared::&lt;scope&gt;</span></code> indicates the state
space where the mbarrier resides.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.sem</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> must be specified together.</p>
<p>The following ordering of memory operations hold for the executing thread when
<code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> having acquire semantics returns <code class="docutils literal notranslate"><span class="pre">True</span></code> :</p>
<ol class="arabic simple">
<li><p>All memory accesses (except <a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async"><span class="std std-ref">async operations</span></a>) requested prior, in program
order, to <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> having release semantics during the completed phase by
the participating threads of the CTA are performed and are visible to the executing thread.</p></li>
<li><p>All <a class="reference internal" href="#data-movement-and-conversion-instructions-cp-async"><span class="std std-ref">cp.async</span></a> operations
requested prior, in program order, to <code class="docutils literal notranslate"><span class="pre">cp.async.mbarrier.arrive</span></code> during the completed phase by
the participating threads of the CTA are performed and made visible to the executing thread.</p></li>
<li><p>All <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> asynchronous operations using the same <em>mbarrier object</em> requested prior,
in program order, to <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> having release semantics during the completed
phase by the participating threads of the CTA are performed and made visible to the executing thread.</p></li>
<li><p>All memory accesses requested after the <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code>, in
program order, are not performed and not visible to memory accesses performed prior to
<code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> having release semantics, in program order, by other threads
participating in the <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code>.</p></li>
<li><p>There is no ordering and visibility guarantee for memory accesses requested by the thread after
<code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code> having release semantics and prior to <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code>,
in program order.</p></li>
</ol>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> introduced in PTX ISA version 7.0.</p>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.parity</span></code> is introduced in PTX ISA version 7.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> introduced in PTX ISA version 7.8.</p>
<p>Support for sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code> on <code class="docutils literal notranslate"><span class="pre">.shared</span></code> introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.scope</span></code> and <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifiers introduced in PTX ISA version 8.0</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example 1a, thread synchronization with test_wait:

.reg .b64 %r1;
.shared .b64 shMem;

mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.
...
mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads executing mbarrier.arrive

// computation not requiring mbarrier synchronization...

waitLoop:
mbarrier.test_wait.shared.b64    complete, [shMem], %r1;
@!complete nanosleep.u32 20;
@!complete bra waitLoop;

// Example 1b, thread synchronization with try_wait :

.reg .b64 %r1;
.shared .b64 shMem;

mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.
...
mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads executing mbarrier.arrive

// computation not requiring mbarrier synchronization...

waitLoop:
mbarrier.try_wait.relaxed.cluster.shared.b64    complete, [shMem], %r1;
@!complete bra waitLoop;


// Example 2, thread synchronization using phase parity :

.reg .b32 i, parArg;
.reg .b64 %r1;
.shared .b64 shMem;

mov.b32 i, 0;
mbarrier.init.shared.b64 [shMem], N;  // N threads participating in the mbarrier.
...
loopStart :                           // One phase per loop iteration
    ...
    mbarrier.arrive.shared.b64  %r1, [shMem]; // N threads
    ...
    and.b32 parArg, i, 1;
    waitLoop:
    mbarrier.test_wait.parity.shared.b64  complete, [shMem], parArg;
    @!complete nanosleep.u32 20;
    @!complete bra waitLoop;
    ...
    add.u32 i, i, 1;
    setp.lt.u32 p, i, IterMax;
@p bra loopStart;


// Example 3, Asynchronous copy completion waiting :

.reg .b64 state;
.shared .b64 shMem2;
.shared .b64 shard1, shard2;
.global .b64 gbl1, gbl2;

mbarrier.init.shared.b64 [shMem2], threadCount;
...
cp.async.ca.shared.global [shard1], [gbl1], 4;
cp.async.cg.shared.global [shard2], [gbl2], 16;

// Absence of .noinc accounts for arrive-on from prior cp.async operation
cp.async.mbarrier.arrive.shared.b64 [shMem2];
...
mbarrier.arrive.shared.b64 state, [shMem2];

waitLoop:
mbarrier.test_wait.shared::cta.b64 p, [shMem2], state;
@!p bra waitLoop;

// Example 4, Synchronizing the CTA0 threads with cluster threads
.reg .b64 %r1, addr, remAddr;
.shared .b64 shMem;

cvta.shared.u64          addr, shMem;
mapa.u64                 remAddr, addr, 0;     // CTA0's shMem instance

// One thread from CTA0 executing the below initialization operation
@p0 mbarrier.init.shared::cta.b64 [shMem], N;  // N = no of cluster threads

barrier.cluster.arrive;
barrier.cluster.wait;

// Entire cluster executing the below arrive operation
mbarrier.arrive.release.cluster.b64              _, [remAddr];

// computation not requiring mbarrier synchronization ...

// Only CTA0 threads executing the below wait operation
waitLoop:
mbarrier.try_wait.parity.acquire.cluster.shared::cta.b64  complete, [shMem], 0;
@!complete bra waitLoop;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-mbarrier-pending-count">
<span id="id353"></span><h5>
<span class="section-number">9.7.13.15.17. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-pending-count">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-mbarrier-pending-count" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code></p>
<p>Query the pending arrival count from the opaque mbarrier state.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mbarrier.pending_count.b64 count, state;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The pending count can be queried from the opaque mbarrier state using <code class="docutils literal notranslate"><span class="pre">mbarrier.pending_count</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">state</span></code> operand is a 64-bit register that must be the result of a prior
<code class="docutils literal notranslate"><span class="pre">mbarrier.arrive.noComplete</span></code> or <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop.noComplete</span></code> instruction. Otherwise, the
behavior is undefined.</p>
<p>The destination register <code class="docutils literal notranslate"><span class="pre">count</span></code> is a 32-bit unsigned integer representing the pending count of
the <em>mbarrier object</em> prior to the <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on"><span class="std std-ref">arrive-on operation</span></a> from
which the <code class="docutils literal notranslate"><span class="pre">state</span></code> register was obtained.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r1;
.reg .b64 state;
.shared .b64 shMem;

mbarrier.arrive.noComplete.b64 state, [shMem], 1;
mbarrier.pending_count.b64 %r1, state;
</pre></div>
</div>
</section>
</section>
<section id="parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy">
<span id="id354"></span><h4>
<span class="section-number">9.7.13.16. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-tensormap-cp-fenceproxy" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code></p>
<p>A fused copy and fence operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tensormap.cp_fenceproxy.cp_qualifiers.fence_qualifiers.sync.aligned  [dst], [src], size;

.cp_qualifiers    = { .global.shared::cta }
.fence_qualifiers = { .to_proxy::from_proxy.release.scope }
.to_proxy::from_proxy  = { .tensormap::generic }
.scope            = { .cta, .cluster, .gpu , .sys }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code> instructions perform the following operations in order :</p>
<ul class="simple">
<li><p>Copies data of size specified by the <code class="docutils literal notranslate"><span class="pre">size</span></code> argument, in bytes, from the location specified
by the address operand <code class="docutils literal notranslate"><span class="pre">src</span></code> in shared memory to the location specified by the address operand
<code class="docutils literal notranslate"><span class="pre">dst</span></code> in the global memory, in the generic proxy.</p></li>
<li><p>Establishes a <em>uni-directional</em> proxy release pattern on the ordering from the copy operation
to the subsequent access performed in the tensormap proxy on the address <code class="docutils literal notranslate"><span class="pre">dst</span></code>.</p></li>
</ul>
<p>The valid value of immediate operand <code class="docutils literal notranslate"><span class="pre">size</span></code> is 128.</p>
<p>The operands <code class="docutils literal notranslate"><span class="pre">src</span></code> and <code class="docutils literal notranslate"><span class="pre">dst</span></code> specify non-generic addresses in <code class="docutils literal notranslate"><span class="pre">shared::cta</span></code> and <code class="docutils literal notranslate"><span class="pre">global</span></code>
state space respectively.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifier specifies the set of threads that can directly observe the proxy
synchronizing effect of this operation, as described in <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code> causes the executing
thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code> instruction. In conditionally executed code, an aligned <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code>
instruction should only be used if it is known that all threads in the warp evaluate the condition
identically, otherwise behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example: manipulate a tensor-map object and then consume it in cp.async.bulk.tensor

.reg .b64 new_addr;
.global .align 128 .b8 gbl[128];
.shared .align 128 .b8 sMem[128];

cp.async.bulk.shared::cluster.global.mbarrier::complete_tx::bytes [sMem], [gMem], 128, [mbar];
...
try_wait_loop:
mbarrier.try_wait.shared.b64 p, [mbar], state;
@!p bra try_wait loop;

tensormap.replace.tile.global_address.shared.b1024.b64   [sMem], new_addr;
tensormap.cp_fenceproxy.global.shared::cta.tensormap::generic.release.gpu.sync.aligned
                                                         [gbl], [sMem], 128;
fence.proxy.tensormap::generic.acquire.gpu [gbl], 128;
cp.async.bulk.tensor.1d.shared::cluster.global.tile  [addr0], [gbl, {tc0}], [mbar0];
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel">
<span id="id355"></span><h4>
<span class="section-number">9.7.13.17. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-try-cancel" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code></p>
<p>Requests cancellation of cluster which is not launched yet.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>clusterlaunchcontrol.try_cancel.async{.space}.completion_mechanism{.multicast::cluster::all}.b128 [addr], [mbar];

.completion_mechanism = { .mbarrier::complete_tx::bytes };
.space = { .shared::cta };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> instruction requests atomically cancelling the launch of
a cluster that has not started running yet. It asynchronously writes an opaque response to shared
memory indicating whether the operation succeeded or failed. The completion of the asynchronous
operation is tracked using the mbarrier completion mechanism at <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p>
<p>On success, the opaque response contains the <code class="docutils literal notranslate"><span class="pre">ctaid</span></code> of the first CTA of the canceled cluster; no
other successful response from other <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> operations from the same
grid will contain that id.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.async</span></code> qualifier indicates that the instruction will initiate the cancellation
operation asynchronously and control will return to the executing thread before the requested
operation is complete.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.space</span></code> qualifier is specified, both operands <code class="docutils literal notranslate"><span class="pre">addr</span></code> and <code class="docutils literal notranslate"><span class="pre">mbar</span></code> must be in the
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space. Otherwise, generic addressing will be assumed for both. The result
is undefined if any of address operands do not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code>.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> specifies that upon completion of the asynchronous operation,
<a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation"><span class="std std-ref">complete-tx</span></a>
operation, with <code class="docutils literal notranslate"><span class="pre">completeCount</span></code> argument equal to amount of data stored in bytes, will be performed
on the mbarrier object specified by the operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>.</p>
<p>The executing thread can then use <a class="reference internal" href="#parallel-synchronization-and-communication-instructions-mbarrier"><span class="std std-ref">mbarrier instructions</span></a> to wait for completion
of the asynchronous operation. No other synchronization mechanisms described in <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a> can be used to guarantee the completion of the asynchronous copy operations.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.multicast::cluster::all</span></code> qualifier indicates that the response is asynchronously written using
weak async-proxy writes to the corresponding local shared memory <code class="docutils literal notranslate"><span class="pre">addr</span></code> of each CTA in the requesting
cluster. The completion of the writes to <code class="docutils literal notranslate"><span class="pre">addr</span></code> of a particular CTA is signaled via a complete-tx operation
to the mbarrier object on the shared memory of that CTA.</p>
<p>The behavior of instruction with <code class="docutils literal notranslate"><span class="pre">.multicast::cluster::all</span></code> qualifier is undefined if any CTA in the
cluster is exited.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">addr</span></code> specifies the naturally aligned address of the 16-byte wide shared memory location where
the requestâ€™s response is written.</p>
<p>The response of <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> instruction will be 16-byte opaque value and will be
it available at location specified by operand <code class="docutils literal notranslate"><span class="pre">addr</span></code>. After loading this response into 16-byte register,
instruction <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code> can be used to check if request was successful and to
retrieve <code class="docutils literal notranslate"><span class="pre">ctaid</span></code> of the first CTA of the canceled cluster.</p>
<p>If the executing CTA has already observed the completion of a <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> instruction
as failed, then the behavior of issuing a subsequent <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> instruction is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.multicast::cluster::all</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Assumption: 1D cluster (cluster_ctaid.y/.z == 1) with 1 thread per CTA.

// Current Cluster to be processed: initially the launched cluster:
mov.b32 xctaid, %ctaid.x;

// Establish full synchronization across all CTAs of the cluster for the first iteration.
// Weaker synchronization may suffice depending on initialization sequence.
barrier.cluster.arrive;
barrier.cluster.wait;

// Iteration loop over all cluster CTAs
processCluster:
  mov.u32  %r0, %tid.x;
  setp.u32.eq p0, %r0, 0x0;
  // Elect a leader thread (thread idx 0) for each CTA to arrive and expect_tx at
  // each CTA local shared memory barrier:
  mov.u32  %r0, %tid.x;
  setp.u32.eq p0, %r0, 0x0;
  // All other threads skip to processing the work of the current cluster:
  @!p0 bra processCurrentCluster;

  // All CTAs in the cluster arrive at their local SMEM barrier and set 16B handle tx count:
  mbarrier.arrive.expect_tx.cluster.relaxed.shared::cta.b64 state, [mbar], 16;

  // First CTA in Cluster attempts to cancel a not-yet-started cluster:
  mov.u32  %r0, %cluster_ctaid.x;
  setp.u32.eq p0, %r0, 0x0;
  @p0 clusterlaunchcontrol.try_cancel.async.mbarrier::complete_tx::bytes.multicast::cluster::all.b128 [addr], [mbar];

  processCurrentCluster:
    // ...process current cluster ("xctaid") while cancellation request for next cluster runs asynchronously...

  // After processing current cluster, wait on cancellation request response for next cluster via specified mbarrier:
  waitLoop:
    // .acquire prevents weak handle read ("ld.shared handle, [addr]") from overtaking this mbarrier.try_wait:
    mbarrier.try_wait.cluster.acquire.shared::cta.b64   complete, [mbar], state;
    @!complete bra waitLoop;
   // Cancellation request has completed.

  // Generic-proxy weak read of cancellation request into 16-byte wide register:
  ld.shared.b128 handle, [addr];

  // Check whether cancellation succeeded:
  clusterlaunchcontrol.query_cancel.is_canceled.pred.b128 p, handle;
  // If cancellation request failed, we couldn't cancel any other cluster, so all current cluster CTAs exit.
  @!p ret;

  // Otherwise, cancellation request succeeded.
  // Extract "ctaid" of first cancelled-cluster CTA which we'll process in next "processCluster" loop iteration:
  @p clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xctaid, _, _, _},  handle;

  // Release current iteration generic-proxy weak read of handle ("ld.shared handle, [addr]")
  // before next iteration async-proxy write to handle ("clusterlaunchcontrol.try_cancel [addr]")
  fence.proxy.async::generic.release.sync_restrict::shared::cta.cluster;

  // Arrive and wait at the next iteration cluster barrier with relaxed semantics.
  barrier.cluster.arrive.relaxed;
  barrier.cluster.wait;

  // Acquire prior iteration generic-proxy weak read of handle ("ld.shared handle, [addr]")
  // before current iteration async-proxy write to handle ("clusterlaunchcontrol.try_cancel [addr]")
  fence.proxy.async::generic.acquire.sync_restrict::shared::cluster.cluster;

  bra processCluster;
</pre></div>
</div>
</section>
<section id="parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel">
<span id="id356"></span><h4>
<span class="section-number">9.7.13.18. </span><a class="reference internal" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel">Parallel Synchronization and Communication Instructions: <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code></a><a class="headerlink" href="#parallel-synchronization-and-communication-instructions-clusterlaunchcontrol-query-cancel" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code></p>
<p>Queries response of <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>clusterlaunchcontrol.query_cancel.is_canceled.pred.b128 pred, try_cancel_response;

clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xdim, ydim, zdim, _},  try_cancel_response;

clusterlaunchcontrol.query_cancel.get_first_ctaid{::dimension}.b32.b128 reg, try_cancel_response;

::dimension = { ::x, ::y, ::z };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code> can be used to decode opaque response
written by instruction <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code>.</p>
<p>After loading response from <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code> instruction into 16-byte
register it can be further queried using <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel</span></code> instruction
as follows:</p>
<p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel.is_canceled.pred.b128</span></code>: If the cluster is canceled
successfully, predicate <code class="docutils literal notranslate"><span class="pre">p</span></code> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>; otherwise, it is set to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
<p>If the request succeeded, the instruction <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel.get_first_ctaid</span></code>
extracts the CTA id of the first CTA in the canceled cluster. By default, the instruction
returns a <code class="docutils literal notranslate"><span class="pre">.v4</span></code> vector whose first three elements are the <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> and <code class="docutils literal notranslate"><span class="pre">z</span></code> coordinate
of first CTA in canceled cluster. The contents of the 4th element are unspecified. The
explicit <code class="docutils literal notranslate"><span class="pre">.get_first_ctaid::x</span></code>, <code class="docutils literal notranslate"><span class="pre">.get_first_ctaid::y</span></code>, or <code class="docutils literal notranslate"><span class="pre">.get_first_ctaid::z</span></code>
qualifiers can be used to extract individual <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code> or <code class="docutils literal notranslate"><span class="pre">z</span></code> coordinates into a 32-bit
register.</p>
<p>If the request fails the behavior of <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.query_cancel.get_first_ctaid</span></code>
is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>clusterlaunchcontrol.query_cancel.is_canceled pred.b128 p, handle;

@p clusterlaunchcontrol.query_cancel.get_first_ctaid.v4.b32.b128 {xdim, ydim, zdim, ignr}  handle;

clusterlaunchcontrol.query_cancel.get_first_ctaid::x.b32.b128 reg0, handle;

clusterlaunchcontrol.query_cancel.get_first_ctaid::y.b32.b128 reg1, handle;

clusterlaunchcontrol.query_cancel.get_first_ctaid::z.b32.b128 reg2, handle;
</pre></div>
</div>
</section>
</section>
<section id="warp-level-matrix-instructions">
<span id="id357"></span><h3>
<span class="section-number">9.7.14. </span><a class="reference internal" href="#warp-level-matrix-instructions">Warp Level Matrix Multiply-Accumulate Instructions</a><a class="headerlink" href="#warp-level-matrix-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The matrix multiply and accumulate operation has the following form:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>D = A * B + C
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> are called accumulators and may refer to the same matrix.</p>
<p>PTX provides two ways to perform matrix multiply-and-accumulate computation:</p>
<ul>
<li>
<p>Using <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions:</p>
<ul>
<li>
<p>This warp-level computation is performed collectively by all threads in the warp as follows:</p>
<ul class="simple">
<li><p>Load matrices A, B and C from memory into registers using the <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> operation. When
the operation completes, the destination registers in each thread hold a fragment of the
loaded matrix.</p></li>
<li><p>Perform the matrix multiply and accumulate operation using the <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> operation on the
loaded matrices. When the operation completes, the destination registers in each thread hold
a fragment of the result matrix returned by the <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> operation.</p></li>
<li><p>Store result Matrix D back to memory using the <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> operation. Alternately, result
matrix D can also be used as argument C for a subsequent <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> operation.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> and <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> instructions implicitly handle the organization of matrix
elements when loading the input matrices from memory for the <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> operation and when
storing the result back to memory.</p>
</li>
</ul>
</li>
<li>
<p>Using <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction:</p>
<ul class="simple">
<li><p>Similar to <code class="docutils literal notranslate"><span class="pre">wmma</span></code>, <code class="docutils literal notranslate"><span class="pre">mma</span></code> also requires computation to be performed collectively by all
threads in the warp however distribution of matrix elements across different threads in warp
needs to be done explicitly before invoking the <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation. The <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction
supports both dense as well as sparse matrix A. The sparse variant can be used when A is a
structured sparse matrix as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></li>
</ul>
</li>
</ul>
<section id="warp-level-matrix-shape">
<span id="id358"></span><h4>
<span class="section-number">9.7.14.1. </span><a class="reference internal" href="#warp-level-matrix-shape">Matrix Shape</a><a class="headerlink" href="#warp-level-matrix-shape" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The matrix multiply and accumulate operations support a limited set of shapes for the operand
matrices A, B and C. The shapes of all three matrix operands are collectively described by the tuple
<code class="docutils literal notranslate"><span class="pre">MxNxK</span></code>, where A is an <code class="docutils literal notranslate"><span class="pre">MxK</span></code> matrix, B is a <code class="docutils literal notranslate"><span class="pre">KxN</span></code> matrix, while C and D are <code class="docutils literal notranslate"><span class="pre">MxN</span></code> matrices.</p>
<p>The following matrix shapes are supported for the specified types:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 5%">
<col style="width: 8%">
<col style="width: 35%">
<col style="width: 25%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Instruction</p></th>
<th class="head"><p>Scale</p></th>
<th class="head"><p>Sparsity</p></th>
<th class="head"><p>Multiplicand Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>PTX ISA version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td rowspan="6"><p>NA</p></td>
<td><p>Dense</p></td>
<td><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
<td><p>PTX ISA version 6.0</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
<td><p>PTX ISA version 6.3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Sub-byte integer - <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code></p></td>
<td><p>PTX ISA version 6.3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">wmma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Single-bit - <code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code></p></td>
<td><p>PTX ISA version 6.3</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="15"><p>NA</p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2"><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 7.8</p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="3"><p>Dense</p></td>
<td rowspan="3"><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code></p></td>
<td><p>PTX ISA version 6.4</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code></p></td>
<td><p>PTX ISA version 6.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2"><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k16</span></code></p></td>
<td><p>PTX ISA version 6.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2"><p>Sub-byte integer - <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code></p></td>
<td><p>PTX ISA version 6.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Single-bit - <code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m16n8k256</span></code></p></td>
<td><p>PTX ISA version 7.0</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 8.4</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="2"><p>Yes</p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
X
(Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Dense</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
X
(Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code>/<code class="docutils literal notranslate"><span class="pre">.ue4m3</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="13"><p>NA</p></td>
<td><p>Sparse</p></td>
<td><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 7.1</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 7.1</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 7.1</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse</p></td>
<td><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 7.1</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse</p></td>
<td><p>Sub-byte integer - <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code> and
<code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code></p></td>
<td><p>PTX ISA version 7.1</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.4</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Sub-byte integer - <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code> and
<code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.5</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="2"><p>Yes</p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
X
(Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td><p>Sparse
with
ordered
metadata</p></td>
<td><p>Alternate floating-point format - <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
X
(Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code>/<code class="docutils literal notranslate"><span class="pre">.ue4m3</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code></p></td>
<td><p>PTX ISA version 8.7</p></td>
</tr>
</tbody>
</table>
</section>
<section id="warp-level-matrix-data-types">
<span id="id359"></span><h4>
<span class="section-number">9.7.14.2. </span><a class="reference internal" href="#warp-level-matrix-data-types">Matrix Data-types</a><a class="headerlink" href="#warp-level-matrix-data-types" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The matrix multiply and accumulate operation is supported separately on integer, floating-point,
sub-byte integer and single bit data-types. All operands must contain the same basic type kind,
i.e., integer or floating-point.</p>
<p>For floating-point matrix multiply and accumulate operation, different matrix operands may have
different precision, as described later.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 33%">
<col style="width: 38%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Multiplicands (A or B)</p></th>
<th class="head"><p>Accumulators (C or D)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code>, <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> or
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Alternate floating Point
with scale</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> or
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> or
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> X (Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating Point
with scale</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> X (Scale)
<code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code> or <code class="docutils literal notranslate"><span class="pre">.ue4m3</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Sub-byte integer</p></td>
<td><p>both <code class="docutils literal notranslate"><span class="pre">.u4</span></code> or both <code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Single-bit integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="warp-level-block-scaling">
<span id="id360"></span><h4>
<span class="section-number">9.7.14.3. </span><a class="reference internal" href="#warp-level-block-scaling">Block Scaling for <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code></a><a class="headerlink" href="#warp-level-block-scaling" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction with the following <code class="docutils literal notranslate"><span class="pre">.kind</span></code> qualifier:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></li>
</ul>
<p>perform matrix multiplication with block scaling. This operation has the following form:
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">(A</span> <span class="pre">*</span> <span class="pre">scale_A)</span> <span class="pre">*</span> <span class="pre">(B</span> <span class="pre">*</span> <span class="pre">scale_B)</span> <span class="pre">+</span> <span class="pre">C</span></code>.</p>
<p>For a <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> matrix of shape <em>M x SFA_N</em>, each row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is divided into
<em>SFA_N</em> number of chunks and each chunk of a row is multiplied with the corresponding
element (henceforth referred as <em>SF_A</em>) from the same row of <code class="docutils literal notranslate"><span class="pre">scale_A</span></code>.</p>
<p>Similarly, for a <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrix of shape <em>SFB_M x N</em>, each column of matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> is
divided into the <em>SFB_M</em> number of chunks and each chunk of a column is multiplied with
the corresponding element (henceforth referred as <em>SF_B</em>) from the same column of <code class="docutils literal notranslate"><span class="pre">scale_B</span></code>.</p>
<p><a class="reference internal" href="#mma-block-scaling"><span class="std std-numref">Figure 42</span></a> shows an example of <code class="docutils literal notranslate"><span class="pre">mma</span></code> with block scaling of <code class="docutils literal notranslate"><span class="pre">scale_vec::2X</span></code>.</p>
<figure class="align-center" id="mma-block-scaling">
<img alt="_images/mma-block-scaling.png" class="image" src="_images/mma-block-scaling.png">
<figcaption>
<p><span class="caption-number">Figure 42 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">mma</span></code> with block scaling of <code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code></span><a class="headerlink" href="#mma-block-scaling" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The shapes for <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices depend upon the qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code>
as shown in <a class="reference internal" href="#mma-scale-vec-matrix-shape"><span class="std std-numref">Table 35</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="mma-scale-vec-matrix-shape">
<caption>
<span class="caption-number">Table 35 </span><span class="caption-text">Shapes for scale matrices depending upon <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier</span><a class="headerlink" href="#mma-scale-vec-matrix-shape" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 36%">
<col style="width: 32%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.scale_vec_size</p></th>
<th class="head"><p>Shape of scale_A</p></th>
<th class="head"><p>Shape of scale_B</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code></p></td>
<td><p>M x 1</p></td>
<td><p>1 x N</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code></p></td>
<td><p>M x 2</p></td>
<td><p>2 x N</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
<td><p>M x 4</p></td>
<td><p>4 x N</p></td>
</tr>
</tbody>
</table>
<p>The valid combination of the exact element types and the <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> are listed in
<a class="reference internal" href="#mma-scaling-kind-type-valid-combination"><span class="std std-numref">Table 36</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="mma-scaling-kind-type-valid-combination">
<caption>
<span class="caption-number">Table 36 </span><span class="caption-text">Valid combinations of <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind</span></code> qualifier</span><a class="headerlink" href="#mma-scaling-kind-type-valid-combination" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 27%">
<col style="width: 23%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.kind::*</p></th>
<th class="head"><p>Element Data Type
.atype and .btype</p></th>
<th class="head"><p>Scale Data Type
.stype</p></th>
<th class="head"><p>.scale_vec_size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ue4m3</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
</tr>
</tbody>
</table>
<p>The <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> argument provides metadata for <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and
<code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively. The tuple <code class="docutils literal notranslate"><span class="pre">{byte-id-a,</span> <span class="pre">thread-id-a}</span></code> and
<code class="docutils literal notranslate"><span class="pre">{byte-id-b,</span> <span class="pre">thread-id-b}</span></code> provides the selector information to choose elements
<em>SF_A</em> and <em>SF_B</em> from corresponding metadata arguments <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code> and
<code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code>.
The tuple <code class="docutils literal notranslate"><span class="pre">{byte-id-a,</span> <span class="pre">thread-id-a}</span></code> allows to select the scale matrix element <em>SF_A</em>
from <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>. Similarly, the tuple <code class="docutils literal notranslate"><span class="pre">{byte-id-b,</span> <span class="pre">thread-id-b}</span></code> allows to select
the scale matrix element <em>SF_B</em> from <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code>.</p>
<p>The components <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code> decides which threads among the quad
contribute the <em>SF_A</em> and <em>SF_B</em> values. The following listing describes the impact
of thread selector component <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code>:</p>
<ul>
<li>
<p>One thread-pair within the quad determined by <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code>, contributes the <em>SF_A</em>
values. The value of 0 selects lower two threads whereas value of 1 selects upper two
threads from the quad. In other words, when <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code> set to 0, thread-pair
satisfying: <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> % 4 == 0 or 1 provides the <em>SF_A</em>. In contrast when
<code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code> set to 1, thread-pair satisfying: <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> % 4 == 2 or 3 provides
the <em>SF_A</em>. Refer <a class="reference internal" href="#mma-scaling-thread-id-a-selection"><span class="std std-numref">Figure 43</span></a> for more details.</p>
<figure class="align-center" id="mma-scaling-thread-id-a-selection">
<img alt="_images/mma-scaling-thread-id-a-selection.png" class="image" src="_images/mma-scaling-thread-id-a-selection.png">
<figcaption>
<p><span class="caption-number">Figure 43 </span><span class="caption-text">Selection of set of values for <em>SF_A</em> based on <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code></span><a class="headerlink" href="#mma-scaling-thread-id-a-selection" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>One thread within the quad, determined by <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code>, contributes the <em>SF_B</em>
value. In other words, each thread satisfying: <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> % 4 == <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code>
provides the <em>SF_B</em>. Refer <a class="reference internal" href="#mma-scaling-thread-id-b-selection"><span class="std std-numref">Figure 44</span></a> for more details.</p>
<figure class="align-center" id="mma-scaling-thread-id-b-selection">
<img alt="_images/mma-scaling-thread-id-b-selection.png" class="image" src="_images/mma-scaling-thread-id-b-selection.png">
<figcaption>
<p><span class="caption-number">Figure 44 </span><span class="caption-text">Selection of set of values for <em>SF_B</em> based on <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code></span><a class="headerlink" href="#mma-scaling-thread-id-b-selection" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
<p>The arguments <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code> selects which bytes from the <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>,
<code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> contribute the <em>SF_A</em> and <em>SF_B</em> values. The following listing describes
implications of <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier on byte selector component <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>,
<code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code>:</p>
<ul class="simple">
<li>
<p>When <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> is <code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code></p>
<ul>
<li><p>One byte each within <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> determined by <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>,
<code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code> respectively contributes the <em>SF_A</em> and <em>SF_B</em> values.</p></li>
</ul>
</li>
<li>
<p>When <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> is <code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code></p>
<ul>
<li><p>One byte-pair (two bytes) within <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> determined by
<code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code> and <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code> contributes the <em>SF_A</em> and <em>SF_B</em> values. The value
of 0 selects lower two bytes whereas value of 2 selects upper two bytes from the
corresponding metadata value.</p></li>
</ul>
</li>
<li>
<p>When <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> is <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p>
<ul>
<li><p>All four bytes within <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> contribute the values.
Hence, <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code> must be zero.</p></li>
</ul>
</li>
</ul>
<p>Refer <a class="reference internal" href="#mma-scaling-byte-id-selection"><span class="std std-numref">Figure 45</span></a> for more details.</p>
<figure class="align-center" id="mma-scaling-byte-id-selection">
<img alt="_images/mma-scaling-byte-id-selection.png" class="image" src="_images/mma-scaling-byte-id-selection.png">
<figcaption>
<p><span class="caption-number">Figure 45 </span><span class="caption-text">Selection of set of values for <em>SF_A</em> or <em>SF_B</em> based on <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code> or <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code></span><a class="headerlink" href="#mma-scaling-byte-id-selection" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#mma-scaling-valid-values-of-selector-components"><span class="std std-numref">Table 37</span></a> enumerates the valid values for
various selector components. Any other value results in an undefined behavior.</p>
<table class="table-no-stripes docutils align-default" id="mma-scaling-valid-values-of-selector-components">
<caption>
<span class="caption-number">Table 37 </span><span class="caption-text">Valid values for various selector components</span><a class="headerlink" href="#mma-scaling-valid-values-of-selector-components" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 26%">
<col style="width: 19%">
<col style="width: 18%">
<col style="width: 19%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>.scale_vec_size</p></th>
<th class="head" colspan="4"><p>Selector Components</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>byte-id-a</p></th>
<th class="head"><p>thread-id-a</p></th>
<th class="head"><p>byte-id-b</p></th>
<th class="head"><p>thread-id-b</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">scale_vec::1X</span></code></p></td>
<td><p>[0, 1, 2, 3]</p></td>
<td rowspan="3"><p>[0, 1]</p></td>
<td><p>[0, 1, 2, 3]</p></td>
<td rowspan="3"><p>[0, 1, 2, 3]</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">scale_vec::2X</span></code></p></td>
<td><p>[0, 2]</p></td>
<td><p>[0, 2]</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">scale_vec::4X</span></code></p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
</section>
<section id="warp-level-matrix-instructions-wmma">
<span id="id361"></span><h4>
<span class="section-number">9.7.14.4. </span><a class="reference internal" href="#warp-level-matrix-instructions-wmma">Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions</a><a class="headerlink" href="#warp-level-matrix-instructions-wmma" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warp level <code class="docutils literal notranslate"><span class="pre">wmma.load,</span> <span class="pre">wmma.mma</span></code> and <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> instructions and the
organization of various matrices invovled in these instruction.</p>
<section id="warp-level-matrix-fragment">
<span id="id362"></span><h5>
<span class="section-number">9.7.14.4.1. </span><a class="reference internal" href="#warp-level-matrix-fragment">Matrix Fragments for WMMA</a><a class="headerlink" href="#warp-level-matrix-fragment" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Each thread in the warp holds a fragment of the matrix. The distribution of fragments loaded by the
threads in a warp is unspecified and is target architecture dependent, and hence the identity of the
fragment within the matrix is also unspecified and is target architecture dependent. The fragment
returned by a <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation can be used as an operand for another <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation if the
shape, layout and element type of the underlying matrix matches. Since fragment layout is
architecture dependent, using the fragment returned by a <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation in one function as an
operand for a <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation in a different function may not work as expected if the two
functions are linked together but were compiled for different link-compatible SM architectures. Note
passing <code class="docutils literal notranslate"><span class="pre">wmma</span></code> fragment to a function having <code class="docutils literal notranslate"><span class="pre">.weak</span></code> linkage is unsafe since at link time
references to such function may get resolved to a function in different compilation module.</p>
<p>Each fragment is a vector expression whose contents are determined as follows. The identity of
individual matrix elements in the fragment is unspecified.</p>
<p class="rubric">Integer fragments</p>
<p>Multiplicands (A or B):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 16%">
<col style="width: 8%">
<col style="width: 57%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> or <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression of two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression of two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four elements from the matrix.</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register
containing four elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four elements from the matrix.</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression containing single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register,
with each containing four elements from the matrix.</p></td>
</tr>
</tbody>
</table>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 21%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code></p></td>
<td rowspan="3"><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
</tr>
</tbody>
</table>
<p class="rubric">Floating point fragments</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 13%">
<col style="width: 71%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A or B</p></td>
<td><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>C or D</p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Floating point fragments for <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> data format</p>
<p>Multiplicands (A or B):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 12%">
<col style="width: 17%">
<col style="width: 9%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m16n16k16</span></code></p></td>
<td><p>A</p></td>
<td rowspan="2"><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing two elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression containing a two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
with containing two elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with
each register containing two elements from the matrix.</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with
each register containing two elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
with each containing two elements from the matrix.</p></td>
</tr>
</tbody>
</table>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 10%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>C or D</p></td>
<td><p>A vector expression containing eight <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Floating point fragments for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> data format</p>
<p>Multiplicands (A or B):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 18%">
<col style="width: 10%">
<col style="width: 59%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code></p></td>
<td><p>A</p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers.</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 9%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code></p></td>
<td><p>C or D</p></td>
<td><p>A vector expression containing eight <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Double precision floating point fragments</p>
<p>Multiplicands (A or B):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 10%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code></p></td>
<td><p>A or B</p></td>
<td><p>A vector expression of single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register.</p></td>
</tr>
</tbody>
</table>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 9%">
<col style="width: 64%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code></p></td>
<td><p>C or D</p></td>
<td><p>A vector expression containing single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Sub-byte integer and single-bit fragments</p>
<p>Multiplicands (A or B):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 11%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u4</span></code> or <code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing eight elements from the matrix.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing 32 elements from the matrix.</p></td>
</tr>
</tbody>
</table>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 20%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Shape</p></th>
<th class="head"><p>Fragment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code></p></td>
<td><p>A vector expression of two <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code></p></td>
<td><p>A vector expression of two <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Manipulating fragment contents</p>
<p>The contents of a matrix fragment can be manipulated by reading and writing to individual
registers in the fragment, provided the following conditions are satisfied:</p>
<ul class="simple">
<li><p>All matrix element in the fragment are operated on uniformly across threads, using the same
parameters.</p></li>
<li><p>The order of the matrix elements is not changed.</p></li>
</ul>
<p>For example, if each register corresponding to a given matrix is multiplied by a uniform constant
value, then the resulting matrix is simply the scaled version of the original matrix.</p>
<p>Note that type conversion between <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f32</span></code> accumulator fragments is not supported in
either direction. The result is undefined even if the order of elements in the fragment remains
unchanged.</p>
</section>
<section id="warp-level-matrix-storage">
<span id="id363"></span><h5>
<span class="section-number">9.7.14.4.2. </span><a class="reference internal" href="#warp-level-matrix-storage">Matrix Storage for WMMA</a><a class="headerlink" href="#warp-level-matrix-storage" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Each matrix can be stored in memory with a <em>row-major</em> or <em>column-major</em> layout. In a <em>row-major</em>
format, consecutive elements of each row are stored in contiguous memory locations, and the row is
called the <em>leading dimension</em> of the matrix. In a <em>column-major</em> format, consecutive elements of
each column are stored in contiguous memory locations and the column is called the <em>leading
dimension</em> of the matrix.</p>
<p>Consecutive instances of the <em>leading dimension</em> (rows or columns) need not be stored contiguously
in memory. The <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> and <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> operations accept an optional argument <code class="docutils literal notranslate"><span class="pre">stride</span></code>
that specifies the offset from the beginning of each row (or column) to the next, in terms of matrix
elements (and not bytes). For example, the matrix being accessed by a <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation may be a
submatrix from a larger matrix stored in memory. This allows the programmer to compose a
multiply-and-accumulate operation on matrices that are larger than the shapes supported by the
<code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation.</p>
<p class="rubric">Address Alignment</p>
<p>The starting address of each instance of the leading dimension (row or column) must be aligned
with the size of the corresponding fragment in bytes. Note that the starting address is
determined by the base pointer and the optional <code class="docutils literal notranslate"><span class="pre">stride</span></code>.</p>
<p>Consider the following instruction as an example:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.row.m16n16k16.f16 {x0,...,x7}, [p], s;
</pre></div>
</div>
<ul class="simple">
<li><p>Fragment size in bytes = 32 (eight elements of type <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>)</p></li>
<li><p>Actual <code class="docutils literal notranslate"><span class="pre">stride</span></code> in bytes = 2 * <code class="docutils literal notranslate"><span class="pre">s</span></code> (since <code class="docutils literal notranslate"><span class="pre">stride</span></code> is specified in terms of <code class="docutils literal notranslate"><span class="pre">.f16</span></code>
elements, not bytes)</p></li>
<li>
<p>For each row of this matrix to be aligned at fragment size the following must be true:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code> is a multiple of 32.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">2*s</span></code> is a multiple of 32.</p></li>
</ol>
</li>
</ul>
<p class="rubric">Default value for stride</p>
<p>The default value of the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is the size of the <em>leading dimension</em> of the matrix. For
example, for an <code class="docutils literal notranslate"><span class="pre">MxK</span></code> matrix, the <code class="docutils literal notranslate"><span class="pre">stride</span></code> is <code class="docutils literal notranslate"><span class="pre">K</span></code> for a <em>row-major</em> layout and <code class="docutils literal notranslate"><span class="pre">M</span></code> for a
<em>column-major</em> layout. In particular, the default strides for the supported matrix shapes are as
follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 13%">
<col style="width: 20%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Shape</p></th>
<th class="head"><p>A (row)</p></th>
<th class="head"><p>A (column)</p></th>
<th class="head"><p>B (row)</p></th>
<th class="head"><p>B (column)</p></th>
<th class="head"><p>Accumulator (row)</p></th>
<th class="head"><p>Accumulator (column)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>16x16x16</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-odd">
<td><p>8x32x16</p></td>
<td><p>16</p></td>
<td><p>8</p></td>
<td><p>32</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-even">
<td><p>32x8x16</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>8</p></td>
<td><p>32</p></td>
</tr>
<tr class="row-odd">
<td><p>8x8x32</p></td>
<td><p>32</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>32</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-even">
<td><p>8x8x128</p></td>
<td><p>128</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>128</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>16x16x8</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even">
<td><p>8x8x4</p></td>
<td><p>4</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
<td><p>4</p></td>
<td><p>8</p></td>
<td><p>8</p></td>
</tr>
</tbody>
</table>
</section>
<section id="warp-level-matrix-instructions-wmma-ld">
<span id="id364"></span><h5>
<span class="section-number">9.7.14.4.3. </span><a class="reference internal" href="#warp-level-matrix-instructions-wmma-ld">Warp-level Matrix Load Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-wmma-ld" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wmma.load</span></code></p>
<p>Collectively load a matrix from memory for WMMA</p>
<p class="rubric">Syntax</p>
<p>Floating point format <code class="docutils literal notranslate"><span class="pre">.f16</span></code> loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride};
wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride};
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride};

.layout = {.row, .col};
.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
.ss     = {.global, .shared{::cta}};
.atype  = {.f16, .s8, .u8};
.btype  = {.f16, .s8, .u8};
.ctype  = {.f16, .f32, .s32};
</pre></div>
</div>
<p>Alternate floating point format <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
.layout = {.row, .col};
.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
.ss     = {.global, .shared{::cta}};
.atype  = {.bf16 };
.btype  = {.bf16 };
.ctype  = {.f32 };
</pre></div>
</div>
<p>Alternate floating point format <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
.layout = {.row, .col};
.shape  = {.m16n16k8 };
.ss     = {.global, .shared{::cta}};
.atype  = {.tf32 };
.btype  = {.tf32 };
.ctype  = {.f32 };
</pre></div>
</div>
<p>Double precision Floating point <code class="docutils literal notranslate"><span class="pre">.f64</span></code> loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.layout.shape{.ss}.atype r, [p] {, stride}
wmma.load.b.sync.aligned.layout.shape{.ss}.btype r, [p] {, stride}
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
.layout = {.row, .col};
.shape  = {.m8n8k4 };
.ss     = {.global, .shared{::cta}};
.atype  = {.f64 };
.btype  = {.f64 };
.ctype  = {.f64 };
</pre></div>
</div>
<p>Sub-byte loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}
wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
.layout = {.row, .col};
.shape  = {.m8n8k32};
.ss     = {.global, .shared{::cta}};
.atype  = {.s4, .u4};
.btype  = {.s4, .u4};
.ctype  = {.s32};
</pre></div>
</div>
<p>Single-bit loads:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.load.a.sync.aligned.row.shape{.ss}.atype r, [p] {, stride}
wmma.load.b.sync.aligned.col.shape{.ss}.btype r, [p] {, stride}
wmma.load.c.sync.aligned.layout.shape{.ss}.ctype r, [p] {, stride}
.layout = {.row, .col};
.shape  = {.m8n8k128};
.ss     = {.global, .shared{::cta}};
.atype  = {.b1};
.btype  = {.b1};
.ctype  = {.s32};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Collectively load a matrix across all threads in a warp from the location indicated by address
operand <code class="docutils literal notranslate"><span class="pre">p</span></code> in the specified state space into destination register <code class="docutils literal notranslate"><span class="pre">r</span></code>.</p>
<p>If no state space is given, perform the memory accesses using
<a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>. <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> operation may be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> and
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces and with generic addressing, where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> or
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> space.</p>
<p>The mutually exclusive qualifiers <code class="docutils literal notranslate"><span class="pre">.a</span></code>, <code class="docutils literal notranslate"><span class="pre">.b</span></code> and <code class="docutils literal notranslate"><span class="pre">.c</span></code> indicate whether matrix A, B or C is
being loaded respectively for the <code class="docutils literal notranslate"><span class="pre">wmma</span></code> computation.</p>
<p>The destination operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression that can hold the fragment
returned by the load operation, as described in <a class="reference internal" href="#warp-level-matrix-fragment"><span class="std std-ref">Matrix Fragments for WMMA</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimensions of all the matrix arguments involved in the
intended <code class="docutils literal notranslate"><span class="pre">wmma</span></code> computation.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.layout</span></code> qualifier indicates whether the matrix to be loaded is stored in <em>row-major</em> or
<em>column-major</em> format.</p>
<p><code class="docutils literal notranslate"><span class="pre">stride</span></code> is an optional 32-bit integer operand that provides an offset in terms of matrix elements
between the start of consecutive instances of the <em>leading dimension</em> (rows or columns). The default
value of <code class="docutils literal notranslate"><span class="pre">stride</span></code> is described in
<a class="reference internal" href="#warp-level-matrix-storage"><span class="std std-ref">Matrix Storage for WMMA</span></a> and must be specified if the actual value is larger than
the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride
is the leading dimension of the larger matrix. Specifying a value lower than the default value
results in undefined behavior.</p>
<p>The required alignment for address <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">stride</span></code> is described in the
<a class="reference internal" href="#warp-level-matrix-storage"><span class="std std-ref">Matrix Storage for WMMA</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> is undefined if all threads do not use the same qualifiers and the
same values of <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">stride</span></code>, or if any thread in the warp has exited.</p>
<p><code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> is treated as a <em>weak</em> memory operation in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code> introduced in PTX ISA version 6.1.</p>
<p>Integer, sub-byte integer and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 6.3.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code> on <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 7.0.</p>
<p>Double precision and alternate floating point precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 7.0.</p>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> sub-qualifier introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Floating point <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Integer <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> or higher.</p>
<p>Sub-byte and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Double precision and alternate floating point precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Load elements from f16 row-major matrix B
.reg .b32 x&lt;8&gt;;

wmma.load.b.sync.aligned.m16n16k16.row.f16 {x0,x1,x2,x3,x4,x5,x,x7}, [ptr];
// Now use {x0, ..., x7} for the actual wmma.mma

// Load elements from f32 column-major matrix C and scale the values:
.reg .b32 x&lt;8&gt;;

wmma.load.c.sync.aligned.m16n16k16.col.f32
                 {x0,x1,x2,x3,x4,x5,x6,x7}, [ptr];

mul.f32 x0, x0, 0.1;
// repeat for all registers x&lt;8&gt;;
...
mul.f32 x7, x7, 0.1;
// Now use {x0, ..., x7} for the actual wmma.mma

// Load elements from integer matrix A:
.reg .b32 x&lt;4&gt;
// destination registers x&lt;4&gt; contain four packed .u8 values each
wmma.load.a.sync.aligned.m32n8k16.row.u8 {x0,x1,x2,x3}, [ptr];

// Load elements from sub-byte integer matrix A:
.reg .b32 x0;
// destination register x0 contains eight packed .s4 values
wmma.load.a.sync.aligned.m8n8k32.row.s4 {x0}, [ptr];

// Load elements from .bf16 matrix A:
.reg .b32 x&lt;4&gt;;
wmma.load.a.sync.aligned.m16n16k16.row.bf16
                {x0,x1,x2,x3}, [ptr];

// Load elements from .tf32 matrix A:
.reg .b32 x&lt;4&gt;;
wmma.load.a.sync.aligned.m16n16k8.row.tf32
                {x0,x1,x2,x3}, [ptr];

// Load elements from .f64 matrix A:
.reg .b32 x&lt;4&gt;;
wmma.load.a.sync.aligned.m8n8k4.row.f64
                {x0}, [ptr];
</pre></div>
</div>
</section>
<section id="warp-level-matrix-instructions-wmma-st">
<span id="id365"></span><h5>
<span class="section-number">9.7.14.4.4. </span><a class="reference internal" href="#warp-level-matrix-instructions-wmma-st">Warp-level Matrix Store Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-wmma-st" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wmma.store</span></code></p>
<p>Collectively store a matrix into memory for WMMA</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride};

.layout = {.row, .col};
.shape  = {.m16n16k16, .m8n32k16, .m32n8k16};
.ss     = {.global, .shared{::cta}};
.type   = {.f16, .f32, .s32};

wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
.layout = {.row, .col};
.shape  = {.m8n8k32, .m8n8k128};
.ss     = {.global, .shared{::cta}};
.type   = {.s32};

wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
.layout = {.row, .col};
.shape  = {.m16n16k8};
.ss     = {.global, .shared{::cta}};
.type   = {.f32};

wmma.store.d.sync.aligned.layout.shape{.ss}.type [p], r {, stride}
.layout = {.row, .col};
.shape  = {.m8n8k4 };
.ss     = {.global, .shared{::cta}};
.type   = {.f64};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Collectively store a matrix across all threads in a warp at the location indicated by address
operand <code class="docutils literal notranslate"><span class="pre">p</span></code> in the specified state space from source register <code class="docutils literal notranslate"><span class="pre">r</span></code>.</p>
<p>If no state space is given, perform the memory accesses using
<a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a>. <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> operation may be used only with <code class="docutils literal notranslate"><span class="pre">.global</span></code> and
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> spaces and with generic addressing, where the address points to <code class="docutils literal notranslate"><span class="pre">.global</span></code> or
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> space.</p>
<p>The source operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression that matches the shape of the
fragment expected by the store operation, as described in <a class="reference internal" href="#warp-level-matrix-fragment"><span class="std std-ref">Matrix Fragments for WMMA</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimensions of all the matrix arguments involved in the
intended <code class="docutils literal notranslate"><span class="pre">wmma</span></code> computation. It must match the <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier specified on the <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>
instruction that produced the D matrix being stored.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.layout</span></code> qualifier indicates whether the matrix to be loaded is stored in <em>row-major</em> or
<em>column-major</em> format.</p>
<p><code class="docutils literal notranslate"><span class="pre">stride</span></code> is an optional 32-bit integer operand that provides an offset in terms of matrix elements
between the start of consecutive instances of the <em>leading dimension</em> (rows or columns). The default
value of <code class="docutils literal notranslate"><span class="pre">stride</span></code> is described in
<a class="reference internal" href="#warp-level-matrix-storage"><span class="std std-ref">Matrix Storage for WMMA</span></a> and must be specified if the actual value is larger than
the default. For example, if the matrix is a sub-matrix of a larger matrix, then the value of stride
is the leading dimension of the larger matrix. Specifying a value lower than the default value
results in undefined behavior.</p>
<p>The required alignment for address <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">stride</span></code> is described in the
<a class="reference internal" href="#warp-level-matrix-storage"><span class="std std-ref">Matrix Storage for WMMA</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> is undefined if all threads do not use the same qualifiers and the
same values of <code class="docutils literal notranslate"><span class="pre">p</span></code> and <code class="docutils literal notranslate"><span class="pre">stride</span></code>, or if any thread in the warp has exited.</p>
<p><code class="docutils literal notranslate"><span class="pre">wmma.store</span></code> is treated as a <em>weak</em> memory operation in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code> introduced in PTX ISA version 6.1.</p>
<p>Integer, sub-byte integer and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 6.3.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code> introduced in PTX ISA version 7.0.</p>
<p>Double precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 7.0.</p>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> sub-qualifier introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Floating point <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Integer <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> or higher.</p>
<p>Sub-byte and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Double precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> and shape <code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Storing f32 elements computed by a wmma.mma
.reg .b32 x&lt;8&gt;;

wmma.mma.sync.m16n16k16.row.col.f32.f32
              {d0, d1, d2, d3, d4, d5, d6, d7}, ...;
wmma.store.d.sync.m16n16k16.row.f32
              [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};

// Store s32 accumulator for m16n16k16 shape:
.reg .b32 d&lt;8&gt;;
wmma.store.d.sync.aligned.m16n16k16.row.s32
              [ptr], {d0, d1, d2, d3, d4, d5, d6, d7};

// Store s32 accumulator for m8n8k128 shape:
.reg .b32 d&lt;2&gt;
wmma.store.d.sync.aligned.m8n8k128.row.s32
[ptr], {d0, d1};

// Store f64 accumulator for m8n8k4 shape:
.reg .f64 d&lt;2&gt;;
wmma.store.d.sync.aligned.m8n8k4.row.f64
              [ptr], {d0, d1};
</pre></div>
</div>
</section>
<section id="warp-level-matrix-instructions-wmma-mma">
<span id="id366"></span><h5>
<span class="section-number">9.7.14.4.5. </span><a class="reference internal" href="#warp-level-matrix-instructions-wmma-mma">Warp-level Matrix Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-wmma-mma" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code></p>
<p>Perform a single matrix multiply-and-accumulate operation across a warp</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Floating point (.f16 multiplicands) wmma.mma
wmma.mma.sync.aligned.alayout.blayout.shape.dtype.ctype d, a, b, c;

// Integer (.u8/.s8 multiplicands) wmma.mma
wmma.mma.sync.aligned.alayout.blayout.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;

.alayout = {.row, .col};
.blayout = {.row, .col};
.shape  =  {.m16n16k16, .m8n32k16, .m32n8k16};
.dtype   = {.f16, .f32};
.atype   = {.s8, .u8};
.btype   = {.s8, .u8};
.ctype   = {.f16, .f32};
</pre></div>
</div>
<p>Floating point format <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;
.alayout = {.row, .col};
.blayout = {.row, .col};
.shape   = {.m16n16k16, .m8n32k16, .m32n8k16};
.atype   = {.bf16 };
.btype   = {.bf16};
</pre></div>
</div>
<p>Floating point format <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.mma.sync.aligned.alayout.blayout.shape.f32.atype.btype.f32 d, a, b, c;
.alayout = {.row, .col};
.blayout = {.row, .col};
.shape   = {.m16n16k8 };
.atype   = {.tf32 };
.btype   = {.tf32};
</pre></div>
</div>
<p>Floating point Double precision <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.mma.sync.aligned.alayout.blayout.shape{.rnd}.f64.f64.f64.f64 d, a, b, c;
.alayout = {.row, .col};
.blayout = {.row, .col};
.shape   = {.m8n8k4 };
.rnd = { .rn, .rz, .rm, .rp };
</pre></div>
</div>
<p>Sub-byte (<code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> multiplicands) <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.mma.sync.aligned.row.col.shape.s32.atype.btype.s32{.satfinite} d, a, b, c;
.shape  = {.m8n8k32};
.atype  = {.s4, .u4};
.btype  = {.s4, .u4};
</pre></div>
</div>
<p>Single-bit (<code class="docutils literal notranslate"><span class="pre">.b1</span></code> multiplicands) <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code>:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wmma.mma.op.popc.sync.aligned.row.col.shape.s32.atype.btype.s32 d, a, b, c;
.shape  = {.m8n8k128};
.atype  = {.b1};
.btype  = {.b1};
.op     = {.xor, .and}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Perform a warp-level matrix multiply-and-accumulate computation <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">*</span> <span class="pre">B</span> <span class="pre">+</span> <span class="pre">C</span></code> using matrices A,
B and C loaded in registers <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> respectively, and store the result matrix in
register <code class="docutils literal notranslate"><span class="pre">d</span></code>. The register arguments <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, <code class="docutils literal notranslate"><span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> hold unspecified fragments of
the corresponding matrices as described in <a class="reference internal" href="#warp-level-matrix-fragment"><span class="std std-ref">Matrix Fragments for WMMA</span></a></p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">.atype</span></code>, <code class="docutils literal notranslate"><span class="pre">.btype</span></code> and <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> indicate the data-type of the
elements in the matrices D, A, B and C respectively.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> without explicit <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code>: <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> are
implicitly set to <code class="docutils literal notranslate"><span class="pre">.f16</span></code>.</p>
<p>For integer <code class="docutils literal notranslate"><span class="pre">wmma</span></code>, <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> and <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must be specified as <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. Also, the values for
<code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> must be the same, i.e., either both are <code class="docutils literal notranslate"><span class="pre">.s8</span></code> or both are <code class="docutils literal notranslate"><span class="pre">.u8</span></code>.</p>
<p>For sub-byte single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code>, <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> and <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must be specified as <code class="docutils literal notranslate"><span class="pre">.s32</span></code>. Also, the
values for <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> must be the same; i.e., either both are <code class="docutils literal notranslate"><span class="pre">.s4</span></code>, both are
<code class="docutils literal notranslate"><span class="pre">.u4</span></code>, or both are <code class="docutils literal notranslate"><span class="pre">.b1</span></code>.</p>
<p>For single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code>, multiplication is replaced by a sequence of logical operations;
specifically, <code class="docutils literal notranslate"><span class="pre">wmma.xor.popc</span></code> and <code class="docutils literal notranslate"><span class="pre">wmma.and.popc</span></code> computes the XOR, AND respectively of a
128-bit row of A with a 128-bit column of B, then counts the number of set bits in the result
(<code class="docutils literal notranslate"><span class="pre">popc</span></code>). This result is added to the corresponding element of C and written into D.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.alayout</span></code> and <code class="docutils literal notranslate"><span class="pre">.blayout</span></code> must match the layout specified on the <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code>
instructions that produce the contents of operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> respectively. Similarly, the
qualifiers <code class="docutils literal notranslate"><span class="pre">.atype</span></code>, <code class="docutils literal notranslate"><span class="pre">.btype</span></code> and <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> must match the corresponding qualifiers on the
<code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> instructions that produce the contents of operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code>
respectively.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier must match the <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier used on the <code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> instructions
that produce the contents of all three input operands <code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code> and <code class="docutils literal notranslate"><span class="pre">c</span></code> respectively.</p>
<p>The destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> is a brace-enclosed vector expression that matches the <code class="docutils literal notranslate"><span class="pre">.shape</span></code> of
the fragment computed by the <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction.</p>
<dl>
<dt>Saturation at the output:</dt>
<dd>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> indicates that the final values in the destination register
are saturated as follows:</p>
<ul class="simple">
<li><p>The output is clamped to the minimum or maximum 32-bit signed integer value. Otherwise, if the
accumulation would overflow, the value wraps.</p></li>
</ul>
</dd>
<dt>Precision and rounding for <code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point operations:</dt>
<dd>
<p>Element-wise multiplication of matrix A and B is performed with at least single precision. When
<code class="docutils literal notranslate"><span class="pre">.ctype</span></code> or <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, accumulation of the intermediate values is performed with
at least single precision. When both <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> and <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> are specified as <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, the
accumulation is performed with at least half precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs is unspecified.</p>
</dd>
<dt>Precision and rounding for <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point operations:</dt>
<dd>
<p>Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
of the intermediate values is performed with at least single precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs is unspecified.</p>
</dd>
</dl>
<p>Rounding modifiers on double precision <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> (default is <code class="docutils literal notranslate"><span class="pre">.rn</span></code>):</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">.rn</span></code></dt>
<dd>
<p>mantissa LSB rounds to nearest even</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rz</span></code></dt>
<dd>
<p>mantissa LSB rounds towards zero</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rm</span></code></dt>
<dd>
<p>mantissa LSB rounds towards negative infinity</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">.rp</span></code></dt>
<dd>
<p>mantissa LSB rounds towards positive infinity</p>
</dd>
</dl>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise
behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> is undefined if all threads in the same warp do not use the same
qualifiers, or if any thread in the warp has exited.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m8n32k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m32n8k16</span></code> introduced in PTX ISA version 6.1.</p>
<p>Integer, sub-byte integer and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 6.3.</p>
<p>Double precision and alternate floating point precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 7.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.and</span></code> operation in single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> introduced in PTX ISA version 7.1.</p>
<p>Modifier <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> is required from PTX ISA version 6.3 onwards, and considered implicit in PTX
ISA versions less than 6.3.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> on floating point <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> is deprecated in PTX ISA version 6.4 and
is removed from PTX ISA version 6.5.</p>
<p class="rubric">Target ISA Notes</p>
<p>Floating point <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p>Integer <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> or higher.</p>
<p>Sub-byte and single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Double precision, alternate floating point precision <code class="docutils literal notranslate"><span class="pre">wmma</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.and</span></code> operation in single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.global .align 32 .f16 A[256], B[256];
.global .align 32 .f32 C[256], D[256];
.reg .b32 a&lt;8&gt; b&lt;8&gt; c&lt;8&gt; d&lt;8&gt;;

wmma.load.a.sync.aligned.m16n16k16.global.row.f16
        {a0, a1, a2, a3, a4, a5, a6, a7}, [A];
wmma.load.b.sync.aligned.m16n16k16.global.col.f16
        {b0, b1, b2, b3, b4, b5, b6, b7}, [B];

wmma.load.c.sync.aligned.m16n16k16.global.row.f32
        {c0, c1, c2, c3, c4, c5, c6, c7}, [C];

wmma.mma.sync.aligned.m16n16k16.row.col.f32.f32
        {d0, d1, d2, d3, d4, d5, d6, d7},
        {a0, a1, a2, a3, a4, a5, a6, a7},
        {b0, b1, b2, b3, b4, b5, b6, b7},
        {c0, c1, c2, c3, c4, c5, c6, c7};

wmma.store.d.sync.aligned.m16n16k16.global.col.f32
        [D], {d0, d1, d2, d3, d4, d5, d6, d7};

// Compute an integer WMMA:
.reg .b32  a, b&lt;4&gt;;
.reg .b32 c&lt;8&gt;, d&lt;8&gt;;
wmma.mma.sync.aligned.m8n32k16.row.col.s32.s8.s8.s32
        {d0, d1, d2, d3, d4, d5, d6, d7},
        {a}, {b0, b1, b2,  b3},
        {c0, c1, c2, c3, c4, c5, c6, c7};

// Compute sub-byte WMMA:
.reg .b32 a, b, c&lt;2&gt; d&lt;2&gt;
wmma.mma.sync.aligned.m8n8k32.row.col.s32.s4.s4.s32
        {d0, d1}, {a}, {b}, {c0, c1};

// Compute single-bit type WMMA:
.reg .b32 a, b, c&lt;2&gt; d&lt;2&gt;
wmma.mma.xor.popc.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32
        {d0, d1}, {a}, {b}, {c0, c1};

// Compute double precision wmma
.reg .f64 a, b, c&lt;2&gt;, d&lt;2&gt;;
wmma.mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64
        {d0, d1}, {a}, {b}, {c0, c1};

// Compute alternate floating point precision wmma
.reg .b32 a&lt;2&gt;, b&lt;2&gt;, c&lt;8&gt;, d&lt;8&gt;;
wmma.mma.sync.aligned.m16n16k8.row.col.f32.tf32.tf32.f32
        {d0, d1, d2, d3, d4, d5, d6, d7},
        {a0, a1, a2, a3}, {b0, b1, b2, b3},
        {c0, c1, c2, c3, c4, c5, c6, c7};
</pre></div>
</div>
</section>
</section>
<section id="warp-level-matrix-instructions-for-mma">
<span id="id367"></span><h4>
<span class="section-number">9.7.14.5. </span>Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction<a class="headerlink" href="#warp-level-matrix-instructions-for-mma" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warp-level <code class="docutils literal notranslate"><span class="pre">mma</span></code>, <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code>, <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code>, and <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code>
instructions and the organization of various matrices involved in these instructions.</p>
<section id="warp-level-matrix-fragment-mma-884-f16">
<span id="id368"></span><h5>
<span class="section-number">9.7.14.5.1. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-884-f16">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type</a><a class="headerlink" href="#warp-level-matrix-fragment-mma-884-f16" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type will compute 4 MMA operations of shape
<code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code>.</p>
<p>Elements of 4 matrices need to be distributed across the threads in a warp. The following table
shows distribution of matrices for MMA operations.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 22%">
<col style="width: 78%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>MMA Computation</p></th>
<th class="head"><p>Threads participating in MMA computation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>MMA computation 1</p></td>
<td><p>Threads with <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> 0-3 (low group) and 16-19 (high group)</p></td>
</tr>
<tr class="row-odd">
<td><p>MMA computation 2</p></td>
<td><p>Threads with <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> 4-7 (low group) and 20-23 (high group)</p></td>
</tr>
<tr class="row-even">
<td><p>MMA computation 3</p></td>
<td><p>Threads with <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> 8-11 (low group) and 24-27 (high group)</p></td>
</tr>
<tr class="row-odd">
<td><p>MMA computation 4</p></td>
<td><p>Threads with <code class="docutils literal notranslate"><span class="pre">%laneid</span></code> 12-15 (low group) and 28-31 (high group)</p></td>
</tr>
</tbody>
</table>
<p>For each of the individual MMA computation shown above, each of the required thread holds a fragment
of the matrix for performing mma operation as follows:</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 63%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers,
with each register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from
the matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown below:</p>
<ul>
<li>
<p>Fragment layout for Row Major matrix A is shown in <a class="reference internal" href="#mma-884-a-row-f16"><span class="std std-numref">Figure 46</span></a>.</p>
<figure class="align-center" id="mma-884-a-row-f16">
<img alt="_images/mma-884-A-row-f16.png" class="image" src="_images/mma-884-A-row-f16.png">
<figcaption>
<p><span class="caption-number">Figure 46 </span><span class="caption-text">MMA .m8n8k4 fragment layout for row-major matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type</span><a class="headerlink" href="#mma-884-a-row-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">            </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w">          </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">                </span><span class="p">(</span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">     </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">            </span><span class="n">i</span><span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Fragment layout for Column Major matrix A is shown in <a class="reference internal" href="#mma-884-a-col-f16"><span class="std std-numref">Figure 47</span></a>.</p>
<p>The layout of the fragments held by different threads is shown below:</p>
<figure class="align-center" id="mma-884-a-col-f16">
<img alt="_images/mma-884-A-col-f16.png" class="image" src="_images/mma-884-A-col-f16.png">
<figcaption>
<p><span class="caption-number">Figure 47 </span><span class="caption-text">MMA .m8n8k4 fragment layout for column-major matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type</span><a class="headerlink" href="#mma-884-a-col-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w">  </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">            </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w">  </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w">   </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 65%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown below:</p>
<ul>
<li>
<p>Fragment layout for Row Major matrix B is shown in <a class="reference internal" href="#mma-884-b-row-f16"><span class="std std-numref">Figure 48</span></a>.</p>
<figure class="align-center" id="mma-884-b-row-f16">
<img alt="_images/mma-884-B-row-f16.png" class="image" src="_images/mma-884-B-row-f16.png">
<figcaption>
<p><span class="caption-number">Figure 48 </span><span class="caption-text">MMA .m8n8k4 fragment layout for row-major matrix B with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type</span><a class="headerlink" href="#mma-884-b-row-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">         </span><span class="n">i</span><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">             </span><span class="n">i</span><span class="o">+</span><span class="mi">4</span><span class="w">     </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w">   </span><span class="n">otherwise</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Fragment layout for Column Major matrix B is shown in <a class="reference internal" href="#mma-884-b-col-f16"><span class="std std-numref">Figure 49</span></a>.</p>
<figure class="align-center" id="mma-884-b-col-f16">
<img alt="_images/mma-884-B-col-f16.png" class="image" src="_images/mma-884-B-col-f16.png">
<figcaption>
<p><span class="caption-number">Figure 49 </span><span class="caption-text">MMA .m8n8k4 fragment layout for column-major matrix B with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type</span><a class="headerlink" href="#mma-884-b-col-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">       </span><span class="n">i</span><span class="w">                 </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">          </span><span class="p">(</span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">   </span><span class="n">otherwise</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</li>
<li>
<p>Accumulators C (or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 57%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with
each register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix
C (or D).</p></td>
<td rowspan="2"><p>c0, c1, c2, c3, c4, c5, c6, c7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression of eight <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown below:</p>
<ul>
<li>
<p>Fragment layout for accumulator matrix when <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f16</span></code> is shown in <a class="reference internal" href="#mma-884-c-f16"><span class="std std-numref">Figure 50</span></a>.</p>
<figure class="align-center" id="mma-884-c-f16">
<img alt="_images/mma-884-C-f16.png" class="image" src="_images/mma-884-C-f16.png">
<figcaption>
<p><span class="caption-number">Figure 50 </span><span class="caption-text">MMA .m8n8k4 fragment layout for matrix C/D with <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> = <code class="docutils literal notranslate"><span class="pre">.f16</span></code></span><a class="headerlink" href="#mma-884-c-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">       </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w">         </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">    </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">          </span><span class="n">i</span><span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Fragment layout for accumulator matrix when <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code> is shown in
<a class="reference internal" href="#mma-884-c-f32-1"><span class="std std-numref">Figure 51</span></a> and <a class="reference internal" href="#mma-884-c-f32-2"><span class="std std-numref">Figure 52</span></a>.</p>
<figure class="align-center" id="mma-884-c-f32-1">
<img alt="_images/mma-884-C-f32-1.png" class="image" src="_images/mma-884-C-f32-1.png">
<figcaption>
<p><span class="caption-number">Figure 51 </span><span class="caption-text">MMA .m8n8k4 computation 1 and 2 fragment layout for matrix C/D with <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> = <code class="docutils literal notranslate"><span class="pre">.f32</span></code></span><a class="headerlink" href="#mma-884-c-f32-1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mma-884-c-f32-2">
<img alt="_images/mma-884-C-f32-2.png" class="image" src="_images/mma-884-C-f32-2.png">
<figcaption>
<p><span class="caption-number">Figure 52 </span><span class="caption-text">MMA .m8n8k4 computation 3 and 4 fragment layout for matrix C/D with <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> = <code class="docutils literal notranslate"><span class="pre">.f32</span></code></span><a class="headerlink" href="#mma-884-c-f32-2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">     </span><span class="n">X</span><span class="w">           </span><span class="k">if</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">        </span><span class="n">X</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">         </span><span class="n">otherwise</span><span class="w"></span>

<span class="w">          </span><span class="n">where</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mb">0b1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mb">0b10</span><span class="p">)</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mb">0b100</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mb">0b10</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mb">0b1</span><span class="p">)</span><span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-884-f64">
<span id="id369"></span><h5>
<span class="section-number">9.7.14.5.2. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-884-f64">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type</a><a class="headerlink" href="#warp-level-matrix-fragment-mma-884-f64" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m8n8k4</span></code> with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type will compute an MMA operation of
shape <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 68%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register, containing
single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> element from the matrix A.</p></td>
<td><p>a0</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-884-a-f64"><span class="std std-numref">Figure 53</span></a>.</p>
<figure class="align-center" id="mma-884-a-f64">
<img alt="_images/mma-884-A-f64.png" class="image" src="_images/mma-884-A-f64.png">
<figcaption>
<p><span class="caption-number">Figure 53 </span><span class="caption-text">MMA .m8n8k4 fragment layout for matrix A  with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type</span><a class="headerlink" href="#mma-884-a-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 70%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register, containing a single
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> element from the matrix B.</p></td>
<td><p>b0</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-884-b-f64"><span class="std std-numref">Figure 54</span></a>.</p>
<figure class="align-center" id="mma-884-b-f64">
<img alt="_images/mma-884-B-f64.png" class="image" src="_images/mma-884-B-f64.png">
<figcaption>
<p><span class="caption-number">Figure 54 </span><span class="caption-text">MMA .m8n8k4 fragment layout for matrix B  with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type</span><a class="headerlink" href="#mma-884-b-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 64%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing of two <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers containing two
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix C.</p></td>
<td><p>c0, c1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-884-c-f64"><span class="std std-numref">Figure 55</span></a>.</p>
<figure class="align-center" id="mma-884-c-f64">
<img alt="_images/mma-884-C-f64.png" class="image" src="_images/mma-884-C-f64.png">
<figcaption>
<p><span class="caption-number">Figure 55 </span><span class="caption-text">MMA .m8n8k4 fragment layout for accumulator matrix C/D  with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type</span><a class="headerlink" href="#mma-884-c-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-8816">
<span id="id370"></span><h5>
<span class="section-number">9.7.14.5.3. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-8816">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k16</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-8816" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m8n8k16</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m8n8k16</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 62%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
four <code class="docutils literal notranslate"><span class="pre">.s8</span></code> or <code class="docutils literal notranslate"><span class="pre">.u8</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8816-a-i8"><span class="std std-numref">Figure 56</span></a>.</p>
<figure class="align-center" id="mma-8816-a-i8">
<img alt="_images/mma-8816-A-i8.png" class="image" src="_images/mma-8816-A-i8.png">
<figcaption>
<p><span class="caption-number">Figure 56 </span><span class="caption-text">MMA .m8n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type</span><a class="headerlink" href="#mma-8816-a-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w">    </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 62%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
four <code class="docutils literal notranslate"><span class="pre">.s8</span></code> or <code class="docutils literal notranslate"><span class="pre">.u8</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8816-b-i8"><span class="std std-numref">Figure 57</span></a>.</p>
<figure class="align-center" id="mma-8816-b-i8">
<img alt="_images/mma-8816-B-i8.png" class="image" src="_images/mma-8816-B-i8.png">
<figcaption>
<p><span class="caption-number">Figure 57 </span><span class="caption-text">MMA .m8n8k16 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type</span><a class="headerlink" href="#mma-8816-b-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">    </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">    </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 59%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing of two <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
<td><p>c0, c1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8816-c-i8"><span class="std std-numref">Figure 58</span></a>.</p>
<figure class="align-center" id="mma-8816-c-i8">
<img alt="_images/mma-8816-C-i8.png" class="image" src="_images/mma-8816-C-i8.png">
<figcaption>
<p><span class="caption-number">Figure 58 </span><span class="caption-text">MMA .m8n8k16 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type</span><a class="headerlink" href="#mma-8816-c-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">    </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-8832">
<span id="id371"></span><h5>
<span class="section-number">9.7.14.5.4. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-8832">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k32</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-8832" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m8n8k32</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 58%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
eight <code class="docutils literal notranslate"><span class="pre">.s4</span></code> or <code class="docutils literal notranslate"><span class="pre">.u4</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8832-a-i4"><span class="std std-numref">Figure 59</span></a>.</p>
<figure class="align-center" id="mma-8832-a-i4">
<img alt="_images/mma-8832-A-i4.png" class="image" src="_images/mma-8832-A-i4.png">
<figcaption>
<p><span class="caption-number">Figure 59 </span><span class="caption-text">MMA .m8n8k32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type</span><a class="headerlink" href="#mma-8832-a-i4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w">    </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 58%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
eight <code class="docutils literal notranslate"><span class="pre">.s4</span></code> or <code class="docutils literal notranslate"><span class="pre">.u4</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3, b4, b5, b6, b7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8832-b-i4"><span class="std std-numref">Figure 60</span></a>.</p>
<figure class="align-center" id="mma-8832-b-i4">
<img alt="_images/mma-8832-B-i4.png" class="image" src="_images/mma-8832-B-i4.png">
<figcaption>
<p><span class="caption-number">Figure 60 </span><span class="caption-text">MMA .m8n8k32 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type</span><a class="headerlink" href="#mma-8832-b-i4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 54%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression of two <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
<td><p>c0, c1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-8832-c-i4"><span class="std std-numref">Figure 61</span></a>:</p>
<figure class="align-center" id="mma-8832-c-i4">
<img alt="_images/mma-8832-C-i4.png" class="image" src="_images/mma-8832-C-i4.png">
<figcaption>
<p><span class="caption-number">Figure 61 </span><span class="caption-text">MMA .m8n8k32 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type</span><a class="headerlink" href="#mma-8832-c-i4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">   </span><span class="n">groupID</span><span class="w"></span>
<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-88128">
<span id="id372"></span><h5>
<span class="section-number">9.7.14.5.5. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-88128">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m8n8k128</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-88128" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m8n8k128</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 70%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing thirty
two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, â€¦ a30, a31</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-88128-a"><span class="std std-numref">Figure 62</span></a>.</p>
<figure class="align-center" id="mma-88128-a">
<img alt="_images/mma-88128-A.png" class="image" src="_images/mma-88128-A.png">
<figcaption>
<p><span class="caption-number">Figure 62 </span><span class="caption-text">MMA .m8n8k128 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-88128-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">31</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 70%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing thirty
two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, â€¦, b30, b31</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-88128-b"><span class="std std-numref">Figure 63</span></a>.</p>
<figure class="align-center" id="mma-88128-b">
<img alt="_images/mma-88128-B.png" class="image" src="_images/mma-88128-B.png">
<figcaption>
<p><span class="caption-number">Figure 63 </span><span class="caption-text">MMA .m8n8k128 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-88128-b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">31</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 63%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing two
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-88128-c"><span class="std std-numref">Figure 64</span></a>.</p>
<figure class="align-center" id="mma-88128-c">
<img alt="_images/mma-88128-C.png" class="image" src="_images/mma-88128-C.png">
<figcaption>
<p><span class="caption-number">Figure 64 </span><span class="caption-text">MMA .m8n8k128 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type</span><a class="headerlink" href="#mma-88128-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-1684">
<span id="id373"></span><h5>
<span class="section-number">9.7.14.5.6. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-1684">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k4</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-1684" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k4</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code>:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 67%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, containing two
<code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-a-tf32"><span class="std std-numref">Figure 65</span></a>.</p>
<figure class="align-center" id="mma-1684-a-tf32">
<img alt="_images/mma-1684-A.png" class="image" src="_images/mma-1684-A.png">
<figcaption>
<p><span class="caption-number">Figure 65 </span><span class="caption-text">MMA .m16n8k4 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#mma-1684-a-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 68%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, containing two
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-a-f64"><span class="std std-numref">Figure 66</span></a>.</p>
<figure class="align-center" id="mma-1684-a-f64">
<img alt="_images/mma-1684-A.png" class="image" src="_images/mma-1684-A.png">
<figcaption>
<p><span class="caption-number">Figure 66 </span><span class="caption-text">MMA .m16n8k4 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1684-a-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Multiplicand B:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 67%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression of a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing a single
<code class="docutils literal notranslate"><span class="pre">.tf32</span></code> element from the matrix B.</p></td>
<td><p>b0</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-b-tf32"><span class="std std-numref">Figure 67</span></a>.</p>
<figure class="align-center" id="mma-1684-b-tf32">
<img alt="_images/mma-1684-B.png" class="image" src="_images/mma-1684-B.png">
<figcaption>
<p><span class="caption-number">Figure 67 </span><span class="caption-text">MMA .m16n8k4 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#mma-1684-b-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 68%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression of a single <code class="docutils literal notranslate"><span class="pre">.f64</span></code> register, containing a single
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> element from the matrix B.</p></td>
<td><p>b0</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-b-f64"><span class="std std-numref">Figure 68</span></a>.</p>
<figure class="align-center" id="mma-1684-b-f64">
<img alt="_images/mma-1684-B.png" class="image" src="_images/mma-1684-B.png">
<figcaption>
<p><span class="caption-number">Figure 68 </span><span class="caption-text">MMA .m16n8k4 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1684-b-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Accumulators (C or D):</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 64%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.f32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-c-f32"><span class="std std-numref">Figure 69</span></a>.</p>
<figure class="align-center" id="mma-1684-c-f32">
<img alt="_images/mma-1684-C.png" class="image" src="_images/mma-1684-C.png">
<figcaption>
<p><span class="caption-number">Figure 69 </span><span class="caption-text">MMA .m16n8k4 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</span><a class="headerlink" href="#mma-1684-c-f32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                            </span><span class="k">for</span><span class="w"> </span><span class="n">c0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c1</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                          </span><span class="k">for</span><span class="w"> </span><span class="n">c2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 64%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1684-c-f64"><span class="std std-numref">Figure 70</span></a>.</p>
<figure class="align-center" id="mma-1684-c-f64">
<img alt="_images/mma-1684-C.png" class="image" src="_images/mma-1684-C.png">
<figcaption>
<p><span class="caption-number">Figure 70 </span><span class="caption-text">MMA .m16n8k4 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1684-c-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                            </span><span class="k">for</span><span class="w"> </span><span class="n">c0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c1</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                          </span><span class="k">for</span><span class="w"> </span><span class="n">c2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-1688">
<span id="id374"></span><h5>
<span class="section-number">9.7.14.5.7. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-1688">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-1688" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 60%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-a-f16"><span class="std std-numref">Figure 71</span></a>.</p>
<figure class="align-center" id="mma-1688-a-f16">
<img alt="_images/mma-1688-A-f16.png" class="image" src="_images/mma-1688-A-f16.png">
<figcaption>
<p><span class="caption-number">Figure 71 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#mma-1688-a-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w">     </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 68%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-a-tf32"><span class="std std-numref">Figure 72</span></a>.</p>
<figure class="align-center" id="mma-1688-a-tf32">
<img alt="_images/mma-1688-A-tf32.png" class="image" src="_images/mma-1688-A-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 72 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#mma-1688-a-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a2</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>
<span class="w">       </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">a2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> :</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 68%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-a-f64"><span class="std std-numref">Figure 73</span></a>.</p>
<figure class="align-center" id="mma-1688-a-f64">
<img alt="_images/mma-1688-A-tf32.png" class="image" src="_images/mma-1688-A-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 73 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1688-a-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a2</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>
<span class="w">       </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">a2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</li>
<li>
<p>Multiplicand B:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 61%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> register, containing
two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-b-f16"><span class="std std-numref">Figure 74</span></a>.</p>
<figure class="align-center" id="mma-1688-b-f16">
<img alt="_images/mma-1688-B-f16.png" class="image" src="_images/mma-1688-B-f16.png">
<figcaption>
<p><span class="caption-number">Figure 74 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#mma-1688-b-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w">    </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 67%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, containing two
<code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-b-tf32"><span class="std std-numref">Figure 75</span></a>.</p>
<figure class="align-center" id="mma-1688-b-tf32">
<img alt="_images/mma-1688-B-tf32.png" class="image" src="_images/mma-1688-B-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 75 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#mma-1688-b-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">    </span><span class="n">threadID_in_group</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">b0</span><span class="w"></span>
<span class="w">       </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">b1</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 68%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, containing two
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-b-f64"><span class="std std-numref">Figure 76</span></a>.</p>
<figure class="align-center" id="mma-1688-b-f64">
<img alt="_images/mma-1688-B-tf32.png" class="image" src="_images/mma-1688-B-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 76 </span><span class="caption-text">MMA .m16n8k8 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1688-b-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">    </span><span class="n">threadID_in_group</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">b0</span><span class="w"></span>
<span class="w">       </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">4</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">b1</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Accumulators (C or D):</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 63%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
<td></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-c-f16-f32"><span class="std std-numref">Figure 77</span></a>.</p>
<figure class="align-center" id="mma-1688-c-f16-f32">
<img alt="_images/mma-1688-C.png" class="image" src="_images/mma-1688-C.png">
<figcaption>
<p><span class="caption-number">Figure 77 </span><span class="caption-text">MMA .m16n8k8 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</span><a class="headerlink" href="#mma-1688-c-f16-f32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                            </span><span class="k">for</span><span class="w"> </span><span class="n">c0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c1</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                          </span><span class="k">for</span><span class="w"> </span><span class="n">c2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 61%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression of four <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers containing four
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-1688-c-f64"><span class="std std-numref">Figure 78</span></a>.</p>
<figure class="align-center" id="mma-1688-c-f64">
<img alt="_images/mma-1688-C.png" class="image" src="_images/mma-1688-C.png">
<figcaption>
<p><span class="caption-number">Figure 78 </span><span class="caption-text">MMA .m16n8k8 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-1688-c-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                            </span><span class="k">for</span><span class="w"> </span><span class="n">c0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c1</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                          </span><span class="k">for</span><span class="w"> </span><span class="n">c2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">c3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">   </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-16816-float">
<span id="id375"></span><h5>
<span class="section-number">9.7.14.5.8. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-float">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with floating point type</a><a class="headerlink" href="#warp-level-matrix-fragment-mma-16816-float" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> floating point types will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 54%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with
each register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements
from the matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-a-f16"><span class="std std-numref">Figure 79</span></a>.</p>
<figure class="align-center" id="mma-16816-a-f16">
<img alt="_images/mma-16816-A-f16.png" class="image" src="_images/mma-16816-A-f16.png">
<figcaption>
<p><span class="caption-number">Figure 79 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#mma-16816-a-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">6</span><span class="w"></span>
<span class="w">          </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">         </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">4</span><span class="w"></span>
<span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 62%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing eight <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, with each
register containing one <code class="docutils literal notranslate"><span class="pre">.f64</span></code> element from the matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-a-f64"><span class="std std-numref">Figure 80</span></a>.</p>
<figure class="align-center" id="mma-16816-a-f64">
<img alt="_images/mma-16816-A-f64.png" class="image" src="_images/mma-16816-A-f64.png">
<figcaption>
<p><span class="caption-number">Figure 80 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-16816-a-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w">                               </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="w">       </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                           </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w">           </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>
<span class="w">       </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w">      </span><span class="n">Otherwise</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Multiplicand B:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 20%">
<col style="width: 58%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with
each register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements
from the matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-b-f16"><span class="std std-numref">Figure 81</span></a>.</p>
<figure class="align-center" id="mma-16816-b-f16">
<img alt="_images/mma-16816-B-f16.png" class="image" src="_images/mma-16816-B-f16.png">
<figcaption>
<p><span class="caption-number">Figure 81 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#mma-16816-b-f16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>where the row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">           </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">       </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 66%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers, with each
register containing one <code class="docutils literal notranslate"><span class="pre">.f64</span></code> element from the matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-b-f64"><span class="std std-numref">Figure 82</span></a>.</p>
<figure class="align-center" id="mma-16816-b-f64">
<img alt="_images/sparse-mma-16816-tf32-B.png" class="image" src="_images/sparse-mma-16816-tf32-B.png">
<figcaption>
<p><span class="caption-number">Figure 82 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type.</span><a class="headerlink" href="#mma-16816-b-f64" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w">           </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 63%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f64</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f64</span></code> registers containing
<code class="docutils literal notranslate"><span class="pre">.f64</span></code> elements from the matrix C (or D).</p></td>
<td rowspan="3"><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers containing
four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> elements from the matrix C (or D).</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix C (or D).</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-c"><span class="std std-numref">Figure 83</span></a>.</p>
<figure class="align-center" id="mma-16816-c">
<img alt="_images/mma-16816-C-f16.png" class="image" src="_images/mma-16816-C-f16.png">
<figcaption>
<p><span class="caption-number">Figure 83 </span><span class="caption-text">MMA .m16n8k16 fragment layout for accumulator matrix matrix C/D.</span><a class="headerlink" href="#mma-16816-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                               </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                             </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-16816-i8-f8">
<span id="id376"></span><h5>
<span class="section-number">9.7.14.5.9. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-i8-f8">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with integer type</a><a class="headerlink" href="#warp-level-matrix-fragment-mma-16816-i8-f8" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 56%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-a-i8"><span class="std std-numref">Figure 84</span></a>.</p>
<figure class="align-center" id="mma-16816-a-i8">
<img alt="_images/mma-16816-A-i8.png" class="image" src="_images/mma-16816-A-i8.png">
<figcaption>
<p><span class="caption-number">Figure 84 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#mma-16816-a-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                          </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x3</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 62%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
four <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register, containing
four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1. b2. b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-b-i8"><span class="std std-numref">Figure 85</span></a>.</p>
<figure class="align-center" id="mma-16816-b-i8">
<img alt="_images/mma-16816-B-i8.png" class="image" src="_images/mma-16816-B-i8.png">
<figcaption>
<p><span class="caption-number">Figure 85 </span><span class="caption-text">MMA .m16n8k16 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#mma-16816-b-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 63%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c1, c2</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16816-c-i8"><span class="std std-numref">Figure 86</span></a>.</p>
<figure class="align-center" id="mma-16816-c-i8">
<img alt="_images/mma-16816-C-i8.png" class="image" src="_images/mma-16816-C-i8.png">
<figcaption>
<p><span class="caption-number">Figure 86 </span><span class="caption-text">MMA .m16n8k16 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code>  type.</span><a class="headerlink" href="#mma-16816-c-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                         </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-16832">
<span id="id377"></span><h5>
<span class="section-number">9.7.14.5.10. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-16832">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-16832" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> or <code class="docutils literal notranslate"><span class="pre">.u4</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 61%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, â€¦, a14, a15</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16832-a-i4"><span class="std std-numref">Figure 87</span></a>.</p>
<figure class="align-center" id="mma-16832-a-i4">
<img alt="_images/mma-16832-A-i4.png" class="image" src="_images/mma-16832-A-i4.png">
<figcaption>
<p><span class="caption-number">Figure 87 </span><span class="caption-text">MMA .m16n8k32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> type.</span><a class="headerlink" href="#mma-16832-a-i4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                         </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">15</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> or <code class="docutils literal notranslate"><span class="pre">.u8</span></code> or <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 61%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, .., a14, a15</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, â€¦, a14, a15</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16832-a-i8"><span class="std std-numref">Figure 88</span></a>.</p>
<figure class="align-center" id="mma-16832-a-i8">
<img alt="_images/mma-16832-A-i8.png" class="image" src="_images/mma-16832-A-i8.png">
<figcaption>
<p><span class="caption-number">Figure 88 </span><span class="caption-text">MMA .m16n8k32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16832-a-i8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">   </span><span class="n">groupID</span><span class="w">                                        </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">12</span><span class="w"></span>
<span class="w">       </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                                     </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">    </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x3</span><span class="p">)</span><span class="w">           </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="w">         </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">16</span><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Multiplicand B:</p>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> or <code class="docutils literal notranslate"><span class="pre">.u4</span></code> :</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 56%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register,
containing eight <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3, b4, b5, b6, b7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16832-b-i4"><span class="std std-numref">Figure 89</span></a>.</p>
<figure class="align-center" id="mma-16832-b-i4">
<img alt="_images/mma-16832-B-i4.png" class="image" src="_images/mma-16832-B-i4.png">
<figcaption>
<p><span class="caption-number">Figure 89 </span><span class="caption-text">MMA .m16n8k32 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> type.</span><a class="headerlink" href="#mma-16832-b-i4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
</div>
</blockquote>
</li>
</ul>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">    </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">7</span><span class="p">}</span><span class="w"></span>
<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">     </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> or <code class="docutils literal notranslate"><span class="pre">.u8</span></code> or <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 56%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.u8</span></code> elements from the
matrix B.</p></td>
<td><p>b0, b1, b2, b3, b4, b5, b6, b7</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, b2, b3, b4, b5, b6, b7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16832-b-i8-1"><span class="std std-numref">Figure 90</span></a> and
<a class="reference internal" href="#mma-16832-b-i8-2"><span class="std std-numref">Figure 91</span></a>.</p>
<figure class="align-center" id="mma-16832-b-i8-1">
<img alt="_images/mma-16832-B-i8_1.png" class="image" src="_images/mma-16832-B-i8_1.png">
<figcaption>
<p><span class="caption-number">Figure 90 </span><span class="caption-text">MMA .m16n8k32 fragment layout for rows 0â€“15 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16832-b-i8-1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mma-16832-b-i8-2">
<img alt="_images/mma-16832-B-i8_2.png" class="image" src="_images/mma-16832-B-i8_2.png">
<figcaption>
<p><span class="caption-number">Figure 91 </span><span class="caption-text">MMA .m16n8k32 fragment layout for rows 16â€“31 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16832-b-i8-2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x3</span><span class="p">)</span><span class="w">           </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x3</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">16</span><span class="w">      </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">   </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</div>
</blockquote>
</li>
</ul>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 63%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16832-c"><span class="std std-numref">Figure 92</span></a>.</p>
<figure class="align-center" id="mma-16832-c">
<img alt="_images/mma-16832-C.png" class="image" src="_images/mma-16832-C.png">
<figcaption>
<p><span class="caption-number">Figure 92 </span><span class="caption-text">MMA .m16n8k32 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> / <code class="docutils literal notranslate"><span class="pre">.f32</span></code> / <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type.</span><a class="headerlink" href="#mma-16832-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">         </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                         </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-16864">
<span id="id378"></span><h5>
<span class="section-number">9.7.14.5.11. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-16864">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-16864" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 61%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code> elements from the
matrix A.</p></td>
<td><p>a0, a1, â€¦, a30, a31</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, â€¦, a30, a31</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16864-a"><span class="std std-numref">Figure 93</span></a>.</p>
<figure class="align-center" id="mma-16864-a">
<img alt="_images/mma-16864-A.png" class="image" src="_images/mma-16864-A.png">
<figcaption>
<p><span class="caption-number">Figure 93 </span><span class="caption-text">MMA .m16n8k64 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16864-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">     </span><span class="n">groupID</span><span class="w">                                     </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">24</span><span class="w"></span>
<span class="w">        </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                                   </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">32</span><span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 61%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.u4</span></code> elements from the
matrix B.</p></td>
<td><p>b0, b1, â€¦, b14, b15</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, â€¦, b14, b15</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16864-b-1"><span class="std std-numref">Figure 94</span></a>
and <a class="reference internal" href="#mma-16864-b-2"><span class="std std-numref">Figure 95</span></a>.</p>
<figure class="align-center" id="mma-16864-b-1">
<img alt="_images/mma-16864-B_1.png" class="image" src="_images/mma-16864-B_1.png">
<figcaption>
<p><span class="caption-number">Figure 94 </span><span class="caption-text">MMA .m16n8k64 fragment layout for rows 0â€“31 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16864-b-1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mma-16864-b-2">
<img alt="_images/mma-16864-B_2.png" class="image" src="_images/mma-16864-B_2.png">
<figcaption>
<p><span class="caption-number">Figure 95 </span><span class="caption-text">MMA .m16n8k64 fragment layout for rows 32â€“63 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#mma-16864-b-2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x7</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">32</span><span class="w">     </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">   </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 64%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers, containing four
<code class="docutils literal notranslate"><span class="pre">.f32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-16864-c"><span class="std std-numref">Figure 96</span></a>.</p>
<figure class="align-center" id="mma-16864-c">
<img alt="_images/mma-16864-C.png" class="image" src="_images/mma-16864-C.png">
<figcaption>
<p><span class="caption-number">Figure 96 </span><span class="caption-text">MMA .m16n8k64 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> / <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type.</span><a class="headerlink" href="#mma-16864-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                       </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w">  </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,..,</span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-168128">
<span id="id379"></span><h5>
<span class="section-number">9.7.14.5.12. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-168128">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-168128" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 72%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each register containing
thirty two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, â€¦, a62, a63</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168128-a"><span class="std std-numref">Figure 97</span></a>.</p>
<figure class="align-center" id="mma-168128-a">
<img alt="_images/mma-168128-A.png" class="image" src="_images/mma-168128-A.png">
<figcaption>
<p><span class="caption-number">Figure 97 </span><span class="caption-text">MMA .m16n8k128 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-168128-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                              </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="w"></span>
<span class="w">          </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">32</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1F</span><span class="p">)</span><span class="w">     </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="p">...,</span><span class="mi">63</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 70%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing a single <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing thirty
two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, â€¦ , b30, b31</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168128-b"><span class="std std-numref">Figure 98</span></a>.</p>
<figure class="align-center" id="mma-168128-b">
<img alt="_images/mma-168128-B.png" class="image" src="_images/mma-168128-B.png">
<figcaption>
<p><span class="caption-number">Figure 98 </span><span class="caption-text">MMA .m16n8k128 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-168128-b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">         </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,...,</span><span class="mi">31</span><span class="p">}</span><span class="w"></span>
<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 62%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168128-c"><span class="std std-numref">Figure 99</span></a>.</p>
<figure class="align-center" id="mma-168128-c">
<img alt="_images/mma-168128-C.png" class="image" src="_images/mma-168128-C.png">
<figcaption>
<p><span class="caption-number">Figure 99 </span><span class="caption-text">MMA .m16n8k128 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type.</span><a class="headerlink" href="#mma-168128-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">                           </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">2</span><span class="w"></span>
<span class="w">          </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                        </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-mma-168256">
<span id="id380"></span><h5>
<span class="section-number">9.7.14.5.13. </span><a class="reference internal" href="#warp-level-matrix-fragment-mma-168256">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">mma.m16n8k256</span></code></a><a class="headerlink" href="#warp-level-matrix-fragment-mma-168256" title="Permalink to this headline">ïƒ</a>
</h5>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.m16n8k256</span></code> will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k256</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 69%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each register
containing thirty two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix A.</p></td>
<td><p>a0, a1, â€¦, a126, a127</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168256-a"><span class="std std-numref">Figure 100</span></a>.</p>
<figure class="align-center" id="mma-168256-a">
<img alt="_images/mma-168256-A.png" class="image" src="_images/mma-168256-A.png">
<figcaption>
<p><span class="caption-number">Figure 100 </span><span class="caption-text">MMA .m16n8k256 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-168256-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">   </span><span class="n">groupID</span><span class="w">                                            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">64</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">96</span><span class="w"></span>
<span class="w">        </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                                        </span><span class="n">otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1F</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">128</span><span class="w">     </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">64</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 8%">
<col style="width: 69%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each register
containing thirty two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> elements from the matrix B.</p></td>
<td><p>b0, b1, â€¦, b62, b63</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168256-b-1"><span class="std std-numref">Figure 101</span></a> and
<a class="reference internal" href="#mma-168256-b-2"><span class="std std-numref">Figure 102</span></a>.</p>
<figure class="align-center" id="mma-168256-b-1">
<img alt="_images/mma-168256-B_1.png" class="image" src="_images/mma-168256-B_1.png">
<figcaption>
<p><span class="caption-number">Figure 101 </span><span class="caption-text">MMA .m16n8k256 fragment layout for rows 0â€“127 of matrix B with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-168256-b-1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="mma-168256-b-2">
<img alt="_images/mma-168256-B_2.png" class="image" src="_images/mma-168256-B_2.png">
<figcaption>
<p><span class="caption-number">Figure 102 </span><span class="caption-text">MMA .m16n8k256 fragment layout for rows 128â€“255 of matrix B with <code class="docutils literal notranslate"><span class="pre">.b1</span></code> type.</span><a class="headerlink" href="#mma-168256-b-2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1F</span><span class="p">)</span><span class="w">             </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1F</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">128</span><span class="w">       </span><span class="k">for</span><span class="w"> </span><span class="n">bi</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">32</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Accumulators (C or D):</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 62%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.ctype / .dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers, containing
four <code class="docutils literal notranslate"><span class="pre">.s32</span></code> elements from the matrix C (or D).</p></td>
<td><p>c0, c1, c2, c3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#mma-168256-c"><span class="std std-numref">Figure 103</span></a>.</p>
<figure class="align-center" id="mma-168256-c">
<img alt="_images/mma-168256-C.png" class="image" src="_images/mma-168256-C.png">
<figcaption>
<p><span class="caption-number">Figure 103 </span><span class="caption-text">MMA .m16n8k256 fragment layout for accumulator matrix C/D with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> type.</span><a class="headerlink" href="#mma-168256-c" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w">           </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">        </span><span class="n">groupID</span><span class="w">                         </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">                       </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="mh">0x1</span><span class="p">)</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">ci</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</li>
</ul>
</section>
<section id="warp-level-matrix-instructions-mma">
<span id="id381"></span><h5>
<span class="section-number">9.7.14.5.14. </span><a class="reference internal" href="#warp-level-matrix-instructions-mma">Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">mma</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-mma" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mma</span></code></p>
<p>Perform matrix multiply-and-accumulate operation</p>
<p class="rubric">Syntax</p>
<p>Half precision floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.m8n8k4.alayout.blayout.dtype.f16.f16.ctype  d, a, b, c;
mma.sync.aligned.m16n8k8.row.col.dtype.f16.f16.ctype  d, a, b, c;
mma.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype d, a, b, c;

.alayout = {.row, .col};
.blayout = {.row, .col};
.ctype   = {.f16, .f32};
.dtype   = {.f16, .f32};
</pre></div>
</div>
<p>Alternate floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.m16n8k4.row.col.f32.tf32.tf32.f32        d, a, b, c;
mma.sync.aligned.m16n8k8.row.col.f32.atype.btype.f32      d, a, b, c;
mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32       d, a, b, c;
mma.sync.aligned.shape.row.col.dtype.f8type.f8type.ctype  d, a, b, c;
mma.sync.aligned.m16n8k32.row.col.kind.dtype.f8f6f4type.f8f6f4type.ctype d, a, b, c;

.atype      = {.bf16, .tf32};
.btype      = {.bf16, .tf32};
.f8type     = {.e4m3, .e5m2};
.f8f6f4type = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};
.ctype      = {.f16, .f32};
.dtype      = {.f16, .f32};
.shape      = {.m16n8k16, .m16n8k32};
.kind       = {.kind::f8f6f4};
</pre></div>
</div>
<p>Alternate floating point type with block scaling:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.m16n8k64.row.col.kind.block_scale{.scale_vec_size}.f32.e2m1.e2m1.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.kind           = {.kind::mxf4};
.scale_vec_size = {.scale_vec::2X};
.stype          = {.ue8m0};

mma.sync.aligned.m16n8k64.row.col.kind.block_scale.scale_vec_size.f32.e2m1.e2m1.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.kind           = {.kind::mxf4nvf4};
.scale_vec_size = {.scale_vec::2X, .scale_vec::4X};
.stype          = {.ue8m0, .ue4m3};

mma.sync.aligned.m16n8k32.row.col.kind.block_scale{.scale_vec_size}.f32.f8f6f4type.f8f6f4type.f32.stype d, a, b, c, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.kind           = {.kind::mxf8f6f4};
.scale_vec_size = {.scale_vec::1X};
.f8f6f4type     = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};
.stype          = {.ue8m0};
</pre></div>
</div>
<p>Double precision floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.shape.row.col.f64.f64.f64.f64 d, a, b, c;

.shape   = {.m8n84, .m16n8k4, .m16n8k8, .m16n8k16};
</pre></div>
</div>
<p>Integer type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c;

.shape   = {.m8n8k16, .m16n8k16, .m16n8k32}
.atype   = {.u8, .s8};
.btype   = {.u8, .s8};

mma.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c;

.shape   = {.m8n8k32, .m16n8k32, .m16n8k64}
.atype   = {.u4, .s4};
.btype   = {.u4, .s4};
</pre></div>
</div>
<p>Single bit:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.sync.aligned.shape.row.col.s32.b1.b1.s32.bitOp.popc d, a, b, c;

.bitOp = {.xor, .and}
.shape = {.m8n8k128, .m16n8k128, .m16n8k256}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Perform a <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> matrix multiply and accumulate operation, <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+C</span></code>, where the A matrix is
<code class="docutils literal notranslate"><span class="pre">MxK</span></code>, the B matrix is <code class="docutils literal notranslate"><span class="pre">KxN</span></code>, and the C and D matrices are <code class="docutils literal notranslate"><span class="pre">MxN</span></code>.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> specifies that the matrices A and B are scaled with <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and
<code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively before performing the matrix multiply and accumulate operation
as specified in the section <a class="reference external" href="#warp-level-block-scaling">Block Scaling</a>. The data type
corresponding to each of the element within <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">Scale_B</span></code> matrices is specified
by <code class="docutils literal notranslate"><span class="pre">.stype</span></code>. Qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> specifies the number of columns of <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> matrix
and number of rows in the matrix <code class="docutils literal notranslate"><span class="pre">scale_B</span></code>.</p>
<p>The valid combinations of <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.stype</span></code> and <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> are described in
<a class="reference internal" href="#mma-scaling-kind-type-valid-combination"><span class="std std-numref">Table 36</span></a>. For <code class="docutils literal notranslate"><span class="pre">mma</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> when the
qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">2X</span></code>. In contrast, when
<code class="docutils literal notranslate"><span class="pre">.kind</span></code> is specified as <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> then the qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> defaults
to <code class="docutils literal notranslate"><span class="pre">1X</span></code>. However, for <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>, it is mandatory to provide valid <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code>.</p>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.sync.m8n8k4</span></code> instruction computes 4 matrix multiply and accumulate
operations. Rest of the <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code> operations compute a single matrix mutliply and accumulate
operation per warp.</p>
<p>For single-bit <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code>, multiplication is replaced by a sequence of logical operations;
specifically, <code class="docutils literal notranslate"><span class="pre">mma.xor.popc</span></code> and <code class="docutils literal notranslate"><span class="pre">mma.and.popc</span></code> computes the XOR, AND respectively of a k-bit
row of A with a k-bit column of B, then counts the number of set bits in the result (<code class="docutils literal notranslate"><span class="pre">popc</span></code>). This
result is added to the corresponding element of C and written into D.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> represent two multiplicand matrices A and B, while <code class="docutils literal notranslate"><span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code>
represent the accumulator and destination matrices, distributed across the threads in warp.
When <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> qualifier is specified, operand <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>, <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> represents
the scale matrix metadata corresponding to <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively. The
tuple <code class="docutils literal notranslate"><span class="pre">{byte-id-a,</span> <span class="pre">thread-id-a}</span></code> and <code class="docutils literal notranslate"><span class="pre">{byte-id-b,</span> <span class="pre">thread-id-b}</span></code> represent selectors for matrices
<code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> respectively from their corresponding metadata arguments <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>,
<code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code>. The operands <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>, <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> are of type <code class="docutils literal notranslate"><span class="pre">.b32</span></code>. The operands
<code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code> are unsigned 16-bit integer values.
For more details on selector arguments refer <a class="reference external" href="#warp-level-block-scaling">Block Scaling</a> section.</p>
<p>The registers in each thread hold a fragment of matrix as described in
<a class="reference internal" href="#warp-level-matrix-instructions-for-mma"><span class="std std-ref">Matrix multiply-accumulate operation using mma instruction</span></a>.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">.atype</span></code>, <code class="docutils literal notranslate"><span class="pre">.btype</span></code> and <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> indicate the data-type of the
elements in the matrices D, A, B and C respectively. The qualifier <code class="docutils literal notranslate"><span class="pre">.stype</span></code> indicate the data-type
of the elements in the matrices <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code>. Specific shapes have type restrictions :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> : When <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must also be <code class="docutils literal notranslate"><span class="pre">.f32</span></code>.</p></li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> :</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must be the same as <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.atype</span></code> must be the same as <code class="docutils literal notranslate"><span class="pre">.btype</span></code>.</p></li>
</ul>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> :</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must be the same as <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>.</p></li>
</ul>
</li>
</ul>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.alayout</span></code> and <code class="docutils literal notranslate"><span class="pre">.blayout</span></code> indicate the row-major or column-major layouts of
matrices A and B respectively.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.kind</span></code> is either of <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, the individual 4-bit and the
6-bit floating point type elements must be packed in an 8-bit container. The matrix element of type
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> resides in central 4 bits of the 8-bit container with padding in the upper 2 bits and
lower 2 bits of the container. When the matrix element is of type <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, the
matrix element resides in the lower 6 bits of the 8-bit container with padding in the upper 2 bits
of the container. In contrast, note that when using <code class="docutils literal notranslate"><span class="pre">mma</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> or
<code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>, no explicit padding is necessary even though matrix elements are of type <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>.</p>
<dl>
<dt>Precision and rounding :</dt>
<dd>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point operations:</p>
<p>Element-wise multiplication of matrix A and B is performed with at least single
precision. When <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> or <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, accumulation of the intermediate values
is performed with at least single precision. When both <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> and <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> are specified
as <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, the accumulation is performed with at least half precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> floating point operations :</p>
<p>Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
of the intermediate values is performed with at least single precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point operations :</p>
<p>Element-wise multiplication of matrix A and B is performed with specified
precision. Accumulation of the intermediate values is performed with at least single
precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point operations :</p>
<p>Precision of the element-wise multiplication and addition operation is identical to that of <code class="docutils literal notranslate"><span class="pre">.f64</span></code>
precision fused multiply-add. Supported rounding modifiers are :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.rn</span></code> : mantissa LSB rounds to nearest even. This is the default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.rz</span></code> : mantissa LSB rounds towards zero.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.rm</span></code> : mantissa LSB rounds towards negative infinity.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.rp</span></code> : mantissa LSB rounds towards positive infinity.</p></li>
</ul>
</li>
<li>
<p>Integer operations :</p>
<p>The integer <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation is performed with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> accumulators. The <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code>
qualifier indicates that on overflow, the accumulated value is limited to the range
<em>MIN_INT32</em>.. <em>MAX_INT32</em> (where the bounds are defined as the minimum negative signed 32-bit
integer and the maximum positive signed 32-bit integer respectively).</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> is not specified, the accumulated value is wrapped instead.</p>
</li>
</ul>
</dd>
</dl>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction causes the executing thread to
wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction should only be used if it
is known that all threads in the warp evaluate the condition identically, otherwise behavior is
undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction is undefined if all threads in the same warp do not use the same
qualifiers, or if any thread in the warp has exited.</p>
<p class="rubric">Notes</p>
<p>Programs using double precision floating point <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction with shapes <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>, and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> require at least 64 registers for compilation.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> shape introduced in PTX ISA version
6.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> shape introduced in PTX ISA version
6.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u8/.s8</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k16</span></code> shape introduced in PTX ISA version
6.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u4/.s4</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code> shape introduced in PTX ISA version
6.5.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> shape introduced in PTX ISA version
7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> shape introduced in PTX ISA
version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> shapes
introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> shapes
introduced in PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u8/.s8</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> shapes introduced in
PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u4/.s4</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code> shapes introduced in
PTX ISA version 7.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">.b1</span></code> single-bit integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code> and
<code class="docutils literal notranslate"><span class="pre">.m16n8k256</span></code> shapes introduced in PTX ISA version 7.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.and</span></code> operation in single-bit <code class="docutils literal notranslate"><span class="pre">mma</span></code> introduced in PTX ISA version 7.1.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>, and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>
shapes introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation introduced in
PTX ISA version 8.4.</p>
<p>Support for shape <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16</span></code> <code class="docutils literal notranslate"><span class="pre">dtype</span></code>/<code class="docutils literal notranslate"><span class="pre">ctype</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate
floating point type mma operation introduced in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation introduced
in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier introduced in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> on <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code> as <code class="docutils literal notranslate"><span class="pre">.stype</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> is introduced in
PTX ISA version 9.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> shape requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">mma.sync.m8n8k4</span></code> is optimized for target architecture <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and may have substantially
reduced performance on other target architectures.</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> shape requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u8/.s8</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k16</span></code> shape requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u4/.s4</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code> shape <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.b1</span></code> single-bit integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code> shape <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code> shape requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> shape requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or
higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> shapes
requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code> shapes
requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u8/.s8</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> shapes requires
<code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.u4/.s4</span></code> integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code> shapes requires
<code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.b1</span></code> single-bit integer type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k256</span></code> shapes
requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.and</span></code> operation in single-bit <code class="docutils literal notranslate"><span class="pre">mma</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>, and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>
shapes require <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation requires <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation requires <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>
and is supported on <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> from PTX ISA version 8.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> and are
supported on <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family from PTX ISA version 8.8.</p>
<p class="rubric">Examples of half precision floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// f16 elements in C and D matrix
.reg .f16x2 %Ra&lt;2&gt; %Rb&lt;2&gt; %Rc&lt;4&gt; %Rd&lt;4&gt;
mma.sync.aligned.m8n8k4.row.col.f16.f16.f16.f16
{%Rd0, %Rd1, %Rd2, %Rd3},
{%Ra0, %Ra1},
{%Rb0, %Rb1},
{%Rc0, %Rc1, %Rc2, %Rc3};


// f16 elements in C and f32 elements in D
.reg .f16x2 %Ra&lt;2&gt; %Rb&lt;2&gt; %Rc&lt;4&gt;
.reg .f32 %Rd&lt;8&gt;
mma.sync.aligned.m8n8k4.row.col.f32.f16.f16.f16
{%Rd0, %Rd1, %Rd2, %Rd3, %Rd4, %Rd5, %Rd6, %Rd7},
{%Ra0, %Ra1},
{%Rb0, %Rb1},
{%Rc0, %Rc1, %Rc2, %Rc3};

 // f32 elements in C and D
.reg .f16x2 %Ra&lt;2&gt;, %Rb&lt;1&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k8.row.col.f32.f16.f16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .f16x2 %Ra&lt;4&gt;, %Rb&lt;2&gt;, %Rc&lt;2&gt;, %Rd&lt;2&gt;;
mma.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1};

.reg .f16 %Ra&lt;4&gt;, %Rb&lt;2&gt;;
.reg .f32 %Rc&lt;2&gt;, %Rd&lt;2&gt;;
mma.sync.aligned.m16n8k16.row.col.f32.f16.f16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};
</pre></div>
</div>
<p class="rubric">Examples of alternate floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %Ra&lt;2&gt;, %Rb&lt;1&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k4.row.col.f32.tf32.tf32.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .f16x2 %Ra&lt;2&gt;, %Rb&lt;1&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k8.row.col.f32.bf16.bf16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;2&gt;, %Rb&lt;1&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Rb2, %Rb3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .f16x2 %Ra&lt;2&gt;, %Rb&lt;1&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.f32.e4m3.e5m2.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k16.row.col.f32.e5m2.e4m3.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .b32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.f16.e4m3.e5m2.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .b32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k16.row.col.f16.e5m2.e5m2.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.kind::f8f6f4.f32.e3m2.e2m3.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .b32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.kind::f8f6f4.f16.e2m3.e2m1.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1};
</pre></div>
</div>
<p class="rubric">Examples of integer type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %Ra, %Rb, %Rc&lt;2&gt;, %Rd&lt;2&gt;;

// s8 elements in A and u8 elements in B
mma.sync.aligned.m8n8k16.row.col.satfinite.s32.s8.u8.s32
  {%Rd0, %Rd1},
  {%Ra},
  {%Rb},
  {%Rc0, %Rc1};

// u4 elements in A and B matrix
mma.sync.aligned.m8n8k32.row.col.satfinite.s32.u4.u4.s32
  {%Rd0, %Rd1},
  {%Ra},
  {%Rb},
  {%Rc0, %Rc1};

// s8 elements in A and u8 elements in B
.reg .b32 %Ra&lt;2&gt;, %Rb, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k16.row.col.satfinite.s32.s8.u8.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb},
  {%Rc0, %Rc1, %Rc2, %Rc3};

// u4 elements in A and s4 elements in B
.reg .b32 %Ra&lt;2&gt;, %Rb, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.satfinite.s32.u4.s4.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb},
  {%Rc0, %Rc1, %Rc2, %Rc3};

// s8 elements in A and s8 elements in B
.reg .b32 %Ra&lt;4&gt;, %Rb&lt;2&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k32.row.col.satfinite.s32.s8.s8.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

// u8 elements in A and u8 elements in B
.reg .b32 %Ra&lt;4&gt;, %Rb&lt;2&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k64.row.col.satfinite.s32.u4.u4.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1 },
  {%Rc0, %Rc1, %Rc2, %Rc3};
</pre></div>
</div>
<p class="rubric">Examples of single bit type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// b1 elements in A and B
.reg .b32 %Ra, %Rb, %Rc&lt;2&gt;, %Rd&lt;2&gt;;
mma.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32.and.popc
  {%Rd0, %Rd1},
  {%Ra},
  {%Rb},
  {%Rc0, %Rc1};

// b1 elements in A and B
.reg .b32 %Ra, %Rb, %Rc&lt;2&gt;, %Rd&lt;2&gt;;
mma.sync.aligned.m8n8k128.row.col.s32.b1.b1.s32.xor.popc
  {%Rd0, %Rd1},
  {%Ra},
  {%Rb},
  {%Rc0, %Rc1};

.reg .b32 %Ra&lt;2&gt;, %Rb, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k128.row.col.s32.b1.b1.s32.xor.popc
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;2&gt;, %Rb, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k128.row.col.s32.b1.b1.s32.and.popc
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;2&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k256.row.col.s32.b1.b1.s32.xor.popc
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;2&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k256.row.col.s32.b1.b1.s32.and.popc
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};
</pre></div>
</div>
<p class="rubric">Examples of <code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f64 %Ra, %Rb, %Rc&lt;2&gt;, %Rd&lt;2&gt;;
mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64
  {%Rd0, %Rd1},
  {%Ra},
  {%Rb},
  {%Rc0, %Rc1};

.reg .f64 %Ra&lt;8&gt;, %Rb&lt;4&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
mma.sync.aligned.m16n8k4.row.col.f64.f64.f64.f64.rn
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0},
  {%Rc0, %Rc1, %Rc2, %Rc3};

mma.sync.aligned.m16n8k8.row.col.f64.f64.f64.f64.rn
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3};

mma.sync.aligned.m16n8k16.row.col.f64.f64.f64.f64.rn
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3, %Ra4, %Ra5, %Ra6, %Ra7},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3};
</pre></div>
</div>
<p class="rubric">Examples of <code class="docutils literal notranslate"><span class="pre">mma</span></code> with block scale</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> .reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
 .reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
 .reg .b32 scaleAData, scaleBData;
 mma.sync.aligned.m16n8k64.row.col.kind::mxf4.block_scale.f32.e2m1.e2m1.f32.ue8m0
   {%Rd0, %Rd1, %Rd2, %Rd3},
   {%Ra0, %Ra1, %Ra2, %Ra3},
   {%Rb0, %Rb1},
   {%Rc0, %Rc1, %Rc2, %Rc3},
   scaleAData, {2, 1}, scaleBData, {2, 3};

 .reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
 .reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
 .reg .b32 scaleAData, scaleBData;
 .reg .u16 bidA, bidB, tidA, tidB;
 mma.sync.aligned.m16n8k64.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue4m3
   {%Rd0, %Rd1, %Rd2, %Rd3},
   {%Ra0, %Ra1, %Ra2, %Ra3},
   {%Rb0, %Rb1},
   {%Rc0, %Rc1, %Rc2, %Rc3},
   scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
.reg .u16 bidA, bidB, tidA, tidB;
mma.sync.aligned.m16n8k64.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue8m0
   {%Rd0, %Rd1, %Rd2, %Rd3},
   {%Ra0, %Ra1, %Ra2, %Ra3},
   {%Rb0, %Rb1},
   {%Rc0, %Rc1, %Rc2, %Rc3},
   scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
mma.sync.aligned.m16n8k32.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e3m2.e2m1.f32.ue8m0
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3},
  scaleAData, {0, 1}, scaleBData, {0, 1};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
mma.sync.aligned.m16n8k32.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e4m3.e5m2.f32.ue8m0
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2,  %Ra3},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3},
  scaleAData, {0, 1}, scaleBData, {0, 0};
</pre></div>
</div>
</section>
<section id="warp-level-matrix-instructions-ldmatrix">
<span id="id382"></span><h5>
<span class="section-number">9.7.14.5.15. </span><a class="reference internal" href="#warp-level-matrix-instructions-ldmatrix">Warp-level matrix load instruction: <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-ldmatrix" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code></p>
<p>Collectively load one or more matrices from shared memory for <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>ldmatrix.sync.aligned.shape.num{.trans}{.ss}.type r, [p];

ldmatrix.sync.aligned.m8n16.num{.ss}.dst_fmt.src_fmt        r, [p];
ldmatrix.sync.aligned.m16n16.num.trans{.ss}.dst_fmt.src_fmt r, [p];

.shape   = {.m8n8, .m16n16};
.num     = {.x1, .x2, .x4};
.ss      = {.shared{::cta}};
.type    = {.b16, .b8};
.dst_fmt = { .b8x16 };
.src_fmt = { .b6x16_p32, .b4x16_p64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Collectively load one or more matrices across all threads in a warp from the location indicated by
the address operand <code class="docutils literal notranslate"><span class="pre">p</span></code>, from <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space into destination register <code class="docutils literal notranslate"><span class="pre">r</span></code>. If no state
space is provided, generic addressing is used, such that the address in <code class="docutils literal notranslate"><span class="pre">p</span></code> points into
<code class="docutils literal notranslate"><span class="pre">.shared</span></code> space. If the generic address doesnâ€™t fall in <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then the behavior
is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimensions of the matrices being loaded. Each matrix element
holds 16-bit or 8-bit or 6-bit or 4-bit data.</p>
<p>Following table shows the matrix load case for each <code class="docutils literal notranslate"><span class="pre">.shape</span></code>.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 27%">
<col style="width: 32%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.shape</p></th>
<th class="head"><p>Matrix shape</p></th>
<th class="head"><p>Element size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n8</span></code></p></td>
<td><p>8x8</p></td>
<td><p>16-bit</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16</span></code></p></td>
<td><p>16x16</p></td>
<td><p>8-bit or 6-bit or 4-bit</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n16</span></code></p></td>
<td><p>8x16</p></td>
<td><p>6-bit or 4-bit</p></td>
</tr>
</tbody>
</table>
<p>Following table shows the valid use of 6-bit or 4-bit data load.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 23%">
<col style="width: 19%">
<col style="width: 28%">
<col style="width: 13%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.src_fmt</p></th>
<th class="head"><p>.shape</p></th>
<th class="head"><p>Source data</p></th>
<th class="head"><p>Padding</p></th>
<th class="head"><p>.dst_fmt</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n16</span></code></p></td>
<td rowspan="2"><p>16 6-bit elements</p></td>
<td rowspan="2"><p>32 bits</p></td>
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.b8x16</span></code>
(16 8-bit
elements)</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m8n16</span></code></p></td>
<td rowspan="2"><p>16 4-bit elements</p></td>
<td rowspan="2"><p>64 bits</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n16</span></code></p></td>
</tr>
</tbody>
</table>
<p>For <code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code> format source data is 16 unsigned 6-bit elements with 32 bits padding.
For <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code> format source data is 16 unsigned 4-bit elements with 64 bits padding.</p>
<p>The values <code class="docutils literal notranslate"><span class="pre">.x1</span></code>, <code class="docutils literal notranslate"><span class="pre">.x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.x4</span></code> for <code class="docutils literal notranslate"><span class="pre">.num</span></code> indicate one, two or four matrices
respectively. When <code class="docutils literal notranslate"><span class="pre">.shape</span></code> is <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>, only <code class="docutils literal notranslate"><span class="pre">.x1</span></code> and <code class="docutils literal notranslate"><span class="pre">.x2</span></code> are valid values for <code class="docutils literal notranslate"><span class="pre">.num</span></code>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction. In conditionally executed code, an <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise the
behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> is undefined if all threads do not use the same qualifiers, or if any
thread in the warp has exited.</p>
<p>The destination operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression consisting of 1, 2, or 4 32-bit
registers as per the value of <code class="docutils literal notranslate"><span class="pre">.num</span></code>. Each component of the vector expression holds a fragment
from the corresponding matrix.</p>
<p>Supported addressing modes for <code class="docutils literal notranslate"><span class="pre">p</span></code> are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>Consecutive instances of row need not be stored contiguously in memory. The eight addresses required
for each matrix are provided by eight threads, depending upon the value of <code class="docutils literal notranslate"><span class="pre">.num</span></code> as shown in the
following table. Each address corresponds to the start of a matrix row. Addresses addr0â€“addr7
correspond to the rows of the first matrix, addresses addr8â€“addr15 correspond to the rows of the
second matrix, and so on.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 21%">
<col style="width: 23%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.num</span></code></p></th>
<th class="head"><p>Threads 0â€“7</p></th>
<th class="head"><p>Threads 8â€“15</p></th>
<th class="head"><p>Threads 16â€“23</p></th>
<th class="head"><p>Threads 24â€“31</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x1</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x2</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>addr8â€“addr15</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x4</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>addr8â€“addr15</p></td>
<td><p>addr16â€“addr23</p></td>
<td><p>addr24â€“addr31</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For .target <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or below, all threads must contain valid addresses. Otherwise, the behavior
is undefined. For <code class="docutils literal notranslate"><span class="pre">.num</span> <span class="pre">=</span> <span class="pre">.x1</span></code> and <code class="docutils literal notranslate"><span class="pre">.num</span> <span class="pre">=</span> <span class="pre">.x2</span></code>, addresses contained in lower threads can be
copied to higher threads to achieve the expected behavior.</p>
</div>
<p>When reading 8x8 matrices, a group of four consecutive threads loads 16 bytes. The matrix addresses
must be naturally aligned accordingly.</p>
<p>Each thread in a warp loads fragments of a row, with thread 0 receiving the first fragment in its
register <code class="docutils literal notranslate"><span class="pre">r</span></code>, and so on. A group of four threads loads an entire row of the matrix as shown in
<a class="reference internal" href="#mma-ldmatrix-fragments"><span class="std std-numref">Figure 104</span></a>.</p>
<figure class="align-center" id="mma-ldmatrix-fragments">
<img alt="_images/mma-ldmatrix-fragments.png" class="image" src="_images/mma-ldmatrix-fragments.png">
<figcaption>
<p><span class="caption-number">Figure 104 </span><span class="caption-text">ldmatrix fragment layout for one 8x8 Matrix with 16-bit elements</span><a class="headerlink" href="#mma-ldmatrix-fragments" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>When <code class="docutils literal notranslate"><span class="pre">.num</span></code> = <code class="docutils literal notranslate"><span class="pre">.x2</span></code>, the elements of the second matrix are loaded in the next destination
register in each thread as per the layout in above table. Similarly, when <code class="docutils literal notranslate"><span class="pre">.num</span></code> = <code class="docutils literal notranslate"><span class="pre">.x4</span></code>,
elements of the third and fourth matrices are loaded in the subsequent destination registers in each
thread.</p>
<p>For matrix shape 16x16, two destination registers <code class="docutils literal notranslate"><span class="pre">r0</span></code> and <code class="docutils literal notranslate"><span class="pre">r1</span></code> of type <code class="docutils literal notranslate"><span class="pre">.b32</span></code> must be
specified and in each register four 8-bit elements are loaded. For 4-bit or 6-bit data, 8-bit
element will have 4 bits or 2 bits of padding respectively.
Refer <a class="reference internal" href="#tcgen05-optional-decompression"><span class="std std-ref">Optional Decompression</span></a> for more details
on these formats.</p>
<p>An entire row of the matrix can be loaded by a group of four consecutive and aligned threads.
Each thread in a warp loads 4 consecutive columns across 2 rows as shown in the
<a class="reference internal" href="#mma-ldmatrix-fragments-1616"><span class="std std-numref">Figure 105</span></a>.</p>
<figure class="align-center" id="mma-ldmatrix-fragments-1616">
<img alt="_images/mma-ldmatrix-fragments-1616.png" class="image" src="_images/mma-ldmatrix-fragments-1616.png">
<figcaption>
<p><span class="caption-number">Figure 105 </span><span class="caption-text">ldmatrix fragment layout for one 16x16 matrix with 8-bit elements</span><a class="headerlink" href="#mma-ldmatrix-fragments-1616" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For matrix shape 8x16, one destination register <code class="docutils literal notranslate"><span class="pre">r0</span></code> of type <code class="docutils literal notranslate"><span class="pre">.b32</span></code> must be specified where four
8-bit elements are loaded in the register. For 4-bit or 6-bit data, 8-bit element will have 4 bits
or 2 bits of padding respectively.</p>
<p>An entire row of the matrix can be loaded by a group of four consecutive and aligned threads.
Each thread in a warp loads 4 consecutive columns as shown in <a class="reference internal" href="#mma-ldmatrix-fragments-816"><span class="std std-numref">Figure 106</span></a>.</p>
<figure class="align-center" id="mma-ldmatrix-fragments-816">
<img alt="_images/mma-ldmatrix-fragments-816.png" class="image" src="_images/mma-ldmatrix-fragments-816.png">
<figcaption>
<p><span class="caption-number">Figure 106 </span><span class="caption-text">ldmatrix fragment layout for one 8x16 matrix with 8-bit elements containing 4-bit/6-bit data</span><a class="headerlink" href="#mma-ldmatrix-fragments-816" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Optional qualifier <code class="docutils literal notranslate"><span class="pre">.trans</span></code> indicates that the matrix is loaded in column-major format. However,
for 16x16 matrices, <code class="docutils literal notranslate"><span class="pre">.trans</span></code> is mandatory.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction is treated as a weak memory operation in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.5.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">::cta</span></code> sub-qualifier introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n16</span></code> shapes introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type with <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> is introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code>, <code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code> qualifiers introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p>Shapes <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n16</span></code> are supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And are supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Type <code class="docutils literal notranslate"><span class="pre">.b8</span></code> with <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> is supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And are supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code>, <code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code> are supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And are supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Load a single 8x8 matrix using 64-bit addressing
.reg .b64 addr;
.reg .b32 d;
ldmatrix.sync.aligned.m8n8.x1.shared::cta.b16 {d}, [addr];

// Load two 8x8 matrices in column-major format
.reg .b64 addr;
.reg .b32 d&lt;2&gt;;
ldmatrix.sync.aligned.m8n8.x2.trans.shared.b16 {d0, d1}, [addr];

// Load four 8x8 matrices
.reg .b64 addr;
.reg .b32 d&lt;4&gt;;
ldmatrix.sync.aligned.m8n8.x4.b16 {d0, d1, d2, d3}, [addr];

// Load one 16x16 matrices of 64-bit elements and transpose them
.reg .b64 addr;
.reg .b32 d&lt;2&gt;;
ldmatrix.sync.aligned.m16n16.x1.trans.shared.b8 {d0, d1}, [addr];

// Load two 16x16 matrices of 64-bit elements and transpose them
.reg .b64 addr;
.reg .b32 d&lt;4&gt;;
ldmatrix.sync.aligned.m16n16.x2.trans.shared::cta.b8 {d0, d1, d2, d3}, [addr];

// Load two 16x16 matrices of 6-bit elements and transpose them
.reg .b64 addr;
.reg .b32 d&lt;4&gt;;
ldmatrix.sync.aligned.m16n16.x2.trans.shared::cta.b8x16.b6x16_p32 {d0, d1, d2, d3}, [addr];
</pre></div>
</div>
</section>
<section id="warp-level-matrix-instructions-stmatrix">
<span id="id383"></span><h5>
<span class="section-number">9.7.14.5.16. </span><a class="reference internal" href="#warp-level-matrix-instructions-stmatrix">Warp-level matrix store instruction: <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-stmatrix" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></p>
<p>Collectively store one or more matrices to shared memory.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>stmatrix.sync.aligned.shape.num{.trans}{.ss}.type [p], r;

.shape  = {.m8n8, .m16n8};
.num    = {.x1, .x2, .x4};
.ss     = {.shared{::cta}};
.type   = {.b16, .b8};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Collectively store one or more matrices across all threads in a warp to the location indicated by
the address operand <code class="docutils literal notranslate"><span class="pre">p</span></code>, in <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space. If no state space is provided, generic
addressing is used, such that the address in <code class="docutils literal notranslate"><span class="pre">p</span></code> points into <code class="docutils literal notranslate"><span class="pre">.shared</span></code> space. If the generic
address doesnâ€™t fall in <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space, then the behavior is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimensions of the matrices being loaded. Each matrix element
holds 16-bit or 8-bit data as indicated by the <code class="docutils literal notranslate"><span class="pre">.type</span></code> qualifier.</p>
<p><code class="docutils literal notranslate"><span class="pre">.m16n8</span></code> shape is valid only for <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type.</p>
<p>The values <code class="docutils literal notranslate"><span class="pre">.x1</span></code>, <code class="docutils literal notranslate"><span class="pre">.x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.x4</span></code> for <code class="docutils literal notranslate"><span class="pre">.num</span></code> indicate one, two or four matrices
respectively.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction. In conditionally executed code, an <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction should only be
used if it is known that all threads in the warp evaluate the condition identically, otherwise the
behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> is undefined if all threads do not use the same qualifiers, or if any
thread in the warp has exited.</p>
<p>The source operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression consisting of 1, 2, or 4 32-bit
registers as per the value of <code class="docutils literal notranslate"><span class="pre">.num</span></code>. Each component of the vector expression holds a fragment
from the corresponding matrix.</p>
<p>Supported addressing modes for <code class="docutils literal notranslate"><span class="pre">p</span></code> are described in <a class="reference internal" href="#addresses-as-operands"><span class="std std-ref">Addresses as Operands</span></a>.</p>
<p>Consecutive instances of row need not be stored contiguously in memory. The eight addresses required
for each matrix are provided by eight threads, depending upon the value of <code class="docutils literal notranslate"><span class="pre">.num</span></code> as shown in the
following table. Each address corresponds to the start of a matrix row. Addresses addr0â€“addr7
correspond to the rows of the first matrix, addresses addr8â€“addr15 correspond to the rows of the
second matrix, and so on.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 20%">
<col style="width: 21%">
<col style="width: 23%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.num</span></code></p></th>
<th class="head"><p>Threads 0â€“7</p></th>
<th class="head"><p>Threads 8â€“15</p></th>
<th class="head"><p>Threads 16â€“23</p></th>
<th class="head"><p>Threads 24â€“31</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x1</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x2</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>addr8â€“addr15</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x4</span></code></p></td>
<td><p>addr0â€“addr7</p></td>
<td><p>addr8â€“addr15</p></td>
<td><p>addr16â€“addr23</p></td>
<td><p>addr24â€“addr31</p></td>
</tr>
</tbody>
</table>
<p>When storing 8x8 matrices, a group of four consecutive threads stores 16 bytes. The matrix addresses
must be naturally aligned accordingly.</p>
<p>Each thread in a warp stores fragments of a row, with thread 0 storing the first fragment from its
register <code class="docutils literal notranslate"><span class="pre">r</span></code>, and so on. A group of four threads stores an entire row of the matrix as shown in
<a class="reference internal" href="#mma-stmatrix-fragments"><span class="std std-numref">Figure 107</span></a>.</p>
<figure class="align-center" id="mma-stmatrix-fragments">
<img alt="_images/mma-stmatrix-fragments.png" class="image" src="_images/mma-stmatrix-fragments.png">
<figcaption>
<p><span class="caption-number">Figure 107 </span><span class="caption-text">stmatrix fragment layout for one 8x8 matrix with 16-bit elements</span><a class="headerlink" href="#mma-stmatrix-fragments" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>When <code class="docutils literal notranslate"><span class="pre">.num</span></code> = <code class="docutils literal notranslate"><span class="pre">.x2</span></code>, the elements of the second matrix are storedd from the next source register
in each thread as per the layout in above table. Similarly, when <code class="docutils literal notranslate"><span class="pre">.num</span></code> = <code class="docutils literal notranslate"><span class="pre">.x4</span></code>, elements of the
third and fourth matrices are stored from the subsequent source registers in each thread.</p>
<p>For 16x8 matrix shape, each of the 32 threads in the warp provides four elements of data per matrix.</p>
<p>Each element in the source operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is of type <code class="docutils literal notranslate"><span class="pre">.b32</span></code> and contains four 8 bit elements <code class="docutils literal notranslate"><span class="pre">e0</span></code>,
<code class="docutils literal notranslate"><span class="pre">e1</span></code>, <code class="docutils literal notranslate"><span class="pre">e2</span></code>, <code class="docutils literal notranslate"><span class="pre">e3</span></code> with <code class="docutils literal notranslate"><span class="pre">e0</span></code> and <code class="docutils literal notranslate"><span class="pre">e3</span></code> containing the LSB and MSB respectively of register <code class="docutils literal notranslate"><span class="pre">r</span></code>.</p>
<figure class="align-center" id="mma-stmatrix-fragments-168">
<img alt="_images/mma-stmatrix-fragments-168.png" class="image" src="_images/mma-stmatrix-fragments-168.png">
<figcaption>
<p><span class="caption-number">Figure 108 </span><span class="caption-text">stmatrix fragment layout for one 16x8 matrix with 8 bit elements</span><a class="headerlink" href="#mma-stmatrix-fragments-168" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Optional qualifier <code class="docutils literal notranslate"><span class="pre">.trans</span></code> indicates that the matrix is stored in column-major format. However,
for 16x8 matrices, <code class="docutils literal notranslate"><span class="pre">.trans</span></code> is mandatory.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction is treated as a weak memory operation in the <a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.m16n8</span></code> shape is introduced in PTX ISA version 8.6.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type with <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> is introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p>Shape <code class="docutils literal notranslate"><span class="pre">.m16n8</span></code> is supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Type <code class="docutils literal notranslate"><span class="pre">.b8</span></code> with <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> is supported on following architectures:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<blockquote>
<div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Store a single 8x8 matrix using 64-bit addressing
.reg .b64 addr;
.reg .b32 r;
stmatrix.sync.aligned.m8n8.x1.shared.b16 [addr], {r};

// Store two 8x8 matrices in column-major format
.reg .b64 addr;
.reg .b32 r&lt;2&gt;;
stmatrix.sync.aligned.m8n8.x2.trans.shared::cta.b16 [addr], {r0, r1};

// Store four 8x8 matrices
.reg .b64 addr;
.reg .b32 r&lt;4&gt;;
stmatrix.sync.aligned.m8n8.x4.b16 [addr], {r0, r1, r2, r3};

// Store a single 16x8 matrix using generic addressing
.reg .b64 addr;
.reg .b32 r;
stmatrix.sync.aligned.m16n8.x1.trans.shared.b8 [addr], {r};

// Store two 16x8 matrices
.reg .b64 addr;
.reg .b32 r&lt;2&gt;;
stmatrix.sync.aligned.m16n8.x2.trans.shared::cta.b8 [addr],{r0, r1};

// Store four 16x8 matrices
.reg .b64 addr;
.reg .b32 r&lt;4&gt;;
stmatrix.sync.aligned.m16n8.x4.b8 [addr], {r0, r1, r2, r3};
</pre></div>
</div>
</section>
<section id="warp-level-matrix-instructions-movmatrix">
<span id="id384"></span><h5>
<span class="section-number">9.7.14.5.17. </span><a class="reference internal" href="#warp-level-matrix-instructions-movmatrix">Warp-level matrix transpose instruction: <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-movmatrix" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">movmatrix</span></code></p>
<p>Transpose a matrix in registers across the warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>movmatrix.sync.aligned.shape.trans.type d, a;

.shape  = {.m8n8};
.type   = {.b16};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Move a row-major matrix across all threads in a warp, reading elements from source <code class="docutils literal notranslate"><span class="pre">a</span></code>, and
writing the transposed elements to destination <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimensions of the matrix being transposed. Each matrix
element holds 16-bit data as indicated by the <code class="docutils literal notranslate"><span class="pre">.type</span></code> qualifier.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> causes the executing thread to wait
until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> instruction should only
be used if it is known that all threads in the warp evaluate the condition identically, otherwise
the behavior is undefined.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code> are 32-bit registers containing fragments of the input matrix and the
resulting matrix respectively. The mandatory qualifier <code class="docutils literal notranslate"><span class="pre">.trans</span></code> indicates that the resulting
matrix in <code class="docutils literal notranslate"><span class="pre">d</span></code> is a transpose of the input matrix specified by <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>Each thread in a warp holds a fragment of a row of the input matrix, with thread 0 holding the first
fragment in register <code class="docutils literal notranslate"><span class="pre">a</span></code>, and so on. A group of four threads holds an entire row of the input
matrix as shown in <a class="reference internal" href="#mma-movmatrix-fragments-src"><span class="std std-numref">Figure 109</span></a>.</p>
<figure class="align-center" id="mma-movmatrix-fragments-src">
<img alt="_images/mma-movmatrix-fragments-src.png" class="image" src="_images/mma-movmatrix-fragments-src.png">
<figcaption>
<p><span class="caption-number">Figure 109 </span><span class="caption-text">movmatrix source matrix fragment layout</span><a class="headerlink" href="#mma-movmatrix-fragments-src" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Each thread in a warp holds a fragment of a column of the result matrix, with thread 0 holding the
first fragment in register <code class="docutils literal notranslate"><span class="pre">d</span></code>, and so on. A group of four threads holds an entire column of the
result matrix as shown in <a class="reference internal" href="#mma-movmatrix-fragments-dst"><span class="std std-numref">Figure 110</span></a>.</p>
<figure class="align-center" id="mma-movmatrix-fragments-dst">
<img alt="_images/mma-movmatrix-fragments-dst.png" class="image" src="_images/mma-movmatrix-fragments-dst.png">
<figcaption>
<p><span class="caption-number">Figure 110 </span><span class="caption-text">movmatrix result matrix fragment layout</span><a class="headerlink" href="#mma-movmatrix-fragments-dst" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 d, a;
movmatrix.sync.aligned.m8n8.trans.b16 d, a;
</pre></div>
</div>
</section>
</section>
<section id="warp-level-matrix-instructions-for-sparse-mma">
<span id="id385"></span><h4>
<span class="section-number">9.7.14.6. </span><a class="reference internal" href="#warp-level-matrix-instructions-for-sparse-mma">Matrix multiply-accumulate operation using <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instruction with sparse matrix A</a><a class="headerlink" href="#warp-level-matrix-instructions-for-sparse-mma" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warp-level <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> instruction with sparse matrix A.
This variant of the <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation can be used when A is a structured sparse matrix with 50%
zeros in each row distributed in a shape-specific granularity. For an <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> sparse
<code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> operation, the <code class="docutils literal notranslate"><span class="pre">MxK</span></code> matrix A is packed into <code class="docutils literal notranslate"><span class="pre">MxK/2</span></code> elements.
For each K-wide row of matrix A, 50% elements are zeros and the remaining K/2 non-zero elements
are packed in the operand representing matrix A. The mapping of these K/2 elements to the
corresponding K-wide row is provided explicitly as metadata.</p>
<section id="warp-level-sparse-matrix-storage">
<span id="id386"></span><h5>
<span class="section-number">9.7.14.6.1. </span><a class="reference internal" href="#warp-level-sparse-matrix-storage">Sparse matrix storage</a><a class="headerlink" href="#warp-level-sparse-matrix-storage" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Granularity of sparse matrix A is defined as the ratio of the number of non-zero elements in a
sub-chunk of the matrix row to the total number of elements in that sub-chunk where the size of the
sub-chunk is shape-specific. For example, in a <code class="docutils literal notranslate"><span class="pre">16x16</span></code> matrix A, sparsity is expected to be at 2:4
granularity, i.e. each 4-element vector (i.e. a sub-chunk of 4 consecutive elements) of a matrix row
contains 2 zeros. Index of each non-zero element in a sub-chunk is stored in the metadata
operand. Values <code class="docutils literal notranslate"><span class="pre">0b0000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b0101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1010</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1111</span></code> are invalid values for metadata and
will result in undefined behavior. In a group of four consecutive threads, one or more threads store
the metadata for the whole group depending upon the matrix shape. These threads are specified using
an additional <em>sparsity selector</em> operand.</p>
<p><a class="reference internal" href="#sparse-mma-storage-example"><span class="std std-numref">Figure 111</span></a> shows an example of a 16x16 matrix A represented in sparse format and sparsity
selector indicating which thread in a group of four consecutive threads stores the metadata.</p>
<figure class="align-center" id="sparse-mma-storage-example">
<img alt="_images/sparse-mma-storage-example.png" class="image" src="_images/sparse-mma-storage-example.png">
<figcaption>
<p><span class="caption-number">Figure 111 </span><span class="caption-text">Sparse MMA storage example</span><a class="headerlink" href="#sparse-mma-storage-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Granularities for different matrix shapes and data types are described below.</p>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> with half-precision and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> operations, matrix A is
structured sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements
in a row of matrix A has two zeros and two non-zero elements. Only the two non-zero elements are
stored in the operand representing matrix A and their positions in the four-wide chunk in matrix
A are indicated by two 2-bit indices in the metadata operand. For <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code>,
<code class="docutils literal notranslate"><span class="pre">0b0100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1001</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1110</span></code> are the meaningful values
of indices; any other values result in an undefined behavior.</p>
<figure class="align-center" id="f16-metadata-example">
<img alt="_images/f16-metadata-example.png" class="image" src="_images/f16-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 112 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#f16-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates the threads which contribute metadata as listed below:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k16</span></code>: One thread within a group of four consecutive threads contributes the metadata for
the entire group. This thread is indicated by a value in {0, 1, 2, 3}.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k32</span></code>: A thread-pair within a group of four consecutive threads contributes the sparsity
metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or 1 (threads T2, T3);
any other value results in an undefined behavior.</p></li>
</ul>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type</p>
<p>When matrix A has <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements, matrix A is structured sparse at a granularity of 1:2. In
other words, each chunk of two adjacent elements in a row of matrix A has one zero and one non-zero
element. Only the non-zero elements are stored in the operand for matrix A and their positions in a
two-wide chunk in matrix A are indicated by the 4-bit index in the metadata. <code class="docutils literal notranslate"><span class="pre">0b1110</span></code> and
<code class="docutils literal notranslate"><span class="pre">0b0100</span></code> are the only meaningful index values; any other values result in an undefined behavior.</p>
<figure class="align-center" id="tf32-metadata-example">
<img alt="_images/tf32-metadata-example.png" class="image" src="_images/tf32-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 113 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#tf32-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates the threads which contribute metadata as listed below:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k8</span></code>: One thread within a group of four consecutive threads contributes the metadata for
the entire group. This thread is indicated by a value in {0, 1, 2, 3}.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k16</span></code>: A thread-pair within a group of four consecutive threads contributes the sparsity
metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or 1 (threads T2, T3);
any other value results in an undefined behavior.</p></li>
</ul>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> with integer type</p>
<p>When matrices A and B have <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements, matrix A is structured sparse at a granularity
of 2:4. In other words, each chunk of four adjacent elements in a row of matrix A have two zeroes
and two non-zero elements. Only the two non-zero elements are stored in sparse matrix and their
positions in the four-wide chunk are indicated by two 2-bit indices in the metadata. For
<code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code>, <code class="docutils literal notranslate"><span class="pre">0b0100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1001</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1110</span></code>
are the meaningful values of indices; any other values result in an undefined behavior.</p>
<figure class="align-center" id="u8s8-metadata-example">
<img alt="_images/u8s8-metadata-example.png" class="image" src="_images/u8s8-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 114 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#u8s8-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>when matrices A and B have <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> elements, matrix A is pair-wise structured sparse at a
granularity of 4:8. In other words, each chunk of eight adjacent elements in a row of matrix A has
four zeroes and four non-zero values. Further, the zero and non-zero values are clustered in
sub-chunks of two elements each within the eight-wide chunk. i.e., each two-wide sub-chunk within
the eight-wide chunk must be all zeroes or all non-zeros. Only the four non-zero values are stored
in sparse matrix and the positions of the two two-wide sub-chunks with non-zero values in the
eight-wide chunk of a row of matrix A are indicated by two 2-bit indices in the metadata. For
<code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code>, <code class="docutils literal notranslate"><span class="pre">0b0100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1001</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1110</span></code>
are the meaningful values of indices; any other values result in an undefined behavior.</p>
<figure class="align-center" id="u4s4-metadata-example">
<img alt="_images/u4s4-metadata-example.png" class="image" src="_images/u4s4-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 115 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type.</span><a class="headerlink" href="#u4s4-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates the threads which contribute metadata as listed below:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type and <code class="docutils literal notranslate"><span class="pre">m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type: A thread-pair
within a group of four consecutive threads contributes the sparsity metadata. Hence, the sparsity
selector must be either 0 (threads T0, T1) or 1 (threads T2, T3); any other value results in an
undefined behavior.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type and <code class="docutils literal notranslate"><span class="pre">m16n8k128</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type: All threads
within a group of four consecutive threads contribute the sparsity metadata. Hence, the sparsity
selector in this case must be 0. Any other value of sparsity selector results in an undefined
behavior.</p></li>
</ul>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">mma.sp{::ordered_metadata}</span></code> operating on <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
type with <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p>
<p>When matrices A and B have <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements, matrix A is
structured sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements in a
row of matrix A have two zeroes and two non-zero elements. Only the two non-zero elements are stored
in sparse matrix and their positions in the four-wide chunk are indicated by two 2-bit indices in the
metadata. <code class="docutils literal notranslate"><span class="pre">0b0100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1001</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1110</span></code> are the meaningful
values of indices; any other values result in an undefined behavior.</p>
<figure class="align-center" id="fp8-metadata-example">
<img alt="_images/fp8-metadata-example.png" class="image" src="_images/fp8-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 116 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#fp8-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates the threads which contribute metadata as listed below:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k64</span></code>: All threads within a group of four consecutive threads contribute the sparsity metadata.
Hence, the sparsity selector in this case must be 0. Any other value of sparsity selector results in
an undefined behavior.</p></li>
</ul>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> operating on <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p>
<p>When matrices A and B have <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements, matrix A is pair-wise structured sparse at a granularity
of 4:8. In other words, each chunk of eight adjacent elements in a row of matrix A has four zeroes and
four non-zero values. Further, the zero and non-zero values are clustered in sub-chunks of two elements
each within the eight-wide chunk. i.e., each two-wide sub-chunk within the eight-wide chunk must be all
zeroes or all non-zeros. Only the four non-zero values are stored in sparse matrix and the positions of
the two two-wide sub-chunks with non-zero values in the eight-wide chunk of a row of matrix A are
indicated by two 2-bit indices in the metadata. <code class="docutils literal notranslate"><span class="pre">0b0100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1001</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1100</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1101</span></code>,
<code class="docutils literal notranslate"><span class="pre">0b1110</span></code> are the meaningful values of indices; any other values result in an undefined behavior.</p>
<figure class="align-center" id="fp4-metadata-example">
<img alt="_images/fp4-metadata-example.png" class="image" src="_images/fp4-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 117 </span><span class="caption-text">Sparse MMA metadata example for <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></span><a class="headerlink" href="#fp4-metadata-example" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates the threads which contribute metadata as listed below:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">m16n8k128</span></code>: All threads within a group of four consecutive threads contribute the sparsity metadata.
Hence, the sparsity selector in this case must be 0. Any other value of sparsity selector results in
an undefined behavior.</p></li>
</ul>
</section>
<section id="warp-level-matrix-fragments-for-sparse-mma">
<span id="id387"></span><h5>
<span class="section-number">9.7.14.6.2. </span><a class="reference internal" href="#warp-level-matrix-fragments-for-sparse-mma">Matrix fragments for multiply-accumulate operation with sparse matrix A</a><a class="headerlink" href="#warp-level-matrix-fragments-for-sparse-mma" title="Permalink to this headline">ïƒ</a>
</h5>
<p>In this section we describe how the contents of thread registers are associated with fragments of
various matrices and the sparsity metadata. The following conventions are used throughout this
section:</p>
<ul class="simple">
<li><p>For matrix A, only the layout of a fragment is described in terms of register vector sizes and
their association with the matrix data.</p></li>
<li><p>For matrix B, when the combination of matrix dimension and the supported data type is not already
covered in <a class="reference internal" href="#warp-level-matrix-instructions-for-mma"><span class="std std-ref">Matrix multiply-accumulate operation using mma instruction</span></a>, a pictorial representation of matrix
fragments is provided.</p></li>
<li><p>For matrices C and D, since the matrix dimension - data type combination is the same for all
supported shapes, and is already covered in
<a class="reference internal" href="#warp-level-matrix-instructions-for-mma"><span class="std std-ref">Matrix multiply-accumulate operation using mma instruction</span></a>, the pictorial representations
of matrix fragments are not included in this section.</p></li>
<li><p>For the metadata operand, pictorial representations of the association between indices of the
elements of matrix A and the contents of the metadata operand are included. <code class="docutils literal notranslate"><span class="pre">Tk:</span> <span class="pre">[m..n]</span></code> present
in cell <code class="docutils literal notranslate"><span class="pre">[x][y..z]</span></code> indicates that bits <code class="docutils literal notranslate"><span class="pre">m</span></code> through <code class="docutils literal notranslate"><span class="pre">n</span></code> (with <code class="docutils literal notranslate"><span class="pre">m</span></code> being higher) in the
metadata operand of thread with <code class="docutils literal notranslate"><span class="pre">%laneid=k</span></code> contains the indices of the non-zero elements from
the chunk <code class="docutils literal notranslate"><span class="pre">[x][y]..[x][z]</span></code> of matrix A.</p></li>
</ul>
<section id="warp-level-matrix-fragment-sparse-mma-16816-f16bf16">
<span id="id388"></span><h6>
<span class="section-number">9.7.14.6.2.1. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16816-f16bf16">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16816-f16bf16" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> floating point type will compute
an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 47%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
with each register containing two non-zero <code class="docutils literal notranslate"><span class="pre">.f16</span></code> /
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements out of 4 consecutive elements from
matrix A.</p></td>
<td><p>Mapping of the non-zero elements is as
described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16816-f16-bf16-a"><span class="std std-numref">Figure 118</span></a>.</p>
<figure class="align-center" id="sparse-mma-16816-f16-bf16-a">
<img alt="_images/sparse-mma-16816-f16-bf16-A.png" class="image" src="_images/sparse-mma-16816-f16-bf16-A.png">
<figcaption>
<p><span class="caption-number">Figure 118 </span><span class="caption-text">Sparse MMA .m16n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-mma-16816-f16-bf16-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-float"><span class="std std-ref">Matrix Fragments for mma.m16n8k16 with floating point type</span></a> for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.b16</span></code> formats.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors each storing the index of a non-zero
element of a 4-wide chunk of matrix A as shown in <a class="reference internal" href="#sparse-mma-metadata-16816-f16bf16"><span class="std std-numref">Figure 119</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16816-f16bf16">
<img alt="_images/sparse-mma-metadata-16816-f16bf16.png" class="image" src="_images/sparse-mma-metadata-16816-f16bf16.png">
<figcaption>
<p><span class="caption-number">Figure 119 </span><span class="caption-text">Sparse MMA .m16n8k16 metadata layout for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16816-f16bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-16832-f16bf16">
<span id="id389"></span><h6>
<span class="section-number">9.7.14.6.2.2. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16832-f16bf16">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16832-f16bf16" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> floating point type will compute
an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 47%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
with each register containing two non-zero <code class="docutils literal notranslate"><span class="pre">.f16</span></code> /
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements out of 4 consecutive elements from
matrix A.</p></td>
<td><p>Mapping of the non-zero elements is as
described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16832-f16-bf16-a"><span class="std std-numref">Figure 120</span></a>.</p>
<figure class="align-center" id="sparse-mma-16832-f16-bf16-a">
<img alt="_images/sparse-mma-16832-f16-bf16-A.png" class="image" src="_images/sparse-mma-16832-f16-bf16-A.png">
<figcaption>
<p><span class="caption-number">Figure 120 </span><span class="caption-text">Sparse MMA .m16n8k32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-mma-16832-f16-bf16-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">6</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="w">          </span><span class="n">For</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">4</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">16</span><span class="w">   </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">3</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 20%">
<col style="width: 57%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, each
containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> / <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements from matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16832-f16bf16-b"><span class="std std-numref">Figure 121</span></a>.</p>
<figure class="align-center" id="sparse-mma-16832-f16bf16-b">
<img alt="_images/sparse-mma-16832-f16bf16-B.png" class="image" src="_images/sparse-mma-16832-f16bf16-B.png">
<figcaption>
<p><span class="caption-number">Figure 121 </span><span class="caption-text">Sparse MMA .m16n8k32 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-mma-16832-f16bf16-b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li><p>Matrix fragments for accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-float"><span class="std std-ref">Matrix Fragments for mma.m16n8k16 with floating point type</span></a>
for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.b16</span></code> formats.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors with each pair of 2-bit vectors storing
the indices of two non-zero element from a 4-wide chunk of matrix A as shown in
<a class="reference internal" href="#sparse-mma-metadata-16832-f16bf16"><span class="std std-numref">Figure 122</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16832-f16bf16">
<img alt="_images/sparse-mma-metadata-16832-f16bf16.png" class="image" src="_images/sparse-mma-metadata-16832-f16bf16.png">
<figcaption>
<p><span class="caption-number">Figure 122 </span><span class="caption-text">Sparse MMA .m16n8k32 metadata layout for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16832-f16bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-16816-tf32">
<span id="id390"></span><h6>
<span class="section-number">9.7.14.6.2.3. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16816-tf32">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16816-tf32" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k16</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type will compute an MMA
operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 58%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing one non-zero <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> element out of 2
consecutive elements from matrix A.</p></td>
<td><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16816-tf32-a"><span class="std std-numref">Figure 123</span></a>.</p>
<figure class="align-center" id="sparse-mma-16816-tf32-a">
<img alt="_images/sparse-mma-16816-tf32-A.png" class="image" src="_images/sparse-mma-16816-tf32-A.png">
<figcaption>
<p><span class="caption-number">Figure 123 </span><span class="caption-text">Sparse MMA .m16n8k16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-mma-16816-tf32-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a2</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w">          </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">a2</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a3</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 64%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, each
containing four <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements from matrix B.</p></td>
<td><p>b0, b1, b2, b3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16816-tf32-b"><span class="std std-numref">Figure 124</span></a>.</p>
<figure class="align-center" id="sparse-mma-16816-tf32-b">
<img alt="_images/sparse-mma-16816-tf32-B.png" class="image" src="_images/sparse-mma-16816-tf32-B.png">
<figcaption>
<p><span class="caption-number">Figure 124 </span><span class="caption-text">Sparse MMA .m16n8k16 fragment layout for matrix B with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-mma-16816-tf32-b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li><p>Matrix fragments for accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-float"><span class="std std-ref">Matrix Fragments for mma.m16n8k16 with floating point type</span></a>.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 8 4-bit vectors each storing the index of a non-zero
element of a 2-wide chunk of matrix A as shown in <a class="reference internal" href="#sparse-mma-metadata-16816-tf32"><span class="std std-numref">Figure 125</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16816-tf32">
<img alt="_images/sparse-mma-metadata-16816-tf32.png" class="image" src="_images/sparse-mma-metadata-16816-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 125 </span><span class="caption-text">Sparse MMA .m16n8k16 metadata layout for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16816-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-1688-tf32">
<span id="id391"></span><h6>
<span class="section-number">9.7.14.6.2.4. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-1688-tf32">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-1688-tf32" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k8</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point type will compute an MMA
operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 53%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, each
containing one non-zero <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> element out of 2
consecutive elements from matrix A.</p></td>
<td><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-1688-tf32"><span class="std std-numref">Figure 126</span></a>.</p>
<figure class="align-center" id="sparse-mma-1688-tf32">
<img alt="_images/sparse-mma-1688-tf32-A.png" class="image" src="_images/sparse-mma-1688-tf32-A.png">
<figcaption>
<p><span class="caption-number">Figure 126 </span><span class="caption-text">Sparse MMA .m16n8k8 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-mma-1688-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The row and column of a matrix fragment can be computed as:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">a0</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">a1</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-1688"><span class="std std-ref">Matrix Fragments for mma.m16n8k8</span></a> for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>
format.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 8 4-bit vectors each storing the index of a non-zero
element of a 2-wide chunk of matrix A as shown in <a class="reference internal" href="#sparse-mma-metadata-1688-tf32"><span class="std std-numref">Figure 127</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-1688-tf32">
<img alt="_images/sparse-mma-metadata-1688-tf32.png" class="image" src="_images/sparse-mma-metadata-1688-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 127 </span><span class="caption-text">Sparse MMA .m16n8k8 metadata layout for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-1688-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-16832-u8s8">
<span id="id392"></span><h6>
<span class="section-number">9.7.14.6.2.5. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16832-u8s8">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> integer type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16832-u8s8" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k32</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> integer type will compute an MMA
operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 54%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four non-zero <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements out
of 8 consecutive elements from matrix A.</p></td>
<td><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16832-u8s8-a"><span class="std std-numref">Figure 128</span></a>.</p>
<figure class="align-center" id="sparse-mma-16832-u8s8-a">
<img alt="_images/sparse-mma-16832-u8s8-A.png" class="image" src="_images/sparse-mma-16832-u8s8-A.png">
<figcaption>
<p><span class="caption-number">Figure 128 </span><span class="caption-text">Sparse MMA .m16n8k32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#sparse-mma-16832-u8s8-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">7</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16832"><span class="std std-ref">Matrix Fragments for mma.m16n8k32</span></a>.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors with each pair of 2-bit vectors storing
the indices of two non-zero elements from a 4-wide chunk of matrix A as shown in
<a class="reference internal" href="#sparse-mma-metadata-16832-u8s8"><span class="std std-numref">Figure 129</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16832-u8s8">
<img alt="_images/sparse-mma-metadata-16832-u8s8.png" class="image" src="_images/sparse-mma-metadata-16832-u8s8.png">
<figcaption>
<p><span class="caption-number">Figure 129 </span><span class="caption-text">Sparse MMA .m16n8k32 metadata layout for <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16832-u8s8" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8">
<span id="id393"></span><h6>
<span class="section-number">9.7.14.6.2.6. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> / <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16864-u8s8-fp8" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type will compute an MMA operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 54%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four non-zero <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements out
of 8 consecutive elements from matrix A.</p></td>
<td rowspan="2"><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four non-zero <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements out of 8 consecutive
elements from matrix A.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16864-u8s8-a-first32col"><span class="std std-numref">Figure 130</span></a>
and <a class="reference internal" href="#sparse-mma-16864-u8s8-a-last32col"><span class="std std-numref">Figure 131</span></a>.</p>
<figure class="align-center" id="sparse-mma-16864-u8s8-a-first32col">
<img alt="_images/sparse-mma-16864-u8s8-A-first32col.png" class="image" src="_images/sparse-mma-16864-u8s8-A-first32col.png">
<figcaption>
<p><span class="caption-number">Figure 130 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for columns 0â€“31 of matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-a-first32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-16864-u8s8-a-last32col">
<img alt="_images/sparse-mma-16864-u8s8-A-last32col.png" class="image" src="_images/sparse-mma-16864-u8s8-A-last32col.png">
<figcaption>
<p><span class="caption-number">Figure 131 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for columns 32â€“63 of matrix A with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-a-last32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">12</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="w">           </span><span class="n">For</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">8</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">8</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">32</span><span class="w">    </span><span class="n">For</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">7</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 58%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.btype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
each containing four <code class="docutils literal notranslate"><span class="pre">.u8</span></code> / <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements from
matrix B.</p></td>
<td rowspan="2"><p>b0, b1, b2, b3, â€¦, b15</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers,
each containing four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> / <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from matrix B.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16864-u8s8-b1"><span class="std std-numref">Figure 132</span></a>,
<a class="reference internal" href="#sparse-mma-16864-u8s8-b2"><span class="std std-numref">Figure 133</span></a>, <a class="reference internal" href="#sparse-mma-16864-u8s8-b3"><span class="std std-numref">Figure 134</span></a> and <a class="reference internal" href="#sparse-mma-16864-u8s8-b4"><span class="std std-numref">Figure 135</span></a>.</p>
<figure class="align-center" id="sparse-mma-16864-u8s8-b1">
<img alt="_images/sparse-mma-16864-u8s8-B1.png" class="image" src="_images/sparse-mma-16864-u8s8-B1.png">
<figcaption>
<p><span class="caption-number">Figure 132 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for rows 0â€“15 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-b1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-16864-u8s8-b2">
<img alt="_images/sparse-mma-16864-u8s8-B2.png" class="image" src="_images/sparse-mma-16864-u8s8-B2.png">
<figcaption>
<p><span class="caption-number">Figure 133 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for rows 16â€“31 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-b2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-16864-u8s8-b3">
<img alt="_images/sparse-mma-16864-u8s8-B3.png" class="image" src="_images/sparse-mma-16864-u8s8-B3.png">
<figcaption>
<p><span class="caption-number">Figure 134 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for rows 32â€“47 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-b3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-16864-u8s8-b4">
<img alt="_images/sparse-mma-16864-u8s8-B4.png" class="image" src="_images/sparse-mma-16864-u8s8-B4.png">
<figcaption>
<p><span class="caption-number">Figure 135 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for rows 48â€“63 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u8s8-b4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li><p>Matrix fragments for accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16816-i8-f8"><span class="std std-ref">Matrix Fragments for mma.m16n8k16 with integer type</span></a>.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors with each pair of 2-bit vectors storing
the indices of two non-zero elements from a 4-wide chunk of matrix A as shown in
<a class="reference internal" href="#sparse-mma-metadata-16864-u8s8-first32col"><span class="std std-numref">Figure 136</span></a> and <a class="reference internal" href="#sparse-mma-metadata-16864-u8s8-last32col"><span class="std std-numref">Figure 137</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16864-u8s8-first32col">
<img alt="_images/sparse-mma-metadata-16864-u8s8-first32col.png" class="image" src="_images/sparse-mma-metadata-16864-u8s8-first32col.png">
<figcaption>
<p><span class="caption-number">Figure 136 </span><span class="caption-text">Sparse MMA .m16n8k64 metadata layout for columns 0â€“31 for <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16864-u8s8-first32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-metadata-16864-u8s8-last32col">
<img alt="_images/sparse-mma-metadata-16864-u8s8-last32col.png" class="image" src="_images/sparse-mma-metadata-16864-u8s8-last32col.png">
<figcaption>
<p><span class="caption-number">Figure 137 </span><span class="caption-text">Sparse MMA .m16n8k64 metadata layout for columns 32â€“63 for <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16864-u8s8-last32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-16864-u4s4">
<span id="id394"></span><h6>
<span class="section-number">9.7.14.6.2.7. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-16864-u4s4">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> integer type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-16864-u4s4" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k64</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> integer type will compute an MMA
operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 54%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p>A vector expression containing two <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight non-zero <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> elements
out of 16 consecutive elements from matrix A.</p></td>
<td><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-16864-u4s4-a"><span class="std std-numref">Figure 138</span></a>.</p>
<figure class="align-center" id="sparse-mma-16864-u4s4-a">
<img alt="_images/sparse-mma-16864-u4s4-A.png" class="image" src="_images/sparse-mma-16864-u4s4-A.png">
<figcaption>
<p><span class="caption-number">Figure 138 </span><span class="caption-text">Sparse MMA .m16n8k64 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type.</span><a class="headerlink" href="#sparse-mma-16864-u4s4-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">15</span><span class="w"></span>
</pre></div>
</div>
</li>
<li><p>Matrix fragments for multiplicand B and accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16864"><span class="std std-ref">Matrix Fragments for mma.m16n8k64</span></a>.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors with each pair of 2-bit vectors storing
the indices of four non-zero elements from a 8-wide chunk of matrix A as shown in
<a class="reference internal" href="#sparse-mma-metadata-16864-u4s4"><span class="std std-numref">Figure 139</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-16864-u4s4">
<img alt="_images/sparse-mma-metadata-16864-u4s4.png" class="image" src="_images/sparse-mma-metadata-16864-u4s4.png">
<figcaption>
<p><span class="caption-number">Figure 139 </span><span class="caption-text">Sparse MMA .m16n8k64 metadata layout for  <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-16864-u4s4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="warp-level-matrix-fragment-sparse-mma-168128-u4s4">
<span id="id395"></span><h6>
<span class="section-number">9.7.14.6.2.8. </span><a class="reference internal" href="#warp-level-matrix-fragment-sparse-mma-168128-u4s4">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> integer type</a><a class="headerlink" href="#warp-level-matrix-fragment-sparse-mma-168128-u4s4" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warp executing sparse <code class="docutils literal notranslate"><span class="pre">mma.m16n8k128</span></code> with <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> / <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> integer type will compute an MMA
operation of shape <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code>.</p>
<p>Elements of the matrix are distributed across the threads in a warp so each thread of the warp holds
a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 52%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight non-zero <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> elements out
of 16 consecutive elements from matrix A.</p></td>
<td rowspan="2"><p>Mapping of the non-zero elements is
as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing eight non-zero <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements out
of 16 consecutive elements from matrix A.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-168128-u4s4-a-first64col"><span class="std std-numref">Figure 140</span></a>
and <a class="reference internal" href="#sparse-mma-168128-u4s4-a-last64col"><span class="std std-numref">Figure 141</span></a>.</p>
<figure class="align-center" id="sparse-mma-168128-u4s4-a-first64col">
<img alt="_images/sparse-mma-168128-u4s4-A-first64col.png" class="image" src="_images/sparse-mma-168128-u4s4-A-first64col.png">
<figcaption>
<p><span class="caption-number">Figure 140 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for columns 0â€“63 of matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-a-first64col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-168128-u4s4-a-last64col">
<img alt="_images/sparse-mma-168128-u4s4-A-last64col.png" class="image" src="_images/sparse-mma-168128-u4s4-A-last64col.png">
<figcaption>
<p><span class="caption-number">Figure 141 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for columns 64â€“127 of matrix A with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-a-last64col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">groupID</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">&gt;&gt;</span><span class="w"> </span><span class="mi">2</span><span class="w"></span>
<span class="n">threadID_in_group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">%</span><span class="n">laneid</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">4</span><span class="w"></span>

<span class="n">row</span><span class="w"> </span><span class="o">=</span><span class="w">      </span><span class="n">groupID</span><span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w">  </span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">8</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">24</span><span class="w"></span>
<span class="w">           </span><span class="n">groupID</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">8</span><span class="w">        </span><span class="n">Otherwise</span><span class="w"></span>

<span class="n">col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">firstcol</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="n">lastcol</span><span class="p">]</span><span class="w">  </span><span class="c1">// As per the mapping of non-zero elements</span>
<span class="w">                              </span><span class="c1">// as described in Sparse matrix storage</span>

<span class="n">Where</span><span class="w"></span>
<span class="n">firstcol</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w">           </span><span class="n">For</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w">  </span><span class="mi">16</span><span class="w"></span>
<span class="w">           </span><span class="p">(</span><span class="n">threadID_in_group</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">64</span><span class="w">    </span><span class="n">For</span><span class="w"> </span><span class="n">ai</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="mi">16</span><span class="w"></span>
<span class="n">lastcol</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="n">firstcol</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">15</span><span class="w"></span>
</pre></div>
</div>
</li>
<li>
<p>Multiplicand B:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 16%">
<col style="width: 62%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, each containing
eight <code class="docutils literal notranslate"><span class="pre">.u4</span></code> / <code class="docutils literal notranslate"><span class="pre">.s4</span></code> elements from matrix B.</p></td>
<td rowspan="2"><p>b0, b1, b2, b3, â€¦, b31</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, each containing
eight <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> elements from matrix B.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-mma-168128-u4s4-b1"><span class="std std-numref">Figure 142</span></a>,
<a class="reference internal" href="#sparse-mma-168128-u4s4-b2"><span class="std std-numref">Figure 143</span></a>, <a class="reference internal" href="#sparse-mma-168128-u4s4-b3"><span class="std std-numref">Figure 144</span></a>, <a class="reference internal" href="#sparse-mma-168128-u4s4-b4"><span class="std std-numref">Figure 145</span></a>.</p>
<figure class="align-center" id="sparse-mma-168128-u4s4-b1">
<img alt="_images/sparse-mma-168128-u4s4-B1.png" class="image" src="_images/sparse-mma-168128-u4s4-B1.png">
<figcaption>
<p><span class="caption-number">Figure 142 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for rows 0â€“31 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-b1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-168128-u4s4-b2">
<img alt="_images/sparse-mma-168128-u4s4-B2.png" class="image" src="_images/sparse-mma-168128-u4s4-B2.png">
<figcaption>
<p><span class="caption-number">Figure 143 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for rows 32â€“63 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-b2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-168128-u4s4-b3">
<img alt="_images/sparse-mma-168128-u4s4-B3.png" class="image" src="_images/sparse-mma-168128-u4s4-B3.png">
<figcaption>
<p><span class="caption-number">Figure 144 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for rows 64â€“95 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-b3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-168128-u4s4-b4">
<img alt="_images/sparse-mma-168128-u4s4-B4.png" class="image" src="_images/sparse-mma-168128-u4s4-B4.png">
<figcaption>
<p><span class="caption-number">Figure 145 </span><span class="caption-text">Sparse MMA .m16n8k128 fragment layout for rows 96â€“127 of matrix B with <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-168128-u4s4-b4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li><p>Matrix fragments for accumulators C and D are the same as in case of
<a class="reference internal" href="#warp-level-matrix-fragment-mma-16864"><span class="std std-ref">Matrix Fragments for mma.m16n8k64</span></a>.</p></li>
<li>
<p>Metadata: A <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors with each pair of 2-bit vectors storing
the indices of four non-zero elements from a 8-wide chunk of matrix A as shown in
<a class="reference internal" href="#sparse-mma-metadata-168128-u4s4-first64col"><span class="std std-numref">Figure 146</span></a> and <a class="reference internal" href="#sparse-mma-metadata-168128-u4s4-last64col"><span class="std std-numref">Figure 147</span></a>.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-mma-metadata-168128-u4s4-first64col">
<img alt="_images/sparse-mma-metadata-168128-u4s4-first64col.png" class="image" src="_images/sparse-mma-metadata-168128-u4s4-first64col.png">
<figcaption>
<p><span class="caption-number">Figure 146 </span><span class="caption-text">Sparse MMA .m16n8k128 metadata layout for  columns 0â€“63 for <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-168128-u4s4-first64col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="sparse-mma-metadata-168128-u4s4-last64col">
<img alt="_images/sparse-mma-metadata-168128-u4s4-last64col.png" class="image" src="_images/sparse-mma-metadata-168128-u4s4-last64col.png">
<figcaption>
<p><span class="caption-number">Figure 147 </span><span class="caption-text">Sparse MMA .m16n8k128 metadata layout for  columns 64â€“127 for <code class="docutils literal notranslate"><span class="pre">.u4</span></code>/<code class="docutils literal notranslate"><span class="pre">.s4</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> type.</span><a class="headerlink" href="#sparse-mma-metadata-168128-u4s4-last64col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
</section>
<section id="warp-level-matrix-instructions-sparse-mma">
<span id="id396"></span><h5>
<span class="section-number">9.7.14.6.3. </span><a class="reference internal" href="#warp-level-matrix-instructions-sparse-mma">Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> / <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code></a><a class="headerlink" href="#warp-level-matrix-instructions-sparse-mma" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">mma.sp</span></code>, <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code></p>
<p>Perform matrix multiply-and-accumulate operation with sparse matrix A</p>
<p class="rubric">Syntax</p>
<p>Half precision floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.spvariant.sync.aligned.m16n8k16.row.col.dtype.f16.f16.ctype  d, a, b, c, e, f;
mma.spvariant.sync.aligned.m16n8k32.row.col.dtype.f16.f16.ctype  d, a, b, c, e, f;

.ctype     = {.f16, .f32};
.dtype     = {.f16, .f32};
.spvariant = {.sp, .sp::ordered_metadata};
</pre></div>
</div>
<p>Alternate floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.spvariant.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32     d, a, b, c, e, f;
mma.spvariant.sync.aligned.m16n8k32.row.col.f32.bf16.bf16.f32     d, a, b, c, e, f;
mma.spvariant.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32      d, a, b, c, e, f;
mma.spvariant.sync.aligned.m16n8k16.row.col.f32.tf32.tf32.f32     d, a, b, c, e, f;
mma.spvariant.sync.aligned.m16n8k64.row.col.f32.f8type.f8type.f32 d, a, b, c, e, f;
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind.dtype.f8f6f4type.f8f6f4type.ctype d, a, b, c, e, f;

.f8type     = {.e4m3, .e5m2};
.spvariant  = {.sp, .sp::ordered_metadata};
.f8f6f4type = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};
.kind       = {kind::f8f6f4};
.ctype      = {.f16, .f32};
.dtype      = {.f16, .f32};
</pre></div>
</div>
<p>Alternate floating point type with block scaling:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.spvariant.sync.aligned.m16n8k128.row.col.kind.block_scale{.scale_vec_size}.f32.e2m1.e2m1.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.spvariant      = {.sp::ordered_metadata};
.kind           = {.kind::mxf4};
.scale_vec_size = {.scale_vec::2X};
.stype          = {.ue8m0};

mma.spvariant.sync.aligned.m16n8k128.row.col.kind.block_scale.scale_vec_size.f32.e2m1.e2m1.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.spvariant      = {.sp::ordered_metadata};
.kind           = {.kind::mxf4nvf4};
.scale_vec_size = {.scale_vec::2X, .scale_vec::4X};
.stype          = {.ue8m0, .ue4m3};

mma.spvariant.sync.aligned.m16n8k64.row.col.kind.block_scale{.scale_vec_size}.f32.f8f6f4type.f8f6f4type.f32.stype d, a, b, c, e, f, scale-a-data, {byte-id-a, thread-id-a}, scale-b-data, {byte-id-b, thread-id-b};

.spvariant      = {.sp::ordered_metadata};
.kind           = {.kind::mxf8f6f4};
.scale_vec_size = {.scale_vec::1X};
.f8f6f4type     = {.e4m3, .e5m2, .e3m2, .e2m3, .e2m1};
.stype          = {.ue8m0};
</pre></div>
</div>
<p>Integer type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mma.spvariant.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c, e, f;

.shape     = {.m16n8k32, .m16n8k64}
.atype     = {.u8, .s8};
.btype     = {.u8, .s8};
.spvariant = {.sp, .sp::ordered_metadata};

mma.spvariant.sync.aligned.shape.row.col{.satfinite}.s32.atype.btype.s32 d, a, b, c, e, f;

.shape     = {.m16n8k64, .m16n8k128}
.atype     = {.u4, .s4};
.btype     = {.u4, .s4};
.spvariant = {.sp, .sp::ordered_metadata};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Perform a <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> matrix multiply and accumulate operation, <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+C</span></code>, where the A matrix is
<code class="docutils literal notranslate"><span class="pre">MxK</span></code>, the B matrix is <code class="docutils literal notranslate"><span class="pre">KxN</span></code>, and the C and D matrices are <code class="docutils literal notranslate"><span class="pre">MxN</span></code>.</p>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">mma.sp.sync/mma.sp::ordered_metadata.sync</span></code> instruction compute a single matrix
multiply and accumulate operation.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> specifies that the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are scaled with <code class="docutils literal notranslate"><span class="pre">scale_A</span></code>
and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively before performing the matrix multiply and accumulate operation
as specified in the section <a class="reference external" href="#warp-level-block-scaling">Block Scaling</a>. The data type corresponding
to each of the element within <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices is specified by <code class="docutils literal notranslate"><span class="pre">.stype</span></code>.
Qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> specifies the number of columns of <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> matrix and number of
rows in the matrix <code class="docutils literal notranslate"><span class="pre">scale_B</span></code>.</p>
<p>The valid combinations of <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.stype</span></code> and <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> are described in
<a class="reference internal" href="#mma-scaling-kind-type-valid-combination"><span class="std std-numref">Table 36</span></a>. For <code class="docutils literal notranslate"><span class="pre">mma</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> when the
qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">2X</span></code>. In contrast,
when <code class="docutils literal notranslate"><span class="pre">.kind</span></code> is specified as <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> then the qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code>
defaults to <code class="docutils literal notranslate"><span class="pre">1X</span></code>. However, for <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>, it is mandatory to provide valid
<code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code>.</p>
<p>Operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> represent two multiplicand matrices A and B, while <code class="docutils literal notranslate"><span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">d</span></code>
represent the accumulator and destination matrices, distributed across the threads in warp. Matrix A
is structured sparse as described in <a class="reference internal" href="#warp-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a> Operands <code class="docutils literal notranslate"><span class="pre">e</span></code> and <code class="docutils literal notranslate"><span class="pre">f</span></code> represent sparsity
metadata and sparsity selector respectively. Operand <code class="docutils literal notranslate"><span class="pre">e</span></code> is a 32-bit integer and operand <code class="docutils literal notranslate"><span class="pre">f</span></code> is
a 32-bit integer constant with values in the range 0..3.
When <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> qualifier is specified, operand <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>, <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> represents
the scale matrix metadata corresponding to <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively.
The tuple <code class="docutils literal notranslate"><span class="pre">{byte-id-a,</span> <span class="pre">thread-id-a}</span></code> and <code class="docutils literal notranslate"><span class="pre">{byte-id-b,</span> <span class="pre">thread-id-b}</span></code> represent selectors for
matrices <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> respectively from their corresponding metadata arguments
<code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>, <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code>. The operands <code class="docutils literal notranslate"><span class="pre">scale-a-data</span></code>, <code class="docutils literal notranslate"><span class="pre">scale-b-data</span></code> are of type
<code class="docutils literal notranslate"><span class="pre">.b32</span></code>. The operands <code class="docutils literal notranslate"><span class="pre">byte-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-a</span></code>, <code class="docutils literal notranslate"><span class="pre">byte-id-b</span></code>, <code class="docutils literal notranslate"><span class="pre">thread-id-b</span></code> are unsigned
16-bit integer values. For more details on selector arguments refer
<a class="reference internal" href="#warp-level-block-scaling"><span class="std std-ref">Block Scaling for mma.sync</span></a> section.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> requires the indices in the sparsity metadata to be sorted
in an increasing order starting from LSB, otherwise behavior is undefined.</p>
<p>The registers in each thread hold a fragment of matrix as described in
<a class="reference internal" href="#warp-level-matrix-fragments-for-sparse-mma"><span class="std std-ref">Matrix fragments for multiply-accumulate operation with sparse matrix A</span></a>.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">.atype</span></code>, <code class="docutils literal notranslate"><span class="pre">.btype</span></code> and <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> indicate the data-type of the
elements in the matrices D, A, B and C respectively. The qualifier <code class="docutils literal notranslate"><span class="pre">.stype</span></code> indicate the
data-type of the elements in the matrices <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code>. In case of shapes
<code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> must be the same as <code class="docutils literal notranslate"><span class="pre">.ctype</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.kind</span></code> is either of <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, the individual 4-bit and
the 6-bit floating point type elements must be packed in an 8-bit container. The matrix element
of type <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> resides in central 4 bits of the 8-bit container with padding in the upper 2
bits and lower 2 bits of the container. When the matrix element is of type <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code> or <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>,
the matrix element resides in the lower 6 bits of the 8-bit container with padding in the upper
2 bits of the container. In contrast, note that when using <code class="docutils literal notranslate"><span class="pre">mma</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> or
<code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>, no explicit padding is necessary even though matrix elements are of type
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>.</p>
<dl>
<dt>Precision and rounding :</dt>
<dd>
<ul>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code> floating point operations :</p>
<p>Element-wise multiplication of matrix A and B is performed with at least single
precision. When <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> or <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, accumulation of the intermediate values
is performed with at least single precision. When both <code class="docutils literal notranslate"><span class="pre">.ctype</span></code> and <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> are specified
as <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, the accumulation is performed with at least half precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> floating point operations :</p>
<p>Element-wise multiplication of matrix A and B is performed with specified precision. Accumulation
of the intermediate values is performed with at least single precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point operations :</p>
<p>Element-wise multiplication of matrix A and B is performed with specified
precision. Accumulation of the intermediate values is performed with at least single
precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p>Integer operations :</p>
<p>The integer <code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code> operation is performed with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> accumulators.
The <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier indicates that on overflow, the accumulated value is limited to the range
<em>MIN_INT32</em>.. <em>MAX_INT32</em> (where the bounds are defined as the minimum negative signed 32-bit
integer and the maximum positive signed 32-bit integer respectively).</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> is not specified, the accumulated value is wrapped instead.</p>
</li>
</ul>
</dd>
</dl>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code> instruction causes
the executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the same
<code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code>
instruction should only be used if it is known that all threads in the warp evaluate the condition identically,
otherwise behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">mma.sp/mma.sp::ordered_metadata</span></code> instruction is undefined if all threads in the same warp
do not use the same qualifiers, or if any thread in the warp has exited.</p>
<p class="rubric">Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instruction may have substantially reduced performance on some target architectures.
Hence, it is advised to use <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> instruction.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation introduced in
PTX ISA version 8.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> introduced in PTX ISA version 8.5.</p>
<p>Support for shape <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16</span></code> dtype/ctype with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating
point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation introduced in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation introduced
in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier introduced in PTX ISA version 8.7.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> on <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code> as <code class="docutils literal notranslate"><span class="pre">.stype</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> is introduced in
PTX ISA version 9.1</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation requires <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p>Support for shape <code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16</span></code> dtype/ctype with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating
point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation requires <code class="docutils literal notranslate"><span class="pre">sm_120</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> alternate floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation requires
<code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> and are supported on <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family from PTX ISA version 8.8.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> qualifier requires <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> and are
supported on <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> and later generation targets in the same family from PTX ISA version 8.8 except for <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>/<code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> are supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></li>
</ul>
<p class="rubric">Examples of half precision floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// f16 elements in C and D matrix
.reg .f16x2 %Ra&lt;2&gt; %Rb&lt;2&gt; %Rc&lt;2&gt; %Rd&lt;2&gt;
.reg .b32 %Re;
mma.sp.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1}, %Re, 0x1;

.reg .f16x2 %Ra&lt;2&gt; %Rb&lt;2&gt; %Rc&lt;2&gt; %Rd&lt;2&gt;
.reg .b32 %Re;

mma.sp::ordered_metadata.sync.aligned.m16n8k16.row.col.f16.f16.f16.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1}, %Re, 0x1;
</pre></div>
</div>
<p class="rubric">Examples of alternate floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %Ra&lt;2&gt;, %Rb&lt;2&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp.sync.aligned.m16n8k8.row.col.f32.tf32.tf32.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

.reg .b32 %Ra&lt;2&gt;, %Rb&lt;2&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp.sync.aligned.m16n8k32.row.col.f32.bf16.bf16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp.sync.aligned.m16n8k64.row.col.f32.e5m2.e4m3.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0;

.reg .b32 %Ra&lt;2&gt;, %Rb&lt;2&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k16.row.col.f32.bf16.bf16.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::f8f6f4.f32.e3m2.e2m3.f32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0;

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .b32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::f8f6f4.f16.e2m3.e2m1.f16
  {%Rd0, %Rd1},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1}, %Re, 0;
</pre></div>
</div>
<p class="rubric">Examples of integer type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;, %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .u32 %Re;

// u8 elements in A and B matrix
mma.sp.sync.aligned.m16n8k32.row.col.satfinite.s32.u8.u8.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

// s8 elements in A and B matrix
mma.sp.sync.aligned.m16n8k64.row.col.satfinite.s32.s8.s8.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;

// s8 elements in A and B matrix with ordered metadata
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.satfinite.s32.s8.s8.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;

// u4 elements in A and B matrix
mma.sp.sync.aligned.m16n8k64.row.col.s32.s4.s4.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1},
  {%Rb0, %Rb1},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x1;

// u4 elements in A and B matrix
mma.sp.sync.aligned.m16n8k128.row.col.satfinite.s32.u4.u4.s32
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3}, %Re, 0x0;
</pre></div>
</div>
<p class="rubric">Examples of mma with block scale</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> .reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
 .reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
 .reg .b32 scaleAData, scaleBData;
 .reg .b32 %Re;
 mma.sp::ordered_metadata.sync.aligned.m16n8k128.row.col.kind::mxf4.block_scale.f32.e2m1.e2m1.f32.ue8m0
   {%Rd0, %Rd1, %Rd2, %Rd3},
   {%Ra0, %Ra1, %Ra2, %Ra3},
   {%Rb0, %Rb1, %Rb2, %Rb3},
   {%Rc0, %Rc1, %Rc2, %Rc3},
   %Re, 0,
   scaleAData, {2, 1}, scaleBData, {2, 3};

 .reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
 .reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
 .reg .b32 scaleAData, scaleBData;
 .reg .u16 bidA, bidB, tidA, tidB;
 .reg .b32 %Re;
 mma.sp::ordered_metadata.sync.aligned.m16n8k128.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue4m3
   {%Rd0, %Rd1, %Rd2, %Rd3},
   {%Ra0, %Ra1, %Ra2, %Ra3},
   {%Rb0, %Rb1, %Rb2, %Rb3},
   {%Rc0, %Rc1, %Rc2, %Rc3},
   %Re, 0,
   scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
.reg .u16 bidA, bidB, tidA, tidB;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k128.row.col.kind::mxf4nvf4.block_scale.scale_vec::4X.f32.e2m1.e2m1.f32.ue8m0
 {%Rd0, %Rd1, %Rd2, %Rd3},
 {%Ra0, %Ra1, %Ra2, %Ra3},
 {%Rb0, %Rb1, %Rb2, %Rb3},
 {%Rc0, %Rc1, %Rc2, %Rc3},
 %Re, 0,
 scaleAData, {bidA, tidA}, scaleBData, {bidB, tidB};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e3m2.e2m1.f32.ue8m0
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2, %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3},
  %Re, 0,
  scaleAData, {0, 1}, scaleBData, {0, 1};

.reg .b32 %Ra&lt;4&gt;, %Rb&lt;4&gt;;
.reg .f32 %Rc&lt;4&gt;, %Rd&lt;4&gt;;
.reg .b32 scaleAData, scaleBData;
.reg .b32 %Re;
mma.sp::ordered_metadata.sync.aligned.m16n8k64.row.col.kind::mxf8f6f4.block_scale.scale_vec::1X.f32.e4m3.e5m2.f32.ue8m0
  {%Rd0, %Rd1, %Rd2, %Rd3},
  {%Ra0, %Ra1, %Ra2,  %Ra3},
  {%Rb0, %Rb1, %Rb2, %Rb3},
  {%Rc0, %Rc1, %Rc2, %Rc3},
  %Re, 0,
  scaleAData, {0, 1}, scaleBData, {0, 0};
</pre></div>
</div>
</section>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions">
<span id="id397"></span><h3>
<span class="section-number">9.7.15. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions">Asynchronous Warpgroup Level Matrix Multiply-Accumulate Instructions</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The warpgroup level matrix multiply and accumulate operation has either of the following forms,
where matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> is called accumulator:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">*</span> <span class="pre">B</span> <span class="pre">+</span> <span class="pre">D</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A</span> <span class="pre">*</span> <span class="pre">B</span></code>, where the input from accumulator D is disabled.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">wgmma</span></code> instructions perform warpgroup level matrix multiply-and-accumulate operation by
having all threads in a warpgroup collectively perform the following actions:</p>
<ol class="arabic simple">
<li><p>Load matrices A, B and D into registers or into shared memory.</p></li>
<li>
<p>Perform the following <code class="docutils literal notranslate"><span class="pre">fence</span></code> operations:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> operations to indicate that the register/shared-memory across the warpgroup
have been written into.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> operation to make the generic proxy operations visible to the async
proxy.</p></li>
</ul>
</li>
<li><p>Issue the asynchronous matrix multiply and accumulate operations using the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
operation on the input matrices. The <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation is performed in the async
proxy.</p></li>
<li><p>Create a wgmma-group and commit all the prior outstanding <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations into the
group, by using <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> operation.</p></li>
<li><p>Wait for the completion of the required wgmma-group.</p></li>
<li><p>Once the wgmma-group completes, all the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations have been performed and
completed.</p></li>
</ol>
<section id="asynchronous-warpgroup-level-matrix-instructions-warpgroup">
<span id="id398"></span><h4>
<span class="section-number">9.7.15.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-warpgroup">Warpgroup</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-warpgroup" title="Permalink to this headline">ïƒ</a>
</h4>
<p>A warpgroup is a set of four contiguous warps such that the <em>warp-rank</em> of the first warp is a
multiple of 4.</p>
<p>warp-rank of a warp is defined as:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>(%tid.x + %tid.y * %ntid.x  + %tid.z * %ntid.x * %ntid.y) / 32
</pre></div>
</div>
</section>
<section id="asynchronous-warpgroup-level-matrix-shape">
<span id="id399"></span><h4>
<span class="section-number">9.7.15.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape">Matrix Shape</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-shape" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The matrix multiply and accumulate operations support a limited set of shapes for the operand
matrices A, B and D. The shapes of all three matrix operands are collectively described by the tuple
<code class="docutils literal notranslate"><span class="pre">MxNxK</span></code>, where A is an <code class="docutils literal notranslate"><span class="pre">MxK</span></code> matrix, B is a <code class="docutils literal notranslate"><span class="pre">KxN</span></code> matrix, while D is a <code class="docutils literal notranslate"><span class="pre">MxN</span></code> matrix.</p>
<p>The following matrix shapes are supported for the specified types for the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
operation:</p>
<table class="table-no-stripes longtable docutils align-default">
<colgroup>
<col style="width: 22%">
<col style="width: 9%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Multiplicand Data type</p></th>
<th class="head"><p>Sparsity</p></th>
<th class="head"><p>Shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Floating-point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.m64n8k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n40k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n48k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n56k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n64k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n72k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n88k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n104k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n120k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n128k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n136k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n144k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n152k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n168k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n184k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n200k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n208k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n216k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n224k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n232k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n248k16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k16</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Alternate floating-point
format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating-point
format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>Sparse</p></td>
</tr>
<tr class="row-odd">
<td><p>Alternate floating-point
format - <code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m64n8k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n40k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n48k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n56k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n64k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n72k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n88k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n104k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n120k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n128k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n136k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n144k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n152k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n168k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n184k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n200k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n208k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n216k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n224k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n232k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n248k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k8</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating-point
format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p>Dense</p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.m64n8k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n40k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n48k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n56k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n64k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n72k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n88k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n104k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n120k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n128k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n136k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n144k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n152k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n168k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n184k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n200k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n208k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n216k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n224k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n232k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n248k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Floating point - <code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>Sparse</p></td>
</tr>
<tr class="row-even">
<td><p>Altername floating-point
format - <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m64n8k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n48k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n64k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n128k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n144k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n208k32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n224k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating-point
format - <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p>Sparse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m64n8k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n40k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n48k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n56k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n64k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n72k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n88k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n104k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n120k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n128k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n136k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n144k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n152k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n168k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n184k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n200k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n208k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n216k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n224k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n232k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n248k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k64</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Integer - <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p>Sparse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m64n8k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n48k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n64k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n128k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n144k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n192k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n208k64</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n224k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n256k64</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Single-bit - <code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.m64n8k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n16k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n24k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n32k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n48k256</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n64k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n80k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n96k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n112k256</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n128k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n144k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n160k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n176k256</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n192k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n208k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n224k256</span></code>, <code class="docutils literal notranslate"><span class="pre">.m64n240k256</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m64n256k256</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="asynchronous-warpgroup-level-matrix-data-types">
<span id="id400"></span><h4>
<span class="section-number">9.7.15.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-data-types">Matrix Data-types</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-data-types" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The matrix multiply and accumulate operation is supported separately on integer, floating-point,
sub-byte integer and single bit data-types. All operands must contain the same basic type kind,
i.e., integer or floating-point.</p>
<p>For floating-point matrix multiply and accumulate operation, different matrix operands may have
different precision, as described later.</p>
<p>For integer matrix multiply and accumulate operation, both multiplicand matrices (A and B) must have
elements of the same data-type, e.g. both signed integer or both unsigned integer.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 34%">
<col style="width: 39%">
<col style="width: 27%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Data-type</p></th>
<th class="head"><p>Multiplicands (A or B)</p></th>
<th class="head"><p>Accumulator (D)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>Integer</p></td>
<td><p>both <code class="docutils literal notranslate"><span class="pre">.u8</span></code> or both <code class="docutils literal notranslate"><span class="pre">.s8</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Alternate floating Point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Single-bit integer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="asynchronous-warpgroup-level-matrix-async-proxy">
<span id="id401"></span><h4>
<span class="section-number">9.7.15.4. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-async-proxy">Async Proxy</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-async-proxy" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations are performed in the asynchronous proxy (or async proxy).</p>
<p>Accessing the same memory location across multiple proxies needs a cross-proxy fence. For the async
proxy, <code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> should be used to synchronize memory between generic proxy and the
async proxy.</p>
<p>The completion of a <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation is followed by an implicit generic-async proxy
fence. So the result of the asynchronous operation is made visible to the generic proxy as soon as
its completion is observed. <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> and <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> operations must be used
to wait for the completion of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instructions.</p>
</section>
<section id="asynchronous-warpgroup-level-matrix-operation-wgmma-mma-async">
<span id="id402"></span><h4>
<span class="section-number">9.7.15.5. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-operation-wgmma-mma-async">Asynchronous Warpgroup Level Matrix Multiply-Accumulate Operation using <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-operation-wgmma-mma-async" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warpgroup level <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction and the organization of
various matrices involved in this instruction.</p>
<section id="asynchronous-warpgroup-level-matrix-fragment">
<span id="id403"></span><h5>
<span class="section-number">9.7.15.5.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment">Register Fragments and Shared Memory Matrix Layouts</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-fragment" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The input matrix A of the warpgroup wide MMA operations can be either in registers or in the shared
memory. The input matrix B of the warpgroup wide MMA operations must be in the shared memory. This
section describes the layouts of register fragments and shared memory expected by the warpgroup MMA
instructions.</p>
<p>When the matrices are in shared memory, their starting addresses must be aligned to 16 bytes.</p>
<section id="asynchronous-warpgroup-level-matrix-register-fragment">
<span id="id404"></span><h6>
<span class="section-number">9.7.15.5.1.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment">Register Fragments</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-register-fragment" title="Permalink to this headline">ïƒ</a>
</h6>
<p>This section describes the organization of various matrices located in register operands of the
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction.</p>
<section id="asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n16">
<span id="id405"></span><h7><span class="section-number">9.7.15.5.1.1.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n16">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n16" title="Permalink to this headline">ïƒ</a></h7>
<p>A warpgroup executing <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk16</span></code> where N is a valid <code class="docutils literal notranslate"><span class="pre">n</span></code> dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A in registers:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 57%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> registers, with each
register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/ <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements from matrix A.</p></td>
<td><p>a0, a1, a2, a3, a4, a5, a6, a7</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n16-a"><span class="std std-numref">Figure 148</span></a>.</p>
<figure class="align-center" id="wgmma-64n16-a">
<img alt="_images/wgmma-64N16-A.png" class="image" src="_images/wgmma-64N16-A.png">
<figcaption>
<p><span class="caption-number">Figure 148 </span><span class="caption-text">WGMMA .m64nNk16 register fragment layout for matrix A.</span><a class="headerlink" href="#wgmma-64n16-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Accumulator D:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 48%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing N/4 number of <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>
registers, with each register containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code>
elements from matrix D.</p></td>
<td rowspan="2">
<p>d0, d1, d2, d3, â€¦, dX, dY, dZ, dW</p>
<p>where
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">4</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">3</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Z</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">2</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">8*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">32}</span></code></p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing N/2 number of <code class="docutils literal notranslate"><span class="pre">.f32</span></code>
registers.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n16-d"><span class="std std-numref">Figure 149</span></a>.</p>
<figure class="align-center" id="wgmma-64n16-d">
<img alt="_images/wgmma-64N16-D.png" class="image" src="_images/wgmma-64N16-D.png">
<figcaption>
<p><span class="caption-number">Figure 149 </span><span class="caption-text">WGMMA .m64nNk16 register fragment layout for accumulator matrix D.</span><a class="headerlink" href="#wgmma-64n16-d" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</section>
<section id="asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n8">
<span id="id406"></span><h7><span class="section-number">9.7.15.5.1.1.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n8">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk8</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n8" title="Permalink to this headline">ïƒ</a></h7>
<p>A warpgroup executing <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk8</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk8</span></code> where N is a valid <code class="docutils literal notranslate"><span class="pre">n</span></code> dimension as listed in <a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A in registers:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 66%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers containing
four <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> elements from matrix A.</p></td>
<td><p>a0, a1, a2, a3</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n8-a"><span class="std std-numref">Figure 150</span></a>.</p>
<figure class="align-center" id="wgmma-64n8-a">
<img alt="_images/wgmma-64N8-A.png" class="image" src="_images/wgmma-64N8-A.png">
<figcaption>
<p><span class="caption-number">Figure 150 </span><span class="caption-text">WGMMA .m64nNk8 register fragment layout for matrix A.</span><a class="headerlink" href="#wgmma-64n8-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Accumulator D:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 55%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing N/2 number of <code class="docutils literal notranslate"><span class="pre">.f32</span></code> registers.</p></td>
<td>
<p>d0, d1, d2, d3, â€¦, dX, dY, dZ, dW</p>
<p>where
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">4</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">3</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Z</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">2</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">8*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">32}</span></code></p>
</td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n8-d"><span class="std std-numref">Figure 151</span></a>.</p>
<figure class="align-center" id="wgmma-64n8-d">
<img alt="_images/wgmma-64N8-D.png" class="image" src="_images/wgmma-64N8-D.png">
<figcaption>
<p><span class="caption-number">Figure 151 </span><span class="caption-text">WGMMA .m64nNk8 register fragment layout for accumulator matrix D.</span><a class="headerlink" href="#wgmma-64n8-d" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</section>
<section id="asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32">
<span id="id407"></span><h7><span class="section-number">9.7.15.5.1.1.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32" title="Permalink to this headline">ïƒ</a></h7>
<p>A warpgroup executing <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk32</span></code> where N is a valid <code class="docutils literal notranslate"><span class="pre">n</span></code> dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A in registers:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 55%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code>/<code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/ <code class="docutils literal notranslate"><span class="pre">.s8</span></code> elements from matrix A.</p></td>
<td rowspan="2"><p>a0, a1, a2, a3, â€¦ , a14, a15</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing four <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> elements from
matrix A.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n32-a"><span class="std std-numref">Figure 152</span></a>.</p>
<figure class="align-center" id="wgmma-64n32-a">
<img alt="_images/wgmma-64N32-A.png" class="image" src="_images/wgmma-64N32-A.png">
<figcaption>
<p><span class="caption-number">Figure 152 </span><span class="caption-text">WGMMA .m64nNk32 register fragment layout for matrix A.</span><a class="headerlink" href="#wgmma-64n32-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Accumulator D:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 30%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
<th class="head"><p>Miscellaneous Information</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing
N/2 number of <code class="docutils literal notranslate"><span class="pre">.s32</span></code>
registers.</p></td>
<td rowspan="3">
<p>d0, d1, d2, d3, â€¦, dX, dY, dZ, dW</p>
<p>where
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">4</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">3</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Z</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">2</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code> depends on .dtype, as
described in the next column.</p>
</td>
<td>
<p><code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">8*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4}</span></code></p>
<blockquote>
<div>
<p><code class="docutils literal notranslate"><span class="pre">=</span> <span class="pre">16*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{3,</span> <span class="pre">4,</span> <span class="pre">...,</span> <span class="pre">15,</span> <span class="pre">16}</span></code></p>
</div>
</blockquote>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p>A vector expression containing
N/2 number of <code class="docutils literal notranslate"><span class="pre">.f32</span></code>
registers.</p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">8*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">32}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p>A vector expression containing
N/4 number of <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>
registers, with each register
containing two <code class="docutils literal notranslate"><span class="pre">.f16</span></code>
elements from matrix D.</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n32-d"><span class="std std-numref">Figure 153</span></a>.</p>
<figure class="align-center" id="wgmma-64n32-d">
<img alt="_images/wgmma-64N32-D.png" class="image" src="_images/wgmma-64N32-D.png">
<figcaption>
<p><span class="caption-number">Figure 153 </span><span class="caption-text">WGMMA .m64nNk32 register fragment layout for accumulator matrix D.</span><a class="headerlink" href="#wgmma-64n32-d" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</section>
<section id="asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n256">
<span id="id408"></span><h7><span class="section-number">9.7.15.5.1.1.4. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n256">Matrix Fragments for <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk256</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n256" title="Permalink to this headline">ïƒ</a></h7>
<p>A warpgroup executing <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk256</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk256</span></code> where N is a valid <code class="docutils literal notranslate"><span class="pre">n</span></code> dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li>
<p>Multiplicand A in registers:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 67%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.b1</span></code></p></td>
<td><p>A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers, with each
register containing thirty two <code class="docutils literal notranslate"><span class="pre">.b1</span></code> element from matrix A.</p></td>
<td><p>a0, a1, a2, â€¦, a127</p></td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n256-a"><span class="std std-numref">Figure 154</span></a>.</p>
<figure class="align-center" id="wgmma-64n256-a">
<img alt="_images/wgmma-64N256-A.png" class="image" src="_images/wgmma-64N256-A.png">
<figcaption>
<p><span class="caption-number">Figure 154 </span><span class="caption-text">WGMMA .m64nNk256 register fragment layout for matrix A.</span><a class="headerlink" href="#wgmma-64n256-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Accumulator D:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 10%">
<col style="width: 50%">
<col style="width: 41%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.dtype</p></th>
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td><p>A vector expression containing N/2 number of <code class="docutils literal notranslate"><span class="pre">.s32</span></code> registers.</p></td>
<td>
<p>d0, d1, d2, d3, â€¦, dX, dY, dZ, dW</p>
<p>where
<code class="docutils literal notranslate"><span class="pre">X</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">4</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Y</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">3</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">Z</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">2</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">W</span> <span class="pre">=</span> <span class="pre">N/2</span>Â  <span class="pre">-</span>Â  <span class="pre">1</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">=</span> <span class="pre">8*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4}</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">=</span> <span class="pre">16*i</span> <span class="pre">where</span> <span class="pre">i</span> <span class="pre">=</span> <span class="pre">{3,</span> <span class="pre">4,</span> <span class="pre">...,</span> <span class="pre">15,</span> <span class="pre">16}</span></code></p>
</td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#wgmma-64n256-d"><span class="std std-numref">Figure 155</span></a>.</p>
<figure class="align-center" id="wgmma-64n256-d">
<img alt="_images/wgmma-64N256-D.png" class="image" src="_images/wgmma-64N256-D.png">
<figcaption>
<p><span class="caption-number">Figure 155 </span><span class="caption-text">WGMMA .m64nNk256 register fragment layout for accumulator matrix D.</span><a class="headerlink" href="#wgmma-64n256-d" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-shared-memory-layout">
<span id="id409"></span><h6>
<span class="section-number">9.7.15.5.1.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout">Shared Memory Matrix Layout</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout" title="Permalink to this headline">ïƒ</a>
</h6>
<p>If the argument <code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> / <code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> of the instruction <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async{.sp}</span></code>
is 0, then <em>K-major</em> is used for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> / <code class="docutils literal notranslate"><span class="pre">B</span></code> respectively. If the value of argument
<code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> is 1 then <em>M-major</em> is used for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>. If the value of the argument
<code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> is 1, then <em>N-major</em> is used for matrix <code class="docutils literal notranslate"><span class="pre">B</span></code>.</p>
<p>In a column-major default BLAS library such as cuBLAS, the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> with and
without transpose can be classified as either <em>K-Major</em> or <em>M-or-N-Major</em> as shown in the
following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 50%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"></th>
<th class="head"><p>Non-Transposed</p></th>
<th class="head"><p>Transposed</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A</p></td>
<td><p>K-major</p></td>
<td><p>M-major</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>K-major</p></td>
<td><p>N-major</p></td>
</tr>
</tbody>
</table>
<p>To avoid confusion with <code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code>, <code class="docutils literal notranslate"><span class="pre">row-major</span></code>, <code class="docutils literal notranslate"><span class="pre">col-major</span></code>, <code class="docutils literal notranslate"><span class="pre">transpose</span></code>, and
<code class="docutils literal notranslate"><span class="pre">non-transpose</span></code>, we will use <em>MN-Major</em> and <em>K-Major</em> throughout this section.</p>
<p>The matrices in the shared memory are made up of one or more â€œswizzle layout atomâ€.
The exact layout of these swizzle atoms depends on the swizzling mode, swizzle-atomicity,
and the leading dimension. The layout of the swizzle are shown in
<a class="reference internal" href="#asynchronous-warpgroup-level-swizzle-lead-dim"><span class="std std-numref">Table 38</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="asynchronous-warpgroup-level-swizzle-lead-dim">
<caption>
<span class="caption-number">Table 38 </span><span class="caption-text">Various combinations of swizzling mode, leading dimension and swizzle-atom layout</span><a class="headerlink" href="#asynchronous-warpgroup-level-swizzle-lead-dim" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 34%">
<col style="width: 31%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling mode</p></th>
<th class="head"><p>Leading Dimension
/ Major-ness</p></th>
<th class="head"><p>Swizzle atom layout
(128b element)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p>128B Swizzling Mode</p></td>
<td><p>M/N</p></td>
<td><p>8x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x8</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>64B Swizzling Mode</p></td>
<td><p>M/N</p></td>
<td><p>4x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x4</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>32B Swizzling Mode</p></td>
<td><p>M/N</p></td>
<td><p>2x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x2</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>None</p></td>
<td><p>M/N</p></td>
<td><p>1x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x1</p></td>
</tr>
</tbody>
</table>
<p>The above shapes are for elements of size 128 bits. For smaller elements sizes, the same
shapes would get multiplied along the leading dimension by a factor of <code class="docutils literal notranslate"><span class="pre">128/sizeof_bits(Element)</span></code>.
For example, 128B MN major swizzle atom would have a shape of <code class="docutils literal notranslate"><span class="pre">(8*(128/32))x8</span> <span class="pre">=</span> <span class="pre">32x8</span></code> for
<code class="docutils literal notranslate"><span class="pre">tf32</span></code> tensor core inputs.</p>
<p class="rubric">Examples</p>
<p>The following are some example layouts of <em>MxK</em> or <em>KxN</em> matrices with various swizzling modes,
and are in units of 128b elements as shown
by each colored cell as shown in
<a class="reference internal" href="#async-warpgroup-smem-layout-128b-mn"><span class="std std-numref">Figure 156</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-128b-k"><span class="std std-numref">Figure 157</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-64b-mn"><span class="std std-numref">Figure 158</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-64b-k"><span class="std std-numref">Figure 159</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-32b-mn"><span class="std std-numref">Figure 160</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-32b-k"><span class="std std-numref">Figure 161</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-mn-interleaved"><span class="std std-numref">Figure 162</span></a>,
<a class="reference internal" href="#async-warpgroup-smem-layout-k-interleaved"><span class="std std-numref">Figure 163</span></a>.</p>
<figure class="align-center" id="async-warpgroup-smem-layout-128b-mn">
<img alt="_images/async-warpgroup-smem-layout-128B-mn.png" class="image" src="_images/async-warpgroup-smem-layout-128B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 156 </span><span class="caption-text">MN major 128B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-128b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-128b-k">
<img alt="_images/async-warpgroup-smem-layout-128B-k.png" class="image" src="_images/async-warpgroup-smem-layout-128B-k.png">
<figcaption>
<p><span class="caption-number">Figure 157 </span><span class="caption-text">K major 128B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-128b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-64b-mn">
<img alt="_images/async-warpgroup-smem-layout-64B-mn.png" class="image" src="_images/async-warpgroup-smem-layout-64B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 158 </span><span class="caption-text">MN major 64B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-64b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-64b-k">
<img alt="_images/async-warpgroup-smem-layout-64B-k.png" class="image" src="_images/async-warpgroup-smem-layout-64B-k.png">
<figcaption>
<p><span class="caption-number">Figure 159 </span><span class="caption-text">K major 64B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-64b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-32b-mn">
<img alt="_images/async-warpgroup-smem-layout-32B-mn.png" class="image" src="_images/async-warpgroup-smem-layout-32B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 160 </span><span class="caption-text">MN major 32B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-32b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-32b-k">
<img alt="_images/async-warpgroup-smem-layout-32B-k.png" class="image" src="_images/async-warpgroup-smem-layout-32B-k.png">
<figcaption>
<p><span class="caption-number">Figure 161 </span><span class="caption-text">K major 32B swizzling</span><a class="headerlink" href="#async-warpgroup-smem-layout-32b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-mn-interleaved">
<img alt="_images/async-warpgroup-smem-layout-mn-interleaved.png" class="image" src="_images/async-warpgroup-smem-layout-mn-interleaved.png">
<figcaption>
<p><span class="caption-number">Figure 162 </span><span class="caption-text">MN major interleaved</span><a class="headerlink" href="#async-warpgroup-smem-layout-mn-interleaved" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="async-warpgroup-smem-layout-k-interleaved">
<img alt="_images/async-warpgroup-smem-layout-k-interleaved.png" class="image" src="_images/async-warpgroup-smem-layout-k-interleaved.png">
<figcaption>
<p><span class="caption-number">Figure 163 </span><span class="caption-text">K major interleaved</span><a class="headerlink" href="#async-warpgroup-smem-layout-k-interleaved" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Following are some of the examples of the 128B swizzling layout for <code class="docutils literal notranslate"><span class="pre">tf32</span></code> element type.</p>
<ul>
<li>
<p>K-Major: <a class="reference internal" href="#async-warpgroup-smem-layout-128b-k-tf32"><span class="std std-numref">Figure 164</span></a></p>
<blockquote>
<div>
<figure class="align-center" id="async-warpgroup-smem-layout-128b-k-tf32">
<img alt="_images/async-warpgroup-smem-layout-128B-k-tf32.png" class="image" src="_images/async-warpgroup-smem-layout-128B-k-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 164 </span><span class="caption-text">K major</span><a class="headerlink" href="#async-warpgroup-smem-layout-128b-k-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
<li>
<p>MN-Major: <a class="reference internal" href="#async-warpgroup-smem-layout-128b-mn-tf32"><span class="std std-numref">Figure 165</span></a></p>
<blockquote>
<div>
<figure class="align-center" id="async-warpgroup-smem-layout-128b-mn-tf32">
<img alt="_images/async-warpgroup-smem-layout-128B-mn-tf32.png" class="image" src="_images/async-warpgroup-smem-layout-128B-mn-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 165 </span><span class="caption-text">MN major</span><a class="headerlink" href="#async-warpgroup-smem-layout-128b-mn-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
<section id="asynchronous-warpgroup-level-majorness-supported-by-strides">
<span id="id410"></span><h7><span class="section-number">9.7.15.5.1.2.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-majorness-supported-by-strides">Major-ness supported by Strides</a><a class="headerlink" href="#asynchronous-warpgroup-level-majorness-supported-by-strides" title="Permalink to this headline">ïƒ</a></h7>
<p>There are two strides involved while accessing a matrix from shared memory:</p>
<ol class="arabic simple">
<li><p>Leading dimension byte offset</p></li>
<li><p>Stride dimension byte offset</p></li>
</ol>
<section id="asynchronous-warpgroup-level-leading-dimension-byte-offset">
<span id="id411"></span><h8><span class="section-number">9.7.15.5.1.2.1.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-leading-dimension-byte-offset">Leading Dimension Byte Offset</a><a class="headerlink" href="#asynchronous-warpgroup-level-leading-dimension-byte-offset" title="Permalink to this headline">ïƒ</a></h8>
<p>The leading dimension byte offset is defined differently for transposed and non-transposed
matrices. The leading byte offset is defined as follows for matrices whose element types are
normalized to 128-bits:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-ness</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>K-Major</p></td>
<td>
<ul class="simple">
<li><p>No-Swizzling: the offset from the first column to the second columns
of the 8x2 tile in the 128-bit element type normalized matrix.</p></li>
<li><p>Swizzled layouts: not used, assumed to be 1.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd">
<td><p>MN-Major</p></td>
<td>
<ul class="simple">
<li><p>Interleave: offset from the first 8 columns to the next 8 columns.</p></li>
<li><p>Swizzled layouts: offset from the first (swizzle-byte-size/16) rows
to the next (swizzle-byte-size/16) rows.</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</section>
<section id="asynchronous-warpgroup-level-stride-dimension-byte-offset">
<span id="id412"></span><h8><span class="section-number">9.7.15.5.1.2.1.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-stride-dimension-byte-offset">Stride Dimension Byte Offset</a><a class="headerlink" href="#asynchronous-warpgroup-level-stride-dimension-byte-offset" title="Permalink to this headline">ïƒ</a></h8>
<p>The stride dimension byte offset is defined differently for transposed and non-transposed
matrices. The stride dimension byte offset is defined as follows for matrices whose element
types are normalized to 128-bits:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-ness</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>K-Major</p></td>
<td><p>The offset from the first 8 rows to the next 8 rows.</p></td>
</tr>
<tr class="row-odd">
<td><p>MN-Major</p></td>
<td>
<ul class="simple">
<li><p>Interleave: offset from the first row to the next row.</p></li>
<li><p>Swizzled layout: offset from the first 8 columns to the next 8
columns</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</section>
<section id="asynchronous-warpgroup-level-canonical-layouts">
<span id="id413"></span><h8><span class="section-number">9.7.15.5.1.2.1.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-canonical-layouts">Canonical Layouts</a><a class="headerlink" href="#asynchronous-warpgroup-level-canonical-layouts" title="Permalink to this headline">ïƒ</a></h8>
<p>In terms of <a class="reference external" href="https://docs.nvidia.com/cutlass/media/docs/cpp/cute/01_layout.html">CuTe layouts</a>
the canonical layout can be expressed as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 4%">
<col style="width: 9%">
<col style="width: 21%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-
ness</p></th>
<th class="head"><p>Swizzling mode</p></th>
<th class="head"><p>Canonical Layout without swizzling</p></th>
<th class="head"><p><a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/bf9da7b76c766d7ee7d536afc77880a4ef1f1156/include/cute/swizzle.hpp">Swizzling</a>
on the previous column</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="4"><p>MN-
major</p></td>
<td><p>No-swizzling or
Interleaved</p></td>
<td><p>((T,1,m),(8,k)):((1,T,SBO),(1T,LBO))</p></td>
<td><p>Swizzle&lt;0, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>32B Swizzling</p></td>
<td><p>((T,2,m),(8,k)):((1,T,LBO),(2T,SBO))</p></td>
<td><p>Swizzle&lt;1, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td><p>64B Swizzling</p></td>
<td><p>((T,4,m),(8,k)):((1,T,LBO),(4T,SBO))</p></td>
<td><p>Swizzle&lt;2, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>128B Swizzling</p></td>
<td><p>((T,8,m),(8,k)):((1,T,LBO),(8T,SBO))</p></td>
<td><p>Swizzle&lt;3, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p>K-
major</p></td>
<td><p>No-swizzling or
Interleaved</p></td>
<td><p>((8,m),(T,2k)):((1T,SBO),(1,LBO))</p></td>
<td><p>Swizzle&lt;0, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>32B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((2T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;1, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td><p>64B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((4T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;2, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>128B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((8T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;3, 4, 3&gt;</p></td>
</tr>
</tbody>
</table>
<p>where</p>
<ul class="simple">
<li><p>T = 128 / sizeof-elements-in-bits
T represents scale factor which normalizes matrix element types to 128-bits.</p></li>
<li><p>m represents the number of repeating patterns across rows.</p></li>
<li><p>k represents the number of repeating patterns across columns.</p></li>
</ul>
<p class="rubric">Examples</p>
<ul>
<li>
<p>K-Major, no-swizzling and tf32 type: <a class="reference internal" href="#async-warpgroup-k-no-swizzle-tf32"><span class="std std-numref">Figure 166</span></a></p>
<figure class="align-center" id="async-warpgroup-k-no-swizzle-tf32">
<img alt="_images/async-warpgroup-k-no-swizzle-tf32.png" class="image" src="_images/async-warpgroup-k-no-swizzle-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 166 </span><span class="caption-text">K major, no-swizzling and tf32 type</span><a class="headerlink" href="#async-warpgroup-k-no-swizzle-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;0,4,3&gt; o ((8,2),(4,4)):((4,32),(1,64))</p>
<p>Canonical Layout :Swizzle&lt;0,4,3&gt; o ((8,m),(T,2k)):((1T,SBO),(1,LBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO</p></td>
<td><p>64*sizeof(tf32)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>32*sizeof(tf32)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 8</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>K-Major, 32B swizzling and tf32 type: <a class="reference internal" href="#async-warpgroup-k-32b-swizzle-tf32"><span class="std std-numref">Figure 167</span></a></p>
<figure class="align-center" id="async-warpgroup-k-32b-swizzle-tf32">
<img alt="_images/async-warpgroup-k-32B-swizzle-tf32.png" class="image" src="_images/async-warpgroup-k-32B-swizzle-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 167 </span><span class="caption-text">K major, 32B swizzling and tf32 type</span><a class="headerlink" href="#async-warpgroup-k-32b-swizzle-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;1,4,3&gt; o ((8,2),(4,4)):((8,64),(1,4))</p>
<p>Canonical Layout :Swizzle&lt;1,4,3&gt; o ((8,m),(T,2k)):((2T,SBO),(1,T))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO</p></td>
<td><p>NA</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>64*sizeof(tf32)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>1 (assumed)</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 16</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, no-swizzling and bf16 type: <a class="reference internal" href="#async-warpgroup-mn-no-swizzle-bf16"><span class="std std-numref">Figure 168</span></a></p>
<figure class="align-center" id="async-warpgroup-mn-no-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-no-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-no-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 168 </span><span class="caption-text">MN major, no-swizzling and bf16 type</span><a class="headerlink" href="#async-warpgroup-mn-no-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;0,4,3&gt; o ((8,1,2),(8,2)):((1,8,64),(8,128))</p>
<p>Canonical Layout :Swizzle&lt;0,4,3&gt; o ((T,1,m),(8,k)):((1,T,SBO),(1T,LBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO</p></td>
<td><p>128*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>64*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 8</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, 32B swizzling and bf16 type: <a class="reference internal" href="#async-warpgroup-mn-32b-swizzle-bf16"><span class="std std-numref">Figure 169</span></a></p>
<figure class="align-center" id="async-warpgroup-mn-32b-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-32B-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-32B-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 169 </span><span class="caption-text">MN major, 32B swizzling and bf16 type</span><a class="headerlink" href="#async-warpgroup-mn-32b-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;1,4,3&gt; o ((8,2,2),(8,2)):((1,8,128),(16,256))</p>
<p>Canonical Layout :Swizzle&lt;1,4,3&gt; o ((T,2,m),(8,k)):((1,T,LBO),(2T,SBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO</p></td>
<td><p>128*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>256*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 32</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, 64B swizzling and bf16 type: <a class="reference internal" href="#async-warpgroup-mn-64b-swizzle-bf16"><span class="std std-numref">Figure 170</span></a></p>
<figure class="align-center" id="async-warpgroup-mn-64b-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-64B-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-64B-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 170 </span><span class="caption-text">MN major, 64B swizzling and bf16 type</span><a class="headerlink" href="#async-warpgroup-mn-64b-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;2,4,3&gt; o ((8,4,2),(8,2)):((1,8,256),(32,512))</p>
<p>Canonical Layout :Swizzle&lt;2,4,3&gt; o ((T,4,m),(8,k)):((1,T,LBO),(4T,SBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO</p></td>
<td><p>256*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>512*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 64</p></td>
</tr>
</tbody>
</table>
</li>
</ul>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor">
<span id="id414"></span><h7><span class="section-number">9.7.15.5.1.2.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor">Matrix Descriptor Format</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor" title="Permalink to this headline">ïƒ</a></h7>
<p>Matrix descriptor specifies the properties of the matrix in shared memory that is a multiplicand in
the matrix multiply and accumulate operation. It is a 64-bit value contained in a register with the
following layout:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 9%">
<col style="width: 11%">
<col style="width: 80%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Bit-field</p></th>
<th class="head"><p>Size in bits</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>13â€“0</p></td>
<td><p>14</p></td>
<td><p>matrix-descriptor-encode(Matrix start address)</p></td>
</tr>
<tr class="row-odd">
<td><p>29â€“16</p></td>
<td><p>14</p></td>
<td><p>matrix-descriptor-encode
(<a class="reference internal" href="#asynchronous-warpgroup-level-leading-dimension-byte-offset"><span class="std std-ref">Leading dimension byte offset</span></a>)</p></td>
</tr>
<tr class="row-even">
<td><p>45â€“32</p></td>
<td><p>14</p></td>
<td><p>matrix-descriptor-encode
(<a class="reference internal" href="#asynchronous-warpgroup-level-stride-dimension-byte-offset"><span class="std std-ref">Stride dimension byte offset</span></a>)</p></td>
</tr>
<tr class="row-odd">
<td><p>51â€“49</p></td>
<td><p>3</p></td>
<td><p>Matrix base offset. This is valid for all swizzling modes except the no-swizzle mode.</p></td>
</tr>
<tr class="row-even">
<td><p>63â€“62</p></td>
<td><p>2</p></td>
<td>
<p>Specifies the swizzling mode to be used:</p>
<ul class="simple">
<li><p>0: No swizzle</p></li>
<li><p>1: 128-Byte swizzle</p></li>
<li><p>2: 64-Byte swizzle</p></li>
<li><p>3: 32-Byte swizzle</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>where</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>matrix-descriptor-encode(x) = (x &amp; 0x3FFFF) &gt;&gt; 4
</pre></div>
</div>
<p>The value of base offset is 0 when the repeating pattern of the specified swizzling mode starts as
per the below table:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 30%">
<col style="width: 70%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling mode</p></th>
<th class="head"><p>Starting address of the repeating pattern</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>128-Byte swizzle</p></td>
<td><p>1024-Byte boundary</p></td>
</tr>
<tr class="row-odd">
<td><p>64-Byte swizzle</p></td>
<td><p>512-Byte boundary</p></td>
</tr>
<tr class="row-even">
<td><p>32-Byte swizzle</p></td>
<td><p>256-Byte boundary</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p>Otherwise, the base offset must be a non-zero value, computed using the following formula:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>base offset = (pattern start addr &gt;&gt; 0x7) &amp; 0x7
</pre></div>
</div>
</section>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions-wgmma-mma">
<span id="id415"></span><h5>
<span class="section-number">9.7.15.5.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma">Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code></p>
<p>Perform matrix multiply-and-accumulate operation across warpgroup</p>
<p class="rubric">Syntax</p>
<p>Half precision floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.mma_async.sync.aligned.shape.dtype.f16.f16  d, a-desc, b-desc, scale-d, imm-scale-a, imm-scale-b, imm-trans-a, imm-trans-b;

wgmma.mma_async.sync.aligned.shape.dtype.f16.f16  d, a, b-desc, scale-d, imm-scale-a, imm-scale-b, imm-trans-b;

.shape   = {.m64n8k16, .m64n16k16, .m64n24k16, .m64n32k16,
            .m64n40k16, .m64n48k16, .m64n56k16, .m64n64k16,
            .m64n72k16, .m64n80k16, .m64n88k16, .m64n96k16,
            .m64n104k16, .m64n112k16, .m64n120k16, .m64n128k16,
            .m64n136k16, .m64n144k16, .m64n152k16, .m64n160k16,
            .m64n168k16, .m64n176k16, .m64n184k16, .m64n192k16,
            .m64n200k16, .m64n208k16, .m64n216k16, .m64n224k16,
            .m64n232k16, .m64n240k16, .m64n248k16, .m64n256k16};
.dtype   = {.f16, .f32};
</pre></div>
</div>
<p>Alternate floating point type :</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.bf16 floating point type:

wgmma.mma_async.sync.aligned.shape.dtype.bf16.bf16  d, a-desc, b-desc, scale-d, imm-scale-a, imm-scale-b, imm-trans-a, imm-trans-b;

wgmma.mma_async.sync.aligned.shape.dtype.bf16.bf16  d, a, b-desc, scale-d, imm-scale-a, imm-scale-b, imm-trans-b;

.shape   = {.m64n8k16, .m64n16k16, .m64n24k16, .m64n32k16,
            .m64n40k16, .m64n48k16, .m64n56k16, .m64n64k16,
            .m64n72k16, .m64n80k16, .m64n88k16, .m64n96k16,
            .m64n104k16, .m64n112k16, .m64n120k16, .m64n128k16,
            .m64n136k16, .m64n144k16, .m64n152k16, .m64n160k16,
            .m64n168k16, .m64n176k16, .m64n184k16, .m64n192k16,
            .m64n200k16, .m64n208k16, .m64n216k16, .m64n224k16,
            .m64n232k16, .m64n240k16, .m64n248k16, .m64n256k16};
.dtype  = {.f32};

.tf32 floating point type:

wgmma.mma_async.sync.aligned.shape.dtype.tf32.tf32  d, a-desc, b-desc, scale-d, imm-scale-a, imm-scale-b;

wgmma.mma_async.sync.aligned.shape.dtype.tf32.tf32  d, a, b-desc, scale-d, imm-scale-a, imm-scale-b;

.shape   = {.m64n8k8, .m64n16k8, .m64n24k8, .m64n32k8,
            .m64n40k8, .m64n48k8, .m64n56k8, .m64n64k8,
            .m64n72k8, .m64n80k8, .m64n88k8, .m64n96k8,
            .m64n104k8, .m64n112k8, .m64n120k8, .m64n128k8,
            .m64n136k8, .m64n144k8, .m64n152k8, .m64n160k8,
            .m64n168k8, .m64n176k8, .m64n184k8, .m64n192k8,
            .m64n200k8, .m64n208k8, .m64n216k8, .m64n224k8,
            .m64n232k8, .m64n240k8, .m64n248k8, .m64n256k8};
.dtype  = {.f32};

FP8 floating point type

wgmma.mma_async.sync.aligned.shape.dtype.atype.btype  d, a-desc, b-desc, scale-d, imm-scale-a, imm-scale-b;

wgmma.mma_async.sync.aligned.shape.dtype.atype.btype  d, a, b-desc, scale-d, imm-scale-a, imm-scale-b;

.shape   = {.m64n8k32, .m64n16k32, .m64n24k32, .m64n32k32,
            .m64n40k32, .m64n48k32, .m64n56k32, .m64n64k32,
            .m64n72k32, .m64n80k32, .m64n88k32, .m64n96k32,
            .m64n104k32, .m64n112k32, .m64n120k32, .m64n128k32,
            .m64n136k32, .m64n144k32, .m64n152k32, .m64n160k32,
            .m64n168k32, .m64n176k32, .m64n184k32, .m64n192k32,
            .m64n200k32, .m64n208k32, .m64n216k32, .m64n224k32,
            .m64n232k32, .m64n240k32, .m64n248k32, .m64n256k32};
.atype  = {.e4m3, .e5m2};
.btype  = {.e4m3, .e5m2};
.dtype  = {.f16, .f32};
</pre></div>
</div>
<p>Integer type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.mma_async.sync.aligned.shape{.satfinite}.s32.atype.btype  d, a-desc, b-desc, scale-d;

wgmma.mma_async.sync.aligned.shape{.satfinite}.s32.atype.btype  d, a, b-desc, scale-d;

.shape   = {.m64n8k32, .m64n16k32, .m64n24k32, .m64n32k32,
            .m64n48k32, .m64n64k32, .m64n80k32, .m64n96k32,
            .m64n112k32, .m64n128k32, .m64n144k32, .m64n160k32,
            .m64n176k32, .m64n192k32, .m64n208k32, .m64n224k32};
.atype  = {.s8, .u8};
.btype  = {.s8, .u8};
</pre></div>
</div>
<p>Single bit:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.mma_async.sync.aligned.shape.s32.b1.b1.op.popc  d, a-desc, b-desc, scale-d;

wgmma.mma_async.sync.aligned.shape.s32.b1.b1.op.popc  d, a, b-desc, scale-d;

.shape   = {.m64n8k256, .m64n16k256, .m64n24k256, .m64n32k256,
            .m64n48k256, .m64n64k256, .m64n80k256, .m64n96k256,
            .m64n112k256, .m64n128k256, .m64n144k256, .m64n160k256,
            .m64n176k256, .m64n192k256, .m64n208k256, .m64n224k256,
            .m64n240k256, .m64n256k256};
.op  = {.and};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> issues a <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> matrix multiply and accumulate operation, <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span>
<span class="pre">A*B+D</span></code>, where the A matrix is <code class="docutils literal notranslate"><span class="pre">MxK</span></code>, the B matrix is <code class="docutils literal notranslate"><span class="pre">KxN</span></code>, and the D matrix is <code class="docutils literal notranslate"><span class="pre">MxN</span></code>.</p>
<p>The operation of the form <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code> is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">scale-d</span></code> is
false.</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction must be used to fence the register accesses of <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction from their prior accesses. Otherwise, the behavior is undefined.</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> and <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> operations must be used to wait for the completion
of the asynchronous matrix multiply and accumulate operations before the results are accessed.</p>
<p>Register operand <code class="docutils literal notranslate"><span class="pre">d</span></code> represents the accumulator matrix as well as the destination matrix,
distributed across the participating threads. Register operand <code class="docutils literal notranslate"><span class="pre">a</span></code> represents the multiplicand
matrix A in register distributed across the participating threads. The 64-bit register operands
<code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which represent the multiplicand matrices A and
B in shared memory respectively. The contents of a matrix descriptor must be same across all the warps
in the warpgroup. The format of the matrix descriptor is described in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor"><span class="std std-ref">Matrix Descriptor Format</span></a>.</p>
<p>Matrices A and B are stored in row-major and column-major format respectively. For certain floating
point variants, the input matrices A and B can be transposed by specifying the value 1 for the
immediate integer arguments <code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> respectively. A value of 0 can be
used to avoid the transpose operation. The valid values of <code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> are 0
and 1. The transpose operation is only supported for the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> variants with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types on matrices accessed from shared memory using matrix descriptors.</p>
<p>For the floating point variants of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation, each element of the input
matrices A and B can be negated by specifying the value -1 for operands <code class="docutils literal notranslate"><span class="pre">imm-scale-a</span></code> and
<code class="docutils literal notranslate"><span class="pre">imm-scale-b</span></code> respectively. A value of 1 can be used to avoid the negate operation. The valid
values of <code class="docutils literal notranslate"><span class="pre">imm-scale-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-scale-b</span></code> are -1 and 1.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> indicate the data type of the elements in
matrices D, A and B respectively. <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> must be the same for all floating point
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> variants except for the FP8 floating point variants. The sizes of individual
data elements of matrices A and B in alternate floating point variants of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
operation are as follows:</p>
<ul class="simple">
<li><p>Matrices A and B have 8-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>.</p></li>
<li><p>Matrices A and B have 16-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>.</p></li>
<li><p>Matrices A and B have 32-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>.</p></li>
</ul>
<p>Precision and rounding:</p>
<ul>
<li>
<p>Floating point operations:</p>
<p>Element-wise multiplication of matrix A and B is performed with at least single precision. When
<code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, accumulation of the intermediate values is performed with at least single
precision. When <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, the accumulation is performed with at least half
precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point operations:</p>
<p>Element-wise multiplication of matrix A and B is performed with specified
precision. <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation involving type <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> will truncate lower 13 bits of
the 32-bit input data before multiplication is issued. Accumulation of the intermediate values is
performed with at least single precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p>Integer operations:</p>
<p>The integer <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation is performed with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> accumulators. The
<code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier indicates that on overflow, the accumulated value is limited to the
range <em>MIN_INT32</em>.. <em>MAX_INT32</em> (where the bounds are defined as the minimum negative signed
32-bit integer and the maximum positive signed 32-bit integer respectively).</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> is not specified, the accumulated value is wrapped instead.</p>
</li>
</ul>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction causes the
executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction should only be used if it is known that all threads in the warpgroup evaluate the
condition identically, otherwise behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.u8.s8</span></code> and <code class="docutils literal notranslate"><span class="pre">.s8.u8</span></code> as .atype.btype introduced in PTX ISA version 8.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
<p class="rubric">Examples of half precision floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f16x2 f16a&lt;40&gt;, f16d&lt;40&gt;;
.reg .f32   f32d&lt;40&gt;;
.reg .b64   descA, descB;
.reg .pred  scaleD;
wgmma.mma_async.sync.aligned.m64n8k16.f32.f16.f16
  {f32d0, f32d1, f32d2, f32d3},
  {f16a0, f16a1, f16a2, f16a3},
  descB,
  1, -1, -1, 1;

wgmma.mma_async.sync.aligned.m64n72k16.f16.f16.f16
  {f16d0, f16d1,  f16d2,  f16d3,  f16d4,  f16d5,  f16d6,  f16d7,  f16d8,
   f16d9, f16d10, f16d11, f16d12, f16d13, f16d14, f16d15, f16d16, f16d17},
  descA,
  descB,
  scaleD, -1, 1, 1, 0;
</pre></div>
</div>
<p class="rubric">Examples of alternate floating point type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .f32   f32d&lt;40&gt;;
.reg .b32   bf16a&lt;40&gt;
.reg .b64   descA, descB;

wgmma.mma_async.sync.aligned.m64n120k16.f32.bf16.bf16
  {f32d0, f32d1, f32d2, f32d3, f32d4, f32d5, f32d6, f32d7, f32d8, f32d9,
   f32d10, f32d11, f32d12, f32d13, f32d14, f32d15, f32d16, f32d17, f32d18, f32d19,
   f32d20, f32d21, f32d22, f32d23, f32d24, f32d25, f32d26, f32d27, f32d28, f32d29,
   f32d30, f32d31, f32d32, f32d33, f32d34, f32d35, f32d36, f32d37, f32d38, f32d39,
   f32d40, f32d41, f32d42, f32d43, f32d44, f32d45, f32d46, f32d47, f32d48, f32d49,
   f32d50, f32d51, f32d52, f32d53, f32d54, f32d55, f32d56, f32d57, f32d58, f32d59},
  {bf16a0, bf16a1, bf16a2, bf16a3},
  descB,
  scaleD, -1, -1, 0;

.reg .f32   f32d&lt;40&gt;;
.reg .b64   descA, descB;

wgmma.mma_async.sync.aligned.m64n16k8.f32.tf32.tf32
  {f32d0, f32d1, f32d2, f32d3, f32d4, f32d5, f32d6, f32d7},
  descA,
  descB,
  0, -1, -1;

.reg .b32 f16d&lt;8&gt;, f16a&lt;8&gt;;
.reg .f32 f32d&lt;8&gt;;
.reg .b64   descA, descB;

wgmma.mma_async.sync.aligned.m64n8k32.f16.e4m3.e5m2
  {f16d0, f16d1},
  descA,
  descB,
  scaleD, -1, 1;

wgmma.mma_async.sync.aligned.m64n8k32.f32.e5m2.e4m3
  {f32d0, f32d1, f32d2, f32d3},
  {f16a0, f16a1, f16a2, f16a3},
  descB,
  1, -1, -1;
</pre></div>
</div>
<p class="rubric">Examples of integer type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .s32 s32d&lt;8&gt;, s32a&lt;8&gt;;
.reg .u32 u32a&lt;8&gt;;
.reg .pred scaleD;
.reg .b64   descA, descB;

wgmma.mma_async.sync.aligned.m64n8k32.s32.s8.s8.satfinite
  {s32d0, s32d1, s32d2, s32d3},
  {s32a0, s32a1, s32a2, s32a3},
  descB,
  1;

wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.u8
  {s32d0, s32d1, s32d2, s32d3},
  descA,
  descB,
  scaleD;

wgmma.mma_async.sync.aligned.m64n8k32.s32.s8.u8.satfinite
  {s32d0, s32d1, s32d2, s32d3},
  {s32a0, s32a1, s32a2, s32a3},
  descB,
  scaleD;

wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.s8
  {s32d0, s32d1, s32d2, s32d3},
  descA,
  descB,
  scaleD;
</pre></div>
</div>
<p class="rubric">Examples of single bit type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .s32 s32d&lt;4&gt;;
.reg .b32 b32a&lt;4&gt;;
.reg .pred scaleD;
.reg .b64   descA, descB;


wgmma.mma_async.sync.aligned.m64n8k256.s32.b1.b1.and.popc
  {s32d0, s32d1, s32d2, s32d3},
  {b32a0, b32a1, b32a2, b32a3},
  descB,
  scaleD;
</pre></div>
</div>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions-for-sparse-wgmma">
<span id="id416"></span><h4>
<span class="section-number">9.7.15.6. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-for-sparse-wgmma">Asynchronous Warpgroup Level Multiply-and-Accumulate Operation using <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> instruction</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-for-sparse-wgmma" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warp-level <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> instruction with sparse matrix A. This
variant of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation can be used when A is a structured sparse matrix with
50% zeros in each row distributed in a shape-specific granularity. For an <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> sparse
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> operation, the <code class="docutils literal notranslate"><span class="pre">MxK</span></code> matrix A is packed into <code class="docutils literal notranslate"><span class="pre">MxK/2</span></code> elements. For each
K-wide row of matrix A, 50% elements are zeros and the remaining <code class="docutils literal notranslate"><span class="pre">K/2</span></code> non-zero elements are
packed in the operand representing matrix A. The mapping of these <code class="docutils literal notranslate"><span class="pre">K/2</span></code> elements to the
corresponding K-wide row is provided explicitly as metadata.</p>
<section id="asynchronous-warpgroup-level-sparse-matrix-storage">
<span id="id417"></span><h5>
<span class="section-number">9.7.15.6.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage">Sparse matrix storage</a><a class="headerlink" href="#asynchronous-warpgroup-level-sparse-matrix-storage" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Granularity of sparse matrix A is defined as the ratio of the number of non-zero elements in a
sub-chunk of the matrix row to the total number of elements in that sub-chunk where the size of the
sub-chunk is shape-specific. For example, in a <code class="docutils literal notranslate"><span class="pre">64x32</span></code> matrix A used in floating point
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations, sparsity is expected to be at 2:4 granularity, i.e. each 4-element
vector (i.e. a sub-chunk of 4 consecutive elements) of a matrix row contains 2 zeros. Index of each
non-zero element in a sub-chunk is stored in the metadata operand. Values <code class="docutils literal notranslate"><span class="pre">0b0000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b0101</span></code>,
<code class="docutils literal notranslate"><span class="pre">0b1010</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1111</span></code> are invalid values for metadata and will result in undefined behavior. In a
group of four consecutive threads, one or more threads store the metadata for the whole group
depending upon the matrix shape. These threads are specified using an additional sparsity selector operand.</p>
<p>Matrix A and its corresponding input operand to the sparse wgmma is similar to the diagram shown in
<a class="reference internal" href="#sparse-mma-storage-example"><span class="std std-numref">Figure 111</span></a>, with an appropriate matrix size.</p>
<p>Granularities for different matrix shapes and data types are described below.</p>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> with half-precision and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types, for all supported <code class="docutils literal notranslate"><span class="pre">64xNx32</span></code> shapes, matrix A is structured
sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements in a row of
matrix A have two zeroes and two non-zero elements. Only the two non-zero elements are stored in
matrix A and their positions in the four-wide chunk in Matrix A are indicated by two 2-bits indices
in the metadata operand.</p>
<figure class="align-center" id="f16-metadata-example-wgmma">
<img alt="_images/f16-metadata-example.png" class="image" src="_images/f16-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 171 </span><span class="caption-text">Sparse WGMMA metadata example for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#f16-metadata-example-wgmma" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates a thread-pair within a group of four consecutive threads which
contributes the sparsity metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or
1 (threads T2, T3); any other value results in an undefined behavior.</p>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type, for all supported <code class="docutils literal notranslate"><span class="pre">64xNx16</span></code> shapes, matrix A is structured sparse at a
granularity of 1:2. In other words, each chunk of two adjacent elements in a row of matrix A have
one zero and one non-zero element. Only the non-zero element is stored in operand for matrix A and
the 4-bit index in the metadata indicates the position of the non-zero element in the two-wide
chunk. 0b1110 and 0b0100 are the only meaningful values of the index, the remaining values result in
an undefined behavior.</p>
<figure class="align-center" id="tf32-metadata-example-wgmma">
<img alt="_images/tf32-metadata-example.png" class="image" src="_images/tf32-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 172 </span><span class="caption-text">Sparse WGMMA metadata example for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#tf32-metadata-example-wgmma" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The sparsity selector indicates a thread-pair within a group of four consecutive threads which
contributes the sparsity metadata. Hence, the sparsity selector must be either 0 (threads T0, T1) or
1 (threads T2, T3); any other value results in an undefined behavior.</p>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> floating point type</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> types, for all supported <code class="docutils literal notranslate"><span class="pre">64xNx64</span></code> shapes, matrix A is structured
sparse at a granularity of 2:4. In other words, each chunk of four adjacent elements in a row of
matrix A have two zeroes and two non-zero elements. Only the two non-zero elements are stored in
matrix A and their positions in the four-wide chunk in Matrix A are indicated by two 2-bits indices
in the metadata operand.</p>
<figure class="align-center" id="e4m3-e5m2-metadata-example-wgmma">
<img alt="_images/u8s8-metadata-example.png" class="image" src="_images/u8s8-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 173 </span><span class="caption-text">Sparse WGMMA metadata example for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> type.</span><a class="headerlink" href="#e4m3-e5m2-metadata-example-wgmma" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>All threads contribute the sparsity metadata and the sparsity selector must be 0; any other value
results in an undefined behavior.</p>
<p class="rubric">Sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code> with integer type</p>
<p>For the integer type, for all supported <code class="docutils literal notranslate"><span class="pre">64xNx64</span></code> shapes, matrix A is structured sparse at a
granularity of 2:4. In other words, each chunk of four adjacent elements in a row of matrix A have
two zeroes and two non-zero elements. Only the two non-zero elements are stored in matrix A and two
2-bit indices in the metadata indicate the position of these two non-zero elements in the four-wide
chunk.</p>
<figure class="align-center" id="u8s8-metadata-example-wgmma">
<img alt="_images/u8s8-metadata-example.png" class="image" src="_images/u8s8-metadata-example.png">
<figcaption>
<p><span class="caption-number">Figure 174 </span><span class="caption-text">Sparse WGMMA metadata example for <code class="docutils literal notranslate"><span class="pre">.u8</span></code>/<code class="docutils literal notranslate"><span class="pre">.s8</span></code> type.</span><a class="headerlink" href="#u8s8-metadata-example-wgmma" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>All threads contribute the sparsity metadata and the sparsity selector must be 0; any other value
results in an undefined behavior.</p>
</section>
<section id="asynchronous-warpgroup-level-matrix-fragments-for-sparse-wgmma">
<span id="id418"></span><h5>
<span class="section-number">9.7.15.6.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragments-for-sparse-wgmma">Matrix fragments for warpgroup-level multiply-accumulate operation with sparse matrix A</a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-fragments-for-sparse-wgmma" title="Permalink to this headline">ïƒ</a>
</h5>
<p>In this section we describe how the contents of thread registers are associated with fragments of A
matrix and the sparsity metadata.</p>
<p>Each warp in the warpgroup provides sparsity information for 16 rows of matrix A. The following
table shows the assignment of warps to rows of matrix A:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 32%">
<col style="width: 68%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Warp</p></th>
<th class="head"><p>Sparsity information for rows of matrix A</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code> % 4 = 3</p></td>
<td><p>48-63</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code> % 4 = 2</p></td>
<td><p>32-47</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code> % 4 = 1</p></td>
<td><p>16-31</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code> % 4 = 0</p></td>
<td><p>0-15</p></td>
</tr>
</tbody>
</table>
<p>The following conventions are used throughout this section:</p>
<ul class="simple">
<li><p>For matrix A, only the layout of a fragment is described in terms of register vector sizes and
their association with the matrix data.</p></li>
<li><p>For matrix D, since the matrix dimension - data type combination is the same for all supported
shapes, and is already covered in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-operation-wgmma-mma-async"><span class="std std-ref">Asynchronous Warpgroup Level Matrix Multiply-Accumulate Operation using wgmma.mma_async instruction</span></a>, the pictorial
representations of matrix fragments are not included in this section.</p></li>
<li><p>For the metadata operand, pictorial representations of the association between indices of the
elements of matrix A and the contents of the metadata operand are included. <code class="docutils literal notranslate"><span class="pre">Tk:</span> <span class="pre">[m..n]</span></code> present
in cell <code class="docutils literal notranslate"><span class="pre">[x][y..z]</span></code> indicates that bits <code class="docutils literal notranslate"><span class="pre">m</span></code> through <code class="docutils literal notranslate"><span class="pre">n</span></code> (with <code class="docutils literal notranslate"><span class="pre">m</span></code> being higher) in the
metadata operand of thread with <code class="docutils literal notranslate"><span class="pre">%laneid=k</span></code> contains the indices of the non-zero elements from
the chunk <code class="docutils literal notranslate"><span class="pre">[x][y]..[x][z]</span></code> of matrix A.</p></li>
</ul>
<section id="asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n32">
<span id="id419"></span><h6>
<span class="section-number">9.7.15.6.2.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n32">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n32" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warpgroup executing sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk32</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk32</span></code> where N is a valid n dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li><p>Multiplicand A, from shared memory is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout"><span class="std std-ref">Shared Memory Matrix Layout</span></a>.</p></li>
<li>
<p>Multiplicand A, from registers:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 51%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragments</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="line-block">
<div class="line">
<code class="docutils literal notranslate"><span class="pre">.f16</span></code> /</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">.bf16</span></code></div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code>
</div>
<div class="line">registers, with each register containing two</div>
<div class="line">non-zero <code class="docutils literal notranslate"><span class="pre">.f16</span></code> /<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> elements out of 4</div>
<div class="line">consecutive elements from matrix A.</div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">Non-zero elements:</div>
<div class="line">a0, a1, a2, a3, a4, a5, a6, a7</div>
</div>
<div class="line-block">
<div class="line">Mapping of the non-zero</div>
<div class="line">elements is as described in</div>
<div class="line"><a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-wgmma-64n32-f16-bf16-a"><span class="std std-numref">Figure 175</span></a>.</p>
<figure class="align-center" id="sparse-wgmma-64n32-f16-bf16-a">
<img alt="_images/sparse-wgmma-64N32-f16-bf16-A.png" class="image" src="_images/sparse-wgmma-64N32-f16-bf16-A.png">
<figcaption>
<p><span class="caption-number">Figure 175 </span><span class="caption-text">Sparse WGMMA .m64nNk32 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-wgmma-64n32-f16-bf16-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
<li>
<p>Accumulator D:</p>
<p>Matrix fragments for accumulator D are the same as in case of
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32"><span class="std std-ref">Matrix Fragments for wgmma.mma_async.m64nNk32</span></a>
for the same <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> format.</p>
</li>
<li>
<p>Multiplicand B:</p>
<p>Shared memory layout for Matrix B is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout"><span class="std std-ref">Shared Memory Matrix Layout</span></a>.</p>
</li>
<li>
<p>Metadata operand is a <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 2-bit vectors each storing the index of a
non-zero element of a 4-wide chunk of matrix A.</p>
<p><a class="reference internal" href="#sparse-wgmma-metadata-64n32-f16bf16"><span class="std std-numref">Figure 176</span></a> shows the mapping of the metadata bits to the elements
of matrix A for a warp. In this figure, variable <code class="docutils literal notranslate"><span class="pre">i</span></code> represents the value of the sparsity
selector operand.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-wgmma-metadata-64n32-f16bf16">
<img alt="_images/sparse-mma-metadata-16832-f16bf16.png" class="image" src="_images/sparse-mma-metadata-16832-f16bf16.png">
<figcaption>
<p><span class="caption-number">Figure 176 </span><span class="caption-text">Sparse WGMMA .m64nNk32 metadata layout for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> type.</span><a class="headerlink" href="#sparse-wgmma-metadata-64n32-f16bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n16">
<span id="id420"></span><h6>
<span class="section-number">9.7.15.6.2.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n16">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n16" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warpgroup executing sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk16</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk16</span></code> where N is a valid n dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li><p>Multiplicand A, from shared memory is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout"><span class="std std-ref">Shared Memory Matrix Layout</span></a>.</p></li>
<li>
<p>Multiplicand A, from registers:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 51%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragments</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code>
</div>
<div class="line">registers, containing four non-zero <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>
</div>
<div class="line">elements out of eight consecutive elements</div>
<div class="line">from matrix A.</div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">Non-zero elements:</div>
<div class="line">a0, a1, a2, a3</div>
<div class="line"><br></div>
<div class="line">Mapping of the non-zero</div>
<div class="line">elements is as described in</div>
<div class="line"><a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-wgmma-64n16-tf32-a"><span class="std std-numref">Figure 177</span></a>.</p>
<figure class="align-center" id="sparse-wgmma-64n16-tf32-a">
<img alt="_images/sparse-wgmma-64N16-tf32-A.png" class="image" src="_images/sparse-wgmma-64N16-tf32-A.png">
<figcaption>
<p><span class="caption-number">Figure 177 </span><span class="caption-text">Sparse WGMMA .m64nNk16 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-wgmma-64n16-tf32-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
<li>
<p>Accumulator D:</p>
<p>Matrix fragments for accumulator D are the same as in case of
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n8"><span class="std std-ref">Matrix Fragments for wgmma.mma_async.m64nNk8</span></a>
for the same <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> format.</p>
</li>
<li>
<p>Multiplicand B:</p>
<p>Shared memory layout for Matrix B is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout"><span class="std std-ref">Shared Memory Matrix Layout</span></a>.</p>
</li>
<li>
<p>Metadata operand is a <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing eight 4-bit vectors each storing the index of a
non-zero element of a 2-wide chunk of matrix A.</p>
<p><a class="reference internal" href="#sparse-wgmma-metadata-64n16-tf32"><span class="std std-numref">Figure 178</span></a> shows the mapping of the metadata bits to the elements
of matrix A for a warp. In this figure, variable <code class="docutils literal notranslate"><span class="pre">i</span></code> represents the value of the sparsity
selector operand.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-wgmma-metadata-64n16-tf32">
<img alt="_images/sparse-mma-metadata-16816-tf32.png" class="image" src="_images/sparse-mma-metadata-16816-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 178 </span><span class="caption-text">Sparse WGMMA .m64nNk16 metadata layout for <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type.</span><a class="headerlink" href="#sparse-wgmma-metadata-64n16-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64">
<span id="id421"></span><h6>
<span class="section-number">9.7.15.6.2.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64">Matrix Fragments for sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk64</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A warpgroup executing sparse <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.m64nNk64</span></code> will compute an MMA operation of shape
<code class="docutils literal notranslate"><span class="pre">.m64nNk64</span></code> where N is a valid n dimension as listed in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shape"><span class="std std-ref">Matrix Shape</span></a>.</p>
<p>Elements of the matrix are distributed across the threads in a warpgroup so each thread of the
warpgroup holds a fragment of the matrix.</p>
<ul>
<li><p>Multiplicand A, from shared memory is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64"><span class="std std-ref">Matrix Fragments for sparse wgmma.mma_async.m64nNk64</span></a>.</p></li>
<li>
<p>Multiplicand A, from registers:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 51%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.atype</p></th>
<th class="head"><p>Fragments</p></th>
<th class="head"><p>Elements</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="line-block">
<div class="line">
<code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code></div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code>
</div>
<div class="line">registers, with each register containing four</div>
<div class="line">non-zero <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> elements out of</div>
<div class="line">eight consecutive elements from matrix A.</div>
</div>
</td>
<td rowspan="2">
<div class="line-block">
<div class="line"><br></div>
<div class="line">Non-zero elements:</div>
<div class="line">a0, a1, a2, â€¦ , a15</div>
<div class="line"><br></div>
<div class="line">Mapping of the non-zero</div>
<div class="line">elements is as described in</div>
<div class="line"><a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a></div>
</div>
</td>
</tr>
<tr class="row-odd">
<td>
<div class="line-block">
<div class="line">
<code class="docutils literal notranslate"><span class="pre">.s8</span></code> /</div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">.u8</span></code></div>
</div>
</td>
<td>
<div class="line-block">
<div class="line">A vector expression containing four <code class="docutils literal notranslate"><span class="pre">.b32</span></code>
</div>
<div class="line">registers, with each register containing four</div>
<div class="line">non-zero <code class="docutils literal notranslate"><span class="pre">.s8</span></code> /<code class="docutils literal notranslate"><span class="pre">.u8</span></code> elements out of</div>
<div class="line">eight consecutive elements from matrix A.</div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The layout of the fragments held by different threads is shown in <a class="reference internal" href="#sparse-wgmma-64n64-e4m3-e5m2-s8-u8-a"><span class="std std-numref">Figure 179</span></a>.</p>
<figure class="align-center" id="sparse-wgmma-64n64-e4m3-e5m2-s8-u8-a">
<img alt="_images/sparse-wgmma-64N64-e4m3-e5m2-s8-u8-A.png" class="image" src="_images/sparse-wgmma-64N64-e4m3-e5m2-s8-u8-A.png">
<figcaption>
<p><span class="caption-number">Figure 179 </span><span class="caption-text">Sparse WGMMA .m64nNk64 fragment layout for matrix A with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/ <code class="docutils literal notranslate"><span class="pre">.s8</span></code>/ <code class="docutils literal notranslate"><span class="pre">.u8</span></code> type.</span><a class="headerlink" href="#sparse-wgmma-64n64-e4m3-e5m2-s8-u8-a" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
<li>
<p>Accumulator D:</p>
<p>Matrix fragments for accumulator D are the same as in case of
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-register-fragment-wgmma-64n32"><span class="std std-ref">Matrix Fragments for wgmma.mma_async.m64nNk32</span></a>
for the same <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> format.</p>
</li>
<li>
<p>Multiplicand B:</p>
<p>Shared memory layout for Matrix B is documented in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-fragment-sparse-wgmma-64n64"><span class="std std-ref">Matrix Fragments for sparse wgmma.mma_async.m64nNk64</span></a>.</p>
</li>
<li>
<p>Metadata operand is a <code class="docutils literal notranslate"><span class="pre">.b32</span></code> register containing 16 4-bit vectors each storing the indices of
two non-zero elements of a 4-wide chunk of matrix A.</p>
<p><a class="reference internal" href="#sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-first32col"><span class="std std-numref">Figure 180</span></a> shows the mapping of the metadata
bits to the elements of columns 0â€“31 of matrix A.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-first32col">
<img alt="_images/sparse-mma-metadata-16864-u8s8-first32col.png" class="image" src="_images/sparse-mma-metadata-16864-u8s8-first32col.png">
<figcaption>
<p><span class="caption-number">Figure 180 </span><span class="caption-text">Sparse WGMMA .m64nNk64 metadata layout for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/ <code class="docutils literal notranslate"><span class="pre">.s8</span></code>/ <code class="docutils literal notranslate"><span class="pre">.u8</span></code> type for columns 0â€“31</span><a class="headerlink" href="#sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-first32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
<p><a class="reference internal" href="#sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-last32col"><span class="std std-numref">Figure 181</span></a> shows the mapping of the metadata
bits to the elements of columns 32â€“63 of matrix A.</p>
<blockquote>
<div>
<figure class="align-center" id="sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-last32col">
<img alt="_images/sparse-mma-metadata-16864-u8s8-last32col.png" class="image" src="_images/sparse-mma-metadata-16864-u8s8-last32col.png">
<figcaption>
<p><span class="caption-number">Figure 181 </span><span class="caption-text">Sparse WGMMA .m64nNk64 metadata layout for <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/ <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>/ <code class="docutils literal notranslate"><span class="pre">.s8</span></code>/ <code class="docutils literal notranslate"><span class="pre">.u8</span></code> type for columns 32â€“63</span><a class="headerlink" href="#sparse-wgmma-metadata-64n64-e4m3-e5m2-s8-u8-last32col" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions-wgmma-mma-sp">
<span id="id422"></span><h5>
<span class="section-number">9.7.15.6.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma-sp">Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-mma-sp" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code></p>
<p>Perform matrix multiply-and-accumulate operation with sparse matrix A across warpgroup</p>
<p class="rubric">Syntax</p>
<p>Half precision floating point type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.mma_async.sp.sync.aligned.shape.dtype.f16.f16  d, a-desc, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b, imm-trans-a, imm-trans-b;

wgmma.mma_async.sp.sync.aligned.shape.dtype.f16.f16  d, a, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b, imm-trans-b;

.shape   = {.m64n8k32, .m64n16k32, .m64n24k32, .m64n32k32,
            .m64n40k32, .m64n48k32, .m64n56k32, .m64n64k32,
            .m64n72k32, .m64n80k32, .m64n88k32, .m64n96k32,
            .m64n104k32, .m64n112k32, .m64n120k32, .m64n128k32,
            .m64n136k32, .m64n144k32, .m64n152k32, .m64n160k32,
            .m64n168k32, .m64n176k32, .m64n184k32, .m64n192k32,
            .m64n200k32, .m64n208k32, .m64n216k32, .m64n224k32,
            .m64n232k32, .m64n240k32, .m64n248k32, .m64n256k32};
.dtype   = {.f16, .f32};
</pre></div>
</div>
<p>Alternate floating point type :</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.bf16 floating point type:

wgmma.mma_async.sp.sync.aligned.shape.dtype.bf16.bf16  d, a-desc, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b, imm-trans-a, imm-trans-b;

wgmma.mma_async.sp.sync.aligned.shape.dtype.bf16.bf16  d, a, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b, imm-trans-b;

.shape   = {.m64n8k32, .m64n16k32, .m64n24k32, .m64n32k32,
            .m64n40k32, .m64n48k32, .m64n56k32, .m64n64k32,
            .m64n72k32, .m64n80k32, .m64n88k32, .m64n96k32,
            .m64n104k32, .m64n112k32, .m64n120k32, .m64n128k32,
            .m64n136k32, .m64n144k32, .m64n152k32, .m64n160k32,
            .m64n168k32, .m64n176k32, .m64n184k32, .m64n192k32,
            .m64n200k32, .m64n208k32, .m64n216k32, .m64n224k32,
            .m64n232k32, .m64n240k32, .m64n248k32, .m64n256k32};
.dtype  = {.f32};

.tf32 floating point type:

wgmma.mma_async.sp.sync.aligned.shape.dtype.tf32.tf32  d, a-desc, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b;

wgmma.mma_async.sp.sync.aligned.shape.dtype.tf32.tf32  d, a, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b;

.shape   = {.m64n8k16, .m64n16k16, .m64n24k16, .m64n32k16,
            .m64n40k16, .m64n48k16, .m64n56k16, .m64n64k16,
            .m64n72k16, .m64n80k16, .m64n88k16, .m64n96k16,
            .m64n104k16, .m64n112k16, .m64n120k16, .m64n128k16,
            .m64n136k16, .m64n144k16, .m64n152k16, .m64n160k16,
            .m64n168k16, .m64n176k16, .m64n184k16, .m64n192k16,
            .m64n200k16, .m64n208k16, .m64n216k16, .m64n224k16,
            .m64n232k16, .m64n240k16, .m64n248k16, .m64n256k16};
.dtype  = {.f32};

FP8 floating point type

wgmma.mma_async.sp.sync.aligned.shape.dtype.atype.btype  d, a-desc, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b;

wgmma.mma_async.sp.sync.aligned.shape.dtype.atype.btype  d, a, b-desc, sp-meta, sp-sel, scale-d, imm-scale-a, imm-scale-b;

.shape   = {.m64n8k64, .m64n16k64, .m64n24k64, .m64n32k64,
            .m64n40k64, .m64n48k64, .m64n56k64, .m64n64k64,
            .m64n72k64, .m64n80k64, .m64n88k64, .m64n96k64,
            .m64n104k64, .m64n112k64, .m64n120k64, .m64n128k64,
            .m64n136k64, .m64n144k64, .m64n152k64, .m64n160k64,
            .m64n168k64, .m64n176k64, .m64n184k64, .m64n192k64,
            .m64n200k64, .m64n208k64, .m64n216k64, .m64n224k64,
            .m64n232k64, .m64n240k64, .m64n248k64, .m64n256k64};
.atype  = {.e4m3, .e5m2};
.btype  = {.e4m3, .e5m2};
.dtype  = {.f16, .f32};
</pre></div>
</div>
<p>Integer type:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.mma_async.sp.sync.aligned.shape{.satfinite}.s32.atype.btype  d, a-desc, b-desc, sp-meta, sp-sel, scale-d;

wgmma.mma_async.sp.sync.aligned.shape{.satfinite}.s32.atype.btype  d, a, b-desc, sp-meta, sp-sel, scale-d;

.shape   = {.m64n8k64, .m64n16k64, .m64n24k64, .m64n32k64,
            .m64n48k64, .m64n64k64, .m64n80k64, .m64n96k64,
            .m64n112k64, .m64n128k64, .m64n144k64, .m64n160k64,
            .m64n176k64, .m64n192k64, .m64n208k64, .m64n224k64,
            .m64n240k64, .m64n256k64};
.atype  = {.s8, .u8};
.btype  = {.s8, .u8};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> issues a <code class="docutils literal notranslate"><span class="pre">MxNxK</span></code> matrix multiply and accumulate operation, <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span>
<span class="pre">A*B+D</span></code>, where the A matrix is <code class="docutils literal notranslate"><span class="pre">MxK</span></code>, the B matrix is <code class="docutils literal notranslate"><span class="pre">KxN</span></code>, and the D matrix is <code class="docutils literal notranslate"><span class="pre">MxN</span></code>.</p>
<p>The matrix A is stored in the packed format Mx(K/2) as described in
<a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.</p>
<p>The operation of the form <code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code> is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">scale-d</span></code> is
false.</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction must be used to fence the register accesses of <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction from their prior accesses. Otherwise, the behavior is undefined.</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> and <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> operations must be used to wait for the completion
of the asynchronous matrix multiply and accumulate operations before the results are accessed.</p>
<p>Register operand <code class="docutils literal notranslate"><span class="pre">d</span></code> represents the accumulator matrix as well as the destination matrix,
distributed across the participating threads. Register operand <code class="docutils literal notranslate"><span class="pre">a</span></code> represents the multiplicand
matrix A in register distributed across the participating threads. The 64-bit register operands
<code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which represent the multiplicand matrices A and
B in shared memory respectively. The contents of a matrix descriptor must be same across all the
warps in the warpgroup. The format of the matrix descriptor is described in
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor"><span class="std std-ref">Matrix Descriptor Format</span></a>. Matrix A is
structured sparse as described in <a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a>.  Operands <code class="docutils literal notranslate"><span class="pre">sp-meta</span></code> and <code class="docutils literal notranslate"><span class="pre">sp-sel</span></code>
represent sparsity metadata and sparsity selector respectively. Operand <code class="docutils literal notranslate"><span class="pre">sp-meta</span></code> is a 32-bit
integer and operand <code class="docutils literal notranslate"><span class="pre">sp-sel</span></code> is a 32-bit integer constant with values in the range 0..3.</p>
<p>The valid values of <code class="docutils literal notranslate"><span class="pre">sp-meta</span></code> and <code class="docutils literal notranslate"><span class="pre">sp-sel</span></code> for each shape is specified in
<a class="reference internal" href="#asynchronous-warpgroup-level-sparse-matrix-storage"><span class="std std-ref">Sparse matrix storage</span></a> and are summarized here :</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 29%">
<col style="width: 42%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Matrix shape</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">.atype</span></code></p></th>
<th class="head"><p>Valid values of <code class="docutils literal notranslate"><span class="pre">sp-meta</span></code></p></th>
<th class="head"><p>Valid values of <code class="docutils literal notranslate"><span class="pre">sp-sel</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m64nNk16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td><p>0b1110 , 0b0100</p></td>
<td><p>0 (threads T0, T1) or 1 (threads T2, T3)</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.m64nNk32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>/
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
<td><p>0b00, 0b01, 0b10, 0b11</p></td>
<td><p>0 (threads T0, T1) or 1 (threads T2, T3)</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m64nNk64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> /
<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> /
<code class="docutils literal notranslate"><span class="pre">.s8</span></code>  /
<code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td><p>0b00, 0b01, 0b10, 0b11</p></td>
<td><p>0 (all threads contribute)</p></td>
</tr>
</tbody>
</table>
<p>Matrices A and B are stored in row-major and column-major format respectively. For certain floating
point variants, the input matrices A and B can be transposed by specifying the value 1 for the
immediate integer arguments <code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> respectively. A value of 0 can be
used to avoid the transpose operation. The valid values of <code class="docutils literal notranslate"><span class="pre">imm-trans-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-trans-b</span></code> are 0
and 1. The transpose operation is only supported for the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> variants with <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> types on matrices accessed from shared memory using matrix descriptors.</p>
<p>For the floating point variants of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation, each element of the input
matrices A and B can be negated by specifying the value -1 for operands <code class="docutils literal notranslate"><span class="pre">imm-scale-a</span></code> and
<code class="docutils literal notranslate"><span class="pre">imm-scale-b</span></code> respectively. A value of 1 can be used to avoid the negate operation. The valid
values of <code class="docutils literal notranslate"><span class="pre">imm-scale-a</span></code> and <code class="docutils literal notranslate"><span class="pre">imm-scale-b</span></code> are -1 and 1.</p>
<p>The qualifiers <code class="docutils literal notranslate"><span class="pre">.dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> indicate the data type of the elements in
matrices D, A and B respectively. <code class="docutils literal notranslate"><span class="pre">.atype</span></code> and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> must be the same for all floating point
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> variants except for the FP8 floating point variants. The sizes of individual
data elements of matrices A and B in alternate floating point variants of the <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
operation are as follows:</p>
<ul class="simple">
<li><p>Matrices A and B have 8-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>.</p></li>
<li><p>Matrices A and B have 16-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>.</p></li>
<li><p>Matrices A and B have 32-bit data elements when <code class="docutils literal notranslate"><span class="pre">.atype</span></code>/ <code class="docutils literal notranslate"><span class="pre">.btype</span></code> is <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>.</p></li>
</ul>
<p>Precision and rounding:</p>
<ul>
<li>
<p>Floating point operations:</p>
<p>Element-wise multiplication of matrix A and B is performed with at least single precision. When
<code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>, accumulation of the intermediate values is performed with at least single
precision. When <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, the accumulation is performed with at least half
precision.</p>
<p>The accumulation order, rounding and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> floating point operations:</p>
<p>Element-wise multiplication of matrix A and B is performed with specified
precision. <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation involving type <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> will truncate lower 13 bits of
the 32-bit input data before multiplication is issued. Accumulation of the intermediate values is
performed with at least single precision.</p>
<p>The accumulation order, rounding, and handling of subnormal inputs are unspecified.</p>
</li>
<li>
<p>Integer operations:</p>
<p>The integer <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation is performed with <code class="docutils literal notranslate"><span class="pre">.s32</span></code> accumulators. The
<code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier indicates that on overflow, the accumulated value is limited to the
range <em>MIN_INT32</em>.. <em>MAX_INT32</em> (where the bounds are defined as the minimum negative signed
32-bit integer and the maximum positive signed 32-bit integer respectively).</p>
<p>If <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> is not specified, the accumulated value is wrapped instead.</p>
</li>
</ul>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction causes the
executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instruction should only be used if it is known that all threads in the warpgroup evaluate the
condition identically, otherwise behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.u8.s8</span></code> and <code class="docutils literal notranslate"><span class="pre">.s8.u8</span></code> as .atype.btype introduced in PTX ISA version 8.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
<p class="rubric">Examples of integer type</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.fence.sync.aligned;
wgmma.mma_async.sp.sync.aligned.m64n8k64.s32.u8.u8  {s32d0, s32d1, s32d2, s32d3},
                                                    descA, descB, spMeta, 0, scaleD;
wgmma.mma_async.sp.sync.aligned.m64n8k64.s32.s8.u8  {s32d0, s32d1, s32d2, s32d3},
                                                    descA, descB, spMeta, 0, scaleD;
wgmma.commit_group.sync.aligned;
wgmma.wait_group.sync.aligned 0;
</pre></div>
</div>
</section>
</section>
<section id="asynchronous-wgmma-proxy-operations">
<span id="id423"></span><h4>
<span class="section-number">9.7.15.7. </span><a class="reference internal" href="#asynchronous-wgmma-proxy-operations">Asynchronous <code class="docutils literal notranslate"><span class="pre">wgmma</span></code> Proxy Operations</a><a class="headerlink" href="#asynchronous-wgmma-proxy-operations" title="Permalink to this headline">ïƒ</a>
</h4>
<p>This section describes warpgroup level <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code>, <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> and <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> instructions.</p>
<section id="asynchronous-warpgroup-level-matrix-instructions-wgmma-fence">
<span id="id424"></span><h5>
<span class="section-number">9.7.15.7.1. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-fence">Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-fence" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code></p>
<p>Enforce an ordering of register accesses between <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> and other operations.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.fence.sync.aligned;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction establishes an ordering between prior accesses to any warpgroup
registers and subsequent accesses to the same registers by a <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction. Only
the accumulator register and the input registers containing the fragments of matrix A require this
ordering.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction must be issued by all warps of the warpgroup at the following
locations:</p>
<ul class="simple">
<li><p>Before the first <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operation in a warpgroup.</p></li>
<li><p>Between a register access by a thread in the warpgroup and any <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction
that accesses the same registers, either as accumulator or input register containing fragments of
matrix A, except when these are accumulator register accesses across multiple <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>
instructions of the same shape. In the latter case, an ordering guarantee is provided by default.</p></li>
</ul>
<p>Otherwise, the behavior is undefined.</p>
<p>An async proxy fence must be used to establish an ordering between prior writes to shared memory
matrices and subsequent reads of the same matrices in a <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction causes the executing
thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction before
resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction. In conditionally executed code, an <code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code> instruction
should only be used if it is known that all threads in the warpgroup evaluate the condition
identically, otherwise the behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example 1, first use example:
wgmma.fence.sync.aligned;    // Establishes an ordering w.r.t. prior accesses to the registers s32d&lt;0-3&gt;
wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.u8  {s32d0, s32d1, s32d2, s32d3},
                                                  descA, descB, scaleD;
wgmma.commit_group.sync.aligned;
wgmma.wait_group.sync.aligned 0;

// Example 2, use-case with the input value updated in between:
wgmma.fence.sync.aligned;
wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.u8  {s32d0, s32d1, s32d2, s32d3},
                                                  descA, descB, scaleD;
...
mov.b32 s32d0, new_val;
wgmma.fence.sync.aligned;
wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.u8  {s32d4, s32d5, s32d6, s32d7},
                                                 {s32d0, s32d1, s32d2, s32d3},
                                                  descB, scaleD;
wgmma.commit_group.sync.aligned;
wgmma.wait_group.sync.aligned 0;
</pre></div>
</div>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group">
<span id="id425"></span><h5>
<span class="section-number">9.7.15.7.2. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group">Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-commit-group" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code></p>
<p>Commits all prior uncommitted <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations into a <em>wgmma-group</em>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.commit_group.sync.aligned;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> instruction creates a new wgmma-group per warpgroup and batches all prior
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instructions initiated by the executing warp but not committed to any
wgmma-group into the new wgmma-group. If there are no uncommitted <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instructions
then <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> results in an empty wgmma-group.</p>
<p>An executing thread can wait for the completion of all <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> operations in a
wgmma-group by using <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> instruction causes the
executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code> instruction. In conditionally executed code, an <code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code>
instruction should only be used if it is known that all threads in the warpgroup evaluate the
condition identically, otherwise the behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.commit_group.sync.aligned;
</pre></div>
</div>
</section>
<section id="asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group">
<span id="id426"></span><h5>
<span class="section-number">9.7.15.7.3. </span><a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group">Asynchronous Multiply-and-Accumulate Instruction: <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code></a><a class="headerlink" href="#asynchronous-warpgroup-level-matrix-instructions-wgmma-wait-group" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code></p>
<p>Signal the completion of a preceding warpgroup operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.wait_group.sync.aligned N;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> instruction will cause the executing thread to wait until only N or fewer of
the most recent wgmma-groups are pending and all the prior wgmma-groups committed by the executing
threads are complete. For example, when N is 0, the executing thread waits on all the prior
wgmma-groups to complete. Operand N is an integer constant.</p>
<p>Accessing the accumulator register or the input register containing the fragments of matrix A of a
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction without first performing a <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> instruction that
waits on a <em>wgmma-group</em> including that <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction is undefined behavior.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> instruction causes the
executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code> instruction. In conditionally executed code, an <code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code>
instruction should only be used if it is known that all threads in the warpgroup evaluate the
condition identically, otherwise the behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>wgmma.fence.sync.aligned;

wgmma.mma_async.sync.aligned.m64n8k32.s32.u8.u8  {s32d0, s32d1, s32d2, s32d3},
                                                  descA, descB, scaleD;
wgmma.commit_group.sync.aligned;

wgmma.mma_async.sync.aligned.m64n8k16.f32.f16.f16 {f32d0, f32d1, f32d2, f32d3},
                                                  {f16a0, f16a1, f16a2, f16a3},
                                                   descB, 1, -1, -1, 1;
wgmma.commit_group.sync.aligned;

wgmma.wait_group.sync.aligned 0;
</pre></div>
</div>
</section>
</section>
</section>
<section id="tensorcore-5th-generation-instructions">
<span id="id427"></span><h3>
<span class="section-number">9.7.16. </span><a class="reference internal" href="#tensorcore-5th-generation-instructions">TensorCore 5th Generation Family Instructions</a><a class="headerlink" href="#tensorcore-5th-generation-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<section id="tensor-memory">
<span id="id428"></span><h4>
<span class="section-number">9.7.16.1. </span><a class="reference internal" href="#tensor-memory">Tensor Memory</a><a class="headerlink" href="#tensor-memory" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The 5<sup>th</sup> generation TensorCore has dedicated on-chip memory that is specialized for use by
TensorCore operations. This Tensor Memory is organized as a two-dimensional matrix where
the horizontal rows are called lanes and the vertical columns are called columns.</p>
<p>On architecture <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>/<code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, the 5<sup>th</sup> generation TensorCoreâ€™s Tensor Memory has a
two-dimensional structure of 512 columns and 128 rows per CTA, with each cell being 32-bits in size.</p>
<p>Restrictions on threads accessing the Tensor Memory via the load and store operations
are specified in <a class="reference internal" href="#tcgen05-tensor-memory-ld-st-access-restrictions"><span class="std std-ref">Access restrictions</span></a>.</p>
<section id="tensor-memory-addressing">
<span id="id429"></span><h5>
<span class="section-number">9.7.16.1.1. </span><a class="reference internal" href="#tensor-memory-addressing">Tensor Memory Addressing</a><a class="headerlink" href="#tensor-memory-addressing" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Tensor Memory addresses are 32-bit wide and specify two components.</p>
<ol class="arabic simple">
<li><p>Lane index</p></li>
<li><p>Column index</p></li>
</ol>
<p>The layout is as follows:</p>
<blockquote>
<div>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 51%">
<col style="width: 49%">
</colgroup>
<tbody>
<tr class="row-odd">
<td><p>31                      16</p></td>
<td><p>15                       0</p></td>
</tr>
<tr class="row-even">
<td><p>Lane index</p></td>
<td><p>Column index</p></td>
</tr>
</tbody>
</table>
</div>
</blockquote>
<p><a class="reference internal" href="#tensor-memory-layout"><span class="std std-numref">Figure 182</span></a> shows the view of the Tensor Memory Layout within CTA.</p>
<figure class="align-center" id="tensor-memory-layout">
<img alt="_images/tensor-memory-layout.png" class="image" src="_images/tensor-memory-layout.png">
<figcaption>
<p><span class="caption-number">Figure 182 </span><span class="caption-text">Tensor Memory Layout and Addressing</span><a class="headerlink" href="#tensor-memory-layout" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tensor-memory-allocation">
<span id="id430"></span><h5>
<span class="section-number">9.7.16.1.2. </span><a class="reference internal" href="#tensor-memory-allocation">Tensor Memory Allocation</a><a class="headerlink" href="#tensor-memory-allocation" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The Tensor Memory is dynamically allocated. The Tensor Memory must be allocated by a single
warp in a CTA using the
<a class="reference internal" href="#tcgen05-memory-alloc-manage-instructions"><span class="std std-ref">Tensor Memory Allocation and Management Instructions</span></a>.</p>
<p>The allocation and deallocation of <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> is performed in terms of
columns. The unit of allocation is 32 columns and the number of columns being allocated must be
a power of 2. When a column is allocated, all 128 lanes of the column are allocated.</p>
<p>All of the Tensor Memory that was allocated in a kernel, must be explicitly deallocated
before the kernel exits.</p>
</section>
</section>
<section id="tcgen05-matrix-data-movement-shape">
<span id="id431"></span><h4>
<span class="section-number">9.7.16.2. </span><a class="reference internal" href="#tcgen05-matrix-data-movement-shape">Matrix and Data Movement Shape</a><a class="headerlink" href="#tcgen05-matrix-data-movement-shape" title="Permalink to this headline">ïƒ</a>
</h4>
<p>There are two kinds of shapes involved.</p>
<ol class="arabic simple">
<li><p>Shapes in the data movement operations</p></li>
<li><p>Shapes in the MMA operations</p></li>
</ol>
<section id="tcgen05-matrix-shape">
<span id="id432"></span><h5>
<span class="section-number">9.7.16.2.1. </span><a class="reference internal" href="#tcgen05-matrix-shape">Matrix Shape</a><a class="headerlink" href="#tcgen05-matrix-shape" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The matrix multiply and accumulate operations support a limited set of shapes for the operand matrices
<code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code> and <code class="docutils literal notranslate"><span class="pre">D</span></code>. The shapes of all three matrix operands are collectively described by the tuple
<em>MxNxK</em> where <code class="docutils literal notranslate"><span class="pre">A</span></code> is <em>MxK</em> matrix, <code class="docutils literal notranslate"><span class="pre">B</span></code> is a <em>KxN</em> matrix, and <code class="docutils literal notranslate"><span class="pre">D</span></code> is a <em>MxN</em> matrix.</p>
<p><a class="reference internal" href="#tcgen05-kind-shapes"><span class="std std-numref">Table 39</span></a> shows matrix shapes that are supported for the specified types for the
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> operation.</p>
<table class="table-no-stripes longtable docutils align-default" id="tcgen05-kind-shapes">
<caption>
<span class="caption-number">Table 39 </span><span class="caption-text">Various combinations of .kind and shapes</span><a class="headerlink" href="#tcgen05-kind-shapes" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 14%">
<col style="width: 8%">
<col style="width: 7%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 14%">
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" colspan="6"><p>Various Combinations</p></th>
<th class="head" colspan="3" rowspan="2"><p>Shapes Supported</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.kind::*</p></th>
<th class="head"><p>Has .ws</p></th>
<th class="head"><p>CTA Group</p></th>
<th class="head"><p>Sparsity</p></th>
<th class="head"><p>dtype</p></th>
<th class="head"><p>atype/btype</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td rowspan="14"><p><code class="docutils literal notranslate"><span class="pre">kind::f16</span></code></p></td>
<td rowspan="8"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="4"><p>1</p></td>
<td rowspan="2"><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="4">
<p>64xNxK</p>
<p>128xNxK</p>
</td>
<td rowspan="4"><p>N = {8, 16, 24, â€¦ 256} steps of 8</p></td>
<td rowspan="2"><p>K = 16</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Sparse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="4"><p>2</p></td>
<td rowspan="2"><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="4">
<p>128xNxK</p>
<p>256xNxK</p>
</td>
<td rowspan="4"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td rowspan="2"><p>K = 16</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Sparse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="4"><p>1</p></td>
<td rowspan="2"><p>Dense</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="4">
<p>32xNxK</p>
<p>64xNxK</p>
<p>128xNxK</p>
</td>
<td rowspan="2"><p>N = {64, 128, 256}</p></td>
<td rowspan="2"><p>K = 16</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Sparse</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td rowspan="2"><p>N = {64, 128}</p></td>
<td rowspan="2"><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>2</p></td>
<td rowspan="2"><p>Either</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p></td>
<td colspan="3" rowspan="2"><p>Invalid</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></p></td>
<td rowspan="4"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.tf32</span></code></p></td>
<td rowspan="2">
<p>64xNxK</p>
<p>128xNxK</p>
</td>
<td rowspan="2"><p>N = {8, 16, 24, â€¦ 256} steps of 8</p></td>
<td><p>K = 8</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>K = 16</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td rowspan="2">
<p>128xNxK</p>
<p>256xNxK</p>
</td>
<td rowspan="2"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td><p>K = 8</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>K = 16</p></td>
</tr>
<tr class="row-odd">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="2"><p>32xNxK
64xNxK
128xNxK</p></td>
<td><p>N = {64, 128, 256}</p></td>
<td><p>K = 8</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>N = {64, 128}</p></td>
<td><p>K = 16</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td colspan="3" rowspan="2"><p>Invalid</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
</tr>
<tr class="row-odd">
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></td>
<td rowspan="4"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="8">
<p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">.f16</span></code></p>
</td>
<td rowspan="8">
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p>
</td>
<td rowspan="2">
<p>64xNxK</p>
<p>128xNxK</p>
</td>
<td rowspan="2"><p>N = {8, 16, â€¦ 256} steps of 8</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td rowspan="2">
<p>128xNxK</p>
<p>256xNxK</p>
</td>
<td rowspan="2"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="2"><p>32xNxK
64xNxK
128xNxK</p></td>
<td><p>N = {64, 128, 256}</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>N = {64, 128}</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td colspan="3" rowspan="2"><p>Invalid</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
</tr>
<tr class="row-odd">
<td rowspan="9"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td rowspan="5"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="9"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td rowspan="9">
<p><code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p>
<p>X</p>
<p>(Scale)</p>
<p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p>
</td>
<td rowspan="2"><p>128xNxK</p></td>
<td rowspan="2"><p>N = {8, 16, â€¦ 256} steps of 8</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p>2</p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2">
<p>128xNxK</p>
<p>256xNxK</p>
</td>
<td rowspan="3"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td rowspan="2"><p>K = 32</p></td>
</tr>
<tr class="row-even"></tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>256xNxK</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td colspan="3" rowspan="4"><p>Invalid</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
</tr>
<tr class="row-even">
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
<td rowspan="4"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.s32</span></code></p></td>
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">.s8</span></code>, <code class="docutils literal notranslate"><span class="pre">.u8</span></code></p></td>
<td rowspan="2">
<p>64xNxK</p>
<p>128xNxK</p>
</td>
<td rowspan="2">
<p>N = {8, 16, 24, 32, 48, â€¦ 256}</p>
<p>steps of 16 after N &gt; 32</p>
</td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td rowspan="2">
<p>128xNxK</p>
<p>256xNxK</p>
</td>
<td rowspan="2"><p>N = {32, 64, â€¦ 256} steps of 32</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="2"><p>32xNxK
64xNxK
128xNxK</p></td>
<td><p>N = {64, 128, 256}</p></td>
<td><p>K = 32</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>N = {64, 128}</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>2</p></td>
<td><p>Dense</p></td>
<td colspan="3" rowspan="2"><p>Invalid</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
</tr>
<tr class="row-even">
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td rowspan="5"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td rowspan="6">
<p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p>
<p>X</p>
<p>(Scale)</p>
<p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code></p>
</td>
<td rowspan="2"><p>128xNxK</p></td>
<td rowspan="2"><p>N = {8, 16, â€¦ 256} steps of 8</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>K = 128</p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p>2</p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2"><p>128xNxK
256xNxK
256xNxK<sup>1</sup></p></td>
<td rowspan="3"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td rowspan="2">
<p>K = 64</p>
<p>K<sup>1</sup>
= 96</p>
</td>
</tr>
<tr class="row-odd"></tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>256xNxK</p></td>
<td><p>K = 128</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td><p>1 / 2</p></td>
<td><p>Either</p></td>
<td colspan="3"><p>Invalid</p></td>
</tr>
<tr class="row-even">
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td rowspan="5"><p>No <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td rowspan="2"><p>1</p></td>
<td><p>Dense</p></td>
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">.f32</span></code></p></td>
<td rowspan="6">
<p><code class="docutils literal notranslate"><span class="pre">.e2m1</span></code></p>
<p>X</p>
<p>(Scale)</p>
<p><code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code>,</p>
<p><code class="docutils literal notranslate"><span class="pre">.ue4m3</span></code></p>
</td>
<td rowspan="2"><p>128xNxK</p></td>
<td rowspan="2"><p>N = {8, 16, â€¦ 256} steps of 8</p></td>
<td><p>K = 64</p></td>
</tr>
<tr class="row-odd">
<td><p>Sparse</p></td>
<td><p>K = 128</p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p>2</p></td>
<td rowspan="2"><p>Dense</p></td>
<td rowspan="2"><p>128xNxK
256xNxK
256xNxK<sup>1</sup></p></td>
<td rowspan="3"><p>N = {16, 32, â€¦ 256} steps of 16</p></td>
<td rowspan="2">
<p>K = 64</p>
<p>K<sup>1</sup>
= 96</p>
</td>
</tr>
<tr class="row-odd"></tr>
<tr class="row-even">
<td><p>Sparse</p></td>
<td><p>256xNxK</p></td>
<td><p>K = 128</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td><p>1 / 2</p></td>
<td><p>Either</p></td>
<td colspan="3"><p>Invalid</p></td>
</tr>
</tbody>
</table>
<section id="tcgen05-matrix-shape-target-isa-note">
<span id="id433"></span><h6>
<span class="section-number">9.7.16.2.1.1. </span><a class="reference internal" href="#tcgen05-matrix-shape-target-isa-note">Target ISA Note</a><a class="headerlink" href="#tcgen05-matrix-shape-target-isa-note" title="Permalink to this headline">ïƒ</a>
</h6>
<ul class="simple">
<li><p>K = 96 is only supported for target architecture <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>.</p></li>
</ul>
</section>
</section>
<section id="tcgen05-specify-matrix-shape">
<span id="id434"></span><h5>
<span class="section-number">9.7.16.2.2. </span><a class="reference internal" href="#tcgen05-specify-matrix-shape">Specifying Matrix Shape</a><a class="headerlink" href="#tcgen05-specify-matrix-shape" title="Permalink to this headline">ïƒ</a>
</h5>
<p><em>M</em> and <em>N</em> can be specified in the <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>.</p>
<p><em>K</em> cannot be explicitly specified but is implicitly determined by the MMA-kind
and the sparsity, as shown in the <a class="reference internal" href="#tcgen05-kind-shapes"><span class="std std-numref">Table 39</span></a>.</p>
</section>
<section id="tcgen05-data-movement-shape">
<span id="id435"></span><h5>
<span class="section-number">9.7.16.2.3. </span><a class="reference internal" href="#tcgen05-data-movement-shape">Data Movement Shape</a><a class="headerlink" href="#tcgen05-data-movement-shape" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The data movement shape indicates the dimension of the data to be moved to or from the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. These shapes are described as a tuple <code class="docutils literal notranslate"><span class="pre">lane</span> <span class="pre">x</span> <span class="pre">size</span></code> where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">lane</span></code> indicates the number of rows in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>; and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">size</span></code> indicates the amount of data, in units of bits (b), across the columns in the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p></li>
</ul>
<p>The following shapes are supported by various tcgen05 operations:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 62%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Shape</p></th>
<th class="head"><p>tcgen05.&lt;op&gt;</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.16x64b</span></code>, <code class="docutils literal notranslate"><span class="pre">.16x128b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.16x256b</span></code>, <code class="docutils literal notranslate"><span class="pre">.16x32bx2</span></code>, <code class="docutils literal notranslate"><span class="pre">.32x32b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">.st</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.4x256b</span></code>, <code class="docutils literal notranslate"><span class="pre">.32x128b</span></code>, <code class="docutils literal notranslate"><span class="pre">.64x128b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.128x256b</span></code>, <code class="docutils literal notranslate"><span class="pre">.128x128b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.cp</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.31x256b</span></code> (implicit)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.shift</span></code></p></td>
</tr>
</tbody>
</table>
<section id="tcgen05-memory-layout">
<span id="id436"></span><h6>
<span class="section-number">9.7.16.2.3.1. </span><a class="reference internal" href="#tcgen05-memory-layout">Memory Layout</a><a class="headerlink" href="#tcgen05-memory-layout" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The following shows the layout of the matrix fragments across threads of the warp.</p>
<section id="tcgen05-matrix-fragments-shape-3232b">
<span id="id437"></span><h7><span class="section-number">9.7.16.2.3.1.1. </span><a class="reference internal" href="#tcgen05-matrix-fragments-shape-3232b">Matrix fragments for shape .32x32b</a><a class="headerlink" href="#tcgen05-matrix-fragments-shape-3232b" title="Permalink to this headline">ïƒ</a></h7>
<p>A <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.32x32b</span></code> instruction has the following data vector register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A vector expression containing <code class="docutils literal notranslate"><span class="pre">.num</span></code>
number of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers as
mentioned in the
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p></td>
<td><p>r0, r1, â€¦</p></td>
</tr>
</tbody>
</table>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.32x32b</span></code> will access 32 lanes of the Tensor Memory.
It loads from or stores to each of the lane (32 * .num)-bits of data as shown in
<a class="reference internal" href="#tcgen05-mma-fragment-3232b"><span class="std std-numref">Figure 183</span></a>.</p>
<figure class="align-center" id="tcgen05-mma-fragment-3232b">
<img alt="_images/tcgen05-mma-fragment-3232b.png" class="image" src="_images/tcgen05-mma-fragment-3232b.png">
<figcaption>
<p><span class="caption-number">Figure 183 </span><span class="caption-text">Matrix Fragment for shape .32x32b</span><a class="headerlink" href="#tcgen05-mma-fragment-3232b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-matrix-fragments-shape-6464b">
<span id="id438"></span><h7><span class="section-number">9.7.16.2.3.1.2. </span><a class="reference internal" href="#tcgen05-matrix-fragments-shape-6464b">Matrix fragments for shape .16x64b</a><a class="headerlink" href="#tcgen05-matrix-fragments-shape-6464b" title="Permalink to this headline">ïƒ</a></h7>
<p>A <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x64b</span></code> instruction has the following data vector register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A vector expression containing <code class="docutils literal notranslate"><span class="pre">.num</span></code>
number of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers as
mentioned in the
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p></td>
<td><p>r0, r1, â€¦</p></td>
</tr>
</tbody>
</table>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x64b</span></code> will access 16 lanes of the Tensor Memory.
It loads from or stores to each of the lane (64 * .num)-bits of data as shown in
<a class="reference internal" href="#tcgen05-mma-fragment-1664b"><span class="std std-numref">Figure 184</span></a>.</p>
<figure class="align-center" id="tcgen05-mma-fragment-1664b">
<img alt="_images/tcgen05-mma-fragment-1664b.png" class="image" src="_images/tcgen05-mma-fragment-1664b.png">
<figcaption>
<p><span class="caption-number">Figure 184 </span><span class="caption-text">Matrix Fragment for shape .16x64b</span><a class="headerlink" href="#tcgen05-mma-fragment-1664b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-matrix-fragments-shape-16128b">
<span id="id439"></span><h7><span class="section-number">9.7.16.2.3.1.3. </span><a class="reference internal" href="#tcgen05-matrix-fragments-shape-16128b">Matrix fragments for shape .16x128b</a><a class="headerlink" href="#tcgen05-matrix-fragments-shape-16128b" title="Permalink to this headline">ïƒ</a></h7>
<p>A <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x128b</span></code> instruction has the following data vector register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A vector expression containing <code class="docutils literal notranslate"><span class="pre">.num</span></code>
number of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers as
mentioned in the
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p></td>
<td><p>r0, r1, â€¦</p></td>
</tr>
</tbody>
</table>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x128b</span></code> will access 16 lanes of the Tensor Memory.
It loads from or stores to each of the lane (128 * .num)-bits of data as shown in
<a class="reference internal" href="#tcgen05-mma-fragment-16128b"><span class="std std-numref">Figure 185</span></a>.</p>
<figure class="align-center" id="tcgen05-mma-fragment-16128b">
<img alt="_images/tcgen05-mma-fragment-16128b.png" class="image" src="_images/tcgen05-mma-fragment-16128b.png">
<figcaption>
<p><span class="caption-number">Figure 185 </span><span class="caption-text">Matrix Fragment for shape .16x128b</span><a class="headerlink" href="#tcgen05-mma-fragment-16128b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-matrix-fragments-shape-16256b">
<span id="id440"></span><h7><span class="section-number">9.7.16.2.3.1.4. </span><a class="reference internal" href="#tcgen05-matrix-fragments-shape-16256b">Matrix fragments for shape .16x256b</a><a class="headerlink" href="#tcgen05-matrix-fragments-shape-16256b" title="Permalink to this headline">ïƒ</a></h7>
<p>A <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x256b</span></code> instruction has the following data vector register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A vector expression containing <code class="docutils literal notranslate"><span class="pre">.num</span></code>
number of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers as
mentioned in the
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p></td>
<td><p>r0, r1, r2, r3, â€¦</p></td>
</tr>
</tbody>
</table>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x256b</span></code> will access 16 lanes of the Tensor Memory.
It loads from or stores to each of the lane (256 * .num)-bits of data as shown in
<a class="reference internal" href="#tcgen05-mma-fragment-16256b"><span class="std std-numref">Figure 186</span></a>.</p>
<figure class="align-center" id="tcgen05-mma-fragment-16256b">
<img alt="_images/tcgen05-mma-fragment-16256b.png" class="image" src="_images/tcgen05-mma-fragment-16256b.png">
<figcaption>
<p><span class="caption-number">Figure 186 </span><span class="caption-text">Matrix Fragment for shape .16x256b</span><a class="headerlink" href="#tcgen05-mma-fragment-16256b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-matrix-fragments-shape-1632b2">
<span id="id441"></span><h7><span class="section-number">9.7.16.2.3.1.5. </span><a class="reference internal" href="#tcgen05-matrix-fragments-shape-1632b2">Matrix fragments for shape .16x32bx2</a><a class="headerlink" href="#tcgen05-matrix-fragments-shape-1632b2" title="Permalink to this headline">ïƒ</a></h7>
<p>A <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x32bx2</span></code> instruction has the following data vector register.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 49%">
<col style="width: 51%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Fragment</p></th>
<th class="head"><p>Elements (low to high)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A vector expression containing <code class="docutils literal notranslate"><span class="pre">.num</span></code>
number of <code class="docutils literal notranslate"><span class="pre">.b32</span></code> registers as
mentioned in the
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p></td>
<td><p>r0, r1, â€¦</p></td>
</tr>
</tbody>
</table>
<p>A warp executing <code class="docutils literal notranslate"><span class="pre">tcgen05{.ld,.st}.16x32bx2</span></code> will access 16 lanes of the Tensor Memory.
It loads from or stores to each of the lane (32 * .num)-bits of data as shown in
<a class="reference internal" href="#tcgen05-mma-fragment-1632b2"><span class="std std-numref">Figure 187</span></a>.</p>
<figure class="align-center" id="tcgen05-mma-fragment-1632b2">
<img alt="_images/tcgen05-mma-fragment-1632b2.png" class="image" src="_images/tcgen05-mma-fragment-1632b2.png">
<figcaption>
<p><span class="caption-number">Figure 187 </span><span class="caption-text">Matrix Fragment for shape .16x32bx2</span><a class="headerlink" href="#tcgen05-mma-fragment-1632b2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
</section>
</section>
<section id="tcgen05-majorness-supported-by-strides">
<span id="id442"></span><h4>
<span class="section-number">9.7.16.3. </span><a class="reference internal" href="#tcgen05-majorness-supported-by-strides">Major-ness supported by Strides</a><a class="headerlink" href="#tcgen05-majorness-supported-by-strides" title="Permalink to this headline">ïƒ</a>
</h4>
<p>There are two strides involved while accessing a matrix from shared memory:</p>
<ol class="arabic simple">
<li><p>Leading dimension stride (byte offset or absolute address)</p></li>
<li><p>Stride dimension byte offset</p></li>
</ol>
<section id="tcgen05-leading-dimension-byte-offset">
<span id="id443"></span><h5>
<span class="section-number">9.7.16.3.1. </span><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset">Leading Dimension Stride: relative offset or absolute address</a><a class="headerlink" href="#tcgen05-leading-dimension-byte-offset" title="Permalink to this headline">ïƒ</a>
</h5>
<p>There are two modes of Leading Dimension Strides as described below.
Bit #52 in the <a class="reference internal" href="#tcgen05-shared-memory-descriptor"><span class="std std-ref">Shared memory descriptor</span></a> is used to distinguish between two modes.</p>
<section id="tcgen05-leading-dimension-byte-offset-relative-offset">
<span id="id444"></span><h6>
<span class="section-number">9.7.16.3.1.1. </span><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-relative-offset">Relative offset mode</a><a class="headerlink" href="#tcgen05-leading-dimension-byte-offset-relative-offset" title="Permalink to this headline">ïƒ</a>
</h6>
<p>In this mode, the leading dimension stride is specified as a relative byte offset between the
columns as explained in the below table.
The leading dimension stride can either be specified as a relative offset between the columns
or as an absolute byte address of next buffer. The leading dimension stride is defined
differently for transposed and non-transposed matrices. The leading dimension stride is defined
as follows for matrices whose element types are normalized to 128-bits:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-ness</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>K-Major</p></td>
<td>
<ul class="simple">
<li><p>No-Swizzling: the stride from the first column to the second column
of the 8x2 tile in the 128-bit element type normalized matrix.</p></li>
<li><p>Swizzled layouts: not used, assumed to be 1.</p></li>
</ul>
</td>
</tr>
<tr class="row-odd">
<td><p>MN-Major</p></td>
<td>
<ul class="simple">
<li><p>Interleave: stride from the first 8 columns to the next 8 columns.</p></li>
<li><p>Swizzled layouts: stride from the first (swizzle-byte-size/16) rows
to the next (swizzle-byte-size/16) rows.</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-leading-dimension-byte-offset-absolute-address">
<span id="id445"></span><h6>
<span class="section-number">9.7.16.3.1.2. </span><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-absolute-address">Absolute address mode for K dimension being 48B</a><a class="headerlink" href="#tcgen05-leading-dimension-byte-offset-absolute-address" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> instruction with <em>K-dimension</em> of 48B would overflow the 128B
shared memory boundary if the data is packed contiguously.</p>
<p>In this case, the absolute address mode can be used to break up the data in the
shared memory into two chunks such that both these chunks are laid out within
the aligned 128-byte address boundary.
The leading dimension absolute address can point to the second data chunk in the shared memory.</p>
<section id="tcgen05-leading-dimension-byte-offset-absolute-address-restriction">
<span id="id446"></span><h7><span class="section-number">9.7.16.3.1.2.1. </span><a class="reference internal" href="#tcgen05-leading-dimension-byte-offset-absolute-address-restriction">Restrictions on the Leading Dimension Absolute Address Stride</a><a class="headerlink" href="#tcgen05-leading-dimension-byte-offset-absolute-address-restriction" title="Permalink to this headline">ïƒ</a></h7>
<p>Following are the restrictions on the absolute address stride mode:</p>
<ol class="arabic simple">
<li><p>Only 128B swizzle (with 16B atomicity) is supported.</p></li>
<li><p>Only K-Major mode is supported. That is, the transpose bits(bits #15 and #16) in
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a> must be 0.</p></li>
<li><p>The matrix base offset must be 0.</p></li>
</ol>
</section>
</section>
</section>
<section id="tcgen05-stride-dimension-byte-offset">
<span id="id447"></span><h5>
<span class="section-number">9.7.16.3.2. </span><a class="reference internal" href="#tcgen05-stride-dimension-byte-offset">Stride Dimension Byte Offset</a><a class="headerlink" href="#tcgen05-stride-dimension-byte-offset" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The stride dimension byte offset is defined differently for transposed and non-transposed
matrices. The stride dimension byte offset is defined as follows for matrices whose element
types are normalized to 128-bits:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 15%">
<col style="width: 85%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-ness</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>K-Major</p></td>
<td><p>The offset from the first 8 rows to the next 8 rows.</p></td>
</tr>
<tr class="row-odd">
<td><p>MN-Major</p></td>
<td>
<ul class="simple">
<li><p>Interleave: offset from the first row to the next row.</p></li>
<li><p>Swizzled layout: offset from the first 8 columns to the next 8
columns</p></li>
</ul>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-canonical-layouts">
<span id="id448"></span><h5>
<span class="section-number">9.7.16.3.3. </span><a class="reference internal" href="#tcgen05-canonical-layouts">Canonical Layouts</a><a class="headerlink" href="#tcgen05-canonical-layouts" title="Permalink to this headline">ïƒ</a>
</h5>
<p>In terms of <a class="reference external" href="https://docs.nvidia.com/cutlass/media/docs/cpp/cute/01_layout.html">CuTe layouts</a>
the canonical layout can be expressed as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 4%">
<col style="width: 9%">
<col style="width: 21%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Major-
ness</p></th>
<th class="head"><p>Swizzling mode</p></th>
<th class="head"><p>Canonical Layout without swizzling</p></th>
<th class="head"><p><a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/bf9da7b76c766d7ee7d536afc77880a4ef1f1156/include/cute/swizzle.hpp">Swizzling</a>
on the previous column</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="4"><p>MN-
major</p></td>
<td><p>No-swizzling or
Interleaved</p></td>
<td><p>((T,1,m),(8,k)):((1,T,SBO),(1T,LBO))</p></td>
<td><p>Swizzle&lt;0, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>32B Swizzling</p></td>
<td><p>((T,2,m),(8,k)):((1,T,LBO),(2T,SBO))</p></td>
<td><p>Swizzle&lt;1, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td><p>64B Swizzling</p></td>
<td><p>((T,4,m),(8,k)):((1,T,LBO),(4T,SBO))</p></td>
<td><p>Swizzle&lt;2, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>128B Swizzling</p></td>
<td><p>((T,8,m),(8,k)):((1,T,LBO),(8T,SBO))</p></td>
<td><p>Swizzle&lt;3, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p>K-
major</p></td>
<td><p>No-swizzling or
Interleaved</p></td>
<td><p>((8,m),(T,2k)):((1T,SBO),(1,LBO))</p></td>
<td><p>Swizzle&lt;0, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>32B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((2T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;1, 4, 3&gt;</p></td>
</tr>
<tr class="row-even">
<td><p>64B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((4T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;2, 4, 3&gt;</p></td>
</tr>
<tr class="row-odd">
<td><p>128B Swizzling</p></td>
<td><p>((8,m),(T,2k)):((8T,SBO),(1,T))</p></td>
<td><p>Swizzle&lt;3, 4, 3&gt;</p></td>
</tr>
</tbody>
</table>
<p>where</p>
<ul class="simple">
<li><p>T = 128 / sizeof-elements-in-bits
T represents scale factor which normalizes matrix element types to 128-bits.</p></li>
<li><p>m represents the number of repeating patterns across rows.</p></li>
<li><p>k represents the number of repeating patterns across columns.</p></li>
</ul>
<p class="rubric">Examples</p>
<ul>
<li>
<p>K-Major, no-swizzling and tf32 type: <a class="reference internal" href="#tcgen05-k-no-swizzle-tf32"><span class="std std-numref">Figure 188</span></a></p>
<figure class="align-center" id="tcgen05-k-no-swizzle-tf32">
<img alt="_images/async-warpgroup-k-no-swizzle-tf32.png" class="image" src="_images/async-warpgroup-k-no-swizzle-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 188 </span><span class="caption-text">K major, no-swizzling and tf32 type</span><a class="headerlink" href="#tcgen05-k-no-swizzle-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;0,4,3&gt; o ((8,2),(4,4)):((4,32),(1,64))</p>
<p>Canonical Layout :Swizzle&lt;0,4,3&gt; o ((8,m),(T,2k)):((1T,SBO),(1,LBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO (relative offset)</p></td>
<td><p>64*sizeof(tf32)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>32*sizeof(tf32)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 8</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>K-Major, 32B swizzling and tf32 type: <a class="reference internal" href="#tcgen05-k-32b-swizzle-tf32"><span class="std std-numref">Figure 189</span></a></p>
<figure class="align-center" id="tcgen05-k-32b-swizzle-tf32">
<img alt="_images/async-warpgroup-k-32B-swizzle-tf32.png" class="image" src="_images/async-warpgroup-k-32B-swizzle-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 189 </span><span class="caption-text">K major, 32B swizzling and tf32 type</span><a class="headerlink" href="#tcgen05-k-32b-swizzle-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;1,4,3&gt; o ((8,2),(4,4)):((8,64),(1,4))</p>
<p>Canonical Layout :Swizzle&lt;1,4,3&gt; o ((8,m),(T,2k)):((2T,SBO),(1,T))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO (relative offset)</p></td>
<td><p>NA</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>64*sizeof(tf32)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>1 (assumed)</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 16</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, no-swizzling and bf16 type: <a class="reference internal" href="#tcgen05-mn-no-swizzle-bf16"><span class="std std-numref">Figure 190</span></a></p>
<figure class="align-center" id="tcgen05-mn-no-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-no-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-no-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 190 </span><span class="caption-text">MN major, no-swizzling and bf16 type</span><a class="headerlink" href="#tcgen05-mn-no-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;0,4,3&gt; o ((8,1,2),(8,2)):((1,8,64),(8,128))</p>
<p>Canonical Layout :Swizzle&lt;0,4,3&gt; o ((T,1,m),(8,k)):((1,T,SBO),(1T,LBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO (relative offset)</p></td>
<td><p>128*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>64*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 8</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, 32B swizzling and bf16 type: <a class="reference internal" href="#tcgen05-mn-32b-swizzle-bf16"><span class="std std-numref">Figure 191</span></a></p>
<figure class="align-center" id="tcgen05-mn-32b-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-32B-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-32B-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 191 </span><span class="caption-text">MN major, 32B swizzling and bf16 type</span><a class="headerlink" href="#tcgen05-mn-32b-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;1,4,3&gt; o ((8,2,2),(8,2)):((1,8,128),(16,256))</p>
<p>Canonical Layout :Swizzle&lt;1,4,3&gt; o ((T,2,m),(8,k)):((1,T,LBO),(2T,SBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO (relative offset)</p></td>
<td><p>128*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>256*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 16</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 32</p></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>MN-Major, 64B swizzling and bf16 type: <a class="reference internal" href="#tcgen05-mn-64b-swizzle-bf16"><span class="std std-numref">Figure 192</span></a></p>
<figure class="align-center" id="tcgen05-mn-64b-swizzle-bf16">
<img alt="_images/async-warpgroup-mn-64B-swizzle-bf16.png" class="image" src="_images/async-warpgroup-mn-64B-swizzle-bf16.png">
<figcaption>
<p><span class="caption-number">Figure 192 </span><span class="caption-text">MN major, 64B swizzling and bf16 type</span><a class="headerlink" href="#tcgen05-mn-64b-swizzle-bf16" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>the strides and related details are as follows:</p>
<p>Exact layout : Swizzle&lt;2,4,3&gt; o ((8,4,2),(8,2)):((1,8,256),(32,512))</p>
<p>Canonical Layout :Swizzle&lt;2,4,3&gt; o ((T,4,m),(8,k)):((1,T,LBO),(4T,SBO))</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>T</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p>m</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even">
<td><p>k</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd">
<td><p>LBO (relative offset)</p></td>
<td><p>256*sizeof(bf16)</p></td>
</tr>
<tr class="row-even">
<td><p>SBO</p></td>
<td><p>512*sizeof(bf16)</p></td>
</tr>
<tr class="row-odd">
<td><p>Encoding of LBO in descriptor</p></td>
<td><p>(LBO) &gt;&gt; 4 = 32</p></td>
</tr>
<tr class="row-even">
<td><p>Encoding of SBO in descriptor</p></td>
<td><p>(SBO) &gt;&gt; 4 = 64</p></td>
</tr>
</tbody>
</table>
</li>
</ul>
</section>
</section>
<section id="tcgen05-matrix-descriptors">
<span id="id449"></span><h4>
<span class="section-number">9.7.16.4. </span><a class="reference internal" href="#tcgen05-matrix-descriptors">Matrix Descriptors</a><a class="headerlink" href="#tcgen05-matrix-descriptors" title="Permalink to this headline">ïƒ</a>
</h4>
<p>There are three kinds of matrix descriptors used by the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> family of instructions.</p>
<section id="tcgen05-shared-memory-descriptor">
<span id="id450"></span><h5>
<span class="section-number">9.7.16.4.1. </span><a class="reference internal" href="#tcgen05-shared-memory-descriptor">Shared memory descriptor</a><a class="headerlink" href="#tcgen05-shared-memory-descriptor" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The shared memory descriptor describes the properties of multiplicand matrix in shared
memory including its location in the shared memory of the current <em>CTA</em>. It is a 64-bit
value contained in a register with the following layout:</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-shared-memory-desc-layout">
<caption>
<span class="caption-number">Table 40 </span><span class="caption-text">Shared memory descriptor layout</span><a class="headerlink" href="#tcgen05-shared-memory-desc-layout" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 78%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Bit-field</p></th>
<th class="head"><p>Size in bits</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>0-13</p></td>
<td><p>14</p></td>
<td><p>matrix-descriptor-encode (Matrix start address)</p></td>
</tr>
<tr class="row-odd">
<td><p>16-29</p></td>
<td><p>14</p></td>
<td>
<p>matrix-descriptor-encode
(<a class="reference internal" href="#tcgen05-leading-dimension-byte-offset"><span class="std std-ref">Leading dimension byte offset relative</span></a>)</p>
<p>OR</p>
<p>matrix-descriptor-encode
(<a class="reference internal" href="#tcgen05-leading-dimension-byte-offset"><span class="std std-ref">Leading dimension byte address absolute</span></a>)</p>
</td>
</tr>
<tr class="row-even">
<td><p>32-45</p></td>
<td><p>14</p></td>
<td><p>matrix-descriptor-encode
(<a class="reference internal" href="#tcgen05-stride-dimension-byte-offset"><span class="std std-ref">Stride dimension byte offset</span></a>)</p></td>
</tr>
<tr class="row-odd">
<td><p>46-48</p></td>
<td><p>3</p></td>
<td><p>Fixed constant value of 0b001</p></td>
</tr>
<tr class="row-even">
<td><p>49-51</p></td>
<td><p>3</p></td>
<td><p>Matrix base offset</p></td>
</tr>
<tr class="row-odd">
<td><p>52</p></td>
<td><p>1</p></td>
<td><p>Leading dimension stride mode:
- 0: byte offset relative
- 1: byte address absolute</p></td>
</tr>
<tr class="row-even">
<td><p>53-60</p></td>
<td><p>8</p></td>
<td><p>Fixed constant value of 0xb00000000</p></td>
</tr>
<tr class="row-odd">
<td><p>61-63</p></td>
<td><p>3</p></td>
<td>
<p>Specifies the swizzling mode to be used:
0. No swizzling
1. 128-Byte with 32B atomic swizzling
2. 128-Byte swizzling
4. 64-Byte swizzling
6. 32-Byte swizzling</p>
<p>Note: Values 3, 5 and 7 are invalid</p>
</td>
</tr>
</tbody>
</table>
<p>where matrix-descriptor-encode(x) = (x &amp; 0x3FFFF) &gt;&gt; 4</p>
<p>The value of base offset is 0 when the repeating pattern of the specified swizzling mode
starts as per shown in <a class="reference internal" href="#tcgen05-start-addr-swizzle-mode"><span class="std std-numref">Table 41</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-start-addr-swizzle-mode">
<caption>
<span class="caption-number">Table 41 </span><span class="caption-text">Starting address of repeating pattern for various swizzling modes</span><a class="headerlink" href="#tcgen05-start-addr-swizzle-mode" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 31%">
<col style="width: 69%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling mode</p></th>
<th class="head"><p>Starting address of the repeating pattern</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>128-Byte swizzle</p></td>
<td><p>1024-Byte boundary</p></td>
</tr>
<tr class="row-odd">
<td><p>64-Byte swizzle</p></td>
<td><p>512-Byte boundary</p></td>
</tr>
<tr class="row-even">
<td><p>32-Byte swizzle</p></td>
<td><p>256-Byte boundary</p></td>
</tr>
</tbody>
</table>
<p>Otherwise, the base offset must be a non-zero value, computed using the following formula:
<code class="docutils literal notranslate"><span class="pre">base</span> <span class="pre">offset</span> <span class="pre">=</span> <span class="pre">(pattern</span> <span class="pre">start</span> <span class="pre">addr</span> <span class="pre">&gt;&gt;</span> <span class="pre">0x7)</span> <span class="pre">&amp;</span> <span class="pre">0x7</span></code></p>
<p>The following must be 16-byte aligned:</p>
<ol class="arabic simple">
<li><p>Matrix start address</p></li>
<li><p>Leading dimension byte offset</p></li>
<li><p>Stride dimension byte offset</p></li>
</ol>
<section id="tcgen05-shared-memory-descriptor-target-isa-note">
<span id="id451"></span><h6>
<span class="section-number">9.7.16.4.1.1. </span><a class="reference internal" href="#tcgen05-shared-memory-descriptor-target-isa-note">Target ISA Note</a><a class="headerlink" href="#tcgen05-shared-memory-descriptor-target-isa-note" title="Permalink to this headline">ïƒ</a>
</h6>
<ul class="simple">
<li><p>The byte address mode for the leading dimension stride is supported on <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>.</p></li>
</ul>
</section>
</section>
<section id="tcgen05-instruction-descriptor">
<span id="id452"></span><h5>
<span class="section-number">9.7.16.4.2. </span><a class="reference internal" href="#tcgen05-instruction-descriptor">Instruction descriptor</a><a class="headerlink" href="#tcgen05-instruction-descriptor" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The instruction descriptor describes the shapes, types and other details of all the matrices
and the matrix-multiplication-and-accumulation operation. It is a 32-bit value in registers
and the exact layout is dependent on the MMA-Kind:</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-instuction-desc-kind-tf32-f16-f8f6f4">
<caption>
<span class="caption-number">Table 42 </span><span class="caption-text">Instruction descriptor format for .kind::tf32, .kind::f16, .kind::f8f6f4 and .kind::i8</span><a class="headerlink" href="#tcgen05-instuction-desc-kind-tf32-f16-f8f6f4" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 40%">
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Bits</p></th>
<th class="head" rowspan="2">
<p>Size</p>
<p>(bits)</p>
</th>
<th class="head" rowspan="2"><p>Description</p></th>
<th class="head" colspan="4"><p>Values</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.kind::tf32</p></th>
<th class="head"><p>.kind::f16</p></th>
<th class="head"><p>.kind::f8f6f4</p></th>
<th class="head"><p>.kind::i8</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p>0-1</p></td>
<td><p>2</p></td>
<td><p><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector"><span class="std std-ref">Sparsity selector</span></a>,
if Sparsity is enabled</p></td>
<td colspan="4"><p>0-3</p></td>
</tr>
<tr class="row-even">
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>Sparsity</p></td>
<td colspan="4">
<p>Dense = 0</p>
<p>Sparse = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>3</p></td>
<td><p>1</p></td>
<td><p>Saturate for integer types</p></td>
<td colspan="3"><p>0 (NA)</p></td>
<td><p>No Saturate = 0
Saturate = 1</p></td>
</tr>
<tr class="row-even">
<td><p>4-5</p></td>
<td><p>2</p></td>
<td><p>dtype (Matrix D type)</p></td>
<td><p>F32 = 1</p></td>
<td colspan="2"><p>F16 = 0
F32 = 1</p></td>
<td><p>S32 = 2</p></td>
</tr>
<tr class="row-odd">
<td><p>6</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="4"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>7-9</p></td>
<td><p>3</p></td>
<td><p>atype (Matrix A type)</p></td>
<td rowspan="2"><p>TF32 = 2</p></td>
<td rowspan="2">
<p>F16 = 0</p>
<p>BF16 = 1</p>
</td>
<td rowspan="2"><p>E4M3 = 0
E5M2 = 1
E2M3 = 3
E3M2 = 4
E2M1 = 5</p></td>
<td rowspan="2">
<p>Unsigned 8b = 0</p>
<p>Signed 8b = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>10-12</p></td>
<td><p>3</p></td>
<td><p>btype (Matrix B type)</p></td>
</tr>
<tr class="row-even">
<td><p>13</p></td>
<td><p>1</p></td>
<td><p>Negate A Matrix</p></td>
<td colspan="3" rowspan="2">
<p>No Negate = 0</p>
<p>Negate = 1</p>
</td>
<td rowspan="2"><p>No Negate = 0</p></td>
</tr>
<tr class="row-odd">
<td><p>14</p></td>
<td><p>1</p></td>
<td><p>Negate B Matrix</p></td>
</tr>
<tr class="row-even">
<td><p>15</p></td>
<td><p>1</p></td>
<td><p>Transpose A Matrix</p></td>
<td colspan="4" rowspan="2">
<p>No Transpose = 0</p>
<p>Transpose = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>16</p></td>
<td><p>1</p></td>
<td><p>Transpose B Matrix</p></td>
</tr>
<tr class="row-even">
<td><p>17-22</p></td>
<td><p>6</p></td>
<td><p>N, Dimension of Matrix B
(3 LSBs not included)</p></td>
<td colspan="4"><p>N &gt;&gt; 3</p></td>
</tr>
<tr class="row-odd">
<td><p>23</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="4"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>24-28</p></td>
<td><p>5</p></td>
<td><p>M, Dimension of Matrix A
(4 LSBs not included)</p></td>
<td colspan="4"><p>M &gt;&gt; 4</p></td>
</tr>
<tr class="row-odd">
<td><p>29</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="4"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>30-31</p></td>
<td><p>2</p></td>
<td><p>Maximum shift while attempting
B matrix -reuse in <code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td colspan="4"><p>no shift = 0
maximum shift of 8 = 1
maximum shift of 16 = 2
maximum shift of 32 = 3</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="tcgen05-instuction-desc-kind-mxf8f6f4">
<caption>
<span class="caption-number">Table 43 </span><span class="caption-text">Instruction descriptor format for .kind::mxf8f6f4</span><a class="headerlink" href="#tcgen05-instuction-desc-kind-mxf8f6f4" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 58%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Bits</p></th>
<th class="head" rowspan="2">
<p>Size</p>
<p>(bits)</p>
</th>
<th class="head" rowspan="2"><p>Description</p></th>
<th class="head"><p>Values</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.kind::mxf8f6f4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p>0-1</p></td>
<td><p>2</p></td>
<td><p>Reserved</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>Sparsity</p></td>
<td>
<p>Dense = 0</p>
<p>Sparse = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>3</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>4-5</p></td>
<td><p>2</p></td>
<td><p><a class="reference internal" href="#tcgen05-mma-scale-factor-b"><span class="std std-ref">Matrix B Scale Factor Data ID</span></a></p></td>
<td><p>0-3</p></td>
</tr>
<tr class="row-odd">
<td><p>6</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>7-9</p></td>
<td><p>3</p></td>
<td><p>atype (Matrix A type)</p></td>
<td rowspan="2"><p>E4M3 = 0
E5M2 = 1
E2M3 = 3
E3M2 = 4
E2M1 = 5</p></td>
</tr>
<tr class="row-odd">
<td><p>10-12</p></td>
<td><p>3</p></td>
<td><p>btype (Matrix B type)</p></td>
</tr>
<tr class="row-even">
<td><p>13</p></td>
<td><p>1</p></td>
<td><p>Negate A Matrix</p></td>
<td rowspan="2">
<p>No Negate = 0</p>
<p>Negate = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>14</p></td>
<td><p>1</p></td>
<td><p>Negate B Matrix</p></td>
</tr>
<tr class="row-even">
<td><p>15</p></td>
<td><p>1</p></td>
<td><p>Transpose A Matrix</p></td>
<td rowspan="2">
<p>No Transpose = 0</p>
<p>Transpose = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>16</p></td>
<td><p>1</p></td>
<td><p>Transpose B Matrix</p></td>
</tr>
<tr class="row-even">
<td><p>17-22</p></td>
<td><p>6</p></td>
<td><p>N, Dimension of Matrix B
(3 LSBs not included)</p></td>
<td><p>N &gt;&gt; 3</p></td>
</tr>
<tr class="row-odd">
<td><p>23</p></td>
<td><p>1</p></td>
<td><p>Scale Matrix Type, for both scale_A /
scale_B</p></td>
<td><p>UE8M0 = 1</p></td>
</tr>
<tr class="row-even">
<td><p>24-26</p></td>
<td><p>3</p></td>
<td><p>Reserved</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td><p>27-28</p></td>
<td><p>2</p></td>
<td><p>M, Dimension of Matrix A
(7 LSBs not included)</p></td>
<td><p>M &gt;&gt; 7</p></td>
</tr>
<tr class="row-even">
<td><p>29-30</p></td>
<td><p>2</p></td>
<td><p><a class="reference internal" href="#tcgen05-mma-scale-factor-a"><span class="std std-ref">Matrix A Scale Factor Data ID</span></a></p></td>
<td><p>0-3</p></td>
</tr>
<tr class="row-odd">
<td><p>31</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="tcgen05-instuction-desc-kind-mxf4-mxf4nvf4">
<caption>
<span class="caption-number">Table 44 </span><span class="caption-text">Instruction descriptor format for .kind::mxf4 and .kind::mxf4nvf4</span><a class="headerlink" href="#tcgen05-instuction-desc-kind-mxf4-mxf4nvf4" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 9%">
<col style="width: 8%">
<col style="width: 47%">
<col style="width: 18%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Bits</p></th>
<th class="head" rowspan="2">
<p>Size</p>
<p>(bits)</p>
</th>
<th class="head" rowspan="2"><p>Description</p></th>
<th class="head" colspan="2"><p>Values</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.kind::mxf4</p></th>
<th class="head"><p>.kind::mxf4nvf4</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p>0-1</p></td>
<td><p>2</p></td>
<td><p>Reserved</p></td>
<td colspan="2"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>2</p></td>
<td><p>1</p></td>
<td><p>Sparsity</p></td>
<td colspan="2">
<p>Dense = 0</p>
<p>Sparse = 1</p>
</td>
</tr>
<tr class="row-odd">
<td><p>3</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="2"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>4-5</p></td>
<td><p>2</p></td>
<td><p><a class="reference internal" href="#tcgen05-mma-scale-factor-b"><span class="std std-ref">Matrix B Scale Factor Data ID</span></a></p></td>
<td colspan="2"><p>0 or 2</p></td>
</tr>
<tr class="row-odd">
<td><p>6</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="2"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>7-9</p></td>
<td><p>3</p></td>
<td><p>atype (Matrix A type)</p></td>
<td colspan="2" rowspan="2"><p>E2M1 = 1</p></td>
</tr>
<tr class="row-odd">
<td><p>10-11</p></td>
<td><p>2</p></td>
<td><p>btype (Matrix B type)</p></td>
</tr>
<tr class="row-even">
<td><p>12</p></td>
<td><p>1</p></td>
<td><p>Reserved</p></td>
<td colspan="2"><p>0</p></td>
</tr>
<tr class="row-odd">
<td><p>13</p></td>
<td><p>1</p></td>
<td><p>Negate A Matrix</p></td>
<td colspan="2" rowspan="2">
<p>No Negate = 0</p>
<p>Negate = 1</p>
</td>
</tr>
<tr class="row-even">
<td><p>14</p></td>
<td><p>1</p></td>
<td><p>Negate B Matrix</p></td>
</tr>
<tr class="row-odd">
<td><p>15</p></td>
<td><p>1</p></td>
<td><p>Transpose A Matrix</p></td>
<td colspan="2" rowspan="2"><p>No Transpose = 0</p></td>
</tr>
<tr class="row-even">
<td><p>16</p></td>
<td><p>1</p></td>
<td><p>Transpose B Matrix</p></td>
</tr>
<tr class="row-odd">
<td><p>17-22</p></td>
<td><p>6</p></td>
<td><p>N, Dimension of Matrix B
(3 LSBs not included)</p></td>
<td colspan="2"><p>N &gt;&gt; 3</p></td>
</tr>
<tr class="row-even">
<td><p>23</p></td>
<td><p>1</p></td>
<td><p>Scale Matrix Type, for both scale_A /
scale_B</p></td>
<td><p>UE8M0 = 1</p></td>
<td><p>UE4M3 = 0</p></td>
</tr>
<tr class="row-odd">
<td><p>24-26</p></td>
<td><p>3</p></td>
<td><p>Reserved</p></td>
<td colspan="2"><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>27-28</p></td>
<td><p>2</p></td>
<td><p>M, Dimension of Matrix A
(7 LSBs not included)</p></td>
<td colspan="2"><p>M &gt;&gt; 7</p></td>
</tr>
<tr class="row-odd">
<td><p>29-30</p></td>
<td><p>2</p></td>
<td><p><a class="reference internal" href="#tcgen05-mma-scale-factor-a"><span class="std std-ref">Matrix A Scale Factor Data ID</span></a></p></td>
<td colspan="2"><p>0 or 2</p></td>
</tr>
<tr class="row-even">
<td><p>31</p></td>
<td><p>1</p></td>
<td><p>K Dimension</p></td>
<td colspan="2">
<p>(Dense K=64 / Sparse K=128) = 0</p>
<p>(Dense K=96) = 1</p>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-zero-column-mask-descriptor">
<span id="id453"></span><h5>
<span class="section-number">9.7.16.4.3. </span><a class="reference internal" href="#tcgen05-zero-column-mask-descriptor">Zero-Column Mask Descriptor</a><a class="headerlink" href="#tcgen05-zero-column-mask-descriptor" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The zero-column mask descriptor is used to generate a mask that specifies which columns of
<code class="docutils literal notranslate"><span class="pre">B</span></code> matrix will have zero value for the MMA operation regardless of the values present in
the shared memory. The total size of the generated mask is N-bits.</p>
<p>A 0-bit in the mask specifies that values of the corresponding column in matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> should
be used for the MMA operation. A 1-bit in the mask specifies 0s must be used for the entire
column for the MMA operation.</p>
<p>The zero-column mask descriptor is a 64-bit value in registers with the following layout:</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-zero-column-mask-desc">
<caption>
<span class="caption-number">Table 45 </span><span class="caption-text">Zero-Column Mask descriptor layout</span><a class="headerlink" href="#tcgen05-zero-column-mask-desc" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 21%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Bits</p></th>
<th class="head"><p>Size (bits)</p></th>
<th class="head"><p>Field Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>0-7</p></td>
<td><p>8</p></td>
<td><p>Start Count 0 (sc0)</p></td>
<td rowspan="4">
<p>Specifies the LSBs that must be skipped</p>
<p>for sub-mask mask-i</p>
</td>
</tr>
<tr class="row-odd">
<td><p>8-15</p></td>
<td><p>8</p></td>
<td><p>Start Count 1 (sc1)</p></td>
</tr>
<tr class="row-even">
<td><p>16-23</p></td>
<td><p>8</p></td>
<td><p>Start Count 2 (sc2)</p></td>
</tr>
<tr class="row-odd">
<td><p>24-31</p></td>
<td><p>8</p></td>
<td><p>Start Count 3 (sc3)</p></td>
</tr>
<tr class="row-even">
<td><p>32</p></td>
<td><p>1</p></td>
<td><p>First Span 0 (fs0)</p></td>
<td rowspan="4">
<p>Specifies the starting value for</p>
<p>sub-mask mask-i</p>
</td>
</tr>
<tr class="row-odd">
<td><p>33</p></td>
<td><p>1</p></td>
<td><p>First Span 1 (fs1)</p></td>
</tr>
<tr class="row-even">
<td><p>34</p></td>
<td><p>1</p></td>
<td><p>First Span 2 (fs2)</p></td>
</tr>
<tr class="row-odd">
<td><p>35</p></td>
<td><p>1</p></td>
<td><p>First Span 3 (fs3)</p></td>
</tr>
<tr class="row-even">
<td><p>36-38</p></td>
<td><p>3</p></td>
<td><p>Reserved</p></td>
<td></td>
</tr>
<tr class="row-odd">
<td><p>39</p></td>
<td><p>1</p></td>
<td><p>Non-Zero Mask</p></td>
<td><p>Value 0 indicates generated mask will have all 0s
Value 1 indicates the mask has to be generated</p></td>
</tr>
<tr class="row-even">
<td><p>40-47</p></td>
<td><p>8</p></td>
<td><p>Skip Span</p></td>
<td><p>(Count of consecutive columns where B matrix is used) - 1</p></td>
</tr>
<tr class="row-odd">
<td><p>48-55</p></td>
<td><p>8</p></td>
<td><p>Use Span</p></td>
<td><p>(Count of consecutive columns where 0s ar used) - 1</p></td>
</tr>
<tr class="row-even">
<td><p>56-61</p></td>
<td><p>6</p></td>
<td><p>Column Shift</p></td>
<td><p>Shifts column by specified amount.
Thus allows MMA on non-0 starting column.
Max shift amount = 16 for M=32
Max shift amount = 32 otherwise</p></td>
</tr>
</tbody>
</table>
<p>The zero-column mask is made up of one or more sub-mask depending on M, as shown in the table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 5%">
<col style="width: 44%">
<col style="width: 14%">
<col style="width: 17%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>M</p></th>
<th class="head"><p>Zero-Column Mask breakup</p></th>
<th class="head"><p>Sub-masks</p></th>
<th class="head"><p>First Span used</p></th>
<th class="head"><p>Start Column used</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>128</p></td>
<td><p>Single sub-mask of size N-bits</p></td>
<td><p>mask0</p></td>
<td><p>fs0</p></td>
<td><p>sc0</p></td>
</tr>
<tr class="row-odd">
<td><p>64</p></td>
<td><p>Two sub-masks, each with size of N/2 bits</p></td>
<td><p>mask0, mask1</p></td>
<td><p>fs0, fs1</p></td>
<td><p>sc0, sc1</p></td>
</tr>
<tr class="row-even">
<td><p>32</p></td>
<td><p>Four sub-masks, each with size of N/4 bits</p></td>
<td><p>mask0, mask1
mask2, mask3</p></td>
<td><p>fs0, fs1, fs2,
fs3</p></td>
<td><p>sc0, sc1, sc2,
sc3</p></td>
</tr>
</tbody>
</table>
<p>The following table shows the coverage of the sub-masks across N-dimension:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 24%">
<col style="width: 27%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>Sub-mask</p></th>
<th class="head" colspan="3"><p>M</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>128</p></th>
<th class="head"><p>64</p></th>
<th class="head"><p>32</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p>mask0</p></td>
<td><p>Columns [0, N-1]</p></td>
<td><p>Columns [0, N/2-1]</p></td>
<td><p>Columns [0, N/4-1]</p></td>
</tr>
<tr class="row-even">
<td><p>mask1</p></td>
<td><p>â€“</p></td>
<td><p>Columns [N/2, N-1]</p></td>
<td><p>Columns [N/4, N/2-1]</p></td>
</tr>
<tr class="row-odd">
<td><p>mask2</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>Columns [N/2, (N/4*3)-1]</p></td>
</tr>
<tr class="row-even">
<td><p>mask3</p></td>
<td><p>â€“</p></td>
<td><p>â€“</p></td>
<td><p>Columns [(N/4*3), N-1]</p></td>
</tr>
</tbody>
</table>
<p>The following examples shows zero-column mask descriptor and their corresponding mask generated:</p>
<ol class="arabic">
<li>
<p>Example 1: M = 128</p>
<p>Input zero-column mask descriptor:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 21%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Start count</p></th>
<th class="head"><p>First span</p></th>
<th class="head"><p>Non-Zero Mask</p></th>
<th class="head"><p>Skip Span</p></th>
<th class="head"><p>Use Span</p></th>
<th class="head"><p>Shift</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>{0, 0, 0, 0}</p></td>
<td><p>{0, 0, 0, 0}</p></td>
<td><p>0</p></td>
<td><p>4</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>Output zero-column mask: 0x0.</p>
<p>As Non-Zero Mask field is 0, the mask is 0x0. All the columns of the matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> will be used
for the MMA operation.</p>
</li>
<li>
<p>Example 2: M = 128</p>
<p>Input zero-column mask descriptor:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 21%">
<col style="width: 15%">
<col style="width: 14%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Start count</p></th>
<th class="head"><p>First span</p></th>
<th class="head"><p>Non-Zero Mask</p></th>
<th class="head"><p>Skip Span</p></th>
<th class="head"><p>Use Span</p></th>
<th class="head"><p>Shift</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>{-, -, -, 0}</p></td>
<td><p>{-, -, -, 0}</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>Output mask0: 0b â€¦ 111 0000 111 0000 (size = N)</p>
</li>
<li>
<p>Example 3: M = 64</p>
<p>Input zero-column mask descriptor:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 21%">
<col style="width: 21%">
<col style="width: 20%">
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Start count
{.., sc1, sc0}</p></th>
<th class="head"><p>First span
{.., fs1, fs0}</p></th>
<th class="head"><p>Non-Zero Mask</p></th>
<th class="head"><p>Skip Span</p></th>
<th class="head"><p>Use Span</p></th>
<th class="head"><p>Shift</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>{-, -, 0, 0}</p></td>
<td><p>{-, -, 0, 1}</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>Output mask0: 0b â€¦   111 0000 111 0000 111</p>
<p>Output masl1: 0b â€¦ 0000 111 0000 111 0000</p>
</li>
<li>
<p>Example 4: M = 32</p>
<p>Input zero-column mask descriptor:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 17%">
<col style="width: 13%">
<col style="width: 11%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Start count
{sc3, sc2, sc1, sc0}</p></th>
<th class="head"><p>First span
{fs3, fs2, fs1, fs0}</p></th>
<th class="head"><p>Non-Zero Mask</p></th>
<th class="head"><p>Skip Span</p></th>
<th class="head"><p>Use Span</p></th>
<th class="head"><p>Shift</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>{1, 2, 1, 0}</p></td>
<td><p>{0, 0, 1, 1}</p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>3</p></td>
<td><p>2</p></td>
</tr>
</tbody>
</table>
<p>Output mask0: 0b â€¦ 0000 111 0000 111</p>
<p>Output mask1: 0b â€¦ 0000 111 0000 11</p>
<p>Output mask2: 0b â€¦ 111 0000 111 00</p>
<p>Output mask3: 0b â€¦ 111 0000 111 000</p>
<p>If N = 128 then <code class="docutils literal notranslate"><span class="pre">B</span></code> Matrix with columns from 2 to 129 will be used for the MMA operation,
due to the shift of 2.</p>
</li>
</ol>
</section>
</section>
<section id="tcgen05-issue-granularity">
<span id="id454"></span><h4>
<span class="section-number">9.7.16.5. </span><a class="reference internal" href="#tcgen05-issue-granularity">Issue Granularity</a><a class="headerlink" href="#tcgen05-issue-granularity" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Each of the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation has different requirements for the number of
threads/warps that needs to issue them.</p>
<p>The following table lists the execution granularity requirements of each of the
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation:</p>
<table class="table-no-stripes longtable docutils align-default" id="tcgen05-ops-execution-granularity">
<caption>
<span class="caption-number">Table 46 </span><span class="caption-text">Execution granularity requirements for tcgen05 operations</span><a class="headerlink" href="#tcgen05-ops-execution-granularity" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 33%">
<col style="width: 12%">
<col style="width: 55%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>tcgen05 operation</p></th>
<th class="head"><p>.cta_group</p></th>
<th class="head"><p>Issue Granularity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">mma</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">cp</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">shift</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">commit</span><span class="w"></span>
</pre></div>
</div>
</td>
<td><p>::1</p></td>
<td><p>An issue from a single thread in the current
CTA would initiate the base operation.</p></td>
</tr>
<tr class="row-odd">
<td><p>::2</p></td>
<td><p>Issue from a single thread from the
<a class="reference internal" href="#tcgen05-cta-pair"><span class="std std-ref">CTA-Pair</span></a> would initiate
the base operation.
When the current CTA issues the operation, the peer
CTA should be active and should not have exited.</p></td>
</tr>
<tr class="row-even">
<td rowspan="2">
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">alloc</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">dealloc</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">relinquish_alloc_permit</span><span class="w"></span>
</pre></div>
</div>
</td>
<td><p>::1</p></td>
<td><p>Issue from a single warp in the current CTA
would initiate the allocation management instruction.</p></td>
</tr>
<tr class="row-odd">
<td><p>::2</p></td>
<td><p>Issue from two warps, one in each of the current CTA
and its <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">Peer CTA</span></a>, in order to
collectively perform the operation, i.e., the first
warp to perform the operation could block until the
the second warp in the <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">Peer CTA</span></a>
also performs the operation (see examples below).</p></td>
</tr>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">ld</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">st</span><span class="p">,</span><span class="w"></span>
<span class="p">.</span><span class="n">wait</span><span class="o">::</span><span class="p">{</span><span class="n">ld</span><span class="p">,</span><span class="w"> </span><span class="n">st</span><span class="p">}</span><span class="w"></span>
</pre></div>
</div>
</td>
<td><p>N/A</p></td>
<td><p>Issue from a warp in the current CTA can access only
1/4 of the Tensor Memory of the current CTA. So, a
warpgroup is needed to access the entire Tensor Memory
of the current CTA.</p></td>
</tr>
<tr class="row-odd">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="p">.</span><span class="n">fence</span><span class="o">::*</span><span class="w"></span>
</pre></div>
</div>
</td>
<td><p>N/A</p></td>
<td><p>A thread needs to fence all its accesses to the tensor
memory that it wants to order with other accesses to
the tensor memory from other threads.</p></td>
</tr>
</tbody>
</table>
<p>The following example shows that:</p>
<ul class="simple">
<li><p>Before attempting to deallocate Tensor Memory, it suffices to ensure that there are no concurrent
Tensor Memory accesses from the <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">Peer CTA</span></a>.</p></li>
<li><p>Warps can immediately exit after deallocating Tensor Memory; no extra synchronization required.</p></li>
</ul>
<table class="table-no-stripes longtable docutils align-default" id="tcgen05-example-deallocate-before-exit">
<caption>
<span class="caption-number">Table 47 </span><span class="caption-text">Example of deallocating Tensor Memory before CTA exit.</span><a class="headerlink" href="#tcgen05-example-deallocate-before-exit" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>CTA0 Warp</p></th>
<th class="head"><p>CTA1 Warp</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>barrier.cluster.arrive;
barrier.cluster.wait;
tcgen05.dealloc.2cta.sync.aligned;
exit;</p></td>
<td><p>barrier.cluster.arrive;
barrier.cluster.wait;
tcgen05.dealloc.2cta.sync.aligned;
exit;</p></td>
</tr>
</tbody>
</table>
<p>This example uses a cluster barrier for illustration purposes but in practice other
synchronization mechanisms are often used.</p>
<p>The following example illustrates a scenario in which the program exhibits non-deterministic
behavior due to incorrect synchronizaton because <code class="docutils literal notranslate"><span class="pre">.dealloc</span></code> may or may not block:</p>
<table class="table-no-stripes longtable docutils align-default" id="tcgen05-example-non-deterministic-deallocation-hang">
<caption>
<span class="caption-number">Table 48 </span><span class="caption-text">Example of non-determinstic hang due to incorrect synchronization</span><a class="headerlink" href="#tcgen05-example-non-deterministic-deallocation-hang" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>CTA0 Warp</p></th>
<th class="head"><p>CTA1 Warp</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>barrier.cluster.arrive;
barrier.cluster.wait;
tcgen05.dealloc.2cta.sync.aligned;
exit;</p></td>
<td><p>tcgen05.dealloc.2cta.sync.aligned;
barrier.cluster.arrive;
barrier.cluster.wait;
exit;</p></td>
</tr>
</tbody>
</table>
<section id="tcgen05-cta-pair">
<span id="id455"></span><h5>
<span class="section-number">9.7.16.5.1. </span><a class="reference internal" href="#tcgen05-cta-pair">CTA Pair</a><a class="headerlink" href="#tcgen05-cta-pair" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Any 2 CTAs within the cluster whose <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code> differs by the last bit only
is said to form a CTA pair.</p>
<p>Within a CTA pair, the CTA whose last bit in the <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code> is:</p>
<ul class="simple">
<li><p>0 is termed the even numbered CTA within the CTA pair.</p></li>
<li><p>1 is termed as the odd numbered CTA within the CTA pair.</p></li>
</ul>
<p>Most of the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations can either execute at a single CTA level granularity OR
at a CTA pair level granularity. When a <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation is performed at CTA pair
granularity, the Tensor Memory of both the CTAs within the CTA pair are accessed. The set
of threads that need to issue the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation is listed in the
<a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a>.</p>
</section>
<section id="tcgen05-peer-cta">
<span id="id456"></span><h5>
<span class="section-number">9.7.16.5.2. </span><a class="reference internal" href="#tcgen05-peer-cta">Peer CTA</a><a class="headerlink" href="#tcgen05-peer-cta" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The peer CTA of the odd CTA within the CTA pair is the even CTA in the same pair.
Similarly, the peer CTA of the even CTA within the CTA pair is the odd CTA in the same pair.</p>
</section>
</section>
<section id="tcgen05-memory-consistency-model">
<span id="id457"></span><h4>
<span class="section-number">9.7.16.6. </span><a class="reference internal" href="#tcgen05-memory-consistency-model">Memory Consistency Model for 5th generation of TensorCore operations</a><a class="headerlink" href="#tcgen05-memory-consistency-model" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Ordering of <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions is described in terms of two key concepts:</p>
<ol class="arabic simple">
<li><p>Pipelined tcgen05 instructions</p></li>
<li><p>Specialized tcgen05-specific inter-thread synchronization mechanisms.</p></li>
</ol>
<p>These concepts combine to form four canonical synchronization patterns, as described further below.</p>
<section id="tcgen05-memory-consistency-model-async-operations">
<span id="id458"></span><h5>
<span class="section-number">9.7.16.6.1. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-async-operations">Asynchronous Operations</a><a class="headerlink" href="#tcgen05-memory-consistency-model-async-operations" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The tcgen05 family of instructions are divided into 2 categories:</p>
<ol class="arabic">
<li>
<p>Asynchronous instructions:</p>
<p>These <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations are not inherently ordered with respect to
other <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations in the same thread (unless pipelined as mentioned below).</p>
</li>
<li>
<p>Synchronous instructions:</p>
<p>These <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations are inherently ordered with respect to other <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code>
operations in the same order.</p>
<p>The Tensor Memory allocation related instructions that access shared memory maintain
same-address ordering with respect to non-<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions.</p>
</li>
</ol>
<p>The following table lists the category of each of the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instruction:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 53%">
<col style="width: 47%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>tcgen05.* operation</p></th>
<th class="head"><p>Category</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.alloc</span></code></p></td>
<td rowspan="6">
<p>Synchronous</p>
<p>instructions</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.dealloc</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.relinquish_alloc_permit</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.fence::*</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.wait::*</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.commit</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.mma</span></code></p></td>
<td rowspan="5">
<p>Asynchronous</p>
<p>instructions</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.cp</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.shift</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.ld</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.st</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-memory-consistency-model-pipelined-instructions">
<span id="id459"></span><h5>
<span class="section-number">9.7.16.6.2. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-pipelined-instructions">Pipelined tcgen05 Instructions</a><a class="headerlink" href="#tcgen05-memory-consistency-model-pipelined-instructions" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations may execute and complete in a different order than they
were issued. However, some specific pairs of the asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions form
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> pipelines, where in the two asynchronous operations are guaranteed to execute in
the same order as the instructions that issued them. The specific pairings are as follows:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> (same N and accumulator and shape)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.copy.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> (same N)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.shift.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> (same N)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.shift.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.cp.4x256b.cta_group::N</span></code> (same N)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.shift.cta_group::N</span></code> (same N)</p></li>
</ol>
<section id="tcgen05-memory-consistency-model-pipelined-instructions-implicit">
<span id="id460"></span><h6>
<span class="section-number">9.7.16.6.2.1. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-pipelined-instructions-implicit">Implicitly pipelined tcgen05 Instructions</a><a class="headerlink" href="#tcgen05-memory-consistency-model-pipelined-instructions-implicit" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code> are implicitly pipelined with respect
to previously issued <code class="docutils literal notranslate"><span class="pre">tcgen05.{mma,cp,shift}</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.{ld,st}</span></code> instructions
respectively that they track from the same thread.</p>
<section id="tcgen05-memory-consistency-model-mbarrier-completion">
<span id="id461"></span><h7><span class="section-number">9.7.16.6.2.1.1. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-mbarrier-completion">mbarrier based completion mechanism</a><a class="headerlink" href="#tcgen05-memory-consistency-model-mbarrier-completion" title="Permalink to this headline">ïƒ</a></h7>
<p>Completion of the following instructionâ€™s asynchronous operations is observed
through the mbarrier based waiting mechanism:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code></p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code> is used to track the completion of the above asynchronous instructions.</p>
<p>Following are the implicitly pipelined <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instruction pairing that uses mbarrier
based completion mechanism:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.commit.cta_group::N</span></code> (same N)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.cp.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.commit.cta_group::N</span></code> (same N)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.shift.cta_group::N</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.commit.cta_group::N</span></code> (same N)</p></li>
</ul>
</section>
<section id="tcgen05-memory-consistency-model-wait-completion">
<span id="id462"></span><h7><span class="section-number">9.7.16.6.2.1.2. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-wait-completion"><code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code> instruction based completion mechanism</a><a class="headerlink" href="#tcgen05-memory-consistency-model-wait-completion" title="Permalink to this headline">ïƒ</a></h7>
<p>Completion of the following instructionâ€™s asynchronous operations is observed through
<code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code> based waiting mechanism:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.wait::ld</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::st</span></code> is used to track the completion of the
<code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> asynchronous instructions.</p>
<p>Following are the implicitly pipelined <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instruction pairing that uses
<code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code> based completion mechanism:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::ld</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::st</span></code></p></li>
</ul>
</section>
</section>
</section>
<section id="tcgen05-memory-consistency-model-inter-thread-sync">
<span id="id463"></span><h5>
<span class="section-number">9.7.16.6.3. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-inter-thread-sync">Specialized Inter-thread Synchronization for tcgen05 instructions</a><a class="headerlink" href="#tcgen05-memory-consistency-model-inter-thread-sync" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions support a specialized inter-thread synchronization which are
optimized for <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> family of instructions. The standard memory consistency model
synchronization mechanisms also apply to the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> family of instructions.</p>
<p>The <a class="reference internal" href="#tcgen05-special-sync-operations"><span class="std std-ref">TensorCore 5th Generation Specialized Synchronization Operations</span></a> section contains the specialized inter-thread
synchronization for tcgen05 instructions.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::before_thread_sync</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::after_thread_sync</span></code> composes
with execution ordering instructions, like morally strong <code class="docutils literal notranslate"><span class="pre">ld</span></code>/<code class="docutils literal notranslate"><span class="pre">st</span></code>/<code class="docutils literal notranslate"><span class="pre">atom</span></code> instructions,
<code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> instruction, <code class="docutils literal notranslate"><span class="pre">barrier</span></code> instructions and so on, to establish an ordering between
the <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations across threads. The asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions that are
ordered across threads also form a <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> pipeline.</p>
<p>An asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation prior to a <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::before_thread_sync</span></code> is ordered
before all subsequent <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> and the execution ordering operations.</p>
<p>An asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation subsequent to a <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::after_thread_sync</span></code> is
ordered after all the prior <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> and the execution ordering operations.</p>
</section>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns">
<span id="id464"></span><h5>
<span class="section-number">9.7.16.6.4. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns">Canonical synchronization patterns</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Using the above rules, the following are the five canonical synchronization patterns:</p>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-same-thread">
<span id="id465"></span><h6>
<span class="section-number">9.7.16.6.4.1. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-same-thread">Pipelined instructions, same thread</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-same-thread" title="Permalink to this headline">ïƒ</a>
</h6>
<p>In this pattern, no explicit ordering mechanism is needed and the ordering guarantee is
provided by the pipelined instruction pairing.</p>
<p>Example:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma
tcgen05.mma (same shape and accumulator)
</pre></div>
</div>
<p>The two instructions will be executed in program order.</p>
</section>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-same-thread">
<span id="id466"></span><h6>
<span class="section-number">9.7.16.6.4.2. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-same-thread">Non-pipelined instructions, same thread</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-same-thread" title="Permalink to this headline">ïƒ</a>
</h6>
<p>In this pattern, explicit waiting mechanisms are used to wait for the completion of the
asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations.</p>
<p>Example 1:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.st
tcgen05.wait::st
tcgen05.ld
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.wait::st</span></code> is used to wait for the completion of the prior asynchronous
instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>.</p>
<p>Example 2:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma [d], ...
tcgen05.commit.mbarrier::arrive::one
mbarrier.try_wait.relaxed.cluster (loop until successful)
tcgen05.fence::after_thread_sync
tcgen05.ld [d], ...
</pre></div>
</div>
<p>For the completion of the asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code> is used.</p>
<p>As <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> is an asynchronous operation, the instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::after_thread_sync</span></code>
is needed.</p>
<p>No explicit <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::before_thread_sync</span></code> is needed as this is implicitly performed by
<code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code>. The combination of <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code> forms a
conceptual asynchronous pipeline and establishes execution ordering.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma [d], ...
tcgen05.fence::before_thread_sync
mbarrier::arrive
</pre></div>
</div>
</section>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-diff-thread">
<span id="id467"></span><h6>
<span class="section-number">9.7.16.6.4.3. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-diff-thread">Pipelined instructions, different thread</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-pipelined-diff-thread" title="Permalink to this headline">ïƒ</a>
</h6>
<p>In this pattern, no explicit waiting mechanism is needed but proper synchronization between threads is needed.</p>
<p>Example:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 40%">
<col style="width: 60%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Thread 0</p></th>
<th class="head"><p>Thread 1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">tcgen05</span><span class="p">.</span><span class="n">cp</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">before_thread_sync</span><span class="w"></span>
<span class="n">mbarrier</span><span class="p">.</span><span class="n">arrive</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"></span>
</pre></div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd">
<td></td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">mbarrier</span><span class="p">.</span><span class="n">try_wait</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"> </span><span class="c1">// loop till success</span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">after_thread_sync</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">mma</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-diff-thread">
<span id="id468"></span><h6>
<span class="section-number">9.7.16.6.4.4. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-diff-thread">Non-pipelined instructions, different thread</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-non-pipelined-diff-thread" title="Permalink to this headline">ïƒ</a>
</h6>
<p>In this pattern, the producer threads that issue the asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions
must explicitly wait for the instructionsâ€™ completion before synchronizing with the consumer threads.</p>
<p>Example 1:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 40%">
<col style="width: 60%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Thread 0</p></th>
<th class="head"><p>Thread 1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">tcgen05</span><span class="p">.</span><span class="n">ld</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">wait</span><span class="o">::</span><span class="n">ld</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">before_thread_sync</span><span class="w"></span>
<span class="n">mbarrier</span><span class="p">.</span><span class="n">arrive</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"></span>
</pre></div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd">
<td></td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">mbarrier</span><span class="p">.</span><span class="n">try_wait</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"> </span><span class="c1">// loop till success</span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">after_thread_sync</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">mma</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>Example 1:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 42%">
<col style="width: 58%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Thread 0</p></th>
<th class="head"><p>Thread 1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">tcgen05</span><span class="p">.</span><span class="n">mma</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">commit</span><span class="p">.</span><span class="n">mbarrier</span><span class="o">::</span><span class="n">arrive</span><span class="o">::</span><span class="n">one</span><span class="w"> </span><span class="p">[</span><span class="n">mbar</span><span class="p">]</span><span class="w"></span>
</pre></div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd">
<td></td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">mbarrier</span><span class="p">.</span><span class="n">try_wait</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"> </span><span class="p">[</span><span class="n">mbar</span><span class="p">]</span><span class="w"> </span><span class="c1">// loop till success</span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">after_thread_sync</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">ld</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>The synchronization mechanisms can also be composed with each other. For example:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Thread 0</p></th>
<th class="head"><p>Thread 1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">tcgen05</span><span class="p">.</span><span class="n">mma</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">commit</span><span class="p">.</span><span class="n">mbarrier</span><span class="o">::</span><span class="n">arrive</span><span class="o">::</span><span class="n">one</span><span class="w"> </span><span class="p">[</span><span class="n">bar1</span><span class="p">]</span><span class="w"></span>
<span class="n">mbarrier</span><span class="p">.</span><span class="n">try_wait</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"> </span><span class="p">[</span><span class="n">bar1</span><span class="p">]</span><span class="w"> </span><span class="c1">// loop</span>
<span class="p">...</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">after_thread_sync</span><span class="w"></span>
<span class="p">...</span><span class="c1">// completion is guaranteed</span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">before_thread_sync</span><span class="w"></span>
<span class="n">mbarrier</span><span class="p">.</span><span class="n">arrive</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w">   </span><span class="p">[</span><span class="n">bar2</span><span class="p">]</span><span class="w"> </span><span class="c1">// loop</span>
<span class="p">...</span><span class="w"></span>
</pre></div>
</div>
</td>
<td></td>
</tr>
<tr class="row-odd">
<td></td>
<td>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="n">mbarrier</span><span class="p">.</span><span class="n">try_wait</span><span class="p">.</span><span class="n">relaxed</span><span class="p">.</span><span class="n">cluster</span><span class="w"> </span><span class="p">[</span><span class="n">bar2</span><span class="p">]</span><span class="w"> </span><span class="c1">// loop</span>
<span class="p">...</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">fence</span><span class="o">::</span><span class="n">after_thread_sync</span><span class="w"></span>
<span class="n">tcgen05</span><span class="p">.</span><span class="n">ld</span><span class="w"></span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-memory-consistency-model-canonical-sync-patterns-reg-dependency-same-thread">
<span id="id469"></span><h6>
<span class="section-number">9.7.16.6.4.5. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-reg-dependency-same-thread">Register dependencies, same thread</a><a class="headerlink" href="#tcgen05-memory-consistency-model-canonical-sync-patterns-reg-dependency-same-thread" title="Permalink to this headline">ïƒ</a>
</h6>
<p>For <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code>, an intra-thread ordering through true register dependency will be respected
regardless of the presence or absence of other forms of synchronization. This form of register
dependency does not imply any other form of ordering. For example, a register dependency does
not imply that a dependee instructionâ€™s memory accesses will be performed before a dependent
instructionâ€™s memory accesses. To enforce such memory orderings and avoiding anti-dependency
hazards around <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::ld</span></code> must be used.</p>
<p>Example:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.ld %r1, ...;
tcgen05.mma ..., %r1, ...;
</pre></div>
</div>
</section>
</section>
<section id="tcgen05-memory-consistency-model-smem-access">
<span id="id470"></span><h5>
<span class="section-number">9.7.16.6.5. </span><a class="reference internal" href="#tcgen05-memory-consistency-model-smem-access">Shared Memory Accesses</a><a class="headerlink" href="#tcgen05-memory-consistency-model-smem-access" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The shared memory accesses by <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code> operations are performed
in the asynchronous proxy (async proxy).</p>
<p>Accessing the same memory location across miltiple proxies needs a cross-proxy fence.
For the async proxy, <code class="docutils literal notranslate"><span class="pre">fence.proxy.async</span></code> should be used to synchronize memory between
generic proxy and the async proxy.</p>
</section>
</section>
<section id="tcgen05-memory-alloc-manage-instructions">
<span id="id471"></span><h4>
<span class="section-number">9.7.16.7. </span><a class="reference internal" href="#tcgen05-memory-alloc-manage-instructions">Tensor Memory Allocation and Management Instructions</a><a class="headerlink" href="#tcgen05-memory-alloc-manage-instructions" title="Permalink to this headline">ïƒ</a>
</h4>
<section id="tcgen05-instructions-tcgen05-alloc-dealloc-relinquish-alloc-permit">
<span id="id472"></span><h5>
<span class="section-number">9.7.16.7.1. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-alloc-dealloc-relinquish-alloc-permit">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-alloc-dealloc-relinquish-alloc-permit" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code></p>
<p>Dynamic <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> allocation management instructions</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.alloc.cta_group.sync.aligned{.shared::cta}.b32  [dst], nCols;

tcgen05.dealloc.cta_group.sync.aligned.b32              taddr, nCols;

tcgen05.relinquish_alloc_permit.cta_group.sync.aligned;

.cta_group = { .cta_group::1, .cta_group::2 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code> is a potentially blocking instruction which dynamically allocates
the specified number of columns in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> and writes
the address of the allocated <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> into shared memory
at the location specified by address operand dst. The <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code> blocks if the
requested amount of <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> is not available and unblocks
as soon as the requested amount of <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> becomes
available for allocation.</p>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code> is a potentially blocking instruction which deallocates the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
specified by the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> address <code class="docutils literal notranslate"><span class="pre">taddr</span></code>. The operand
<code class="docutils literal notranslate"><span class="pre">taddr</span></code> must point to a previous <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> allocation.
If <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified,</p>
<ul class="simple">
<li><p>issuing warp and <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTA</span></a> warp must synchronize <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> accesses
before attempting to collectively deallocate the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code> may block to collectively performs the deallocation with
the other <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTA</span></a>â€™s warp.</p></li>
</ul>
<p>All of the Tensor Memory that was allocated using <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code> instruction in a kernel,
must be explicitly deallocated using <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code> before the kernel exits.</p>
<p>The unsigned 32-bit operand <code class="docutils literal notranslate"><span class="pre">nCols</span></code> specify the number of columns to be allocated or
de-allocated. The unit of allocation and de-allocation is 32 columns and all of lanes
per column. The number of columns must be a power of 2. The operand <code class="docutils literal notranslate"><span class="pre">nCols</span></code> must be
within the range [32, 512]. The number of columns allocated should not increase between
any two allocations in the execution order within the CTA. Operand <code class="docutils literal notranslate"><span class="pre">nCols</span></code> must be
power of 2.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code> specifies that the CTA of the executing
thread is relinquishing the right to allocate <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. So,
it is illegal for a CTA to perform <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code> after any of its constituent threads
execute <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code>.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used.
If the address specified by <code class="docutils literal notranslate"><span class="pre">dst</span></code> does not fall within the address window of
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> state space then the behavior is undefined.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> specifies the number of CTAs involved in the allocation and
de-allocation operation. When <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> is specified, one warp from the CTA must
perform the allocation and de-allocation. When <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified, one warp
from each of the <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTAs</span></a> must collectively perform the allocation and
de-allocation. Refer to the <a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a> section.
When <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified, the issuing warp must make sure that peer CTA is launched
and its warps eventually participate in collective operations.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that the instruction causes the executing thread
to wait until all threads in the warp execute the same instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the
same instruction. In conditionally executed code, the instruction should only be used if it
is known that all threads in the warp evaluate the condition identically, otherwise behavior
is undefined.</p>
<p>The behavior of the instruction is undefined if all the threads in the warp do not use the
same values of <code class="docutils literal notranslate"><span class="pre">nCols</span></code>, or if any thread in the warp has exited.</p>
<p>The store operation in <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code> is treated as a weak memory operation in the
<a class="reference internal" href="#memory-consistency-model"><span class="std std-ref">Memory Consistency Model</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Example 1:

tcgen05.alloc.cta_group::1.sync.aligned.shared::cta.b32 [sMemAddr1], 32;
ld.shared.b32 taddr, [sMemAddr1];
// use taddr ...
// more allocations and its usages ...
tcgen05.dealloc.cta_group::1.sync.aligned.b32  taddr, 32;
// more deallocations ...
tcgen05.relinquish_alloc_permit.cta_group::1.sync.aligned;

// Example 2:

// Following instructions are performed by current warp and the warp in the peer-CTA:
tcgen05.alloc.cta_group::2.sync.aligned.shared::cta.b32 [sMemAddr2], 32;
ld.shared.b32 taddr, [sMemAddr2];
// use taddr ...
// more allocations and its usages ...
tcgen05.dealloc.cta_group::2.sync.aligned.b32  taddr, 32;
// more deallocations ...
tcgen05.relinquish_alloc_permit.cta_group::2.sync.aligned;
</pre></div>
</div>
</section>
</section>
<section id="tcgen05-tensor-memory-ld-st">
<span id="id473"></span><h4>
<span class="section-number">9.7.16.8. </span><a class="reference internal" href="#tcgen05-tensor-memory-ld-st">Tensor Memory and Register Load/Store Instructions</a><a class="headerlink" href="#tcgen05-tensor-memory-ld-st" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The threads of the CTA can perform the loads and stores to the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
of the CTA and move data between registers and Tensor Memory. The loads and stores of data
can be performed in certain shapes as specified in the
<a class="reference internal" href="#tcgen05-matrix-data-movement-shape"><span class="std std-ref">Matrix and Data Movement Shape</span></a> section.</p>
<section id="tcgen05-tensor-memory-ld-st-access-restrictions">
<span id="id474"></span><h5>
<span class="section-number">9.7.16.8.1. </span><a class="reference internal" href="#tcgen05-tensor-memory-ld-st-access-restrictions">Access restrictions</a><a class="headerlink" href="#tcgen05-tensor-memory-ld-st-access-restrictions" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Not all threads of the CTA can access the entire Tensor Memory via the <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> and
<code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> operations.</p>
<p>The Tensor Memory of a CTA is divided into 4 equal chunks such that each warp of a warpgroup
in the CTA can access a chunk of the Tensor Memory. All the columns of the Tensor Memory can
be accessed by all the four warps of a warpgroup. A lane of the Tensor Memory can be accessed
by a single warp in the warpgroup. The following table describes the access restriction.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 64%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>ID of the warp within the warpgroup</p></th>
<th class="head"><p>Accessible Lanes</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>0</p></td>
<td><p>0-31</p></td>
</tr>
<tr class="row-odd">
<td><p>1</p></td>
<td><p>32-63</p></td>
</tr>
<tr class="row-even">
<td><p>2</p></td>
<td><p>64-95</p></td>
</tr>
<tr class="row-odd">
<td><p>3</p></td>
<td><p>96-127</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-tensor-memory-ld-st-packing-unpacking">
<span id="id475"></span><h5>
<span class="section-number">9.7.16.8.2. </span><a class="reference internal" href="#tcgen05-tensor-memory-ld-st-packing-unpacking">Packing and Unpacking</a><a class="headerlink" href="#tcgen05-tensor-memory-ld-st-packing-unpacking" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Optionally, the following pack and unpack operations can be performed during the load and store:</p>
<ol class="arabic simple">
<li><p>Packing: two 16-bit chunks can be packed into a single 32-bit chunk in the register in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code></p></li>
<li><p>Unpacking: a single 32-bit chunk in the register can be unpacked into two 16-bit chunks in <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></p></li>
</ol>
<p>as shown in the <a class="reference internal" href="#tcgen05-ld-st-pack-unpack"><span class="std std-numref">Figure 193</span></a>.</p>
<figure class="align-center" id="tcgen05-ld-st-pack-unpack">
<img alt="_images/tcgen05-ld-st-pack-unpack.png" class="image" src="_images/tcgen05-ld-st-pack-unpack.png">
<figcaption>
<p><span class="caption-number">Figure 193 </span><span class="caption-text">Pack/Unpack operations for tcgen05 ld/st</span><a class="headerlink" href="#tcgen05-ld-st-pack-unpack" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-instructions-tcgen05-ld">
<span id="id476"></span><h5>
<span class="section-number">9.7.16.8.3. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-ld">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-ld" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code></p>
<p>Asynchronous collective load from tensor memory into registers.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Base load instruction:

tcgen05.ld.sync.aligned.shape1.num{.pack}.b32    r, [taddr];

tcgen05.ld.sync.aligned.shape2.num{.pack}.b32    r, [taddr], immHalfSplitoff;

.shape1 = { .16x64b, .16x128b, .16x256b, .32x32b }
.shape2 = { .16x32bx2 }
.num    = { .x1, .x2, .x4, .x8, .x16, .x32, .x64, .x128 }
.pack   = { .pack::16b }

// Floating point type load along with reduction :

tcgen05.ld.red.sync.aligned.shape3.num.redOp{.abs}{.NaN}.f32 r, redval, [taddr];

tcgen05.ld.red.sync.aligned.shape4.num.redOp{.abs}{.NaN}.f32 r, redval, [taddr], immHalfSplitoff;

// Integer type load along with reduction :

tcgen05.ld.red.sync.aligned.shape3.num.redOp.type r, redval, [taddr];

tcgen05.ld.red.sync.aligned.shape4.num.redOp.type r, redval, [taddr], immHalfSplitoff;

.shape3 = { .32x32b   }
.shape4 = { .16x32bx2 }
.redOp  = { .min, .max }
.type   = { .u32, .s32 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> asynchronously loads data from the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
at the location specified by the 32-bit address operand <code class="docutils literal notranslate"><span class="pre">taddr</span></code> into the destination
register <code class="docutils literal notranslate"><span class="pre">r</span></code>, collectively across all threads of the warps.</p>
<p>All the threads in the warp must specify the same value of <code class="docutils literal notranslate"><span class="pre">taddr</span></code>, which must be the
base address of the collective load operation. Otherwise, the behavior is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier and the <code class="docutils literal notranslate"><span class="pre">.num</span></code> qualifier together determines the total
dimension of the data which is loaded from the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The <code class="docutils literal notranslate"><span class="pre">.shape</span></code>
qualifier indicates the base dimension of data to be accessed as described in the
<a class="reference internal" href="#tcgen05-data-movement-shape"><span class="std std-ref">Data Movement Shape</span></a>. The <code class="docutils literal notranslate"><span class="pre">.num</span></code> qualifier indicates
the repeat factor on the base dimension resulting in the total dimension of the data that
is accessed.</p>
<p>The shape <code class="docutils literal notranslate"><span class="pre">.16x32bx2</span></code> performs two accesses into Tensor Memory of the shape <code class="docutils literal notranslate"><span class="pre">.16x32b</span></code>.
The base address of the first access is specified by taddr and the base address of the
second access is specified by <code class="docutils literal notranslate"><span class="pre">taddr+immHalfSplitoff</span></code>, where <code class="docutils literal notranslate"><span class="pre">immHalfSplitoff</span></code> is an
immediate argument.</p>
<p>The destination operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression consisting of one
or more 32-bit registers as per the value of <code class="docutils literal notranslate"><span class="pre">.shape</span></code> and <code class="docutils literal notranslate"><span class="pre">.num</span></code>. The size of the
vector for various combinations of <code class="docutils literal notranslate"><span class="pre">.num</span></code> and <code class="docutils literal notranslate"><span class="pre">.shape</span></code> is shown in
<a class="reference internal" href="#tcgen05-num-shapes-ld"><span class="std std-numref">Table 49</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-num-shapes-ld">
<caption>
<span class="caption-number">Table 49 </span><span class="caption-text">Various-combinations of .num and .shape</span><a class="headerlink" href="#tcgen05-num-shapes-ld" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 47%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>.num</p></th>
<th class="head" colspan="3"><p>.shape</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.16x32bx2 / .16x64b / .32x32b</p></th>
<th class="head"><p>.16x128b</p></th>
<th class="head"><p>.16x256b</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x1</span></code></p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x2</span></code></p></td>
<td><p>2</p></td>
<td><p>4</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x4</span></code></p></td>
<td><p>4</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x8</span></code></p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x16</span></code></p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>64</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x32</span></code></p></td>
<td><p>32</p></td>
<td><p>64</p></td>
<td><p>128</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x64</span></code></p></td>
<td><p>64</p></td>
<td><p>128</p></td>
<td><p>NA</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x128</span></code></p></td>
<td><p>128</p></td>
<td><p>NA</p></td>
<td><p>NA</p></td>
</tr>
</tbody>
</table>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.red</span></code> specifies that the reduction operation specified by <code class="docutils literal notranslate"><span class="pre">.redOp</span></code> is
performed on the data that is loaded across columns in each lane. The result of the
reduction operation is written into the corresponding threadâ€™s 32-bit destination register
operand <code class="docutils literal notranslate"><span class="pre">redVal</span></code>. When <code class="docutils literal notranslate"><span class="pre">.red</span></code> qualifier is specified, <code class="docutils literal notranslate"><span class="pre">.num</span></code> modifier must be at least
<code class="docutils literal notranslate"><span class="pre">.x2</span></code>.</p>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.pack::16b</span></code> can be used to pack two 16-bit elements from adjacent
columns into a single 32-bit element during the load as shown in the section
<a class="reference internal" href="#tcgen05-tensor-memory-ld-st-packing-unpacking"><span class="std std-ref">Packing and Unpacking</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> causes the executing thread
to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> instruction before
resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the
same <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> instruction
should only be used if it is known that all threads in the warp evaluate the condition
identically, otherwise behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> is undefined if all threads do not use the same values of <code class="docutils literal notranslate"><span class="pre">taddr</span></code>,
or if any thread in the warp has exited.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> is performed asynchronously and more details are specified in the
section <a class="reference internal" href="#tcgen05-memory-consistency-model"><span class="std std-ref">Memory Consistency Model for 5th generation of TensorCore operations</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld.red</span></code> is introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld.red</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.ld.sync.aligned.32x32b.x2.b32     {r0, r1}, [taddr1];

tcgen05.ld.sync.aligned.16x128b.x4.b32    {r0, r1, r2, r3, r4, r5, r6, r7}, [taddr2];

tcgen05.ld.red.sync.aligned.16x32bx2.x8.u32.max {r0, r1, r2, r3, r4, r5, r6, r7},
                                                 redVal, [taddr3], 16;
</pre></div>
</div>
</section>
<section id="tcgen05-instructions-tcgen05-st">
<span id="id477"></span><h5>
<span class="section-number">9.7.16.8.4. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-st">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-st" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></p>
<p>Asynchronous collective store to tensor memory from registers.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.st.sync.aligned.shape1.num{.unpack}.b32    [taddr], r;

tcgen05.st.sync.aligned.shape2.num{.unpack}.b32    [taddr], immHalfSplitoff, r;

.shape1 = { .16x64b, .16x128b, .16x256b, .32x32b }
.shape2 = { .16x32bx2 }
.num    = { .x1, .x2, .x4, .x8, .x16, .x32, .x64, .x128 }
.unpack = { .unpack::16b }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> asynchronously stores data from the source register <code class="docutils literal notranslate"><span class="pre">r</span></code> into
the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> at the location specified by the 32-bit address operand <code class="docutils literal notranslate"><span class="pre">taddr</span></code>,
collectively across all threads of the warps.</p>
<p>All the threads in the warp must specify the same value of <code class="docutils literal notranslate"><span class="pre">taddr</span></code>, which must be the base
address of the collective store operation. Otherwise, the behavior is undefined.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier and the <code class="docutils literal notranslate"><span class="pre">.num</span></code> qualifier together determines the total dimension
of the data which is stored to the Tensor Memory. The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the base
dimension of data to be accessed as described in the
<a class="reference internal" href="#tcgen05-data-movement-shape"><span class="std std-ref">Data Movement Shape</span></a>. The <code class="docutils literal notranslate"><span class="pre">.num</span></code>
qualifier indicates the repeat factor on the base dimension resulting in the total dimension of
the data that is accessed.</p>
<p>The shape <code class="docutils literal notranslate"><span class="pre">.16x32bx2</span></code> performs two accesses into Tensor Memory of the shape <code class="docutils literal notranslate"><span class="pre">.16x32b</span></code>.
The base address of the first access is specified by <code class="docutils literal notranslate"><span class="pre">taddr</span></code> and the base address of the
second access is specified by <code class="docutils literal notranslate"><span class="pre">taddr+immHalfSplitoff</span></code>, where <code class="docutils literal notranslate"><span class="pre">immHalfSplitoff</span></code> is an
immediate argument.</p>
<p>The source operand <code class="docutils literal notranslate"><span class="pre">r</span></code> is a brace-enclosed vector expression consisting of one or more 32-bit
registers as per the value of <code class="docutils literal notranslate"><span class="pre">.shape</span></code> and <code class="docutils literal notranslate"><span class="pre">.num</span></code>. The size of the vector for various
combinations of <code class="docutils literal notranslate"><span class="pre">.num</span></code> and <code class="docutils literal notranslate"><span class="pre">.shape</span></code> is shown in <a class="reference internal" href="#tcgen05-num-shapes-st"><span class="std std-numref">Table 50</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-num-shapes-st">
<caption>
<span class="caption-number">Table 50 </span><span class="caption-text">Various-combinations of .num and .shape</span><a class="headerlink" href="#tcgen05-num-shapes-st" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 23%">
<col style="width: 47%">
<col style="width: 15%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head" rowspan="2"><p>.num</p></th>
<th class="head" colspan="3"><p>.shape</p></th>
</tr>
<tr class="row-even">
<th class="head"><p>.16x32bx2 / .16x64b / .32x32b</p></th>
<th class="head"><p>.16x128b</p></th>
<th class="head"><p>.16x256b</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x1</span></code></p></td>
<td><p>1</p></td>
<td><p>2</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x2</span></code></p></td>
<td><p>2</p></td>
<td><p>4</p></td>
<td><p>8</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x4</span></code></p></td>
<td><p>4</p></td>
<td><p>8</p></td>
<td><p>16</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x8</span></code></p></td>
<td><p>8</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x16</span></code></p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>64</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x32</span></code></p></td>
<td><p>32</p></td>
<td><p>64</p></td>
<td><p>128</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.x64</span></code></p></td>
<td><p>64</p></td>
<td><p>128</p></td>
<td><p>NA</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.x128</span></code></p></td>
<td><p>128</p></td>
<td><p>NA</p></td>
<td><p>NA</p></td>
</tr>
</tbody>
</table>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.unpack::16b</span></code> can be used to unpack a 32-bit element in the
register into two 16-bit elements and store them in adjacent columns as shown in the
section <a class="reference internal" href="#tcgen05-tensor-memory-ld-st-packing-unpacking"><span class="std std-ref">Packing and Unpacking</span></a>.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> causes the executing
thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> instruction
before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute
the same <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> instruction. In conditionally executed code, a <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
instruction should only be used if it is known that all threads in the warp evaluate
the condition identically, otherwise behavior is undefined.</p>
<p>The behavior of <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> is undefined if all threads do not use the same values of
<code class="docutils literal notranslate"><span class="pre">taddr</span></code>, or if any thread in the warp has exited.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> is performed asynchronously and more details are specified
in the section <a class="reference internal" href="#tcgen05-memory-consistency-model"><span class="std std-ref">Memory Consistency Model for 5th generation of TensorCore operations</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.st.sync.aligned.16x64b.x4.b32               [taddr0], {r0,  r1,  r2,  r3};

tcgen05.st.sync.aligned.16x128b.x1.unpack::16b.b32  [taddr1], {r0,  r1};
</pre></div>
</div>
</section>
<section id="tcgen05-instructions-tcgen05-wait">
<span id="id478"></span><h5>
<span class="section-number">9.7.16.8.5. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-wait">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-wait" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code></p>
<p>Waits for the completion of all prior asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> instructions.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.wait_operation.sync.aligned;

.wait_operation = { .wait::ld, .wait::st }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::st</span></code> causes the executing thread to block until all prior
<code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> operations issued by the executing thread have completed.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.wait::ld</span></code> causes the executing thread to block until all prior
<code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> operations issued by the executing thread have completed.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">tcgen05.wait_operation</span></code> causes the
executing thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">tcgen05.wait_operation</span></code>
instruction before resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warp must execute the
same <code class="docutils literal notranslate"><span class="pre">tcgen05.wait_operation</span></code> instruction.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Example 1:

tcgen05.ld.sync.aligned.32x32b.x2.b32     {r0, r1}, [taddr0];

// Prevents subsequent tcgen05.mma from racing ahead of the tcgen05.ld

tcgen05.wait::ld.sync.aligned;

tcgen05.mma.cta_group::1.kind::f16   [taddr0],  a-desc,  b-desc, idesc, p;

Example 2:

tcgen05.st.sync.aligned.32x32b.x2.b32     [taddr0], {r0, r1};

// Prevents the write to taddr0 in tcgen05.mma from racing ahead of the tcgen05.st

tcgen05.wait::st.sync.aligned;

tcgen05.mma.cta_group::1.kind::f16   [taddr0],  a-desc,  b-desc, idesc, p;
</pre></div>
</div>
</section>
</section>
<section id="tcgen05-data-movement-instructions">
<span id="id479"></span><h4>
<span class="section-number">9.7.16.9. </span><a class="reference internal" href="#tcgen05-data-movement-instructions">Tensor Memory Data Movement Instructions</a><a class="headerlink" href="#tcgen05-data-movement-instructions" title="Permalink to this headline">ïƒ</a>
</h4>
<p>Data from the shared memory can be copied asynchronously to the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
using the <a class="reference internal" href="#tcgen05-instructions-tcgen05-cp"><span class="std std-ref">Tensorcore 5th Generation Instructions: tcgen05.cp</span></a> operation.</p>
<section id="tcgen05-optional-decompression">
<span id="id480"></span><h5>
<span class="section-number">9.7.16.9.1. </span><a class="reference internal" href="#tcgen05-optional-decompression">Optional Decompression</a><a class="headerlink" href="#tcgen05-optional-decompression" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Optionally, during the copy, a vector of 4-bit and 6-bit
custom floating point types can be decompressed into 8-bit types.</p>
<section id="tcgen05-optional-decompression-4bit-8bit">
<span id="id481"></span><h6>
<span class="section-number">9.7.16.9.1.1. </span><a class="reference internal" href="#tcgen05-optional-decompression-4bit-8bit">Decompression of 4-bit floating point to 8-bit type</a><a class="headerlink" href="#tcgen05-optional-decompression-4bit-8bit" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A contiguous set of 16 elements of 4-bits each followed by 8 bytes of padding can be converted
into 16 elements of 8-bits each as shown in <a class="reference internal" href="#tcgen05-decompression-4b8b"><span class="std std-numref">Figure 194</span></a>.</p>
<figure class="align-center" id="tcgen05-decompression-4b8b">
<img alt="_images/tcgen05-decompression-4b8b.png" class="image" src="_images/tcgen05-decompression-4b8b.png">
<figcaption>
<p><span class="caption-number">Figure 194 </span><span class="caption-text">Decompression from 4-bit to 8-bit</span><a class="headerlink" href="#tcgen05-decompression-4b8b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The individual 4-bit to 8-bit decompression would look like as shown in <a class="reference internal" href="#tcgen05-decompression-4b8b-individual"><span class="std std-numref">Figure 195</span></a>.</p>
<figure class="align-center" id="tcgen05-decompression-4b8b-individual">
<img alt="_images/tcgen05-decompression-4b8b-individual.png" class="image" src="_images/tcgen05-decompression-4b8b-individual.png">
<figcaption>
<p><span class="caption-number">Figure 195 </span><span class="caption-text">Individual decompression from 4-bit to 8-bit</span><a class="headerlink" href="#tcgen05-decompression-4b8b-individual" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-optional-decompression-6bit-8bit">
<span id="id482"></span><h6>
<span class="section-number">9.7.16.9.1.2. </span><a class="reference internal" href="#tcgen05-optional-decompression-6bit-8bit">Decompression of 6-bit floating point to 8-bit type</a><a class="headerlink" href="#tcgen05-optional-decompression-6bit-8bit" title="Permalink to this headline">ïƒ</a>
</h6>
<p>A contiguous set of 16 elements of 6-bits each followed by 4 bytes of padding is
decompressed into 16 elements of 8-bits each as shown in <a class="reference internal" href="#tcgen05-decompression-6b8b"><span class="std std-numref">Figure 196</span></a>.</p>
<figure class="align-center" id="tcgen05-decompression-6b8b">
<img alt="_images/tcgen05-decompression-6b8b.png" class="image" src="_images/tcgen05-decompression-6b8b.png">
<figcaption>
<p><span class="caption-number">Figure 196 </span><span class="caption-text">Decompression from 6-bit to 8-bit</span><a class="headerlink" href="#tcgen05-decompression-6b8b" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>The individual 6-bit to 8-bit decompression for types <code class="docutils literal notranslate"><span class="pre">E3M2</span></code> and <code class="docutils literal notranslate"><span class="pre">E2M3</span></code> is shown in
<a class="reference internal" href="#tcgen05-decompression-6b8b-individual1"><span class="std std-numref">Figure 197</span></a> and <a class="reference internal" href="#tcgen05-decompression-6b8b-individual2"><span class="std std-numref">Figure 198</span></a>
respectively.</p>
<figure class="align-center" id="tcgen05-decompression-6b8b-individual1">
<img alt="_images/tcgen05-decompression-6b8b-individual1.png" class="image" src="_images/tcgen05-decompression-6b8b-individual1.png">
<figcaption>
<p><span class="caption-number">Figure 197 </span><span class="caption-text">Individual decompression from 6-bit to 8-bit for E3M2 type</span><a class="headerlink" href="#tcgen05-decompression-6b8b-individual1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-decompression-6b8b-individual2">
<img alt="_images/tcgen05-decompression-6b8b-individual2.png" class="image" src="_images/tcgen05-decompression-6b8b-individual2.png">
<figcaption>
<p><span class="caption-number">Figure 198 </span><span class="caption-text">Individual decompression from 6-bit to 8-bit for E2M3 type</span><a class="headerlink" href="#tcgen05-decompression-6b8b-individual2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="tcgen05-instructions-tcgen05-cp">
<span id="id483"></span><h5>
<span class="section-number">9.7.16.9.2. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-cp">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-cp" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code></p>
<p>Initiates an asynchronous copy operation from shared memory to the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.cp.cta_group.shape{.multicast}{.dst_fmt.src_fmt} [taddr], s-desc;

.cta_group = { .cta_group::1, .cta_group::2 }
.src_fmt   = { .b6x16_p32 , .b4x16_p64 }
.dst_fmt   = { .b8x16 }
.shape     = { .128x256b, .4x256b, .128x128b, .64x128b**, .32x128b*** }
.multicast = { .warpx2::02_13** , .warpx2::01_23**, .warpx4*** }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code> initiates an asynchronous copy operation from shared memory to the
location specified by the address operand <code class="docutils literal notranslate"><span class="pre">taddr</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p>
<p>The 64-bit register operand <code class="docutils literal notranslate"><span class="pre">s-desc</span></code> is the matrix descriptor which represents the source
matrix in the shared memory that needs to be copied. The format of the matrix descriptor is
described in <a class="reference internal" href="#tcgen05-matrix-descriptors"><span class="std std-ref">Matrix Descriptors</span></a>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifier indicates the dimension of data to be copied as described in the
<a class="reference internal" href="#tcgen05-data-movement-shape"><span class="std std-ref">Data Movement Shape</span></a>.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> specifies the number of CTAs whose <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> is
accessed when a single thread of a single CTA executes the <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code> instruction.
When <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> is specified, the data is copied into the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
of the current CTA. When <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified, the data is copied into the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of both the current and the <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTAs</span></a>.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>When the qualifiers <code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code> and <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code> are specified, the data is decompressed
from the source format <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code> in the shared memory to the destination format
<code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code> in <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> by the copy operation. The details of source
and the destination formats as specified in the section
<a class="reference internal" href="#tcgen05-optional-decompression"><span class="std std-ref">Optional Decompression</span></a>.</p>
<p>Some of the <code class="docutils literal notranslate"><span class="pre">.shape</span></code> qualifiers require certain <code class="docutils literal notranslate"><span class="pre">.multicast</span></code> qualifiers.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.64x128b</span></code> requires <code class="docutils literal notranslate"><span class="pre">.warpx2::02_13</span></code> or <code class="docutils literal notranslate"><span class="pre">.warpx2::01_23</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.32x128b</span></code> requires <code class="docutils literal notranslate"><span class="pre">.warpx4</span></code></p></li>
</ol>
<p>When the <code class="docutils literal notranslate"><span class="pre">.multicast</span></code> qualifier is specified as either <code class="docutils literal notranslate"><span class="pre">.warpx2::02_13</span></code> or
<code class="docutils literal notranslate"><span class="pre">.warpx2::01_23</span></code> then the data being copied is multicasted into warp pairs and each
warp in the warp pair receive half of the data. Warp pairs are formed as follows:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.warpx2::02_13</span></code> : warps 0 and 2 form a pair; warps 1 and 3 form a pair.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.warpx2::01_23</span></code> : warps 0 and 1 form a pair; warps 2 and 3 form a pair.</p></li>
</ol>
<p>When the <code class="docutils literal notranslate"><span class="pre">.multicast</span></code> modifier is specified as <code class="docutils literal notranslate"><span class="pre">.warpx4</span></code> then the data being
copied is multicasted into all 4 warps.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.cp.cta_group::1.128x256b                 [taddr0], sdesc0;
tcgen05.cp.cta_group::2.128x128b.b8x16.b6x16_p32 [taddr1], sdesc1;
tcgen05.cp.cta_group::1.64x128b.warpx2::02_13    [taddr2], sdesc2;
</pre></div>
</div>
</section>
<section id="tcgen05-instructions-tcgen05-shift">
<span id="id484"></span><h5>
<span class="section-number">9.7.16.9.3. </span><a class="reference internal" href="#tcgen05-instructions-tcgen05-shift">Tensorcore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code></a><a class="headerlink" href="#tcgen05-instructions-tcgen05-shift" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code></p>
<p>Asynchronously shift down the rows of the matrix in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> for a warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.shift.cta_group.down  [taddr];

.cta_group = { .cta_group::1, .cta_group::2 }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code> is an asynchronous instruction which initiates the shifting of 32-byte
elements downwards across all the rows, except the last, by one row. The address operand <code class="docutils literal notranslate"><span class="pre">taddr</span></code>
specifies the base address of the matrix in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> whose rows must
be down shifted.</p>
<p>The lane of the address operand <code class="docutils literal notranslate"><span class="pre">taddr</span></code> must be aligned to 32.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> specifies the number of CTAs whose <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
is touched when a single thread of a single CTA executes the <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code> instruction.
When <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> is specified, the shift operation is performed in the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of the current CTA. When <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> is specified,
the shift operation is performed in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of both the current and the
<a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTAs</span></a>.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.shift.down.cta_group::1 [taddr0];
tcgen05.shift.down.cta_group::2 [taddr1];
</pre></div>
</div>
</section>
</section>
<section id="tcgen05-mma">
<span id="id485"></span><h4>
<span class="section-number">9.7.16.10. </span><a class="reference internal" href="#tcgen05-mma">TensorCore 5th Generation Matrix Multiply and accumulate Operations</a><a class="headerlink" href="#tcgen05-mma" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The 5<sup>th</sup> generation of TensorCore operations of shape <em>MxNxK</em> perform matrix
multiplication and accumulation of the form:</p>
<p><code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span></code></p>
<p>where:</p>
<ul class="simple">
<li><p>the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix has shape <em>MxK</em>, in either Tensor Memory or Shared Memory</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix has shape <em>KxN</em>, in Shared Memory of the current CTA and optionally in peer CTA</p></li>
<li><p>the <code class="docutils literal notranslate"><span class="pre">D</span></code> matrix is of the shape <em>MxN</em>, in Tensor Memory</p></li>
</ul>
<p>Optionally an input predicate can be used to disable the input from the accumulator
matrix and the following operation can be performed as</p>
<p><code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code></p>
<p>The matrix multiplication and accumulation operations are categorized into various kinds
based on input types and the throughput of the multiplication operation. The following shows the
different kinds of MMA operations that are supported:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">f16</span></code> : supports <code class="docutils literal notranslate"><span class="pre">f16</span></code> and <code class="docutils literal notranslate"><span class="pre">bf16</span></code> input types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tf32</span></code> : supports <code class="docutils literal notranslate"><span class="pre">tf32</span></code> input types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">f8f6f4</span></code> : supports all input combinations of <code class="docutils literal notranslate"><span class="pre">f8</span></code>, <code class="docutils literal notranslate"><span class="pre">f6</span></code> and <code class="docutils literal notranslate"><span class="pre">f4</span></code> types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">i8</span></code> : supports signed and unsigned 8-bit integer input types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mxf8f6f4</span></code>/<code class="docutils literal notranslate"><span class="pre">mxf4</span></code> : supports mx-floating points input types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mxf4nvf4</span></code> : supports <code class="docutils literal notranslate"><span class="pre">mxf4</span></code> type and a custom NVIDIA floating-point
type for inputs where the type of the vector elements is 4 bits and requires a common
scaling factor to form the complete floating-point type, similar to other mx-types.</p></li>
</ol>
<p>Optionally, the 5<sup>th</sup> generation of TensorCore MMAs support dense and sparse matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>.
<a class="reference internal" href="#tcgen05-sparse-matrices"><span class="std std-ref">Sparse Matrices</span></a> describes the details of the sparse matrices.</p>
<p>Some of the MMA-kinds requires scaling of input matrices from memory to form the matrix
<code class="docutils literal notranslate"><span class="pre">A</span></code> and matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> before performing the MMA operation.
<a class="reference internal" href="#tcgen05-block-scaling"><span class="std std-ref">Block Scaling for tcgen05.mma.sync</span></a> describes the details of the scaling of matrices.</p>
<p>The following table show the various matrices involved in the MMA operations and the memory in
which they can reside:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 46%">
<col style="width: 54%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Matrix Type</p></th>
<th class="head"><p>Memory</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">A</span></code></p></td>
<td><p>Tensor Memory OR Shared Memory</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">B</span></code></p></td>
<td><p>Shared Memory</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">D</span></code></p></td>
<td rowspan="3"><p>Tensor Memory</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">Sparse</span> <span class="pre">Meta</span> <span class="pre">Data</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">A-Scale</span></code> / <code class="docutils literal notranslate"><span class="pre">B-Scale</span></code></p></td>
</tr>
</tbody>
</table>
<p>A sequence of MMA instructions may reuse the same <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with a sequence of <code class="docutils literal notranslate"><span class="pre">B</span></code>
matrices or may reuse the same <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with a sequence of <code class="docutils literal notranslate"><span class="pre">A</span></code> matrices.
In these patterns the TensorCore may be able to laod the unchanged matrix once and reuse
it through the sequence without multiple reloads. The <code class="docutils literal notranslate"><span class="pre">A</span></code> or <code class="docutils literal notranslate"><span class="pre">B</span></code> matrices are loaded
into a TensorCore collector buffer (i.e., special cache).</p>
<p>An MMA instruction has an optional <code class="docutils literal notranslate"><span class="pre">collector</span></code> qualifier to specify when an <code class="docutils literal notranslate"><span class="pre">A</span></code> or <code class="docutils literal notranslate"><span class="pre">B</span></code>
matrix is new to the sequence and should be loaded, unchanged within the sequence
and should be reused, or the last use in the sequence and should be discarded.
The <code class="docutils literal notranslate"><span class="pre">collector</span></code> qualifier is used to give the TensorCore permission to reuse a previously
loaded <code class="docutils literal notranslate"><span class="pre">A</span></code> or <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix; however reuse is opportunistic in that the TensorCore may
reload a matrix even when it has permission to reuse that matrix. Thus, the source
memory of an <code class="docutils literal notranslate"><span class="pre">A</span></code> or <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix must not be modified while the MMA instruction using those
matrices has not completed - regardless of <code class="docutils literal notranslate"><span class="pre">collector</span></code> qualifier permissions.</p>
<p>The 5<sup>th</sup> generation of TensorCore MMAs can be used for general matrix multiplication OR for
convolution operations. In case of convolutions, the activations can be stored in either
matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> or matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> while the weights will be stored in the other matrix.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 8%">
<col style="width: 12%">
<col style="width: 25%">
<col style="width: 44%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Activation
Matrix</p></th>
<th class="head"><p>Weights
Matrix</p></th>
<th class="head"><p>Name of the
op</p></th>
<th class="head"><p>Instruction
Name</p></th>
<th class="head"><p>Collector Buffer Applicability</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">A</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">B</span></code></p></td>
<td><p>Activation
Stationary</p></td>
<td><p>(default <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code>)</p></td>
<td><p>Collector buffer is applicable on matrix <code class="docutils literal notranslate"><span class="pre">A</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">B</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">A</span></code></p></td>
<td><p>Weights
Stationary</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.ws</span></code></p></td>
<td><p>Collector buffer is applicable on matrix <code class="docutils literal notranslate"><span class="pre">B</span></code></p></td>
</tr>
</tbody>
</table>
<section id="tcgen05-transpose-and-negate-operations">
<span id="id486"></span><h5>
<span class="section-number">9.7.16.10.1. </span><a class="reference internal" href="#tcgen05-transpose-and-negate-operations">Transpose and Negate operations</a><a class="headerlink" href="#tcgen05-transpose-and-negate-operations" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> can be transposed by specifying the Tranpose <code class="docutils literal notranslate"><span class="pre">A</span></code> Matrix
and Transpose <code class="docutils literal notranslate"><span class="pre">B</span></code> Matrix bits in the instruction descriptor respectively.</p>
<p>The elements of the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> can be negated by specifying the Negate
<code class="docutils literal notranslate"><span class="pre">A</span></code> Matrix and Negate <code class="docutils literal notranslate"><span class="pre">B</span></code> Matrix bits in the instruction descriptor respectively.</p>
<p>The support for Transpose and Negate operation for various MMA-Kind are shown in
<a class="reference internal" href="#tcgen05-transpose-negate-mma-kind"><span class="std std-numref">Table 51</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-transpose-negate-mma-kind">
<caption>
<span class="caption-number">Table 51 </span><span class="caption-text">Transpose and Negate operation for various MMA-Kind</span><a class="headerlink" href="#tcgen05-transpose-negate-mma-kind" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 35%">
<col style="width: 34%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>MMA-Kind</p></th>
<th class="head"><p>Is Transpose A/B supported</p></th>
<th class="head"><p>Is Negate A/B supported</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>No</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
<p>For <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code>, the transpose operations on matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are supported
only with 128B swizzling mode with 32B swizzle-atomicity.</p>
<p>For all other MMA-Kinds, the transpose operations on matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are not supported
on 128B swizzling mode with 32B swizzle-atomicity.</p>
<p><a class="reference internal" href="#tcgen05-kind-shapes-8b-transpose-b"><span class="std std-numref">Table 52</span></a> shows the valid combinations of N shape with
<code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> qualifier for 8bit transpose B.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-kind-shapes-8b-transpose-b">
<caption>
<span class="caption-number">Table 52 </span><span class="caption-text">Various combinations of N shape with .cta_group qualifier for 8bit transpose B</span><a class="headerlink" href="#tcgen05-kind-shapes-8b-transpose-b" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 37%">
<col style="width: 63%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.cta_group</p></th>
<th class="head"><p>N shape</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>1</p></td>
<td><p>16 &lt;= N &lt;= 256, step 16</p></td>
</tr>
<tr class="row-odd">
<td><p>2</p></td>
<td><p>32 &lt;= N &lt;= 256, step 32</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-matrix-layout-organization">
<span id="id487"></span><h5>
<span class="section-number">9.7.16.10.2. </span><a class="reference internal" href="#tcgen05-matrix-layout-organization">Matrix Layout Organization</a><a class="headerlink" href="#tcgen05-matrix-layout-organization" title="Permalink to this headline">ïƒ</a>
</h5>
<p><a class="reference internal" href="#tcgen05-matrices-majorness"><span class="std std-numref">Table 53</span></a> describes the major-ness used for different matrices.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-matrices-majorness">
<caption>
<span class="caption-number">Table 53 </span><span class="caption-text">Major-ness for different matrices</span><a class="headerlink" href="#tcgen05-matrices-majorness" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 7%">
<col style="width: 18%">
<col style="width: 75%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Residing in Memory</p></th>
<th class="head"><p>Default Major-ness</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>D</p></td>
<td><p>Tensor Memory</p></td>
<td rowspan="2"><p>Row-Major</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>A</p></td>
<td><p>Tensor Memory</p></td>
</tr>
<tr class="row-even">
<td><p>Shared Memory</p></td>
<td rowspan="2"><p>Depends on swizzling mode.
Refer
<a class="reference external" href="#tcgen05-shared-memory-layout-swizzling">Shared Memory Layout and Swizzling</a></p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>Shared Memory</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-matrix-layout-organization-valid-comb-type-size-majorness-swizzle">
<span id="id488"></span><h5>
<span class="section-number">9.7.16.10.3. </span><a class="reference internal" href="#tcgen05-matrix-layout-organization-valid-comb-type-size-majorness-swizzle">Valid Combinations of Type-Size, Major-ness and Swizzling</a><a class="headerlink" href="#tcgen05-matrix-layout-organization-valid-comb-type-size-majorness-swizzle" title="Permalink to this headline">ïƒ</a>
</h5>
<table class="table-no-stripes docutils align-default" id="tcgen05-matrices-valid-type-size-majorness-swizzle">
<caption>
<span class="caption-number">Table 54 </span><span class="caption-text">Valid Combinations of Type-Size, Major-ness and Swizzling</span><a class="headerlink" href="#tcgen05-matrices-valid-type-size-majorness-swizzle" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 19%">
<col style="width: 32%">
<col style="width: 13%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Type-Size</p></th>
<th class="head"><p>Major-ness</p></th>
<th class="head"><p>Matrix</p></th>
<th class="head"><p>Supported Swizzle</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p>4-bit,
6-bit,
8-bit,
16-bit,
32-bit</p></td>
<td><p>Row</p></td>
<td><p>A</p></td>
<td rowspan="2"><p>All swizzling modes</p></td>
</tr>
<tr class="row-odd">
<td><p>Column</p></td>
<td><p>B</p></td>
</tr>
<tr class="row-even">
<td rowspan="2">
<p>8-bit</p>
<p>16-bit</p>
</td>
<td><p>Column (transpose)</p></td>
<td><p>A</p></td>
<td rowspan="2"><p>All except 128B
swizzling with 32B
atomicity</p></td>
</tr>
<tr class="row-odd">
<td><p>Row (transpose)</p></td>
<td><p>B</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>32-bit</p></td>
<td><p>Column (transpose)</p></td>
<td><p>A</p></td>
<td rowspan="2"><p>Only 128B swizzling
with 32B atomicity</p></td>
</tr>
<tr class="row-odd">
<td><p>Row (transpose)</p></td>
<td><p>B</p></td>
</tr>
</tbody>
</table>
</section>
<section id="tcgen05-packing-formats">
<span id="id489"></span><h5>
<span class="section-number">9.7.16.10.4. </span><a class="reference internal" href="#tcgen05-packing-formats">Packing formats of elements in Tensor and Shared memory</a><a class="headerlink" href="#tcgen05-packing-formats" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="tcgen05-packing-formats-mat-d">
<span id="id490"></span><h6>
<span class="section-number">9.7.16.10.4.1. </span><a class="reference internal" href="#tcgen05-packing-formats-mat-d">Packing format for matrix D in Tensor Memory</a><a class="headerlink" href="#tcgen05-packing-formats-mat-d" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The sub-word elements of matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> are expected not to be packed within a 32-bit Tensor Memory word.
For example, if the type of elements of the matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> is 16 bits then a Tensor Memory word
would contain a single 16-bit element in its lower 16 bits.</p>
</section>
<section id="tcgen05-packing-formats-mat-a-b">
<span id="id491"></span><h6>
<span class="section-number">9.7.16.10.4.2. </span><a class="reference internal" href="#tcgen05-packing-formats-mat-a-b">Packing format for matrix A and B</a><a class="headerlink" href="#tcgen05-packing-formats-mat-a-b" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The 6-bit and 4-bit floating point types have different packing format requirements for
different MMA kinds in both Tensor memory and Shared memory. The requirements are as follows.</p>
</section>
<section id="tcgen05-packing-formats-mxf8f6f4-tmem">
<span id="id492"></span><h6>
<span class="section-number">9.7.16.10.4.3. </span><a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-tmem">Packing format used for matrix A by <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> in Tensor Memory</a><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-tmem" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The individual 4-bit and the 6-bit floating point type elements must be packed in an 8-bit container
in Tensor memory as shown below. The 8-bit containers must be contiguously packed in a 32-bit Tensor
Memory word. For example, if the type of elements of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is 6 bits then 4 consecutive
<code class="docutils literal notranslate"><span class="pre">A</span></code> elements should be packed in one 32-bit Tensor Memory word.</p>
<ul>
<li>
<p>4-bit packing format as shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig1"><span class="std std-numref">Figure 199</span></a></p>
<figure class="align-center" id="tcgen05-packing-formats-mxf8f6f4-tmem-dig1">
<img alt="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig1.png" class="image" src="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 199 </span><span class="caption-text">4-bit packing format with type E2M1</span><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>6-bit packing format</p>
<ul>
<li>
<p>Type E3M2 as shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig2"><span class="std std-numref">Figure 200</span></a></p>
<figure class="align-center" id="tcgen05-packing-formats-mxf8f6f4-tmem-dig2">
<img alt="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig2.png" class="image" src="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 200 </span><span class="caption-text">6-bit packing format with type E3M2</span><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li>
<p>Type E2M3 as shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig3"><span class="std std-numref">Figure 201</span></a></p>
<figure class="align-center" id="tcgen05-packing-formats-mxf8f6f4-tmem-dig3">
<img alt="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig3.png" class="image" src="_images/tcgen05-packing-formats-mxf8f6f4-tmem-dig3.png">
<figcaption>
<p><span class="caption-number">Figure 201 </span><span class="caption-text">6-bit packing format with type E2M3</span><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-tmem-dig3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
</ul>
</li>
</ul>
</section>
<section id="tcgen05-packing-formats-mxf8f6f4-smem">
<span id="id493"></span><h6>
<span class="section-number">9.7.16.10.4.4. </span><a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-smem">Packing format used for matrix A and B by <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code> in Shared Memory</a><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-smem" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The 4-bit and 6-bit floating point elements in shared memory must be contiguously packed along
with padding as follows.</p>
<ul>
<li>
<p>4-bit packing format as shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-smem-dig1"><span class="std std-numref">Figure 202</span></a></p>
<figure class="align-center" id="tcgen05-packing-formats-mxf8f6f4-smem-dig1">
<img alt="_images/tcgen05-packing-formats-mxf8f6f4-smem-dig1.png" class="image" src="_images/tcgen05-packing-formats-mxf8f6f4-smem-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 202 </span><span class="caption-text">4-bit packing format</span><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-smem-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</li>
<li><p>6-bit packing format as shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf8f6f4-smem-dig2"><span class="std std-numref">Figure 203</span></a></p></li>
</ul>
<blockquote>
<div>
<figure class="align-center" id="tcgen05-packing-formats-mxf8f6f4-smem-dig2">
<img alt="_images/tcgen05-packing-formats-mxf8f6f4-smem-dig2.png" class="image" src="_images/tcgen05-packing-formats-mxf8f6f4-smem-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 203 </span><span class="caption-text">6-bit packing format</span><a class="headerlink" href="#tcgen05-packing-formats-mxf8f6f4-smem-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</section>
<section id="tcgen05-packing-formats-mxf4-tmem">
<span id="id494"></span><h6>
<span class="section-number">9.7.16.10.4.5. </span><a class="reference internal" href="#tcgen05-packing-formats-mxf4-tmem">Packing format used for matrix A by <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> in Tensor Memory</a><a class="headerlink" href="#tcgen05-packing-formats-mxf4-tmem" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Two 4-bit floating point type elements must be packed in an 8-bit container in Tensor memory as
shown in <a class="reference internal" href="#tcgen05-packing-formats-mxf4-tmem-dig1"><span class="std std-numref">Figure 204</span></a> for <code class="docutils literal notranslate"><span class="pre">mxf4</span></code>.</p>
<figure class="align-center" id="tcgen05-packing-formats-mxf4-tmem-dig1">
<img alt="_images/tcgen05-packing-formats-mxf4-tmem-dig1.png" class="image" src="_images/tcgen05-packing-formats-mxf4-tmem-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 204 </span><span class="caption-text">4-bit packing format with type E2M1</span><a class="headerlink" href="#tcgen05-packing-formats-mxf4-tmem-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-packing-formats-mxf4-smem">
<span id="id495"></span><h6>
<span class="section-number">9.7.16.10.4.6. </span><a class="reference internal" href="#tcgen05-packing-formats-mxf4-smem">Packing format used for matrix A and B by <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> in Shared Memory</a><a class="headerlink" href="#tcgen05-packing-formats-mxf4-smem" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The packing format for 4-bit floating point elements in shared memory is to pack two 4-bit
elements in a 8-bit container, with no padding.</p>
</section>
</section>
<section id="tcgen05-data-path-layout-organization">
<span id="id496"></span><h5>
<span class="section-number">9.7.16.10.5. </span><a class="reference internal" href="#tcgen05-data-path-layout-organization">Data Path Layout Organization</a><a class="headerlink" href="#tcgen05-data-path-layout-organization" title="Permalink to this headline">ïƒ</a>
</h5>
<p>Different MMA variants access the tensor memory with different layout organization.
The following table lists the various layouts:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 3%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 19%">
<col style="width: 29%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>M</p></th>
<th class="head"><p>cta_group</p></th>
<th class="head"><p>A-Sparsity</p></th>
<th class="head"><p>Is .ws mode</p></th>
<th class="head"><p>Datapath organization</p></th>
<th class="head"><p>Layout ID</p></th>
<th class="head"><p>Tensor Memory Datapath Lane Alignment</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>32</p></td>
<td><p>::1</p></td>
<td><p>Either</p></td>
<td><p>Yes</p></td>
<td><p>1x4</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-g"><span class="std std-ref">Layout G</span></a></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td><p>64</p></td>
<td><p>::1</p></td>
<td><p>Either</p></td>
<td><p>Yes</p></td>
<td><p>2x3</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-e"><span class="std std-ref">Layout E</span></a></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>64</p></td>
<td><p>::1</p></td>
<td><p>Either</p></td>
<td><p>No</p></td>
<td><p>4x1 (1/2 datapath utilized)</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-f"><span class="std std-ref">Layout F</span></a></p></td>
<td><p>0 or 16</p></td>
</tr>
<tr class="row-odd">
<td><p>128</p></td>
<td><p>::1</p></td>
<td><p>Either</p></td>
<td><p>Either</p></td>
<td><p>4x1</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-d"><span class="std std-ref">Layout D</span></a></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even">
<td><p>128</p></td>
<td><p>::2</p></td>
<td><p>Dense</p></td>
<td><p>N/A</p></td>
<td><p>2x2</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-b"><span class="std std-ref">Layout B</span></a></p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd">
<td><p>128</p></td>
<td><p>::2</p></td>
<td><p>Sparse</p></td>
<td><p>N/A</p></td>
<td><p>4x1 (1/2 datapath utilized)</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-c"><span class="std std-ref">Layout C</span></a></p></td>
<td><p>0 or 16</p></td>
</tr>
<tr class="row-even">
<td><p>256</p></td>
<td><p>::2</p></td>
<td><p>Either</p></td>
<td><p>N/A</p></td>
<td><p>4x1</p></td>
<td><p><a class="reference internal" href="#tcgen05-data-path-layout-a"><span class="std std-ref">Layout A</span></a></p></td>
<td><p>0</p></td>
</tr>
</tbody>
</table>
<p>The layouts which utilize only half the datapath lanes, i.e.,
<a class="reference internal" href="#tcgen05-data-path-layout-f"><span class="std std-ref">Layout F</span></a> and
<a class="reference internal" href="#tcgen05-data-path-layout-c"><span class="std std-ref">Layout C</span></a>, must use the same Tensor Memory
lane alignment across matrices <code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">D</span></code> and the sparsity metadata matrix.</p>
<p>The following shows the warps that can access the Tensor Memory regions via
<code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code> along with the addresses for various Tensor Memory Layouts.</p>
<section id="tcgen05-data-path-layout-a">
<span id="id497"></span><h6>
<span class="section-number">9.7.16.10.5.1. </span><a class="reference internal" href="#tcgen05-data-path-layout-a">Layout A (M = 256)</a><a class="headerlink" href="#tcgen05-data-path-layout-a" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 256 is shown in <a class="reference internal" href="#tcgen05-data-path-layout-a1"><span class="std std-numref">Figure 205</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-a1">
<img alt="_images/tcgen05-data-path-layout-a1.png" class="image" src="_images/tcgen05-data-path-layout-a1.png">
<figcaption>
<p><span class="caption-number">Figure 205 </span><span class="caption-text">Layout organization for M = 256</span><a class="headerlink" href="#tcgen05-data-path-layout-a1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-a2"><span class="std std-numref">Figure 206</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-a2">
<img alt="_images/tcgen05-data-path-layout-a2.png" class="image" src="_images/tcgen05-data-path-layout-a2.png">
<figcaption>
<p><span class="caption-number">Figure 206 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-a2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-b">
<span id="id498"></span><h6>
<span class="section-number">9.7.16.10.5.2. </span><a class="reference internal" href="#tcgen05-data-path-layout-b">Layout B (M = 128 + cta-group::2 + Dense A matrix)</a><a class="headerlink" href="#tcgen05-data-path-layout-b" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 128 + .cta_group::2 + Dense A matrix is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-b1"><span class="std std-numref">Figure 207</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-b1">
<img alt="_images/tcgen05-data-path-layout-b1.png" class="image" src="_images/tcgen05-data-path-layout-b1.png">
<figcaption>
<p><span class="caption-number">Figure 207 </span><span class="caption-text">Layout organization for M = 128 + .cta_group::2 + Dense A matrix</span><a class="headerlink" href="#tcgen05-data-path-layout-b1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-b2"><span class="std std-numref">Figure 208</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-b2">
<img alt="_images/tcgen05-data-path-layout-b2.png" class="image" src="_images/tcgen05-data-path-layout-b2.png">
<figcaption>
<p><span class="caption-number">Figure 208 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-b2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-c">
<span id="id499"></span><h6>
<span class="section-number">9.7.16.10.5.3. </span><a class="reference internal" href="#tcgen05-data-path-layout-c">Layout C (M = 128 + cta-group::2 + Sparse A matrix)</a><a class="headerlink" href="#tcgen05-data-path-layout-c" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 128 + .cta_group::2 + Sparse A matrix is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-c1"><span class="std std-numref">Figure 209</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-c1">
<img alt="_images/tcgen05-data-path-layout-c1.png" class="image" src="_images/tcgen05-data-path-layout-c1.png">
<figcaption>
<p><span class="caption-number">Figure 209 </span><span class="caption-text">Layout organization for M = 128 + .cta_group::2 + Sparse A matrix</span><a class="headerlink" href="#tcgen05-data-path-layout-c1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-c2"><span class="std std-numref">Figure 210</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-c2">
<img alt="_images/tcgen05-data-path-layout-c2.png" class="image" src="_images/tcgen05-data-path-layout-c2.png">
<figcaption>
<p><span class="caption-number">Figure 210 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-c2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-d">
<span id="id500"></span><h6>
<span class="section-number">9.7.16.10.5.4. </span><a class="reference internal" href="#tcgen05-data-path-layout-d">Layout D (M = 128 + cta-group::1)</a><a class="headerlink" href="#tcgen05-data-path-layout-d" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 128 + .cta_group::1 is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-d1"><span class="std std-numref">Figure 211</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-d1">
<img alt="_images/tcgen05-data-path-layout-d1.png" class="image" src="_images/tcgen05-data-path-layout-d1.png">
<figcaption>
<p><span class="caption-number">Figure 211 </span><span class="caption-text">Layout organization for M = 128 + .cta_group::1</span><a class="headerlink" href="#tcgen05-data-path-layout-d1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-d2"><span class="std std-numref">Figure 212</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-d2">
<img alt="_images/tcgen05-data-path-layout-d2.png" class="image" src="_images/tcgen05-data-path-layout-d2.png">
<figcaption>
<p><span class="caption-number">Figure 212 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-d2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-e">
<span id="id501"></span><h6>
<span class="section-number">9.7.16.10.5.5. </span><a class="reference internal" href="#tcgen05-data-path-layout-e">Layout E (M = 64 + .ws mode)</a><a class="headerlink" href="#tcgen05-data-path-layout-e" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 64 + .ws mode is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-e1"><span class="std std-numref">Figure 213</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-e1">
<img alt="_images/tcgen05-data-path-layout-e1.png" class="image" src="_images/tcgen05-data-path-layout-e1.png">
<figcaption>
<p><span class="caption-number">Figure 213 </span><span class="caption-text">Layout organization for M = 64 + .ws mode</span><a class="headerlink" href="#tcgen05-data-path-layout-e1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-e2"><span class="std std-numref">Figure 214</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-e2">
<img alt="_images/tcgen05-data-path-layout-e2.png" class="image" src="_images/tcgen05-data-path-layout-e2.png">
<figcaption>
<p><span class="caption-number">Figure 214 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-e2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-f">
<span id="id502"></span><h6>
<span class="section-number">9.7.16.10.5.6. </span><a class="reference internal" href="#tcgen05-data-path-layout-f">Layout F (M = 64 + non .ws mode)</a><a class="headerlink" href="#tcgen05-data-path-layout-f" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 64 + non .ws mode is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-f1"><span class="std std-numref">Figure 215</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-f1">
<img alt="_images/tcgen05-data-path-layout-f1.png" class="image" src="_images/tcgen05-data-path-layout-f1.png">
<figcaption>
<p><span class="caption-number">Figure 215 </span><span class="caption-text">Layout organization for M = 64 + non .ws mode</span><a class="headerlink" href="#tcgen05-data-path-layout-f1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-f2"><span class="std std-numref">Figure 216</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-f2">
<img alt="_images/tcgen05-data-path-layout-f2.png" class="image" src="_images/tcgen05-data-path-layout-f2.png">
<figcaption>
<p><span class="caption-number">Figure 216 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-f2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-data-path-layout-g">
<span id="id503"></span><h6>
<span class="section-number">9.7.16.10.5.7. </span><a class="reference internal" href="#tcgen05-data-path-layout-g">Layout G (M = 32)</a><a class="headerlink" href="#tcgen05-data-path-layout-g" title="Permalink to this headline">ïƒ</a>
</h6>
<p>Layout organization for M = 32 is shown in
<a class="reference internal" href="#tcgen05-data-path-layout-g1"><span class="std std-numref">Figure 217</span></a>.</p>
<figure class="align-center" id="tcgen05-data-path-layout-g1">
<img alt="_images/tcgen05-data-path-layout-g1.png" class="image" src="_images/tcgen05-data-path-layout-g1.png">
<figcaption>
<p><span class="caption-number">Figure 217 </span><span class="caption-text">Layout organization for M = 32</span><a class="headerlink" href="#tcgen05-data-path-layout-g1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Addresses for the above region to be used in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>
is shown in <a class="reference internal" href="#tcgen05-data-path-layout-g2"><span class="std std-numref">Figure 218</span></a></p>
<figure class="align-center" id="tcgen05-data-path-layout-g2">
<img alt="_images/tcgen05-data-path-layout-g2.png" class="image" src="_images/tcgen05-data-path-layout-g2.png">
<figcaption>
<p><span class="caption-number">Figure 218 </span><span class="caption-text">Addresses to use in <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code> / <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code></span><a class="headerlink" href="#tcgen05-data-path-layout-g2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="tcgen05-shared-memory-layout-swizzling">
<span id="id504"></span><h5>
<span class="section-number">9.7.16.10.6. </span><a class="reference internal" href="#tcgen05-shared-memory-layout-swizzling">Shared Memory Layout and Swizzling</a><a class="headerlink" href="#tcgen05-shared-memory-layout-swizzling" title="Permalink to this headline">ïƒ</a>
</h5>
<p>If the bit <code class="docutils literal notranslate"><span class="pre">Transpose</span> <span class="pre">A</span> <span class="pre">Matrix</span></code> / <code class="docutils literal notranslate"><span class="pre">Transpose</span> <span class="pre">B</span> <span class="pre">Matrix</span></code> in the
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a> is 0, then <em>K-major</em> is
used for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> / <code class="docutils literal notranslate"><span class="pre">B</span></code> respectively. If the bit <code class="docutils literal notranslate"><span class="pre">Transpose</span> <span class="pre">A</span> <span class="pre">Matrix</span></code> in the
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a> is 1 then <em>M-major</em> is
used for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>. If the bit <code class="docutils literal notranslate"><span class="pre">Transpose</span> <span class="pre">B</span> <span class="pre">Matrix</span></code> in the
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a> is 1, then <em>N-major</em> is
used for matrix <code class="docutils literal notranslate"><span class="pre">B</span></code>.</p>
<p>In a column-major default BLAS library such as cuBLAS, the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> with and
without transpose can be classified as either <em>K-Major</em> or <em>M-or-N-Major</em> as shown in the
following table:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 50%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"></th>
<th class="head"><p>Non-Transposed</p></th>
<th class="head"><p>Transposed</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>A</p></td>
<td><p>K-major</p></td>
<td><p>M-major</p></td>
</tr>
<tr class="row-odd">
<td><p>B</p></td>
<td><p>K-major</p></td>
<td><p>N-major</p></td>
</tr>
</tbody>
</table>
<p>To avoid confusion with <code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code>, <code class="docutils literal notranslate"><span class="pre">row-major</span></code>, <code class="docutils literal notranslate"><span class="pre">col-major</span></code>, <code class="docutils literal notranslate"><span class="pre">transpose</span></code>, and
<code class="docutils literal notranslate"><span class="pre">non-transpose</span></code>, we will use <em>MN-Major</em> and <em>K-Major</em> throughout this section.</p>
<p>The matrices in the shared memory are made up of one or more â€œswizzle layout atomâ€.
The exact layout of these swizzle atoms depends on the swizzling mode, swizzle-atomicity,
and the leading dimension. The layout of the swizzle are shown in
<a class="reference internal" href="#tcgen05-smem-swizzle-mode"><span class="std std-numref">Table 55</span></a></p>
<table class="table-no-stripes docutils align-default" id="tcgen05-smem-swizzle-mode">
<caption>
<span class="caption-number">Table 55 </span><span class="caption-text">Layout for swizzle atoms</span><a class="headerlink" href="#tcgen05-smem-swizzle-mode" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 38%">
<col style="width: 27%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Swizzling mode and
Swizzle-Atomicity</p></th>
<th class="head"><p>Leading
Dimension</p></th>
<th class="head"><p>Swizzle atom layout
(128b element)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="2"><p>128B Swizzling with
32B atomicity</p></td>
<td><p>M/N</p></td>
<td><p>8x4</p></td>
</tr>
<tr class="row-odd">
<td><p>â€“</p></td>
<td><p>â€“</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>128B Swizzling with
16B atomicity</p></td>
<td><p>M/N</p></td>
<td><p>8x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x8</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>64B Swizzling Mode</p></td>
<td><p>M/N</p></td>
<td><p>4x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x4</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>32B Swizzling Mode</p></td>
<td><p>M/N</p></td>
<td><p>2x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x2</p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>None</p></td>
<td><p>M/N</p></td>
<td><p>1x8</p></td>
</tr>
<tr class="row-odd">
<td><p>K</p></td>
<td><p>8x1</p></td>
</tr>
</tbody>
</table>
<p>The above shapes are for elements of size 128 bits. For smaller element sizes, the same shapes
would get multiplied along the leading dimension by a factor of <code class="docutils literal notranslate"><span class="pre">128</span> <span class="pre">/</span> <span class="pre">sizeof_bits(Element)</span></code>.
For example, 128B MN major swizzle atom would have a shape of (8*(128/32))x8 = 32x8 for
tf32 tensor core inputs.</p>
<p>Some example Layouts of <em>MxK</em> or <em>KxN</em> matrices with various swizzling modes, and are in units
of 128b elements as shown by each colored cell as shown in
<a class="reference internal" href="#tcgen05-smem-layout-128b-32b-atom-mn"><span class="std std-numref">Figure 219</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-128b-mn"><span class="std std-numref">Figure 220</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-128b-k"><span class="std std-numref">Figure 221</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-64b-mn"><span class="std std-numref">Figure 222</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-64b-k"><span class="std std-numref">Figure 223</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-32b-mn"><span class="std std-numref">Figure 224</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-32b-k"><span class="std std-numref">Figure 225</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-no-swizzle-mn"><span class="std std-numref">Figure 226</span></a>,
<a class="reference internal" href="#tcgen05-smem-layout-no-swizzle-k"><span class="std std-numref">Figure 227</span></a>.</p>
<figure class="align-center" id="tcgen05-smem-layout-128b-32b-atom-mn">
<img alt="_images/tcgen05-smem-layout-128B-32B-atom-mn.png" class="image" src="_images/tcgen05-smem-layout-128B-32B-atom-mn.png">
<figcaption>
<p><span class="caption-number">Figure 219 </span><span class="caption-text">MN major 128B swizzling with 32B atomicity</span><a class="headerlink" href="#tcgen05-smem-layout-128b-32b-atom-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-128b-mn">
<img alt="_images/tcgen05-smem-layout-128B-mn.png" class="image" src="_images/tcgen05-smem-layout-128B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 220 </span><span class="caption-text">MN major 128B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-128b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-128b-k">
<img alt="_images/tcgen05-smem-layout-128B-k.png" class="image" src="_images/tcgen05-smem-layout-128B-k.png">
<figcaption>
<p><span class="caption-number">Figure 221 </span><span class="caption-text">K major 128B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-128b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-64b-mn">
<img alt="_images/tcgen05-smem-layout-64B-mn.png" class="image" src="_images/tcgen05-smem-layout-64B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 222 </span><span class="caption-text">MN major 64B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-64b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-64b-k">
<img alt="_images/tcgen05-smem-layout-64B-k.png" class="image" src="_images/tcgen05-smem-layout-64B-k.png">
<figcaption>
<p><span class="caption-number">Figure 223 </span><span class="caption-text">K major 64B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-64b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-32b-mn">
<img alt="_images/tcgen05-smem-layout-32B-mn.png" class="image" src="_images/tcgen05-smem-layout-32B-mn.png">
<figcaption>
<p><span class="caption-number">Figure 224 </span><span class="caption-text">MN major 32B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-32b-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-32b-k">
<img alt="_images/tcgen05-smem-layout-32B-k.png" class="image" src="_images/tcgen05-smem-layout-32B-k.png">
<figcaption>
<p><span class="caption-number">Figure 225 </span><span class="caption-text">K major 32B swizzling</span><a class="headerlink" href="#tcgen05-smem-layout-32b-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-no-swizzle-mn">
<img alt="_images/tcgen05-smem-layout-no-swizzle-mn.png" class="image" src="_images/tcgen05-smem-layout-no-swizzle-mn.png">
<figcaption>
<p><span class="caption-number">Figure 226 </span><span class="caption-text">MN major no-swizzling mode</span><a class="headerlink" href="#tcgen05-smem-layout-no-swizzle-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-smem-layout-no-swizzle-k">
<img alt="_images/tcgen05-smem-layout-no-swizzle-k.png" class="image" src="_images/tcgen05-smem-layout-no-swizzle-k.png">
<figcaption>
<p><span class="caption-number">Figure 227 </span><span class="caption-text">K major no-swizzling mode</span><a class="headerlink" href="#tcgen05-smem-layout-no-swizzle-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>Following are some of the examples of the 128B swizzling layout for <code class="docutils literal notranslate"><span class="pre">tf32</span></code> element type.</p>
<ul>
<li>
<p>K-Major: <a class="reference internal" href="#tcgen05-smem-layout-k"><span class="std std-numref">Figure 228</span></a></p>
<blockquote>
<div>
<figure class="align-center" id="tcgen05-smem-layout-k">
<img alt="_images/tcgen05-smem-layout-k.png" class="image" src="_images/tcgen05-smem-layout-k.png">
<figcaption>
<p><span class="caption-number">Figure 228 </span><span class="caption-text">K major</span><a class="headerlink" href="#tcgen05-smem-layout-k" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
<li>
<p>MN-Major: <a class="reference internal" href="#tcgen05-smem-layout-mn"><span class="std std-numref">Figure 229</span></a></p>
<blockquote>
<div>
<figure class="align-center" id="tcgen05-smem-layout-mn">
<img alt="_images/tcgen05-smem-layout-mn.png" class="image" src="_images/tcgen05-smem-layout-mn.png">
<figcaption>
<p><span class="caption-number">Figure 229 </span><span class="caption-text">MN major</span><a class="headerlink" href="#tcgen05-smem-layout-mn" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</div>
</blockquote>
</li>
</ul>
</section>
<section id="tcgen05-block-scaling">
<span id="id505"></span><h5>
<span class="section-number">9.7.16.10.7. </span><a class="reference internal" href="#tcgen05-block-scaling">Block Scaling for <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sync</span></code></a><a class="headerlink" href="#tcgen05-block-scaling" title="Permalink to this headline">ïƒ</a>
</h5>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> instructions with the following <code class="docutils literal notranslate"><span class="pre">.kind</span></code> qualifier:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></li>
</ul>
<p>perform matrix multiplication with block scaling. This operation has the following form:</p>
<p><code class="docutils literal notranslate"><span class="pre">(A</span> <span class="pre">*</span> <span class="pre">scale_A)</span>Â  <span class="pre">*</span> <span class="pre">(B</span> <span class="pre">*</span> <span class="pre">scale_B)</span> <span class="pre">+</span> <span class="pre">D</span></code></p>
<p>where <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> are matrices residing in <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p>
<p>For a <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> matrix of shape <em>M x SFA_N</em>, each row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is divided into
<em>SFA_N</em> number of chunks and each chunk of a row is multiplied with the corresponding
element in the <em>SF_A</em> of the same row.</p>
<p>Similarly, for a <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrix of shape <em>SFB_M x N</em>, each column of matrix <code class="docutils literal notranslate"><span class="pre">B</span></code> is
divided into the <em>SFB_M</em> number of chunks and each chunk of a column is multiplied with
the corresponding element in the <em>SF_B</em> of the same column.</p>
<p>Scale factors for <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> matrices need to be duplicated to all 32 lane partitions
of tensor memory.</p>
<p><a class="reference internal" href="#tcgen05-mma-block-scaling"><span class="std std-numref">Figure 230</span></a> shows an example of <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> with block scaling of
<code class="docutils literal notranslate"><span class="pre">scale_vec::2X</span></code>.</p>
<figure class="align-center" id="tcgen05-mma-block-scaling">
<img alt="_images/tcgen05-mma-block-scaling.png" class="image" src="_images/tcgen05-mma-block-scaling.png">
<figcaption>
<p><span class="caption-number">Figure 230 </span><span class="caption-text"><code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> with block scaling of <code class="docutils literal notranslate"><span class="pre">scale_vec::2X</span></code></span><a class="headerlink" href="#tcgen05-mma-block-scaling" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<section id="tcgen05-mma-scale-valid-vec-size">
<span id="id506"></span><h6>
<span class="section-number">9.7.16.10.7.1. </span><a class="reference internal" href="#tcgen05-mma-scale-valid-vec-size">Valid combinations of scale_vectorsize with types and MMA-Kind</a><a class="headerlink" href="#tcgen05-mma-scale-valid-vec-size" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The shape of <em>scale_A</em> and <em>scale_B</em> matrices depend on the <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> as shown in
<a class="reference internal" href="#tcgen05-mma-scale-valid-comb"><span class="std std-numref">Table 56</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-mma-scale-valid-comb">
<caption>
<span class="caption-number">Table 56 </span><span class="caption-text">Valid combinations of scale_vectorsize and shapes</span><a class="headerlink" href="#tcgen05-mma-scale-valid-comb" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 19%">
<col style="width: 20%">
<col style="width: 26%">
<col style="width: 17%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.scale_vectorsize</p></th>
<th class="head"><p>.kind::*</p></th>
<th class="head"><p>K</p></th>
<th class="head"><p>Shape of scale_A</p></th>
<th class="head"><p>Shape of scale_B</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td><p>All supported values of K</p></td>
<td><p>M x 1</p></td>
<td><p>1 x N</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>All supported values of K</p></td>
<td><p>M x 2</p></td>
<td><p>2 x N</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>All supported values of K</p></td>
<td><p>M x 4</p></td>
<td><p>4 x N</p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.block16</span></code></p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>K = 96</p></td>
<td><p>M x 6</p></td>
<td><p>6 x N</p></td>
</tr>
<tr class="row-even">
<td><p>All supported values of K
except 96</p></td>
<td><p>M x 4</p></td>
<td><p>4 x N</p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.block32</span></code></p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>K = 96</p></td>
<td><p>M x 3</p></td>
<td><p>3 x N</p></td>
</tr>
<tr class="row-even">
<td><p>All supported values of K
except 96</p></td>
<td><p>M x 2</p></td>
<td><p>2 x N</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td><p>All supported values of K</p></td>
<td><p>M x 1</p></td>
<td><p>1 x N</p></td>
</tr>
</tbody>
</table>
<p>The valid combination of the exact element types and the <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> are listed in
<a class="reference internal" href="#tcgen05-mma-scale-valid-comb-detail"><span class="std std-numref">Table 57</span></a>.</p>
<table class="table-no-stripes docutils align-default" id="tcgen05-mma-scale-valid-comb-detail">
<caption>
<span class="caption-number">Table 57 </span><span class="caption-text">Valid combinations of scale_vectorsize with types and MMA-Kind</span><a class="headerlink" href="#tcgen05-mma-scale-valid-comb-detail" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 27%">
<col style="width: 25%">
<col style="width: 23%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.kind::*</p></th>
<th class="head"><p>Element Data Type</p></th>
<th class="head"><p>Scale Data Type</p></th>
<th class="head"><p>.scale_vectorsize</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
<td><p>E4M3, E5M2, E2M3
E3M2, E2M1</p></td>
<td><p>UE8M0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.block32</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p>E2M1</p></td>
<td><p>UE8M0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.block32</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></td>
<td><p>E2M1</p></td>
<td><p>UE8M0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.block32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.block16</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>E2M1</p></td>
<td><p>UE4M3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code>
/ <code class="docutils literal notranslate"><span class="pre">.block16</span></code></p></td>
</tr>
</tbody>
</table>
<p>New <code class="docutils literal notranslate"><span class="pre">.blockN</span></code> qualifiers are aliases for <code class="docutils literal notranslate"><span class="pre">.scale_vec::NX</span></code> qualifiers as:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.block32</span></code> is alias for <code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code> or <code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>
based on <code class="docutils literal notranslate"><span class="pre">.kind</span></code> and K dimension</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.block16</span></code> is alias for <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></li>
</ul>
</section>
<section id="tcgen05-mma-scale-factor-a">
<span id="id507"></span><h6>
<span class="section-number">9.7.16.10.7.2. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a">Scale Factor A ID</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The value of the scale factor <code class="docutils literal notranslate"><span class="pre">A</span> <span class="pre">ID</span></code> selects the sub-columns in the Tensor Memory to
form the scale factor <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix, which is used to scale the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p>
<p>The following shows the scale factor matrix layout for various scale vector sizes:</p>
<section id="tcgen05-mma-scale-factor-a-layout-1x">
<span id="id508"></span><h7><span class="section-number">9.7.16.10.7.2.1. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-1x">Layout of the Scale Factor A Matrix for scale_vec::1X/block32 with K=32/K=64</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a-layout-1x" title="Permalink to this headline">ïƒ</a></h7>
<p>There is one scale factor per row of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with block size as 32 and the scale factor must be provided in
1-byte aligned sub-column of the Tensor Memory. <em>SFA_ID</em> specifies the byte offset in the
Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-1x-dig"><span class="std std-numref">Figure 231</span></a> shows which sub-columns get selected for
different values of <em>SFA_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-1x-dig">
<img alt="_images/tcgen05-mma-scale-factor-a-1x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-a-1x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 231 </span><span class="caption-text">Layout of scale factor A matrix with scale_vec::1X/block32 with K=32/K=64</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-1x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFA_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, <em>SFA_ID</em> values of 1, 2 and 3 would select the blue, yellow, and red columns,
respectively.</p>
</section>
<section id="tcgen05-mma-scale-factor-a-layout-2x">
<span id="id509"></span><h7><span class="section-number">9.7.16.10.7.2.2. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-2x">Layout of the Scale Factor A Matrix for scale_vec::2X/block32 with K=64/K=128</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a-layout-2x" title="Permalink to this headline">ïƒ</a></h7>
<p>There are two scale factors per row of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with block size as 32 and the scale factor must be provided in
2-byte aligned sub-column of the Tensor Memory. <em>SFA_ID</em> specifies the half word offset in the
Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-2x-dig"><span class="std std-numref">Figure 232</span></a> shows which sub-columns gets selected for different
values of <em>SFA_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-2x-dig">
<img alt="_images/tcgen05-mma-scale-factor-a-2x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-a-2x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 232 </span><span class="caption-text">Layout of scale factor A matrix with scale_vec::2X/block32 with K=64/K=128</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-2x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFA_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, if <em>SFA_ID</em> is 2, then all of the blue columns are selected to form the scale
factor matrix.</p>
</section>
<section id="tcgen05-mma-scale-factor-a-layout-4x">
<span id="id510"></span><h7><span class="section-number">9.7.16.10.7.2.3. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-4x">Layout of the Scale Factor A Matrix for scale_vec::4X/block16 with K=64/K=128</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a-layout-4x" title="Permalink to this headline">ïƒ</a></h7>
<p>There are four scale factors per row of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with block size as 16 and the scale factor must be provided in
4-byte aligned sub-column of the Tensor Memory. The <em>SFA_ID</em> value must be 0 and this specifies
that all of the columns (in green) will be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-4x-dig"><span class="std std-numref">Figure 233</span></a> shows which sub-columns gets selected for different
values of <em>SFA_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-4x-dig">
<img alt="_images/tcgen05-mma-scale-factor-a-4x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-a-4x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 233 </span><span class="caption-text">Layout of scale factor A matrix with scale_vec::4X/block16 with K=64/K=128</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-4x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-mma-scale-factor-a-layout-block32-k96">
<span id="id511"></span><h7><span class="section-number">9.7.16.10.7.2.4. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-block32-k96">Layout of the Scale Factor A Matrix for block32 with K=96 (Semantically equivalent to scale_vec::3X)</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a-layout-block32-k96" title="Permalink to this headline">ïƒ</a></h7>
<p>There are three scale factors per row of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with block size as 32 and the scale
factor must be provided in 4-byte aligned sub-column of the Tensor Memory. <em>SFA_ID</em> specifies
the byte offset in the Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-block32-k96-dig1"><span class="std std-numref">Figure 234</span></a>, <a class="reference internal" href="#tcgen05-mma-scale-factor-a-block32-k96-dig2"><span class="std std-numref">Figure 235</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-block32-k96-dig3"><span class="std std-numref">Figure 236</span></a> and <a class="reference internal" href="#tcgen05-mma-scale-factor-a-block32-k96-dig4"><span class="std std-numref">Figure 237</span></a>
show which sub-columns get selected for different values of <em>SFA_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block32-k96-dig1">
<img alt="_images/tcgen05-mma-scale-factor-a-block32-k96-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block32-k96-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 234 </span><span class="caption-text">Layout of scale factor A matrix with block32 with K=96 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block32-k96-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block32-k96-dig2">
<img alt="_images/tcgen05-mma-scale-factor-a-block32-k96-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block32-k96-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 235 </span><span class="caption-text">Layout of scale factor A matrix with block32 with K=96 with SFA_ID=01</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block32-k96-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block32-k96-dig3">
<img alt="_images/tcgen05-mma-scale-factor-a-block32-k96-dig3.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block32-k96-dig3.png">
<figcaption>
<p><span class="caption-number">Figure 236 </span><span class="caption-text">Layout of scale factor A matrix with block32 with K=96 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block32-k96-dig3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block32-k96-dig4">
<img alt="_images/tcgen05-mma-scale-factor-a-block32-k96-dig4.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block32-k96-dig4.png">
<figcaption>
<p><span class="caption-number">Figure 237 </span><span class="caption-text">Layout of scale factor A matrix with block32 with K=96 with SFA_ID=11</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block32-k96-dig4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFA_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, <em>SFA_ID</em> values of 1, 2 and 3 would select the blue, yellow, and red columns,
respectively.</p>
</section>
<section id="tcgen05-mma-scale-factor-a-layout-block16-k96">
<span id="id512"></span><h7><span class="section-number">9.7.16.10.7.2.5. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-a-layout-block16-k96">Layout of the Scale Factor A Matrix for block16 with K=96 (Semantically equivalent to scale_vec::6X)</a><a class="headerlink" href="#tcgen05-mma-scale-factor-a-layout-block16-k96" title="Permalink to this headline">ïƒ</a></h7>
<p>There are six scale factors per row of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix with block size as 16 and the scale
factor must be provided in 4-byte aligned sub-column of the Tensor Memory. <em>SFA_ID</em> specifies
the byte offset in the Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-a-block16-k96-dig1"><span class="std std-numref">Figure 238</span></a> and <a class="reference internal" href="#tcgen05-mma-scale-factor-a-block16-k96-dig2"><span class="std std-numref">Figure 239</span></a>
show which sub-columns get selected for different values of <em>SFA_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block16-k96-dig1">
<img alt="_images/tcgen05-mma-scale-factor-a-block16-k96-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block16-k96-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 238 </span><span class="caption-text">Layout of scale factor A matrix with block16 with K=96 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block16-k96-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-a-block16-k96-dig2">
<img alt="_images/tcgen05-mma-scale-factor-a-block16-k96-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-a-block16-k96-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 239 </span><span class="caption-text">Layout of scale factor A matrix with block16 with K=96 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-a-block16-k96-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFA_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, if <em>SFA_ID</em> is 2, then all of the blue columns are selected to form the scale
factor matrix.</p>
</section>
</section>
<section id="tcgen05-mma-scale-factor-b">
<span id="id513"></span><h6>
<span class="section-number">9.7.16.10.7.3. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b">Scale Factor B ID</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The value of the scale factor <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">ID</span></code> selects the sub-columns in the Tensor Memory to
form the scale factor <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix, which is used to scale the matrix <code class="docutils literal notranslate"><span class="pre">B</span></code>.</p>
<p>The following shows the scale factor matrix layout for various scale vector sizes:</p>
<section id="tcgen05-mma-scale-factor-b-layout-1x">
<span id="id514"></span><h7><span class="section-number">9.7.16.10.7.3.1. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-1x">Layout of the Scale Factor B Matrix for scale_vec::1X/block32 with K=32/K=64</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b-layout-1x" title="Permalink to this headline">ïƒ</a></h7>
<p>There is one scale factor per row of the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with block size as 32 and the scale factor must be provided in
1-byte aligned sub-column of the Tensor Memory. <em>SFB_ID</em> specifies the byte offset in the
Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-1x-dig"><span class="std std-numref">Figure 240</span></a> shows which sub-columns get selected for
different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-1x-dig">
<img alt="_images/tcgen05-mma-scale-factor-b-1x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-b-1x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 240 </span><span class="caption-text">Layout of scale factor B matrix with scale_vec::1X/block32 with K=32/K=64</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-1x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFB_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, <em>SFB_ID</em> values of 1, 2 and 3 would select the blue, yellow, and red columns, respectively.</p>
</section>
<section id="tcgen05-mma-scale-factor-b-layout-2x">
<span id="id515"></span><h7><span class="section-number">9.7.16.10.7.3.2. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-2x">Layout of the Scale Factor B Matrix for scale_vec::2X/block32 with K=64/K=128</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b-layout-2x" title="Permalink to this headline">ïƒ</a></h7>
<p>There are two scale factors per row of the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with block size as 32 and the scale factor must be provided in
2-byte aligned sub-column of the Tensor Memory. <em>SFB_ID</em> specifies the half word offset in the
Tensor Memory word that must be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-2x-dig"><span class="std std-numref">Figure 241</span></a> shows which sub-columns get selected for
different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-2x-dig">
<img alt="_images/tcgen05-mma-scale-factor-b-2x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-b-2x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 241 </span><span class="caption-text">Layout of scale factor B matrix with scale_vec::2X/block32 with K=64/K=128</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-2x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFB_ID</em> is 0, then all the green columns are selected to form the scale factor
matrix. Similarly, if <em>SFB_ID</em> is 2, then all of the blue columns are selected to form the scale
factor matrix.</p>
</section>
<section id="tcgen05-mma-scale-factor-b-layout-4x">
<span id="id516"></span><h7><span class="section-number">9.7.16.10.7.3.3. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-4x">Layout of the Scale Factor B Matrix for scale_vec::4X/block16 with K=64/K=128</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b-layout-4x" title="Permalink to this headline">ïƒ</a></h7>
<p>There are four scale factors per row of the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with block size as 16 and the scale factor must be provided in
4-byte aligned sub-column of the Tensor Memory. The <em>SFB_ID</em> value must be 0 and this specifies
that all of the columns (in green) will be used for the scale factor matrix.
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-4x-dig"><span class="std std-numref">Figure 242</span></a> shows which sub-columns get selected for
different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-4x-dig">
<img alt="_images/tcgen05-mma-scale-factor-b-4x-dig.png" class="image" src="_images/tcgen05-mma-scale-factor-b-4x-dig.png">
<figcaption>
<p><span class="caption-number">Figure 242 </span><span class="caption-text">Layout of scale factor B matrix with scale_vec::4X/block16 with K=64/K=128</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-4x-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-mma-scale-factor-b-layout-block32-k96">
<span id="id517"></span><h7><span class="section-number">9.7.16.10.7.3.4. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-block32-k96">Layout of the Scale Factor B Matrix for block32 with K=96 (Semantically equivalent to scale_vec::3X)</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b-layout-block32-k96" title="Permalink to this headline">ïƒ</a></h7>
<p>There are three scale factors per row of the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with block size as 32 and the scale factor
must be provided in 4-byte aligned sub-column of the Tensor Memory. <em>SFB_ID</em> specifies the byte
offset in the Tensor Memory word that must be used for the scale factor matrix.</p>
<p>For N&lt;=128, <a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig1"><span class="std std-numref">Figure 243</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig2"><span class="std std-numref">Figure 244</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig3"><span class="std std-numref">Figure 245</span></a> and
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig4"><span class="std std-numref">Figure 246</span></a> show which
sub-columns get selected for different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig1">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 243 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&lt;=128 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig2">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 244 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&lt;=128 with SFA_ID=01</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig3">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig3.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig3.png">
<figcaption>
<p><span class="caption-number">Figure 245 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&lt;=128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig4">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig4.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig4.png">
<figcaption>
<p><span class="caption-number">Figure 246 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&lt;=128 with SFA_ID=11</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-nlt128-dig4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For N&gt;128, <a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig1"><span class="std std-numref">Figure 247</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig2"><span class="std std-numref">Figure 248</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig3"><span class="std std-numref">Figure 249</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig4"><span class="std std-numref">Figure 250</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig5"><span class="std std-numref">Figure 251</span></a> and
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig6"><span class="std std-numref">Figure 252</span></a> show which
sub-columns get selected for different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig1">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 247 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig2">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 248 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=01</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig3">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig3.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig3.png">
<figcaption>
<p><span class="caption-number">Figure 249 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig4">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig4.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig4.png">
<figcaption>
<p><span class="caption-number">Figure 250 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig5">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig5.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig5.png">
<figcaption>
<p><span class="caption-number">Figure 251 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=11</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig5" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig6">
<img alt="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig6.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig6.png">
<figcaption>
<p><span class="caption-number">Figure 252 </span><span class="caption-text">Layout of scale factor B matrix with block32 with K=96 and N&gt;128 with SFA_ID=11</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block32-k96-ngt128-dig6" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFB_ID</em> is 0, then all the green columns are selected to form the
scale factor matrix. Similarly, <em>SFB_ID</em> values of 1, 2 and 3 would select the blue,
yellow, and red columns, respectively.</p>
</section>
<section id="tcgen05-mma-scale-factor-b-layout-block16-k96">
<span id="id518"></span><h7><span class="section-number">9.7.16.10.7.3.5. </span><a class="reference internal" href="#tcgen05-mma-scale-factor-b-layout-block16-k96">Layout of the Scale Factor B Matrix for block16 with K=96 (Semantically equivalent to scale_vec::6X)</a><a class="headerlink" href="#tcgen05-mma-scale-factor-b-layout-block16-k96" title="Permalink to this headline">ïƒ</a></h7>
<p>There are six scale factors per row of the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix with block size as 16 and the scale factor
must be provided in 4-byte aligned sub-column of the Tensor Memory. <em>SFB_ID</em> specifies the byte
offset in the Tensor Memory word that must be used for the scale factor matrix.</p>
<p>For N&lt;=128, <a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig1"><span class="std std-numref">Figure 253</span></a> and
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig2"><span class="std std-numref">Figure 254</span></a> show which sub-columns
get selected for different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig1">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 253 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&lt;=128 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig2">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 254 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&lt;=128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-nlt128-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For N&gt;128, <a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig1"><span class="std std-numref">Figure 255</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig2"><span class="std std-numref">Figure 256</span></a>,
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig3"><span class="std std-numref">Figure 257</span></a> and
<a class="reference internal" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig4"><span class="std std-numref">Figure 258</span></a> show which sub-columns
get selected for different values of <em>SFB_ID</em>.</p>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig1">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig1.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig1.png">
<figcaption>
<p><span class="caption-number">Figure 255 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&gt;128 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig1" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig2">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig2.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig2.png">
<figcaption>
<p><span class="caption-number">Figure 256 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&gt;128 with SFA_ID=00</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig2" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig3">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig3.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig3.png">
<figcaption>
<p><span class="caption-number">Figure 257 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&gt;128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig3" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<figure class="align-center" id="tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig4">
<img alt="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig4.png" class="image" src="_images/tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig4.png">
<figcaption>
<p><span class="caption-number">Figure 258 </span><span class="caption-text">Layout of scale factor B matrix with block16 with K=96 and N&gt;128 with SFA_ID=10</span><a class="headerlink" href="#tcgen05-mma-scale-factor-b-block16-k96-ngt128-dig4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
<p>For example, if <em>SFB_ID</em> is 0, then all the green columns are selected to form the
scale factor matrix. Similarly, if <em>SFB_ID</em> is 2, then all of the blue columns are
selected to form the scale factor matrix.</p>
</section>
</section>
</section>
<section id="tcgen05-sparse-matrices">
<span id="id519"></span><h5>
<span class="section-number">9.7.16.10.8. </span><a class="reference internal" href="#tcgen05-sparse-matrices">Sparse Matrices</a><a class="headerlink" href="#tcgen05-sparse-matrices" title="Permalink to this headline">ïƒ</a>
</h5>
<p>This instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> can be used when the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is a structured
sparse matrix with 50% zeros in each row distributed as per its sparse granularity.</p>
<p>In a <em>MxNxK</em> sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> operation, the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> of shape <em>MxK</em> is
stored in a packed form as <em>Mx(K/2)</em> in memory. For each <em>K-wide</em> row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>,
50% of elements are zeros and the remaining <em>K/2</em> non-zero elements are stored in
memory. The metadata specifies the mapping of the <em>K/2</em> non-zero elements to the <em>K</em>
elements before performing the MMA operation.</p>
<p>Granularity of sparse matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is defined as the ratio of the number of non-zero
elements in a sub-chunk of the matrix row to the total number of elements in that
sub-chunk where the size of the sub-chunk is shape-specific. The following table lists
the granularity of different <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> variants:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 51%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.kind of tcgen05.mma</p></th>
<th class="head"><p>Sparse Granularity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></p></td>
<td><p>1:2</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></p></td>
<td rowspan="4"><p>2:4</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p>4:8 (in pairs)</p></td>
</tr>
</tbody>
</table>
<section id="tcgen05-sparse-matrices-kind-tf32">
<span id="id520"></span><h6>
<span class="section-number">9.7.16.10.8.1. </span><a class="reference internal" href="#tcgen05-sparse-matrices-kind-tf32">Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-kind-tf32" title="Permalink to this headline">ïƒ</a>
</h6>
<p>For <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code>, matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is structured sparse at a granularity of <code class="docutils literal notranslate"><span class="pre">1:2</span></code>.
In other words, each chunk of two adjacent elements in a row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> has one
zero and one non-zero element. Only the non-zero element is stored in memory and the
4-bit index in the metadata indicates the position of the non-zero element in the
two-wide chunk. The only meaningful values of the index are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0b1110</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b0100</span></code></p></li>
</ul>
<p>Rest of the values result in undefined behavior.</p>
<figure class="align-center" id="tcgen05-sparse-mma-metadata-tf32">
<img alt="_images/tcgen05-sparse-mma-metadata-tf32.png" class="image" src="_images/tcgen05-sparse-mma-metadata-tf32.png">
<figcaption>
<p><span class="caption-number">Figure 259 </span><span class="caption-text">Sparse tcgen05.mma metadata example for tf32 kind</span><a class="headerlink" href="#tcgen05-sparse-mma-metadata-tf32" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-kind-f16-f8f8f4-mxf8f6f4">
<span id="id521"></span><h6>
<span class="section-number">9.7.16.10.8.2. </span><a class="reference internal" href="#tcgen05-sparse-matrices-kind-f16-f8f8f4-mxf8f6f4">Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-kind-f16-f8f8f4-mxf8f6f4" title="Permalink to this headline">ïƒ</a>
</h6>
<p>For the following <code class="docutils literal notranslate"><span class="pre">.kind</span></code> variants of <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::f8f8f4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></li>
</ul>
<p>matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is structured sparse at a granularity of <code class="docutils literal notranslate"><span class="pre">2:4</span></code>. In other words, each chunk
of four adjacent elements in a row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> has two zero and two non-zero elements.
Only the non-zero elements are stored in memory and the two 2-bit indices in the metadata
indicates the position of the two non-zero elements in the four-wide chunk. The only
meaningful values of the index are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0b0100</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1000</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1100</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1001</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1101</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b0110</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1110</span></code></p></li>
</ul>
<figure class="align-center" id="tcgen05-sparse-mma-metadata-f16-f8f6f4-mxf8f6f4">
<img alt="_images/tcgen05-sparse-mma-metadata-f16-f8f6f4-mxf8f6f4.png" class="image" src="_images/tcgen05-sparse-mma-metadata-f16-f8f6f4-mxf8f6f4.png">
<figcaption>
<p><span class="caption-number">Figure 260 </span><span class="caption-text">Sparse tcgen05.mma metadata example for f16/f8f6f4/mxf8f6f4 kind</span><a class="headerlink" href="#tcgen05-sparse-mma-metadata-f16-f8f6f4-mxf8f6f4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-kind-mxf4">
<span id="id522"></span><h6>
<span class="section-number">9.7.16.10.8.3. </span><a class="reference internal" href="#tcgen05-sparse-matrices-kind-mxf4">Sparse <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-kind-mxf4" title="Permalink to this headline">ïƒ</a>
</h6>
<p>For <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>, matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> is pair-wise structured
sparse at a granularity of <code class="docutils literal notranslate"><span class="pre">4:8</span></code>. In other words, each chunk of eight adjacent
elements in a row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> has four zero and four non-zero elements. The
zero and non-zero elements are clustered in sub-chunks of two elements each within
the eight-wide chunk, so each two-wide sub-chunk within the eight-wide chunk must be
all zeros or all non-zeros. Only the four non-zero elements are stored in memory and
the two 2-bit indices in the metadata indicates the position of the two two-wide
sub-chunks with non-zero values in the eight-wide chunk of a row of matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>.
The only meaningful values of the index are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">0b0100</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1000</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1100</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1001</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1101</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b0110</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">0b1110</span></code></p></li>
</ul>
<p>Rest of the values result in undefined behavior.</p>
<figure class="align-center" id="tcgen05-sparse-mma-metadata-mxf4">
<img alt="_images/tcgen05-sparse-mma-metadata-mxf4.png" class="image" src="_images/tcgen05-sparse-mma-metadata-mxf4.png">
<figcaption>
<p><span class="caption-number">Figure 261 </span><span class="caption-text">Sparse tcgen05.mma metadata example for mxf4 kind</span><a class="headerlink" href="#tcgen05-sparse-mma-metadata-mxf4" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector">
<span id="id523"></span><h6>
<span class="section-number">9.7.16.10.8.4. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector">Sparsity selector</a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The value of the sparsity selector selects the sub-columns in the Tensor Memory
to form the sparsity metadata matrix, which is used with matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> to form the
multiplicand matrix.</p>
<p>The following shows the sparse metadata matrix layout in Tensor Memory for various MMA variants:</p>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64">
<span id="id524"></span><h7><span class="section-number">9.7.16.10.8.4.1. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64">Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64" title="Permalink to this headline">ïƒ</a></h7>
<p><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64-dig"><span class="std std-numref">Figure 262</span></a> shows which sub-columns gets
selected for different values of Sparsity Selector.</p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64.png">
<figcaption>
<p><span class="caption-number">Figure 262 </span><span class="caption-text">Sparsity Metadata Layout for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m64-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256">
<span id="id525"></span><h7><span class="section-number">9.7.16.10.8.4.2. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256">Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256" title="Permalink to this headline">ïƒ</a></h7>
<p><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256-dig"><span class="std std-numref">Figure 263</span></a> shows which sub-columns gets
selected for different values of Sparsity Selector.</p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256.png">
<figcaption>
<p><span class="caption-number">Figure 263 </span><span class="caption-text">Sparsity Metadata Layout for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f16-m128-256-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64">
<span id="id526"></span><h7><span class="section-number">9.7.16.10.8.4.3. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64">Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64" title="Permalink to this headline">ïƒ</a></h7>
<p><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64-dig"><span class="std std-numref">Figure 264</span></a> shows which sub-columns gets
selected for different values of Sparsity Selector.</p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64.png">
<figcaption>
<p><span class="caption-number">Figure 264 </span><span class="caption-text">Sparsity Metadata Layout for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m64-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256">
<span id="id527"></span><h7><span class="section-number">9.7.16.10.8.4.4. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256">Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256" title="Permalink to this headline">ïƒ</a></h7>
<p><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256-dig"><span class="std std-numref">Figure 265</span></a> shows which sub-columns gets
selected for different values of Sparsity Selector.</p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256.png">
<figcaption>
<p><span class="caption-number">Figure 265 </span><span class="caption-text">Sparsity Metadata Layout for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-tf32-m128-256-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64">
<span id="id528"></span><h7><span class="section-number">9.7.16.10.8.4.5. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64">Layout of the Sparsity Metadata Matrix for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64" title="Permalink to this headline">ïƒ</a></h7>
<p>The value of the sparsity selector:</p>
<ul class="simple">
<li><p>must be 0 for <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></li>
<li><p>is assumed to be 0 for <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></li>
</ul>
<p>and all of the columns are selected as
shown in <a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64-dig"><span class="std std-numref">Figure 266</span></a></p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64.png">
<figcaption>
<p><span class="caption-number">Figure 266 </span><span class="caption-text">Sparsity Metadata Layout for M = 64 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m64-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
<section id="tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256">
<span id="id529"></span><h7><span class="section-number">9.7.16.10.8.4.6. </span><a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256">Layout of the Sparsity Metadata Matrix for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></a><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256" title="Permalink to this headline">ïƒ</a></h7>
<p>The value of the sparsity selector:</p>
<ul class="simple">
<li><p>must be 0 for <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></li>
<li><p>is assumed to be 0 for <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></p></li>
</ul>
<p>and all of the columns are selected as
shown in <a class="reference internal" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256-dig"><span class="std std-numref">Figure 267</span></a></p>
<figure class="align-center" id="tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256-dig">
<img alt="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256.png" class="image" src="_images/tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256.png">
<figcaption>
<p><span class="caption-number">Figure 267 </span><span class="caption-text">Sparsity Metadata Layout for M = 128 / M = 256 for <code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code></span><a class="headerlink" href="#tcgen05-sparse-matrices-sparsity-selector-kind-f8f6f4-mxf8f6f4-m128-256-dig" title="Permalink to this image">ïƒ</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="tcgen05-sparse-matrices-alignment-restriction">
<span id="id530"></span><h6>
<span class="section-number">9.7.16.10.8.5. </span><a class="reference internal" href="#tcgen05-sparse-matrices-alignment-restriction">Alignment restriction</a><a class="headerlink" href="#tcgen05-sparse-matrices-alignment-restriction" title="Permalink to this headline">ïƒ</a>
</h6>
<p>The layouts which utilize only half the datapath lanes as specified in
<a class="reference internal" href="#tcgen05-data-path-layout-organization"><span class="std std-ref">Data Path Layout Organization</span></a>,
i.e. <a class="reference internal" href="#tcgen05-data-path-layout-f"><span class="std std-ref">Layout F</span></a> and
<a class="reference internal" href="#tcgen05-data-path-layout-c"><span class="std std-ref">Layout C</span></a>, must use the same alignment
across matrices A, D and the sparsity metadata matrix.</p>
</section>
</section>
<section id="tcgen05-mma-instructions">
<span id="id531"></span><h5>
<span class="section-number">9.7.16.10.9. </span><a class="reference internal" href="#tcgen05-mma-instructions">TensorCore 5th Generation of MMA Instructions</a><a class="headerlink" href="#tcgen05-mma-instructions" title="Permalink to this headline">ïƒ</a>
</h5>
<section id="tcgen05-mma-instructions-mma">
<span id="id532"></span><h6>
<span class="section-number">9.7.16.10.9.1. </span><a class="reference internal" href="#tcgen05-mma-instructions-mma">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code></a><a class="headerlink" href="#tcgen05-mma-instructions-mma" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code></p>
<p>Perform the 5<sup>th</sup> generation of matrix multiply and accumulate operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 1. Floating-point type without block scaling:

tcgen05.mma.cta_group.kind   [d-tmem],  a-desc,  b-desc, idesc,
                             { disable-output-lane }, enable-input-d {, scale-input-d};

tcgen05.mma.cta_group.kind   [d-tmem], [a-tmem], b-desc, idesc,
                             { disable-output-lane }, enable-input-d {, scale-input-d};

.kind      = { .kind::f16, .kind::tf32, .kind::f8f6f4 }
.cta_group = { .cta_group::1, .cta_group::2 }

----------------------------------------------------------------------------------

// 2. Floating-point type with block scaling:

tcgen05.mma.cta_group.kind.block_scale{.scale_vectorsize}
                                        [d-tmem],  a-desc,  b-desc, idesc,
                                        [scale-A-tmem], [scale-B-tmem], enable-input-d;

tcgen05.mma.cta_group.kind.block_scale{.scale_vectorsize}
                                        [d-tmem], [a-tmem], b-desc, idesc,
                                        [scale-A-tmem], [scale-B-tmem], enable-input-d;

.kind = { .kind::mxf8f6f4, .kind::mxf4, .kind::mxf4nvf4 }
.cta_group      = { .cta_group::1,   .cta_group::2 }
.scale_vectorsize = { .scale_vec::1X, .scale_vec::2X, .scale_vec::4X, .block16, .block32 }

----------------------------------------------------------------------------------

// 3. Convolution MMA for floating-point type without block scaling:

tcgen05.mma.cta_group.kind.collector_usage [d-tmem],  a-desc,  b-desc, idesc,
                                           { disable-output-lane }, enable-input-d {, scale-input-d};

tcgen05.mma.cta_group.kind{.ashift}.collector_usage [d-tmem], [a-tmem], b-desc, idesc,
                                                    { disable-output-lane }, enable-input-d {, scale-input-d};

tcgen05.mma.cta_group.kind.ashift{.collector_usage} [d-tmem], [a-tmem], b-desc, idesc,
                                                    { disable-output-lane }, enable-input-d {, scale-input-d};

.kind      = { .kind::f16, .kind::tf32, .kind::f8f6f4 }
.cta_group = { .cta_group::1,   .cta_group::2 }
.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }

----------------------------------------------------------------------------------

// 4. Activation Stationary MMA for floating-point type with block scaling:

tcgen05.mma.cta_group.kind.block_scale{.scale_vectorsize}.collector_usage
                                            [d-tmem],  a-desc,  b-desc, idesc,
                                            [scale-A-tmem], [scale-B-tmem], enable-input-d;

tcgen05.mma.cta_group.kind.block_scale{.scale_vectorsize}.collector_usage
                                            [d-tmem], [a-tmem], b-desc, idesc,
                                            [scale-A-tmem], [scale-B-tmem], enable-input-d;

.cta_group       = { .cta_group::1,   .cta_group::2 }
.scale_vectorsize  = { .scale_vec::1X, .scale_vec::2X, .scale_vec::4X, .block16, .block32 }
.kind            = { .kind::mxf8f6f4, .kind::mxf4, .kind::mxf4nvf4 }
.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }

----------------------------------------------------------------------------------

// 5. Integer type:

tcgen05.mma.cta_group.kind::i8  [d-tmem],  a-desc,  b-desc, idesc,
                                { disable-output-lane }, enable-input-d;

tcgen05.mma.cta_group.kind::i8  [d-tmem], [a-tmem], b-desc, idesc,
                                { disable-output-lane }, enable-input-d;

.cta_group = { .cta_group::1,   .cta_group::2  }

----------------------------------------------------------------------------------

// 6. Convolution MMA for integer type:

tcgen05.mma.cta_group.kind::i8.collector_usage          [d-tmem],  a-desc,  b-desc, idesc,
                                                        { disable-output-lane }, enable-input-d;

tcgen05.mma.cta_group.kind::i8.ashift{.collector_usage} [d-tmem], [a-tmem], b-desc, idesc,
                                                        { disable-output-lane }, enable-input-d;

tcgen05.mma.cta_group.kind::i8{.ashift}.collector_usage [d-tmem], [a-tmem], b-desc, idesc,
                                                        { disable-output-lane }, enable-input-d;

.cta_group       = { .cta_group::1,   .cta_group::2  }
.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> is an asynchronous instruction which initiates an <em>MxNxK</em> matrix
multiply and accumulate operation,
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span></code>
where the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix is <em>MxK</em>, the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix is <em>KxN</em>, and the <code class="docutils literal notranslate"><span class="pre">D</span></code> matrix is <em>MxN</em>.</p>
<p>The operation of the form
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code>
is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">enable-input-d</span></code> is false.</p>
<p>The optional immediate argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> can be specified to scale the input
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> as follows:
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span> <span class="pre">*</span> <span class="pre">(2</span> <span class="pre">^</span> <span class="pre">-</span> <span class="pre">scale-input-d)</span></code></p>
<p>The valid range of values for argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> is [0, 15]. The argument
<code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> is only valid for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code>.</p>
<p>The 32-bit register operand <code class="docutils literal notranslate"><span class="pre">idesc</span></code> is the instruction descriptor as described
in <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>, specifies
the shapes, exact types, sparsity and other details of the input matrices,
output matrix and the matrix multiply and accumulate operation.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> specifies that the matrix multiply and
accumulate operation is performed on the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of the
executing threadâ€™s CTA only. The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> specifies that the matrix
multiply and accumulate operation is performed on the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
of the executing threadâ€™s CTA and its <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTA</span></a>.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> has single thread semantics, unlike the collective
instructions <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>. So, a single thread issuing the
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> will result in the initiation of the whole matrix multiply and
accumulate operation. Refer to the section <a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a>.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.kind</span></code> specifies the general kind of the element types of the multiplicand
matrices. The exact types of the elements of the input and output matrices for each MMA-kind
are specified in the <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>.</p>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">d-tmem</span></code> specifies the address of the destination and the accumulation
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The address operand <code class="docutils literal notranslate"><span class="pre">a-tmem</span></code>
specifies the address of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.
The 64-bit register operand <code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which
represent the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> in shared memory respectively. The format of the
matrix descriptor is described in <a class="reference internal" href="#tcgen05-matrix-descriptors"><span class="std std-ref">Matrix Descriptors</span></a>.</p>
<p>The vector operand <code class="docutils literal notranslate"><span class="pre">disable-output-lane</span></code> specifies the lane(s) in the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> that should be not be updated with the resultant
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code>. Elements of the vector operand <code class="docutils literal notranslate"><span class="pre">disable-output-lane</span></code> forms a mask where
each bit corresponds to a lane of the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>, with least
significant bit of the first element of the vector (leftmost in syntax) corresponding
to the lane 0 of the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. If a bit in the mask is 1,
then the corresponding lane in the Tensor Memory for the resultant matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> will not
be updated. The size of the vector is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 23%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.cta_group</p></th>
<th class="head"><p>Size of the vector disable-output-lane</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>::1</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>::2</p></td>
<td><p>8</p></td>
</tr>
</tbody>
</table>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> specifies that the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are scaled with
<code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively before performing the matrix multiply
and accumulate operation as specified in the section <a class="reference internal" href="#tcgen05-block-scaling"><span class="std std-ref">Block Scaling for tcgen05.mma.sync</span></a>.
The address operand <code class="docutils literal notranslate"><span class="pre">scale-A-tmem</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-B-tmem</span></code> specify the base address the
matrices <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> respectively in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p>
<p>For qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code>,</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">.scale_vec::NX</span></code> is specified: N specifies the number of columns in <code class="docutils literal notranslate"><span class="pre">scale_A</span></code>
matrix and number of rows in <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrix.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.blockN</span></code> is specified: N specifies the block size for which single scale factor
will be applied. In this form, value of N is same as the K-dimension / (N of <code class="docutils literal notranslate"><span class="pre">.scale_vec::NX</span></code>).</p></li>
</ul>
<p>Aliased <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> variants:</p>
<ol class="arabic simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">.block16</span></code> is aliased with:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf4nvf4</span></code> and K = 64 or 128</p></li>
</ol>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.block32</span></code> is aliased with:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf8f6f4</span></code> for all supported values of K</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and K = 64 or 128</p></li>
</ol>
</li>
</ol>
<p>The valid combinations of MMA-kind and <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> are
described in <a class="reference internal" href="#tcgen05-mma-scale-valid-comb"><span class="std std-numref">Table 56</span></a>. For <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> when the qualifier
<code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.block32</span></code>. For <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>,
the qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> must be explicitly specified.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.ashift</span></code> shifts the rows of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix down by one row, except for
the last row in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. Qualifier <code class="docutils literal notranslate"><span class="pre">.ashift</span></code> is only allowed
with <em>M</em> = 128 or <em>M</em> = 256.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> specifies the usage of collector buffer for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>.
Following collector buffer operations can be specified:</p>
<table class="table-no-stripes longtable docutils align-default">
<colgroup>
<col style="width: 34%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.collector_usage</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::fill</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix read from the memory
should be filled in collector buffer.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::use</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix can be read from the
collector buffer. This requires a previous fill to
the collector buffer to be still valid.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::lastuse</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix can be read from the
collector buffer and the contents of the collector
buffer can be discarded. This requires a previous
fill to the collector buffer to be valid till the
collector buffer is read.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::discard</span></code></p></td>
<td><p>Specifies that the contents of the collector buffer
for <code class="docutils literal notranslate"><span class="pre">A</span></code> can be discarded.</p></td>
</tr>
</tbody>
</table>
<p>If no <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> qualifier is specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.collector::a::discard</span></code>.
It is illegal to specify either of <code class="docutils literal notranslate"><span class="pre">.collector::a::use</span></code> or <code class="docutils literal notranslate"><span class="pre">.collector::a::fill</span></code> along with
<code class="docutils literal notranslate"><span class="pre">.ashift</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> introduced in PTX ISA version 8.7.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.block16</span></code> and <code class="docutils literal notranslate"><span class="pre">.block32</span></code> introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8 except <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p>Argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> and is supported on <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family from PTX ISA version 8.8.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code>,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.block16</span></code>, <code class="docutils literal notranslate"><span class="pre">.block32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>.</p></li>
</ul>
<p>For Target ISA details on matrix shape, check <a class="reference internal" href="#tcgen05-matrix-shape-target-isa-note"><span class="std std-ref">Target ISA Note</span></a>.</p>
<p>For Target ISA details on shared memory descriptor, check <a class="reference internal" href="#tcgen05-shared-memory-descriptor-target-isa-note"><span class="std std-ref">Target ISA Note</span></a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma.cta_group::1.kind::tf32      [taddr0],  adesc,  bdesc, idesc, {m0, m1, m2, m3}, p;
tcgen05.mma.cta_group::1.kind::mxf8f6f4  [taddr2],  [taddr1],  bdesc, idesc,
                                         [tmem_scaleA], [tmem_scaleB], p;

tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [mbarObj0];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj0], 0;
@!p bra loop;
</pre></div>
</div>
</section>
<section id="tcgen05-mma-instructions-mma-sp">
<span id="id533"></span><h6>
<span class="section-number">9.7.16.10.9.2. </span><a class="reference internal" href="#tcgen05-mma-instructions-mma-sp">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code></a><a class="headerlink" href="#tcgen05-mma-instructions-mma-sp" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code></p>
<p>Perform the 5<sup>th</sup> generation of matrix multiply and accumulate operation with sparse <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 1. Floating-point type without block scaling:

tcgen05.mma.sp.cta_group.kind  [d-tmem],  a-desc,  b-desc, [sp-meta-tmem] ,  idesc,
                               { disable-output-lane }, enable-input-d{, scale-input-d};

tcgen05.mma.sp.cta_group.kind  [d-tmem], [a-tmem], b-desc, [sp-meta-tmem] , idesc,
                               { disable-output-lane }, enable-input-d{, scale-input-d};

.kind       = { .kind::f16, , .kind::tf32, .kind::f8f6f4 }
.cta_group  = { .cta_group::1,  .cta_group::2 }

----------------------------------------------------------------------------------

// 2. Floating-point type with block scaling:

tcgen05.mma.sp.cta_group.kind.block_scale{.scale_vectorsize}
                                         [d-tmem],  a-desc,  b-desc , [sp-meta-tmem] , idesc,
                                         [scale-A-tmem], [scale-B-tmem], enable-input-d;

tcgen05.mma.sp.cta_group.kind.block_scale{.scale_vectorsize}
                                         [d-tmem], [a-tmem], b-desc , [sp-meta-tmem] , idesc,
                                         [scale-A-tmem], [scale-B-tmem], enable-input-d;

.scale_vectorsize = { .scale_vec::1X, .scale_vec::2X, .scale_vec::4X, .block16, .block32 }
.cta_group      = { .cta_group::1,  .cta_group::2 }
.kind = { .kind::mxf8f6f4, .kind::mxf4, .kind::mxf4nvf4 }

----------------------------------------------------------------------------------

// 3. Convolution MMA with floating-point type without block scaling:

tcgen05.mma.sp.cta_group.kind.collector_usage           [d-tmem],  a-desc,  b-desc,
                                                        [sp-meta-tmem] ,  idesc,
                                                        { disable-output-lane }, enable-input-d
                                                        {, scale-input-d};

tcgen05.mma.sp.cta_group.kind.ashift{.collector_usage}  [d-tmem], [a-tmem], b-desc,
                                                        [sp-meta-tmem] , idesc,
                                                        { disable-output-lane }, enable-input-d
                                                        {, scale-input-d};

tcgen05.mma.sp.cta_group.kind{.ashift}.collector_usage  [d-tmem], [a-tmem], b-desc,
                                                        [sp-meta-tmem] , idesc,
                                                        { disable-output-lane }, enable-input-d
                                                        {, scale-input-d};

.kind            = { .kind::f16, .kind::tf32, .kind::f8f6f4 }
.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }

----------------------------------------------------------------------------------

// 4. Activation Stationary MMA with floating-point type with block scaling:

tcgen05.mma.sp.cta_group.kind.block_scale{.scale_vectorsize}.collector_usage
                                         [d-tmem],  a-desc,  b-desc , [sp-meta-tmem] , idesc,
                                         [scale-A-tmem], [scale-B-tmem], enable-input-d;

tcgen05.mma.sp.cta_group.kind.block_scale{.scale_vectorsize}.collector_usage
                                         [d-tmem], [a-tmem], b-desc , [sp-meta-tmem] , idesc,
                                         [scale-A-tmem], [scale-B-tmem], enable-input-d;

.kind = { .kind::mxf8f6f4, .kind::mxf4, .kind::mxf4nvf4 }
.scale_vectorsize = { .scale_vec::1X, .scale_vec::2X, .scale_vec::4X, .block16, .block32 }
.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }

----------------------------------------------------------------------------------

// 5. Integer type:

tcgen05.mma.sp.cta_group.kind::i8 [d-tmem],  a-desc,  b-desc, [sp-meta-tmem] , idesc,
                                  { disable-output-lane }, enable-input-d;

tcgen05.mma.sp.cta_group.kind::i8 [d-tmem], [a-tmem], b-desc, [sp-meta-tmem] , idesc,
                                  { disable-output-lane }, enable-input-d;

.cta_group      = { .cta_group::1,  .cta_group::2 }

----------------------------------------------------------------------------------

// 6. Convolution MMA with Integer type:

tcgen05.mma.sp.cta_group.kind::i8.collector_usage          [d-tmem],  a-desc,  b-desc,
                                                           [sp-meta-tmem] , idesc,
                                                           { disable-output-lane }, enable-input-d;

tcgen05.mma.sp.cta_group.kind::i8.ashift{.collector_usage} [d-tmem], [a-tmem], b-desc,
                                                           [sp-meta-tmem], idesc ,
                                                           { disable-output-lane }, enable-input-d;

tcgen05.mma.sp.cta_group.kind::i8{.ashift}.collector_usage [d-tmem], [a-tmem], b-desc,
                                                           [sp-meta-tmem], idesc ,
                                                           { disable-output-lane }, enable-input-d;

.collector_usage = { .collector::buffer::op }
::buffer         = { ::a }
::op             = { ::fill, ::use, ::lastuse, ::discard* }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> is an asynchronous instruction which initiates an
<em>MxNxK</em> matrix multiply and accumulate operation of the form
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span></code>
where the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix is <em>Mx(K/2)</em>, the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix is <em>KxN</em>, and the <code class="docutils literal notranslate"><span class="pre">D</span></code> matrix is <em>MxN</em>.
<a class="reference internal" href="#tcgen05-sparse-matrices"><span class="std std-ref">Sparse Matrices</span></a> describes the details of the sparsity.</p>
<p>The operation of the form
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code>
is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">enable-input-d</span></code> is false.</p>
<p>The optional immediate argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> can be specified to scale the
input matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> as follows:
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span> <span class="pre">*</span> <span class="pre">(2</span> <span class="pre">^</span> <span class="pre">-</span> <span class="pre">scale-input-d)</span></code></p>
<p>The valid range of values for argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> is [0, 15]. The argument
<code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> is only valid for <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code>.</p>
<p>The 32-bit register operand <code class="docutils literal notranslate"><span class="pre">idesc</span></code> is the instruction descriptor as described in
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>, specifies the shapes,
exact types, sparsity and other details of the input matrices, output matrix and the
matrix multiply and accumulate operation.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> specifies that the matrix multiply and accumulate
operation is performed on the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of the executing
threadâ€™s CTA only. The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> specifies that the matrix
multiply and accumulate operation is performed on the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
of the executing threadâ€™s CTA and its <a class="reference internal" href="#tcgen05-peer-cta"><span class="std std-ref">peer CTA</span></a>.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> has single thread semantics, unlike the collective
instructions <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>. So, a single thread issuing the
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code> will result in the initiation of the whole matrix multiply and
accumulate operation. Refer to the section <a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a>.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.kind</span></code> specifies the general kind of the element types of the multiplicand
matrices. The exact types of the elements of the input and output matrices for each MMA-kind
are specified in the <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>.</p>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">d-tmem</span></code> specifies the address of the destination and the accumulation
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The address operand <code class="docutils literal notranslate"><span class="pre">a-tmem</span></code>
specifies the address of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The
64-bit register operand <code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which represent
the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> in shared memory respectively. The format of the matrix descriptor
is described in <a class="reference internal" href="#tcgen05-matrix-descriptors"><span class="std std-ref">Matrix Descriptors</span></a>.</p>
<p>The vector operand <code class="docutils literal notranslate"><span class="pre">disable-output-lane</span></code> specifies the lane(s) in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>
that should be not be updated with the resultant matrix <code class="docutils literal notranslate"><span class="pre">D</span></code>. Elements of the vector operand
<code class="docutils literal notranslate"><span class="pre">disable-output-lane</span></code> forms a mask where each bit corresponds to a lane of the
<a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. with least significant bit of the first element of
the vector (leftmost in syntax) corresponding to the lane 0 of the Tensor Memory. If a bit in
the mask is 1, then the corresponding lane in the Tensor Memory for the resultant matrix <code class="docutils literal notranslate"><span class="pre">D</span></code>
will not be updated. The size of the vector is as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 23%">
<col style="width: 77%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.cta_group</p></th>
<th class="head"><p>Size of the vector disable-output-lane</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>::1</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-odd">
<td><p>::2</p></td>
<td><p>8</p></td>
</tr>
</tbody>
</table>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> specifies that the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> are scaled with
<code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrices respectively before performing the matrix multiply
and accumulate operation as specified in the section <a class="reference internal" href="#tcgen05-block-scaling"><span class="std std-ref">Block Scaling for tcgen05.mma.sync</span></a>.
The address operand <code class="docutils literal notranslate"><span class="pre">scale-A-tmem</span></code> and <code class="docutils literal notranslate"><span class="pre">scale-B-tmem</span></code> specify the base address the
matrices <code class="docutils literal notranslate"><span class="pre">scale_A</span></code> and <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> respectively in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>.</p>
<p>For qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code>,</p>
<ul class="simple">
<li><p>If <code class="docutils literal notranslate"><span class="pre">.scale_vec::NX</span></code> is specified: N specifies the number of columns in <code class="docutils literal notranslate"><span class="pre">scale_A</span></code>
matrix and number of rows in <code class="docutils literal notranslate"><span class="pre">scale_B</span></code> matrix.</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">.blockN</span></code> is specified: N specifies the block size for which single scale factor
will be applied. In this form, value of N is same as the K-dimension / (N of <code class="docutils literal notranslate"><span class="pre">.scale_vec::NX</span></code>).</p></li>
</ul>
<p>Aliased <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> variants:</p>
<ol class="arabic simple">
<li>
<p><code class="docutils literal notranslate"><span class="pre">.block16</span></code> is aliased with:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf4nvf4</span></code> and K = 64 or 128</p></li>
</ol>
</li>
<li>
<p><code class="docutils literal notranslate"><span class="pre">.block32</span></code> is aliased with:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf8f6f4</span></code> for all supported values of K</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code> when <code class="docutils literal notranslate"><span class="pre">.kind</span> <span class="pre">=</span> <span class="pre">.kind::mxf4</span></code> or <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and K = 64 or 128</p></li>
</ol>
</li>
</ol>
<p>The valid combinations of MMA-kind and <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> are
described in <a class="reference internal" href="#tcgen05-mma-scale-valid-comb"><span class="std std-numref">Table 56</span></a>. For <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> when the qualifier
<code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> is not specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.block32</span></code>. For <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>,
the qualifier <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code> must be explicitly specified.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.ashift</span></code> shifts the rows of the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix down by one row, except for
the last row in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. Qualifier <code class="docutils literal notranslate"><span class="pre">.ashift</span></code> is only allowed
with <em>M</em> = 128 or <em>M</em> = 256.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> specifies the usage of collector buffer for matrix <code class="docutils literal notranslate"><span class="pre">A</span></code>.
Following collector buffer operations can be specified:</p>
<table class="table-no-stripes longtable docutils align-default">
<colgroup>
<col style="width: 34%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.collector_usage</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::fill</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix read from the memory
should be filled in collector buffer.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::use</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix can be read from the
collector buffer. This requires a previous fill to
the collector buffer to be still valid.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::lastuse</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix can be read from the
collector buffer and the contents of the collector
buffer can be discarded. This requires a previous
fill to the collector buffer to be valid till the
collector buffer is read.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::a::discard</span></code></p></td>
<td><p>Specifies that the contents of the collector buffer
for <code class="docutils literal notranslate"><span class="pre">A</span></code> can be discarded.</p></td>
</tr>
</tbody>
</table>
<p>If no <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> qualifier is specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.collector::a::discard</span></code>.
It is illegal to specify either of <code class="docutils literal notranslate"><span class="pre">.collector::a::use</span></code> or <code class="docutils literal notranslate"><span class="pre">.collector::a::fill</span></code> along with
<code class="docutils literal notranslate"><span class="pre">.ashift</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> introduced in PTX ISA version 8.7.</p>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.block16</span></code> and <code class="docutils literal notranslate"><span class="pre">.block32</span></code> introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8 except <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>/<code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>/<code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code> are supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p>Argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> and is supported on <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family from PTX ISA version 8.8.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">.scale_vectorsize</span></code>,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.block16</span></code>, <code class="docutils literal notranslate"><span class="pre">.block32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>.</p></li>
</ul>
<p>For Target ISA details on matrix shape, check <a class="reference internal" href="#tcgen05-matrix-shape-target-isa-note"><span class="std std-ref">Target ISA Note</span></a>.</p>
<p>For Target ISA details on shared memory descriptor, check <a class="reference internal" href="#tcgen05-shared-memory-descriptor-target-isa-note"><span class="std std-ref">Target ISA Note</span></a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma.sp.cta_group::1.kind::f16      [taddr0],  adesc,  bdesc, [tmem_spmeta0], idesc, p;

tcgen05.mma.sp.cta_group::1.kind::mxf8f6f4.collector::a:fill
                                           [taddr2],  [taddr1],  bdesc, [tmem_spmeta1], idesc,
                                           [tmem_scaleA], [tmem_scaleB], p;

tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [mbarObj0];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj0], 0;
@!p bra loop;
</pre></div>
</div>
</section>
<section id="tcgen05-mma-instructions-mma-ws">
<span id="id534"></span><h6>
<span class="section-number">9.7.16.10.9.3. </span><a class="reference internal" href="#tcgen05-mma-instructions-mma-ws">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code></a><a class="headerlink" href="#tcgen05-mma-instructions-mma-ws" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code></p>
<p>Perform the 5<sup>th</sup> generation of weight stationary convolution matrix multiply and accumulate
operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 1. Floating-point type without block scaling:

tcgen05.mma.ws.cta_group::1.kind{.collector_usage}    [d-tmem],  a-desc,  b-desc,  idesc,
                                                      enable-input-d {, zero-column-mask-desc };

tcgen05.mma.ws.cta_group::1.kind{.collector_usage}    [d-tmem], [a-tmem], b-desc, idesc,
                                                      enable-input-d {, zero-column-mask-desc };

.kind = { .kind::f16, .kind::tf32, .kind::f8f6f4 }

----------------------------------------------------------------------------------

// 2. Integer type:

tcgen05.mma.ws.cta_group::1.kind::i8{.collector_usage} [d-tmem],  a-desc,  b-desc, idesc,
                                                       enable-input-d {, zero-column-mask-desc};

tcgen05.mma.ws.cta_group::1.kind::i8{.collector_usage} [d-tmem], [a-tmem], b-desc, idesc,
                                                       enable-input-d {, zero-column-mask-desc};

.collector_usage = { .collector::buffer::op }
::buffer = { ::b0, ::b1, ::b2, ::b3 }
::op   = { ::fill, ::use, ::lastuse, ::discard}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code> is an asynchronous instruction which initiates an <em>MxNxK</em>
matrix multiply and accumulate operation,
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span></code>
where the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix is <em>MxK</em>, the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix is <em>KxN</em>, and the <code class="docutils literal notranslate"><span class="pre">D</span></code> matrix is <em>MxN</em>.</p>
<p>The operation of the form
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code>
is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">enable-input-d</span></code> is false.</p>
<p>The 32-bit register operand <code class="docutils literal notranslate"><span class="pre">idesc</span></code> is the instruction descriptor as described in
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>, specifies the shapes, exact
types, sparsity and other details of the input matrices, output matrix and the matrix
multiply and accumulate operation.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> specifies that the matrix multiply and accumulate operation
is performed on the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a> of the executing threadâ€™s CTA only.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code> has single thread semantics, unlike the collective
instructions <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>. So, a single thread issuing the
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code> will result in the initiation of the whole matrix multiply and accumulate
operation. Refer to the section <a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a>.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.kind</span></code> specifies the general kind of the element types of the multiplicand
matrices. The exact types of the elements of the input and output matrices for each MMA-kind
are specified in the <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>.</p>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">d-tmem</span></code> specifies the address of the destination and the accumulation
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The address operand <code class="docutils literal notranslate"><span class="pre">a-tmem</span></code>
specifies the address of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The
64-bit register operand <code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which represent
the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> in shared memory respectively. The format of the matrix descriptor
is described in <a class="reference internal" href="#tcgen05-matrix-descriptors"><span class="std std-ref">Matrix Descriptors</span></a>.</p>
<p>The optional operand <code class="docutils literal notranslate"><span class="pre">zero-column-mask-desc</span></code> is a 64-bit register which specifies the
<a class="reference internal" href="#tcgen05-zero-column-mask-descriptor"><span class="std std-ref">Zero-Column Mask Descriptor</span></a>. The zero-column
mask descriptor is used to generate a mask that specifies which columns of <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix
will have zero value for the matrix multiply and accumulate operation regardless of the
values present in the shared memory.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> specifies the usage of collector buffer for Matrix <code class="docutils literal notranslate"><span class="pre">B</span></code>.
Following collector buffer operations can be specified:</p>
<table class="table-no-stripes longtable docutils align-default">
<colgroup>
<col style="width: 35%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.collector_usage</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::fill</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix read from the memory
should be filled in collector buffer #N.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::use</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix can be read from the
collector buffer #N. This requires a previous fill
to the collector buffer #N to be still valid.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::lastuse</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix can be read from the
collector buffer #N after which the contents of the
collector buffer #N can be discarded. This requires
a previous fill to the collector buffer #N to be
valid till the collector buffer #N is read.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::discard</span></code></p></td>
<td><p>Specifies that the contents of the collector buffer
#N can be discarded.</p></td>
</tr>
</tbody>
</table>
<p>If no <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> qualifier is specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.collector::b0::discard</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8 except <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma.ws.cta_group::1.kind::i8.collector::b2:use [taddr2], [taddr1], bdesc, idesc, p;
tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [mbarObj0];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj0], 0;
@!p bra loop;
</pre></div>
</div>
</section>
<section id="tcgen05-mma-instructions-mma-ws-sp">
<span id="id535"></span><h6>
<span class="section-number">9.7.16.10.9.4. </span><a class="reference internal" href="#tcgen05-mma-instructions-mma-ws-sp">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code></a><a class="headerlink" href="#tcgen05-mma-instructions-mma-ws-sp" title="Permalink to this headline">ïƒ</a>
</h6>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code></p>
<p>Perform the 5<sup>th</sup> generation of weight stationary convolution matrix multiply and accumulate
operation with sparse <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 1. Floating-point type without block scaling:

tcgen05.mma.ws.sp.cta_group::1.kind{.collector_usage} [d-tmem],  a-desc,  b-desc,
                                                      [sp-meta-tmem] ,  idesc,
                                                      enable-input-d {, zero-column-mask-desc};

tcgen05.mma.ws.sp.cta_group::1.kind{.collector_usage} [d-tmem], [a-tmem], b-desc,
                                                      [sp-meta-tmem] , idesc,
                                                      enable-input-d {, zero-column-mask-desc};

.kind = { .kind::f16, .kind::tf32, .kind::f8f6f4 }

----------------------------------------------------------------------------------

// 2. Integer type:

tcgen05.mma.ws.sp.cta_group::1.kind::i8{.collector_usage} [d-tmem], a-desc, b-desc,
                                                          [sp-meta-tmem] , idesc,
                                                          enable-input-d {, zero-column-mask-desc};

tcgen05.mma.ws.sp.cta_group::1.kind::i8{.collector_usage} [d-tmem], [a-tmem], b-desc,
                                                          [sp-meta-tmem] , idesc,
                                                          enable-input-d {, zero-column-mask-desc};

.collector_usage = { .collector::buffer::op }
::buffer = { ::b0, ::b1, ::b2, ::b3 }
::op   = { ::fill, ::use, ::lastuse, ::discard}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code> is an asynchronous instruction which initiates
an <em>MxNxK</em> matrix multiply and accumulate operation,
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B+D</span></code>
where the <code class="docutils literal notranslate"><span class="pre">A</span></code> matrix is <em>Mx(K/2)</em>, the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix is <em>KxN</em>, and the <code class="docutils literal notranslate"><span class="pre">D</span></code> matrix
is <em>MxN</em>. <a class="reference internal" href="#tcgen05-sparse-matrices"><span class="std std-ref">Sparse Matrices</span></a> describes the details of the
sparsity.</p>
<p>The operation of the form
<code class="docutils literal notranslate"><span class="pre">D</span> <span class="pre">=</span> <span class="pre">A*B</span></code>
is issued when the input predicate argument <code class="docutils literal notranslate"><span class="pre">enable-input-d</span></code> is false.</p>
<p>The 32-bit register operand <code class="docutils literal notranslate"><span class="pre">idesc</span></code> is the instruction descriptor as described in
<a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>, specifies the shapes, exact
types, sparsity and other details of the input matrices, output matrix and the matrix
multiply and accumulate operation.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> specifies that the matrix multiply and accumulate
operation is performed on the Tensor Memory of the executing threadâ€™s CTA only.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code> has single thread semantics, unlike the collective
instructions <code class="docutils literal notranslate"><span class="pre">mma.sync</span></code> or <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>. So, a single thread issuing the
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code> will result in the initiation of the whole matrix multiply and
accumulate operation. Refer to the section <a class="reference internal" href="#tcgen05-issue-granularity"><span class="std std-ref">Issue Granularity</span></a>.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.kind</span></code> specifies the general kind of the element types of the multiplicand
matrices. The exact types of the elements of the input and output matrices for each MMA-kind are
specified in the <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a>.</p>
<p>The address operand <code class="docutils literal notranslate"><span class="pre">d-tmem</span></code> specifies the address of the destination and the accumulation
matrix <code class="docutils literal notranslate"><span class="pre">D</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The address operand <code class="docutils literal notranslate"><span class="pre">a-tmem</span></code> specifies
the address of the matrix <code class="docutils literal notranslate"><span class="pre">A</span></code> in the <a class="reference internal" href="#tensor-memory"><span class="std std-ref">Tensor Memory</span></a>. The 64-bit register
operand <code class="docutils literal notranslate"><span class="pre">a-desc</span></code> and <code class="docutils literal notranslate"><span class="pre">b-desc</span></code> are the matrix descriptors which represent the matrices <code class="docutils literal notranslate"><span class="pre">A</span></code>
and <code class="docutils literal notranslate"><span class="pre">B</span></code> in shared memory respectively. The format of the matrix descriptor is described in
<a class="reference internal" href="#tcgen05-matrix-descriptors"><span class="std std-ref">Matrix Descriptors</span></a>.</p>
<p>The optional operand <code class="docutils literal notranslate"><span class="pre">zero-column-mask-desc</span></code> is a 64-bit register which specifies the
<a class="reference internal" href="#tcgen05-zero-column-mask-descriptor"><span class="std std-ref">Zero-Column Mask Descriptor</span></a>. The zero-column
mask descriptor is used to generate a mask that specifies which columns of <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix
will have zero value for the matrix multiply and accumulate operation regardless of the
values present in the shared memory.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> specifies the usage of collector buffer for Matrix <code class="docutils literal notranslate"><span class="pre">B</span></code>.
Following collector buffer operations can be specified:</p>
<table class="table-no-stripes longtable docutils align-default">
<colgroup>
<col style="width: 35%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.collector_usage</p></th>
<th class="head"><p>Semantics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::fill</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix read from the memory
should be filled in collector buffer #N.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::use</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix can be read from the
collector buffer #N. This requires a previous fill
to the collector buffer #N to be still valid.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::lastuse</span></code></p></td>
<td><p>Specifies that the <code class="docutils literal notranslate"><span class="pre">B</span></code> matrix can be read from the
collector buffer #N after which the contents of the
collector buffer #N can be discarded. This requires
a previous fill to the collector buffer #N to be
valid till the collector buffer #N is read.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.collector::bN::discard</span></code></p></td>
<td><p>Specifies that the contents of the collector buffer
#N can be discarded.</p></td>
</tr>
</tbody>
</table>
<p>If no <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code> qualifier is specified, then it defaults to <code class="docutils literal notranslate"><span class="pre">.collector::b0::discard</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8 except <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code> is supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.mma.ws.sp.cta_group::1.kind::tf32.collector::b1::fill  [taddr1], [taddr0], bdesc,
                                                               [tmem_spmeta0], idesc, p;

tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [mbarObj0];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj0], 0;
@!p bra loop;
</pre></div>
</div>
</section>
</section>
</section>
<section id="tcgen05-special-sync-operations">
<span id="id536"></span><h4>
<span class="section-number">9.7.16.11. </span><a class="reference internal" href="#tcgen05-special-sync-operations">TensorCore 5th Generation Specialized Synchronization Operations</a><a class="headerlink" href="#tcgen05-special-sync-operations" title="Permalink to this headline">ïƒ</a>
</h4>
<section id="tcgen05-special-sync-operations-fence">
<span id="id537"></span><h5>
<span class="section-number">9.7.16.11.1. </span><a class="reference internal" href="#tcgen05-special-sync-operations-fence">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.fence</span></code></a><a class="headerlink" href="#tcgen05-special-sync-operations-fence" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.fence</span></code></p>
<p>Specialized fence for the asynchronous tcgen05 operations.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.fence::before_thread_sync ;
tcgen05.fence::after_thread_sync  ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::before_thread_sync</span></code> orders all the prior asynchronous
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations with respect to the subsequent <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> and the execution
ordering operations.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::after_thread_sync</span></code> orders all the subsequent asynchronous
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations with respect to the prior <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> and the execution ordering
operations.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::*</span></code> instructions compose with execution ordering instructions across
a thread scope and provide ordering between <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions across the same scope.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::before_thread_sync</span></code> instructions behave as code motion fence for prior
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions as they cannot be hoisted across. The <code class="docutils literal notranslate"><span class="pre">tcgen05.fence::after_thread_sync</span></code>
instructions behave as code motion fence for subsequent <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions as they cannot
be hoisted across.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// Producer thread:

tcgen05.cp.cta_group::1.128x256b  [taddr0], sdesc0;

tcgen05.fence::before_thread_sync;
st.relaxed.b32 [flag], 1;

// Consumer thread:

loop:
ld.relaxed.b32 r, [flag];
setp.eq.u32 p, r, 1;
@!p bra loop;

tcgen05.fence::after_thread_sync;
tcgen05.mma.cta_group.kind   [taddr0], adesc, bdesc, idesc, p;
</pre></div>
</div>
</section>
</section>
<section id="tcgen-async-sync-operations">
<span id="id538"></span><h4>
<span class="section-number">9.7.16.12. </span><a class="reference internal" href="#tcgen-async-sync-operations">TensorCore 5th Generation Async Synchronization Operations</a><a class="headerlink" href="#tcgen-async-sync-operations" title="Permalink to this headline">ïƒ</a>
</h4>
<section id="tcgen-async-sync-operations-commit">
<span id="id539"></span><h5>
<span class="section-number">9.7.16.12.1. </span><a class="reference internal" href="#tcgen-async-sync-operations-commit">TensorCore 5th Generation Instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code></a><a class="headerlink" href="#tcgen-async-sync-operations-commit" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code></p>
<p>Makes the mbarrier object track the completion of all prior async-tcgen05 operations initiated
by the executing thread.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>tcgen05.commit.cta_group.completion_mechanism{.shared::cluster}{.multicast}.b64
                                                            [mbar] {, ctaMask};

.completion_mechanism = { .mbarrier::arrive::one }
.cta_group            = { .cta_group::1, .cta_group::2 }
.multicast            = { .multicast::cluster }
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code> is an asynchronous instruction which makes the mbarrier object,
specified by the address operand <code class="docutils literal notranslate"><span class="pre">mbar</span></code>, track the completion of all the prior asynchronous
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations, as listed in
<a class="reference internal" href="#tcgen05-memory-consistency-model-mbarrier-completion"><span class="std std-ref">mbarrier based completion mechanism</span></a>,
initiated by the executing thread. Upon the completion of the tracked asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code>
operations, the signal specified by the <code class="docutils literal notranslate"><span class="pre">.completion_mechanism</span></code> is triggered by the system
on the mbarrier object.
This instruction accesses its <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> operand using generic-proxy.</p>
<p>The instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.commit.cta_group::1</span></code> tracks for the completion of all prior
asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations with <code class="docutils literal notranslate"><span class="pre">.cta_group::1</span></code> issued by the current thread.
Similarly, the instruction <code class="docutils literal notranslate"><span class="pre">tcgen05.commit.cta_group::2</span></code> tracks for the completion of all
prior asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operations with <code class="docutils literal notranslate"><span class="pre">.cta_group::2</span></code> issued by the current thread.</p>
<p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>
qualifier.</p>
<p>The qualifier <code class="docutils literal notranslate"><span class="pre">.mbarrier::arrive::one</span></code> indicates that upon the completion of the prior
asynchronous <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> operation issued by the current thread, an arrive-on operation, with
the count argument of 1, is signaled on the mbarrier object. The scope of the arrive-on operation
is the cluster scope.</p>
<p>The optional qualifier <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> allows signaling on the mbarrier objects of multiple
CTAs in the cluster. Operand <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> specifies the CTAs in the cluster such that each bit
position in the 16-bit <code class="docutils literal notranslate"><span class="pre">ctaMask</span></code> operand corresponds to the <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code> of the destination
CTA. The mbarrier signal is multicast to the same offset as <code class="docutils literal notranslate"><span class="pre">mbar</span></code> in the shared memory of each
destination CTA.</p>
<p>If no state space is specified then <a class="reference internal" href="#generic-addressing"><span class="std std-ref">Generic Addressing</span></a> is used. If the
address specified by <code class="docutils literal notranslate"><span class="pre">mbar</span></code> does not fall within the address window of <code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> state
space then the behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Example 1:
tcgen05.cp.cta_group::1.128x256b                      [taddr0], sdesc0;
tcgen05.commit.cta_group::1.mbarrier::arrive::one.b64 [mbarObj1];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj1], 0;
@!p bra loop;

Example 2:
tcgen05.mma.cta_group::2.kind::tf32    [taddr0],  adesc,  bdesc, idesc, p;
tcgen05.commit.cta_group::2.mbarrier::arrive::one.b64 [mbarObj2];

loop:
mbarrier.try_wait.parity.b64 p, [mbarObj2], 0;
@!p bra loop;
</pre></div>
</div>
</section>
</section>
</section>
<section id="stack-manipulation-instructions">
<span id="id540"></span><h3>
<span class="section-number">9.7.17. </span><a class="reference internal" href="#stack-manipulation-instructions">Stack Manipulation Instructions</a><a class="headerlink" href="#stack-manipulation-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The stack manipulation instructions can be used to dynamically allocate and deallocate memory on the
stack frame of the current function.</p>
<p>The stack manipulation instrucitons are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">stacksave</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stackrestore</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">alloca</span></code></p></li>
</ul>
<section id="stack-manipulation-instructions-stacksave">
<span id="id541"></span><h4>
<span class="section-number">9.7.17.1. </span><a class="reference internal" href="#stack-manipulation-instructions-stacksave">Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">stacksave</span></code></a><a class="headerlink" href="#stack-manipulation-instructions-stacksave" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">stacksave</span></code></p>
<p>Save the value of stack pointer into a register.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>stacksave.type  d;

.type = { .u32, .u64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Copies the current value of stack pointer into the destination register <code class="docutils literal notranslate"><span class="pre">d</span></code>. Pointer returned by
<code class="docutils literal notranslate"><span class="pre">stacksave</span></code> can be used in a subsequent <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> instruction to restore the stack
pointer. If <code class="docutils literal notranslate"><span class="pre">d</span></code> is modified prior to use in <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> instruction, it may corrupt data in
the stack.</p>
<p>Destination operand <code class="docutils literal notranslate"><span class="pre">d</span></code> has the same type as the instruction type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>d = stackptr;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">stacksave</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_52</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .u32 rd;
stacksave.u32 rd;

.reg .u64 rd1;
stacksave.u64 rd1;
</pre></div>
</div>
</section>
<section id="stack-manipulation-instructions-stackrestore">
<span id="id542"></span><h4>
<span class="section-number">9.7.17.2. </span><a class="reference internal" href="#stack-manipulation-instructions-stackrestore">Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code></a><a class="headerlink" href="#stack-manipulation-instructions-stackrestore" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">stackrestore</span></code></p>
<p>Update the stack pointer with a new value.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>stackrestore.type  a;

.type = { .u32, .u64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Sets the current stack pointer to source register <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> is used with operand <code class="docutils literal notranslate"><span class="pre">a</span></code> written by a prior <code class="docutils literal notranslate"><span class="pre">stacksave</span></code> instruction, it
will effectively restore the state of stack as it was before <code class="docutils literal notranslate"><span class="pre">stacksave</span></code> was executed. Note that
if <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> is used with an arbitrary value of <code class="docutils literal notranslate"><span class="pre">a</span></code>, it may cause corruption of stack
pointer. This implies that the correct use of this feature requires that <code class="docutils literal notranslate"><span class="pre">stackrestore.type</span> <span class="pre">a</span></code> is
used after <code class="docutils literal notranslate"><span class="pre">stacksave.type</span> <span class="pre">a</span></code> without redefining the value of <code class="docutils literal notranslate"><span class="pre">a</span></code> between them.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">a</span></code> has the same type as the instruction type.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>stackptr = a;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_52</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .u32 ra;
stacksave.u32 ra;
// Code that may modify stack pointer
...
stackrestore.u32 ra;
</pre></div>
</div>
</section>
<section id="stack-manipulation-instructions-alloca">
<span id="id543"></span><h4>
<span class="section-number">9.7.17.3. </span><a class="reference internal" href="#stack-manipulation-instructions-alloca">Stack Manipulation Instructions: <code class="docutils literal notranslate"><span class="pre">alloca</span></code></a><a class="headerlink" href="#stack-manipulation-instructions-alloca" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">alloca</span></code></p>
<p>Dynamically allocate memory on stack.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>alloca.type  ptr, size{, immAlign};

.type = { .u32, .u64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">alloca</span></code> instruction dynamically allocates memory on the stack frame of the current function
and updates the stack pointer accordingly. The returned pointer <code class="docutils literal notranslate"><span class="pre">ptr</span></code> points to local memory and
can be used in the address operand of <code class="docutils literal notranslate"><span class="pre">ld.local</span></code> and <code class="docutils literal notranslate"><span class="pre">st.local</span></code> instructions.</p>
<p>If sufficient memory is unavailable for allocation on the stack, then execution of <code class="docutils literal notranslate"><span class="pre">alloca</span></code> may
result in stack overflow. In such cases, attempting to access the allocated memory with <code class="docutils literal notranslate"><span class="pre">ptr</span></code> will
result in undefined program behavior.</p>
<p>The memory allocated by <code class="docutils literal notranslate"><span class="pre">alloca</span></code> is deallocated in the following ways:</p>
<ul class="simple">
<li><p>It is automatically deallocated when the function exits.</p></li>
<li><p>It can be explicitly deallocated using <code class="docutils literal notranslate"><span class="pre">stacksave</span></code> and <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> instructions:
<code class="docutils literal notranslate"><span class="pre">stacksave</span></code> can be used to save the value of stack pointer before executing <code class="docutils literal notranslate"><span class="pre">alloca</span></code>, and
<code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> can be used after <code class="docutils literal notranslate"><span class="pre">alloca</span></code> to restore stack pointer to the original value which
was previously saved with <code class="docutils literal notranslate"><span class="pre">stacksave</span></code>. Note that accessing deallocated memory after executing
<code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> results in undefined behavior.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">size</span></code> is an unsigned value which specifies the amount of memory in number of bytes to be
allocated on stack. <code class="docutils literal notranslate"><span class="pre">size</span> <span class="pre">=</span> <span class="pre">0</span></code> may not lead to a valid memory allocation.</p>
<p>Both <code class="docutils literal notranslate"><span class="pre">ptr</span></code> and <code class="docutils literal notranslate"><span class="pre">size</span></code> have the same type as the instruction type.</p>
<p><code class="docutils literal notranslate"><span class="pre">immAlign</span></code> is a 32-bit value which specifies the alignment requirement in number of bytes for the
memory allocated by <code class="docutils literal notranslate"><span class="pre">alloca</span></code>. It is an integer constant, must be a power of 2 and must not exceed
2^23. <code class="docutils literal notranslate"><span class="pre">immAlign</span></code> is an optional argument with default value being 8 which is the minimum
guaranteed alignment.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>alloca.type ptr, size, immAlign:

a = max(immAlign, frame_align); // frame_align is the minimum guaranteed alignment

// Allocate size bytes of stack memory with alignment a and update the stack pointer.
// Since the stack grows down, the updated stack pointer contains a lower address.
stackptr = alloc_stack_mem(size, a);

// Return the new value of stack pointer as ptr. Since ptr is the lowest address of the memory
// allocated by alloca, the memory can be accessed using ptr up to (ptr + size of allocated memory).
stacksave ptr;
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">alloca</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_52</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .u32 ra, stackptr, ptr, size;

stacksave.u32 stackptr;     // Save the current stack pointer
alloca ptr, size, 8;        // Allocate stack memory
st.local.u32 [ptr], ra;     // Use the allocated stack memory
stackrestore.u32 stackptr;  // Deallocate memory by restoring the stack pointer
</pre></div>
</div>
</section>
</section>
<section id="video-instructions">
<span id="id544"></span><h3>
<span class="section-number">9.7.18. </span><a class="reference internal" href="#video-instructions">Video Instructions</a><a class="headerlink" href="#video-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>All video instructions operate on 32-bit register operands. However, the video instructions may be
classified as either scalar or SIMD based on whether their core operation applies to one or multiple
values.</p>
<p>The video instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vadd</span></code>, <code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vadd4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vsub</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmad</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vavrg2</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmin</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmax</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vshl</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vshr</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vset</span></code>, <code class="docutils literal notranslate"><span class="pre">vset2</span></code>, <code class="docutils literal notranslate"><span class="pre">vset4</span></code></p></li>
</ul>
<section id="scalar-video-instructions">
<span id="id545"></span><h4>
<span class="section-number">9.7.18.1. </span><a class="reference internal" href="#scalar-video-instructions">Scalar Video Instructions</a><a class="headerlink" href="#scalar-video-instructions" title="Permalink to this headline">ïƒ</a>
</h4>
<p>All scalar video instructions operate on 32-bit register operands. The scalar video instructions
are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vadd</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vsub</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmin</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmax</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vshl</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vshr</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmad</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vset</span></code></p></li>
</ul>
<p>The scalar video instructions execute the following stages:</p>
<ol class="arabic simple">
<li><p>Extract and sign- or zero-extend byte, half-word, or word values from its source operands, to
produce signed 33-bit input values.</p></li>
<li><p>Perform a scalar arithmetic operation to produce a signed 34-bit result.</p></li>
<li><p>Optionally clamp the result to the range of the destination type.</p></li>
<li>
<p>Optionally perform one of the following:</p>
<ul class="simple">
<li><p>apply a second operation to the intermediate result and a third operand, or</p></li>
<li><p>truncate the intermediate result to a byte or half-word value and merge into a specified
position in the third operand to produce the final result.</p></li>
</ul>
</li>
</ol>
<p>The general format of scalar video instructions is as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 32-bit scalar operation, with optional secondary operation
vop.dtype.atype.btype{.sat}        d, a{.asel}, b{.bsel};
vop.dtype.atype.btype{.sat}.secop  d, a{.asel}, b{.bsel}, c;

// 32-bit scalar operation, with optional data merge
vop.dtype.atype.btype{.sat}   d.dsel, a{.asel}, b{.bsel}, c;


.dtype = .atype = .btype = { .u32, .s32 };
.dsel  = .asel  = .bsel  = { .b0, .b1, .b2, .b3, .h0, .h1 };
.secop = { .add, .min, .max };
</pre></div>
</div>
<p>The source and destination operands are all 32-bit registers. The type of each operand (<code class="docutils literal notranslate"><span class="pre">.u32</span></code> or
<code class="docutils literal notranslate"><span class="pre">.s32</span></code>) is specified in the instruction type; all combinations of <code class="docutils literal notranslate"><span class="pre">dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">atype</span></code>, and
<code class="docutils literal notranslate"><span class="pre">btype</span></code> are valid. Using the <code class="docutils literal notranslate"><span class="pre">atype/btype</span></code> and <code class="docutils literal notranslate"><span class="pre">asel/bsel</span></code> specifiers, the input values are
extracted and sign- or zero-extended internally to <code class="docutils literal notranslate"><span class="pre">.s33</span></code> values. The primary operation is then
performed to produce an <code class="docutils literal notranslate"><span class="pre">.s34</span></code> intermediate result. The sign of the intermediate result depends on
dtype.</p>
<p>The intermediate result is optionally clamped to the range of the destination type (signed or
unsigned), taking into account the subword destination size in the case of optional data merging.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.s33 optSaturate( .s34 tmp, Bool sat, Bool sign, Modifier dsel ) {
    if ( !sat )  return tmp;

    switch ( dsel ) {
        case .b0, .b1, .b2, .b3:
            if ( sign )  return CLAMP( tmp, S8_MAX, S8_MIN );
            else         return CLAMP( tmp, U8_MAX, U8_MIN );
        case .h0, .h1:
            if ( sign )  return CLAMP( tmp, S16_MAX, S16_MIN );
            else         return CLAMP( tmp, U16_MAX, U16_MIN );
        default:
            if ( sign )  return CLAMP( tmp, S32_MAX, S32_MIN );
            else         return CLAMP( tmp, U32_MAX, U32_MIN );
    }
}
</pre></div>
</div>
<p>This intermediate result is then optionally combined with the third source operand using a secondary
arithmetic operation or subword data merge, as shown in the following pseudocode. The sign of the
third operand is based on <code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.s33 optSecOp(Modifier secop, .s33 tmp, .s33 c) {
    switch ( secop ) {
        .add:     return tmp + c;
        .min:     return MIN(tmp, c);
        .max      return MAX(tmp, c);
        default:  return tmp;
    }
}
</pre></div>
</div>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.s33 optMerge( Modifier dsel, .s33 tmp, .s33 c ) {
    switch ( dsel ) {
        case .h0:  return ((tmp &amp; 0xffff)        | (0xffff0000 &amp; c);
        case .h1:  return ((tmp &amp; 0xffff) &lt;&lt; 16) | (0x0000ffff &amp; c);
        case .b0:  return ((tmp &amp; 0xff)          | (0xffffff00 &amp; c);
        case .b1:  return ((tmp &amp; 0xff) &lt;&lt;  8)   | (0xffff00ff &amp; c);
        case .b2:  return ((tmp &amp; 0xff) &lt;&lt; 16)   | (0xff00ffff &amp; c);
        case .b3:  return ((tmp &amp; 0xff) &lt;&lt; 24)   | (0x00ffffff &amp; c);
        default:   return tmp;
    }
}
</pre></div>
</div>
<p>The lower 32-bits are then written to the destination operand.</p>
<section id="scalar-video-instructions-vadd-vsub-vabsdiff-vmin-vmax">
<span id="id546"></span><h5>
<span class="section-number">9.7.18.1.1. </span><a class="reference internal" href="#scalar-video-instructions-vadd-vsub-vabsdiff-vmin-vmax">Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax</span></code></a><a class="headerlink" href="#scalar-video-instructions-vadd-vsub-vabsdiff-vmin-vmax" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vadd</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub</span></code></p>
<p>Integer byte/half-word/word addition/subtraction.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code></p>
<p>Integer byte/half-word/word absolute value of difference.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vmin</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax</span></code></p>
<p>Integer byte/half-word/word minimum/maximum.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 32-bit scalar operation, with optional secondary operation
vop.dtype.atype.btype{.sat}       d, a{.asel}, b{.bsel};
vop.dtype.atype.btype{.sat}.op2   d, a{.asel}, b{.bsel}, c;

// 32-bit scalar operation, with optional data merge
vop.dtype.atype.btype{.sat}  d.dsel, a{.asel}, b{.bsel}, c;

 vop   = { vadd, vsub, vabsdiff, vmin, vmax };
.dtype = .atype = .btype = { .u32, .s32 };
.dsel  = .asel  = .bsel  = { .b0, .b1, .b2, .b3, .h0, .h1 };
.op2   = { .add, .min, .max };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Perform scalar arithmetic operation with optional saturate, and optional secondary arithmetic operation or subword data merge.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract byte/half-word/word and sign- or zero-extend
// based on source operand type
ta = partSelectSignExtend( a, atype, asel );
tb = partSelectSignExtend( b, btype, bsel );

switch ( vop ) {
    case vadd:     tmp = ta + tb;
    case vsub:     tmp = ta - tb;
    case vabsdiff: tmp = | ta - tb |;
    case vmin:     tmp = MIN( ta, tb );
    case vmax:     tmp = MAX( ta, tb );
}
// saturate, taking into account destination type and merge operations
tmp = optSaturate( tmp, sat, isSigned(dtype), dsel );
d = optSecondaryOp( op2, tmp, c );  // optional secondary operation
d = optMerge( dsel, tmp, c );       // optional merge with c operand
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vadd</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vadd.s32.u32.s32.sat      r1, r2.b0, r3.h0;
vsub.s32.s32.u32.sat      r1, r2.h1, r3.h1;
vabsdiff.s32.s32.s32.sat  r1.h0, r2.b0, r3.b2, c;
vmin.s32.s32.s32.sat.add  r1, r2, r3, c;
</pre></div>
</div>
</section>
<section id="scalar-video-instructions-vshl-vshr">
<span id="id547"></span><h5>
<span class="section-number">9.7.18.1.2. </span><a class="reference internal" href="#scalar-video-instructions-vshl-vshr">Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vshl</span></code>, <code class="docutils literal notranslate"><span class="pre">vshr</span></code></a><a class="headerlink" href="#scalar-video-instructions-vshl-vshr" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vshl</span></code>, <code class="docutils literal notranslate"><span class="pre">vshr</span></code></p>
<p>Integer byte/half-word/word left/right shift.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 32-bit scalar operation, with optional secondary operation
vop.dtype.atype.u32{.sat}.mode       d, a{.asel}, b{.bsel};
vop.dtype.atype.u32{.sat}.mode.op2   d, a{.asel}, b{.bsel}, c;

// 32-bit scalar operation, with optional data merge
vop.dtype.atype.u32{.sat}.mode  d.dsel, a{.asel}, b{.bsel}, c;

 vop   = { vshl, vshr };
.dtype = .atype = { .u32, .s32 };
.mode  = { .clamp, .wrap };
.dsel  = .asel  = .bsel  = { .b0, .b1, .b2, .b3, .h0, .h1 };
.op2   = { .add, .min, .max };
</pre></div>
</div>
<p class="rubric">Description</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">vshl</span></code></dt>
<dd>
<p>Shift <code class="docutils literal notranslate"><span class="pre">a</span></code> left by unsigned amount in <code class="docutils literal notranslate"><span class="pre">b</span></code> with optional saturate, and optional secondary
arithmetic operation or subword data merge. Left shift fills with zero.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">vshr</span></code></dt>
<dd>
<p>Shift <code class="docutils literal notranslate"><span class="pre">a</span></code> right by unsigned amount in <code class="docutils literal notranslate"><span class="pre">b</span></code> with optional saturate, and optional secondary
arithmetic operation or subword data merge. Signed shift fills with the sign bit, unsigned shift
fills with zero.</p>
</dd>
</dl>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract byte/half-word/word and sign- or zero-extend
// based on source operand type
ta = partSelectSignExtend( a,atype, asel );
tb = partSelectSignExtend( b, .u32, bsel );
if ( mode == .clamp  &amp;&amp; tb &gt; 32 )  tb = 32;
if ( mode == .wrap )                       tb = tb &amp; 0x1f;
switch ( vop ){
   case vshl:  tmp = ta &lt;&lt; tb;
   case vshr:  tmp = ta &gt;&gt; tb;
}
// saturate, taking into account destination type and merge operations
tmp = optSaturate( tmp, sat, isSigned(dtype), dsel );
d = optSecondaryOp( op2, tmp, c );  // optional secondary operation
d = optMerge( dsel, tmp, c );       // optional merge with c operand
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vshl</span></code>, <code class="docutils literal notranslate"><span class="pre">vshr</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vshl.s32.u32.u32.clamp  r1, r2, r3;
vshr.u32.u32.u32.wrap   r1, r2, r3.h1;
</pre></div>
</div>
</section>
<section id="scalar-video-instructions-vmad">
<span id="id548"></span><h5>
<span class="section-number">9.7.18.1.3. </span><a class="reference internal" href="#scalar-video-instructions-vmad">Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vmad</span></code></a><a class="headerlink" href="#scalar-video-instructions-vmad" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vmad</span></code></p>
<p>Integer byte/half-word/word multiply-accumulate.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 32-bit scalar operation
vmad.dtype.atype.btype{.sat}{.scale}     d, {-}a{.asel}, {-}b{.bsel},
                                         {-}c;
vmad.dtype.atype.btype.po{.sat}{.scale}  d, a{.asel}, b{.bsel}, c;

.dtype = .atype = .btype = { .u32, .s32 };
.asel  = .bsel  = { .b0, .b1, .b2, .b3, .h0, .h1 };
.scale = { .shr7, .shr15 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Calculate <code class="docutils literal notranslate"><span class="pre">(a*b)</span> <span class="pre">+</span> <span class="pre">c</span></code>, with optional operand negates, <em>plus one</em> mode, and scaling.</p>
<p>The source operands support optional negation with some restrictions. Although PTX syntax allows
separate negation of the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> operands, internally this is represented as negation of the
product <code class="docutils literal notranslate"><span class="pre">(a*b)</span></code>. That is, <code class="docutils literal notranslate"><span class="pre">(a*b)</span></code> is negated if and only if exactly one of <code class="docutils literal notranslate"><span class="pre">a</span></code> or <code class="docutils literal notranslate"><span class="pre">b</span></code> is
negated. PTX allows negation of either <code class="docutils literal notranslate"><span class="pre">(a*b)</span></code> or <code class="docutils literal notranslate"><span class="pre">c</span></code>.</p>
<p>The plus one mode (<code class="docutils literal notranslate"><span class="pre">.po</span></code>) computes <code class="docutils literal notranslate"><span class="pre">(a*b)</span> <span class="pre">+</span> <span class="pre">c</span> <span class="pre">+</span> <span class="pre">1</span></code>, which is used in computing averages. Source
operands may not be negated in <code class="docutils literal notranslate"><span class="pre">.po</span></code> mode.</p>
<p>The intermediate result of <code class="docutils literal notranslate"><span class="pre">(a*b)</span></code> is unsigned if atype and btype are unsigned and the product
<code class="docutils literal notranslate"><span class="pre">(a*b)</span></code> is not negated; otherwise, the intermediate result is signed. Input <code class="docutils literal notranslate"><span class="pre">c</span></code> has the same
sign as the intermediate result.</p>
<p>The final result is unsigned if the intermediate result is unsigned and <code class="docutils literal notranslate"><span class="pre">c</span></code> is not negated.</p>
<p>Depending on the sign of the <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> operands, and the operand negates, the following
combinations of operands are supported for VMAD:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> (u32 * u32) + u32  // intermediate unsigned; final unsigned
-(u32 * u32) + s32  // intermediate   signed; final   signed
 (u32 * u32) - u32  // intermediate unsigned; final   signed
 (u32 * s32) + s32  // intermediate   signed; final   signed
-(u32 * s32) + s32  // intermediate   signed; final   signed
 (u32 * s32) - s32  // intermediate   signed; final   signed
 (s32 * u32) + s32  // intermediate   signed; final   signed
-(s32 * u32) + s32  // intermediate   signed; final   signed
 (s32 * u32) - s32  // intermediate   signed; final   signed
 (s32 * s32) + s32  // intermediate   signed; final   signed
-(s32 * s32) + s32  // intermediate   signed; final   signed
 (s32 * s32) - s32  // intermediate   signed; final   signed
</pre></div>
</div>
<p>The intermediate result is optionally scaled via right-shift; this result is sign-extended if the
final result is signed, and zero-extended otherwise.</p>
<p>The final result is optionally saturated to the appropriate 32-bit range based on the type (signed
or unsigned) of the final result.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract byte/half-word/word and sign- or zero-extend
// based on source operand type
ta = partSelectSignExtend( a, atype, asel );
tb = partSelectSignExtend( b, btype, bsel );
signedFinal = isSigned(atype) || isSigned(btype) ||
                                 (a.negate ^ b.negate) || c.negate;
tmp[127:0] = ta * tb;

lsb = 0;
if ( .po )                  {              lsb = 1; } else
if ( a.negate ^ b.negate )  { tmp = ~tmp;  lsb = 1; } else
if ( c.negate )             { c   = ~c;    lsb = 1; }

c128[127:0] = (signedFinal) sext32( c ) : zext ( c );
tmp = tmp + c128 + lsb;
switch( scale ) {
   case .shr7:   result = (tmp &gt;&gt;  7) &amp; 0xffffffffffffffff;
   case .shr15:  result = (tmp &gt;&gt; 15) &amp; 0xffffffffffffffff;
}
if ( .sat ) {
     if (signedFinal) result = CLAMP(result, S32_MAX, S32_MIN);
     else             result = CLAMP(result, U32_MAX, U32_MIN);
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vmad</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vmad.s32.s32.u32.sat    r0, r1, r2, -r3;
vmad.u32.u32.u32.shr15  r0, r1.h0, r2.h0, r3;
</pre></div>
</div>
</section>
<section id="scalar-video-instructions-vset">
<span id="id549"></span><h5>
<span class="section-number">9.7.18.1.4. </span><a class="reference internal" href="#scalar-video-instructions-vset">Scalar Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset</span></code></a><a class="headerlink" href="#scalar-video-instructions-vset" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vset</span></code></p>
<p>Integer byte/half-word/word comparison.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 32-bit scalar operation, with optional secondary operation
vset.atype.btype.cmp       d, a{.asel}, b{.bsel};
vset.atype.btype.cmp.op2   d, a{.asel}, b{.bsel}, c;

// 32-bit scalar operation, with optional data merge
vset.atype.btype.cmp  d.dsel, a{.asel}, b{.bsel}, c;

.atype = .btype = { .u32, .s32 };
.cmp   = { .eq, .ne, .lt, .le, .gt, .ge };
.dsel  = .asel  = .bsel  = { .b0, .b1, .b2, .b3, .h0, .h1 };
.op2   = { .add, .min, .max };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Compare input values using specified comparison, with optional secondary arithmetic operation or
subword data merge.</p>
<p>The intermediate result of the comparison is always unsigned, and therefore destination <code class="docutils literal notranslate"><span class="pre">d</span></code> and
operand <code class="docutils literal notranslate"><span class="pre">c</span></code> are also unsigned.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract byte/half-word/word and sign- or zero-extend
// based on source operand type
ta = partSelectSignExtend( a, atype, asel );
tb = partSelectSignExtend( b, btype, bsel );
tmp = compare( ta, tb, cmp ) ? 1 : 0;
d = optSecondaryOp( op2, tmp, c );    // optional secondary operation
d = optMerge( dsel, tmp, c );         // optional merge with c operand
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vset</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vset.s32.u32.lt    r1, r2, r3;
vset.u32.u32.ne    r1, r2, r3.h1;
</pre></div>
</div>
</section>
</section>
<section id="simd-video-instructions">
<span id="id550"></span><h4>
<span class="section-number">9.7.18.2. </span><a class="reference internal" href="#simd-video-instructions">SIMD Video Instructions</a><a class="headerlink" href="#simd-video-instructions" title="Permalink to this headline">ïƒ</a>
</h4>
<p>The SIMD video instructions operate on pairs of 16-bit values and quads of 8-bit values.</p>
<p>The SIMD video instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vadd4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vsub2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vavrg2</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vmax2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vset2</span></code>, <code class="docutils literal notranslate"><span class="pre">vset4</span></code></p></li>
</ul>
<p>PTX includes SIMD video instructions for operation on pairs of 16-bit values and quads of 8-bit
values. The SIMD video instructions execute the following stages:</p>
<ol class="arabic simple">
<li><p>Form input vectors by extracting and sign- or zero-extending byte or half-word values from the
source operands, to form pairs of signed 17-bit values.</p></li>
<li><p>Perform a SIMD arithmetic operation on the input pairs.</p></li>
<li><p>Optionally clamp the result to the appropriate signed or unsigned range, as determinted by the
destination type.</p></li>
<li>
<p>Optionally perform one of the following:</p>
<ol class="loweralpha simple">
<li><p>perform a second SIMD merge operation, or</p></li>
<li><p>apply a scalar accumulate operation to reduce the intermediate SIMD results to a single
scalar.</p></li>
</ol>
</li>
</ol>
<p>The general format of dual half-word SIMD video instructions is as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 2-way SIMD operation, with second SIMD merge or accumulate
vop2.dtype.atype.btype{.sat}{.add}  d{.mask}, a{.asel}, b{.bsel}, c;

.dtype = .atype = .btype = { .u32, .s32 };
.mask  = { .h0, .h1, .h10 };
.asel  = .bsel = { .hxy, where x,y are from { 0, 1, 2, 3 } };
</pre></div>
</div>
<p>The general format of quad byte SIMD video instructions is as follows:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// 4-way SIMD operation, with second SIMD merge or accumulate
vop4.dtype.atype.btype{.sat}{.add}  d{.mask}, a{.asel}, b{.bsel}, c;

.dtype = .atype = .btype = { .u32, .s32 };
.mask  = { .b0,
           .b1, .b10
           .b2, .b20, .b21, .b210,
           .b3, .b30, .b31, .b310, .b32, .b320, .b321, .b3210 };
.asel = .bsel = .bxyzw, where x,y,z,w are from { 0, ..., 7 };
</pre></div>
</div>
<p>The source and destination operands are all 32-bit registers. The type of each operand (<code class="docutils literal notranslate"><span class="pre">.u32</span></code> or
<code class="docutils literal notranslate"><span class="pre">.s32</span></code>) is specified in the instruction type; all combinations of <code class="docutils literal notranslate"><span class="pre">dtype</span></code>, <code class="docutils literal notranslate"><span class="pre">atype</span></code>, and
<code class="docutils literal notranslate"><span class="pre">btype</span></code> are valid. Using the <code class="docutils literal notranslate"><span class="pre">atype/btype</span></code> and <code class="docutils literal notranslate"><span class="pre">asel/bsel</span></code> specifiers, the input values are
extracted and sign- or zero-extended internally to <code class="docutils literal notranslate"><span class="pre">.s33</span></code> values. The primary operation is then
performed to produce an <code class="docutils literal notranslate"><span class="pre">.s34</span></code> intermediate result. The sign of the intermediate result depends on
<code class="docutils literal notranslate"><span class="pre">dtype</span></code>.</p>
<p>The intermediate result is optionally clamped to the range of the destination type (signed or
unsigned), taking into account the subword destination size in the case of optional data merging.</p>
<section id="simd-video-instructions-vadd2-vsub2-vavrg2-vabsdiff2-vmin2-vmax2">
<span id="id551"></span><h5>
<span class="section-number">9.7.18.2.1. </span><a class="reference internal" href="#simd-video-instructions-vadd2-vsub2-vavrg2-vabsdiff2-vmin2-vmax2">SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub2</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg2</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax2</span></code></a><a class="headerlink" href="#simd-video-instructions-vadd2-vsub2-vavrg2-vabsdiff2-vmin2-vmax2" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub2</span></code></p>
<p>Integer dual half-word SIMD addition/subtraction.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vavrg2</span></code></p>
<p>Integer dual half-word SIMD average.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code></p>
<p>Integer dual half-word SIMD absolute value of difference.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax2</span></code></p>
<p>Integer dual half-word SIMD minimum/maximum.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// SIMD instruction with secondary SIMD merge operation
vop2.dtype.atype.btype{.sat}  d{.mask}, a{.asel}, b{.bsel}, c;

// SIMD instruction with secondary accumulate operation
vop2.dtype.atype.btype.add  d{.mask}, a{.asel}, b{.bsel}, c;

 vop2  = { vadd2, vsub2, vavrg2, vabsdiff2, vmin2, vmax2 };
.dtype = .atype = .btype = { .u32, .s32 };
.mask  = { .h0, .h1, .h10 };  // defaults to .h10
.asel  = .bsel  = { .hxy, where x,y are from { 0, 1, 2, 3 } };
   .asel defaults to .h10
   .bsel defaults to .h32
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Two-way SIMD parallel arithmetic operation with secondary operation.</p>
<p>Elements of each dual half-word source to the operation are selected from any of the four half-words
in the two source operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> using the <code class="docutils literal notranslate"><span class="pre">asel</span></code> and <code class="docutils literal notranslate"><span class="pre">bsel</span></code> modifiers.</p>
<p>The selected half-words are then operated on in parallel.</p>
<p>The results are optionally clamped to the appropriate range determined by the destination type
(signed or unsigned). Saturation cannot be used with the secondary accumulate operation.</p>
<p>For instructions with a secondary SIMD merge operation:</p>
<ul class="simple">
<li><p>For half-word positions indicated in mask, the selected half-word results are copied into
destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. For all other positions, the corresponding half-word from source operand <code class="docutils literal notranslate"><span class="pre">c</span></code>
is copied to <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p>For instructions with a secondary accumulate operation:</p>
<ul class="simple">
<li><p>For half-word positions indicated in mask, the selected half-word results are added to operand
<code class="docutils literal notranslate"><span class="pre">c</span></code>, producing a result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract pairs of half-words and sign- or zero-extend
// based on operand type
Va = extractAndSignExt_2( a, b, .asel, .atype );
Vb = extractAndSignExt_2( a, b, .bsel, .btype );
Vc = extractAndSignExt_2( c );

for (i=0; i&lt;2; i++) {
    switch ( vop2 ) {
       case vadd2:             t[i] = Va[i] + Vb[i];
       case vsub2:             t[i] = Va[i] - Vb[i];
       case vavrg2:            if ( ( Va[i] + Vb[i] ) &gt;= 0 ) {
                                   t[i] = ( Va[i] + Vb[i] + 1 ) &gt;&gt; 1;
                               } else {
                                   t[i] = ( Va[i] + Vb[i] ) &gt;&gt; 1;
                               }
       case vabsdiff2:         t[i] = | Va[i] - Vb[i] |;
       case vmin2:             t[i] = MIN( Va[i], Vb[i] );
       case vmax2:             t[i] = MAX( Va[i], Vb[i] );
    }
    if (.sat) {
        if ( .dtype == .s32 )  t[i] = CLAMP( t[i], S16_MAX, S16_MIN );
        else                   t[i] = CLAMP( t[i], U16_MAX, U16_MIN );
    }
}
// secondary accumulate or SIMD merge
mask = extractMaskBits( .mask );
if (.add) {
    d = c;
    for (i=0; i&lt;2; i++) {  d += mask[i] ? t[i] : 0;  }
} else {
    d = 0;
    for (i=0; i&lt;2; i++)  {  d |= mask[i] ? t[i] : Vc[i];  }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vadd2</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub2</span></code>, <code class="docutils literal notranslate"><span class="pre">varvg2</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin2</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax2</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vadd2.s32.s32.u32.sat  r1, r2, r3, r1;
vsub2.s32.s32.s32.sat  r1.h0, r2.h10, r3.h32, r1;
vmin2.s32.u32.u32.add  r1.h10, r2.h00, r3.h22, r1;
</pre></div>
</div>
</section>
<section id="simd-video-instructions-vset2">
<span id="id552"></span><h5>
<span class="section-number">9.7.18.2.2. </span><a class="reference internal" href="#simd-video-instructions-vset2">SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset2</span></code></a><a class="headerlink" href="#simd-video-instructions-vset2" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vset2</span></code></p>
<p>Integer dual half-word SIMD comparison.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// SIMD instruction with secondary SIMD merge operation
vset2.atype.btype.cmp  d{.mask}, a{.asel}, b{.bsel}, c;

// SIMD instruction with secondary accumulate operation
vset2.atype.btype.cmp.add  d{.mask}, a{.asel}, b{.bsel}, c;

.atype = .btype = { .u32, .s32 };
.cmp   = { .eq, .ne, .lt, .le, .gt, .ge };
.mask  = { .h0, .h1, .h10 };  // defaults to .h10
.asel  = .bsel  = { .hxy, where x,y are from { 0, 1, 2, 3 } };
   .asel defaults to .h10
   .bsel defaults to .h32
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Two-way SIMD parallel comparison with secondary operation.</p>
<p>Elements of each dual half-word source to the operation are selected from any of the four half-words
in the two source operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> using the <code class="docutils literal notranslate"><span class="pre">asel</span></code> and <code class="docutils literal notranslate"><span class="pre">bsel</span></code> modifiers.</p>
<p>The selected half-words are then compared in parallel.</p>
<p>The intermediate result of the comparison is always unsigned, and therefore the half-words of
destination <code class="docutils literal notranslate"><span class="pre">d</span></code> and operand <code class="docutils literal notranslate"><span class="pre">c</span></code> are also unsigned.</p>
<p>For instructions with a secondary SIMD merge operation:</p>
<ul class="simple">
<li><p>For half-word positions indicated in mask, the selected half-word results are copied into
destination <code class="docutils literal notranslate"><span class="pre">d</span></code>. For all other positions, the corresponding half-word from source operand <code class="docutils literal notranslate"><span class="pre">b</span></code>
is copied to <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p>For instructions with a secondary accumulate operation:</p>
<ul class="simple">
<li><p>For half-word positions indicated in mask, the selected half-word results are added to operand
<code class="docutils literal notranslate"><span class="pre">c</span></code>, producing <code class="docutils literal notranslate"><span class="pre">a</span></code> result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract pairs of half-words and sign- or zero-extend
// based on operand type
Va = extractAndSignExt_2( a, b, .asel, .atype );
Vb = extractAndSignExt_2( a, b, .bsel, .btype );
Vc = extractAndSignExt_2( c );
for (i=0; i&lt;2; i++) {
    t[i] = compare( Va[i], Vb[i], .cmp ) ? 1 : 0;
}
// secondary accumulate or SIMD merge
mask = extractMaskBits( .mask );
if (.add) {
    d = c;
    for (i=0; i&lt;2; i++) {  d += mask[i] ? t[i] : 0;  }
} else {
    d = 0;
    for (i=0; i&lt;2; i++)  {  d |= mask[i] ? t[i] : Vc[i];  }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vset2</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vset2.s32.u32.lt      r1, r2, r3, r0;
vset2.u32.u32.ne.add  r1, r2, r3, r0;
</pre></div>
</div>
</section>
<section id="simd-video-instructions-vadd4-vsub4-vavrg4-vabsdiff4-vmin4-vmax4">
<span id="id553"></span><h5>
<span class="section-number">9.7.18.2.3. </span><a class="reference internal" href="#simd-video-instructions-vadd4-vsub4-vavrg4-vabsdiff4-vmin4-vmax4">SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vadd4</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code>, <code class="docutils literal notranslate"><span class="pre">vavrg4</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code></a><a class="headerlink" href="#simd-video-instructions-vadd4-vsub4-vavrg4-vabsdiff4-vmin4-vmax4" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vadd4</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code></p>
<p>Integer quad byte SIMD addition/subtraction.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vavrg4</span></code></p>
<p>Integer quad byte SIMD average.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code></p>
<p>Integer quad byte SIMD absolute value of difference.</p>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vmin4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code></p>
<p>Integer quad byte SIMD minimum/maximum.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// SIMD instruction with secondary SIMD merge operation
vop4.dtype.atype.btype{.sat}  d{.mask}, a{.asel}, b{.bsel}, c;

// SIMD instruction with secondary accumulate operation
vop4.dtype.atype.btype.add  d{.mask}, a{.asel}, b{.bsel}, c;
vop4  = { vadd4, vsub4, vavrg4, vabsdiff4, vmin4, vmax4 };

.dtype = .atype = .btype = { .u32, .s32 };
.mask  = { .b0,
           .b1, .b10
           .b2, .b20, .b21, .b210,
           .b3, .b30, .b31, .b310, .b32, .b320, .b321, .b3210 };
    defaults to .b3210
.asel = .bsel = .bxyzw, where x,y,z,w are from { 0, ..., 7 };
   .asel defaults to .b3210
   .bsel defaults to .b7654
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Four-way SIMD parallel arithmetic operation with secondary operation.</p>
<p>Elements of each quad byte source to the operation are selected from any of the eight bytes in the
two source operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> using the <code class="docutils literal notranslate"><span class="pre">asel</span></code> and <code class="docutils literal notranslate"><span class="pre">bsel</span></code> modifiers.</p>
<p>The selected bytes are then operated on in parallel.</p>
<p>The results are optionally clamped to the appropriate range determined by the destination type
(signed or unsigned). Saturation cannot be used with the secondary accumulate operation.</p>
<p>For instructions with a secondary SIMD merge operation:</p>
<ul class="simple">
<li><p>For byte positions indicated in mask, the selected byte results are copied into destination
<code class="docutils literal notranslate"><span class="pre">d</span></code>. For all other positions, the corresponding byte from source operand <code class="docutils literal notranslate"><span class="pre">c</span></code> is copied to
<code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p>For instructions with a secondary accumulate operation:</p>
<ul class="simple">
<li><p>For byte positions indicated in mask, the selected byte results are added to operand <code class="docutils literal notranslate"><span class="pre">c</span></code>,
producing a result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract quads of bytes and sign- or zero-extend
// based on operand type
Va = extractAndSignExt_4( a, b, .asel, .atype );
Vb = extractAndSignExt_4( a, b, .bsel, .btype );
Vc = extractAndSignExt_4( c );
for (i=0; i&lt;4; i++) {
    switch ( vop4 ) {
        case vadd4:            t[i] = Va[i] + Vb[i];
        case vsub4:            t[i] = Va[i] - Vb[i];
        case vavrg4:           if ( ( Va[i] + Vb[i] ) &gt;= 0 ) {
                                   t[i] = ( Va[i] + Vb[i] + 1 ) &gt;&gt; 1;
                               } else {
                                   t[i] = ( Va[i] + Vb[i] ) &gt;&gt; 1;
                               }
        case vabsdiff4:        t[i] = | Va[i] - Vb[i] |;
        case vmin4:            t[i] = MIN( Va[i], Vb[i] );
        case vmax4:            t[i] = MAX( Va[i], Vb[i] );
    }
    if (.sat) {
        if ( .dtype == .s32 )  t[i] = CLAMP( t[i], S8_MAX, S8_MIN );
        else                   t[i] = CLAMP( t[i], U8_MAX, U8_MIN );
    }
}
// secondary accumulate or SIMD merge
mask = extractMaskBits( .mask );
if (.add) {
    d = c;
    for (i=0; i&lt;4; i++) {  d += mask[i] ? t[i] : 0;  }
} else {
    d = 0;
    for (i=0; i&lt;4; i++)  {  d |= mask[i] ? t[i] : Vc[i];  }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vadd4</span></code>, <code class="docutils literal notranslate"><span class="pre">vsub4</span></code>, <code class="docutils literal notranslate"><span class="pre">varvg4</span></code>, <code class="docutils literal notranslate"><span class="pre">vabsdiff4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin4</span></code>, <code class="docutils literal notranslate"><span class="pre">vmax4</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vadd4.s32.s32.u32.sat  r1, r2, r3, r1;
vsub4.s32.s32.s32.sat  r1.b0, r2.b3210, r3.b7654, r1;
vmin4.s32.u32.u32.add  r1.b00, r2.b0000, r3.b2222, r1;
</pre></div>
</div>
</section>
<section id="simd-video-instructions-vset4">
<span id="id554"></span><h5>
<span class="section-number">9.7.18.2.4. </span><a class="reference internal" href="#simd-video-instructions-vset4">SIMD Video Instructions: <code class="docutils literal notranslate"><span class="pre">vset4</span></code></a><a class="headerlink" href="#simd-video-instructions-vset4" title="Permalink to this headline">ïƒ</a>
</h5>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">vset4</span></code></p>
<p>Integer quad byte SIMD comparison.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// SIMD instruction with secondary SIMD merge operation
vset4.atype.btype.cmp  d{.mask}, a{.asel}, b{.bsel}, c;

// SIMD instruction with secondary accumulate operation
vset4.atype.btype.cmp.add  d{.mask}, a{.asel}, b{.bsel}, c;

.atype = .btype = { .u32, .s32 };
.cmp   = { .eq, .ne, .lt, .le, .gt, .ge };
.mask  = { .b0,
           .b1, .b10
           .b2, .b20, .b21, .b210,
           .b3, .b30, .b31, .b310, .b32, .b320, .b321, .b3210 };
    defaults to .b3210
.asel = .bsel = .bxyzw, where x,y,z,w are from { 0, ..., 7 };
   .asel defaults to .b3210
   .bsel defaults to .b7654
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Four-way SIMD parallel comparison with secondary operation.</p>
<p>Elements of each quad byte source to the operation are selected from any of the eight bytes in the
two source operands <code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> using the <code class="docutils literal notranslate"><span class="pre">asel</span></code> and <code class="docutils literal notranslate"><span class="pre">bsel</span></code> modifiers.</p>
<p>The selected bytes are then compared in parallel.</p>
<p>The intermediate result of the comparison is always unsigned, and therefore the bytes of destination
<code class="docutils literal notranslate"><span class="pre">d</span></code> and operand <code class="docutils literal notranslate"><span class="pre">c</span></code> are also unsigned.</p>
<p>For instructions with a secondary SIMD merge operation:</p>
<ul class="simple">
<li><p>For byte positions indicated in mask, the selected byte results are copied into destination
<code class="docutils literal notranslate"><span class="pre">d</span></code>. For all other positions, the corresponding byte from source operand <code class="docutils literal notranslate"><span class="pre">b</span></code> is copied to
<code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p>For instructions with a secondary accumulate operation:</p>
<ul class="simple">
<li><p>For byte positions indicated in mask, the selected byte results are added to operand <code class="docutils literal notranslate"><span class="pre">c</span></code>,
producing a result in <code class="docutils literal notranslate"><span class="pre">d</span></code>.</p></li>
</ul>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// extract quads of bytes and sign- or zero-extend
// based on operand type
Va = extractAndSignExt_4( a, b, .asel, .atype );
Vb = extractAndSignExt_4( a, b, .bsel, .btype );
Vc = extractAndSignExt_4( c );
for (i=0; i&lt;4; i++) {
    t[i] = compare( Va[i], Vb[i], cmp ) ? 1 : 0;
}
// secondary accumulate or SIMD merge
mask = extractMaskBits( .mask );
if (.add) {
    d = c;
    for (i=0; i&lt;4; i++) {  d += mask[i] ? t[i] : 0;  }
} else {
    d = 0;
    for (i=0; i&lt;4; i++)  {  d |= mask[i] ? t[i] : Vc[i];  }
}
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">vset4</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>vset4.s32.u32.lt      r1, r2, r3, r0;
vset4.u32.u32.ne.max  r1, r2, r3, r0;
</pre></div>
</div>
</section>
</section>
</section>
<section id="miscellaneous-instructions">
<span id="id555"></span><h3>
<span class="section-number">9.7.19. </span><a class="reference internal" href="#miscellaneous-instructions">Miscellaneous Instructions</a><a class="headerlink" href="#miscellaneous-instructions" title="Permalink to this headline">ïƒ</a>
</h3>
<p>The Miscellaneous instructions are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">brkpt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nanosleep</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pmevent</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">trap</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></p></li>
</ul>
<section id="miscellaneous-instructions-brkpt">
<span id="id556"></span><h4>
<span class="section-number">9.7.19.1. </span><a class="reference internal" href="#miscellaneous-instructions-brkpt">Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">brkpt</span></code></a><a class="headerlink" href="#miscellaneous-instructions-brkpt" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">brkpt</span></code></p>
<p>Breakpoint.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>brkpt;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Suspends execution.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">brkpt</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_11</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    brkpt;
@p  brkpt;
</pre></div>
</div>
</section>
<section id="miscellaneous-instructions-nanosleep">
<span id="id557"></span><h4>
<span class="section-number">9.7.19.2. </span><a class="reference internal" href="#miscellaneous-instructions-nanosleep">Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">nanosleep</span></code></a><a class="headerlink" href="#miscellaneous-instructions-nanosleep" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">nanosleep</span></code></p>
<p>Suspend the thread for an approximate delay given in nanoseconds.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>nanosleep.u32 t;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Suspends the thread for a sleep duration approximately close to the delay <code class="docutils literal notranslate"><span class="pre">t</span></code>, specified in
nanoseconds. <code class="docutils literal notranslate"><span class="pre">t</span></code> may be a register or an immediate value.</p>
<p>The sleep duration is approximated, but guaranteed to be in the interval <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">2*t]</span></code>. The maximum
sleep duration is 1 millisecond. The implementation may reduce the sleep duration for individual
threads within a warp such that all sleeping threads in the warp wake up together.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">nanosleep</span></code> introduced in PTX ISA 6.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">nanosleep</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 r;
.reg .pred p;

nanosleep.u32 r;
nanosleep.u32 42;
@p nanosleep.u32 r;
</pre></div>
</div>
</section>
<section id="miscellaneous-instructions-pmevent">
<span id="id558"></span><h4>
<span class="section-number">9.7.19.3. </span><a class="reference internal" href="#miscellaneous-instructions-pmevent">Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">pmevent</span></code></a><a class="headerlink" href="#miscellaneous-instructions-pmevent" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">pmevent</span></code></p>
<p>Trigger one or more Performance Monitor events.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>pmevent       a;    // trigger a single performance monitor event
pmevent.mask  a;    // trigger one or more performance monitor events
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Triggers one or more of a fixed number of performance monitor events, with event index or mask
specified by immediate operand <code class="docutils literal notranslate"><span class="pre">a</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pmevent</span></code> (without modifier <code class="docutils literal notranslate"><span class="pre">.mask</span></code>) triggers a single performance monitor event indexed by
immediate operand <code class="docutils literal notranslate"><span class="pre">a</span></code>, in the range <code class="docutils literal notranslate"><span class="pre">0..15</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">pmevent.mask</span></code> triggers one or more of the performance monitor events. Each bit in the 16-bit
immediate operand <code class="docutils literal notranslate"><span class="pre">a</span></code> controls an event.</p>
<p>Programmatic performance moniter events may be combined with other hardware events using Boolean
functions to increment one of the four performance counters. The relationship between events and
counters is programmed via API calls from the host.</p>
<p class="rubric">Notes</p>
<p>Currently, there are sixteen performance monitor events, numbered 0 through 15.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">pmevent</span></code> introduced in PTX ISA version 1.4.</p>
<p><code class="docutils literal notranslate"><span class="pre">pmevent.mask</span></code> introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>pmevent supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">pmevent.mask</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    pmevent      1;
@p  pmevent      7;
@q  pmevent.mask 0xff;
</pre></div>
</div>
</section>
<section id="miscellaneous-instructions-trap">
<span id="id559"></span><h4>
<span class="section-number">9.7.19.4. </span><a class="reference internal" href="#miscellaneous-instructions-trap">Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">trap</span></code></a><a class="headerlink" href="#miscellaneous-instructions-trap" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">trap</span></code></p>
<p>Perform trap operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>trap;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Abort execution and generate an interrupt to the host CPU.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    trap;
@p  trap;
</pre></div>
</div>
</section>
<section id="miscellaneous-instructions-setmaxnreg">
<span id="id560"></span><h4>
<span class="section-number">9.7.19.5. </span><a class="reference internal" href="#miscellaneous-instructions-setmaxnreg">Miscellaneous Instructions: <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></a><a class="headerlink" href="#miscellaneous-instructions-setmaxnreg" title="Permalink to this headline">ïƒ</a>
</h4>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></p>
<p>Hint to change the number of registers owned by the warp.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setmaxnreg.action.sync.aligned.u32 imm-reg-count;

.action = { .inc, .dec };
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> provides a hint to the system to update the maximum number of per-thread registers
owned by the executing warp to the value specified by the <code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code> operand.</p>
<p>Qualifier <code class="docutils literal notranslate"><span class="pre">.dec</span></code> is used to release extra registers such that the absolute per-thread maximum
register count is reduced from its current value to <code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code>. Qualifier <code class="docutils literal notranslate"><span class="pre">.inc</span></code> is used to
request additional registers such that the absolute per-thread maximum register count is increased
from its current value to <code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code>.</p>
<p>A pool of available registers is maintained per-CTA. Register adjustments requested by the
<code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instructions are handled by supplying extra registers from this pool to the
requesting warp or by releasing extra registers from the requesting warp to this pool, depending
upon the value of the <code class="docutils literal notranslate"><span class="pre">.action</span></code> qualifier.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">setmaxnreg.inc</span></code> instruction blocks the execution until enough registers are available in the
CTAâ€™s register pool. After the instruction <code class="docutils literal notranslate"><span class="pre">setmaxnreg.inc</span></code> obtains new registers from the CTA
pool, the initial contents of the new registers are undefined. The new registers must be initialized
before they are used.</p>
<p>The same <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction must be executed by all warps in a
<a class="reference internal" href="#asynchronous-warpgroup-level-matrix-instructions-warpgroup"><span class="std std-ref">warpgroup</span></a>. After executing a
<code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction, all warps in the <em>warpgroup</em> must synchronize explicitly before
executing subsequent setmaxnreg instructions. If a <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction is not executed by all
warps in the <em>warpgroup</em>, then the behavior is undefined.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code> is an integer constant. The value of <code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code> must be in the
range 24 to 256 (both inclusive) and must be a multiple of 8.</p>
<p>Changes to the register file of the warp always happen at the tail-end of the register file.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction requires that the kernel has been launched with a valid value of
maximum number of per-thread registers specified via the appropriate compilation via the appropriate
compile-time option or the appropriate performance tuning directive. Otherwise, the <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code>
instruction may have no effect.</p>
<p>When qualifier <code class="docutils literal notranslate"><span class="pre">.dec</span></code> is specified, the maximum number of per-thread registers owned by the warp
prior to the execution of <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction should be greater than or equal to the
<code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code>. Otherwise, the behaviour is undefined.</p>
<p>When qualifier <code class="docutils literal notranslate"><span class="pre">.inc</span></code> is specified, the maximum number of per-thread registers owned by the warp
prior to the execution of <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction should be less than or equal to the
<code class="docutils literal notranslate"><span class="pre">imm-reg-count</span></code>. Otherwise, the behaviour is undefined.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier indicates that <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction causes the executing
thread to wait until all threads in the warp execute the same <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction before
resuming execution.</p>
<p>The mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier indicates that all threads in the warpgroup must execute the
same <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction. In conditionally executed code, <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction should
only be used if it is known that all threads in warpgroup evaluate the condition identically,
otherwise the behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on following architectures:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></li>
<li>
<p>And is supported on following family-specific architectures from PTX ISA version 8.8:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> or higher in the same family</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> or higher in the same family (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> from PTX ISA version 9.0)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> or higher in the same family</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> or higher in the same family</p></li>
</ul>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>setmaxnreg.dec.sync.aligned.u32 64;
setmaxnreg.inc.sync.aligned.u32 192;
</pre></div>
</div>
</section>
</section>
</section>
</section>
<section id="special-registers">
<span id="id561"></span><h1>
<span class="section-number">10. </span><a class="reference internal" href="#special-registers">Special Registers</a><a class="headerlink" href="#special-registers" title="Permalink to this headline">ïƒ</a>
</h1>
<p>PTX includes a number of predefined, read-only variables, which are
visible as special registers and accessed through <code class="docutils literal notranslate"><span class="pre">mov</span></code> or <code class="docutils literal notranslate"><span class="pre">cvt</span></code>
instructions.</p>
<p>The special registers are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">%tid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%ntid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%laneid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%warpid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%ctaid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%nctaid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%smid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%nsmid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%gridid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%clusterid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code>, <code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code>, <code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code>, <code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code>, <code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%clock</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock64</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%pm0,</span> <span class="pre">...,</span> <span class="pre">%pm7</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%pm0_64,</span> <span class="pre">...,</span> <span class="pre">%pm7_64</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%envreg0,</span> <span class="pre">...,</span> <span class="pre">%envreg31</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code>,
<code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset&lt;2&gt;</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code></p></li>
</ul>
<section id="special-registers-tid">
<span id="id562"></span><h2>
<span class="section-number">10.1. </span><a class="reference internal" href="#special-registers-tid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%tid</span></code></a><a class="headerlink" href="#special-registers-tid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%tid</span></code></p>
<p>Thread identifier within a CTA.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %tid;                  // thread id vector
.sreg .u32 %tid.x, %tid.y, %tid.z;    // thread id components
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only, per-thread special register initialized with the thread identifier within
the CTA. The <code class="docutils literal notranslate"><span class="pre">%tid</span></code> special register contains a 1D, 2D, or 3D vector to match the CTA shape; the
<code class="docutils literal notranslate"><span class="pre">%tid</span></code> value in unused dimensions is <code class="docutils literal notranslate"><span class="pre">0</span></code>. The fourth element is unused and always returns
zero. The number of threads in each dimension are specified by the predefined special register
<code class="docutils literal notranslate"><span class="pre">%ntid</span></code>.</p>
<p>Every thread in the CTA has a unique <code class="docutils literal notranslate"><span class="pre">%tid</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">%tid</span></code> component values range from <code class="docutils literal notranslate"><span class="pre">0</span></code> through <code class="docutils literal notranslate"><span class="pre">%ntid-1</span></code> in each CTA dimension.</p>
<p><code class="docutils literal notranslate"><span class="pre">%tid.y</span> <span class="pre">==</span> <span class="pre">%tid.z</span> <span class="pre">==</span> <span class="pre">0</span></code> in 1D CTAs. <code class="docutils literal notranslate"><span class="pre">%tid.z</span> <span class="pre">==</span> <span class="pre">0</span></code> in 2D CTAs.</p>
<p>It is guaranteed that:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0  &lt;=  %tid.x &lt;  %ntid.x
0  &lt;=  %tid.y &lt;  %ntid.y
0  &lt;=  %tid.z &lt;  %ntid.z
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0 with type <code class="docutils literal notranslate"><span class="pre">.v4.u16</span></code>.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.v4.u32</span></code> in PTX ISA version 2.0. For compatibility with legacy PTX code, 16-bit
<code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions may be used to read the lower 16-bits of each component of
<code class="docutils literal notranslate"><span class="pre">%tid</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32      %r1,%tid.x;  // move tid.x to %rh

// legacy code accessing 16-bit components of %tid
mov.u16      %rh,%tid.x;
cvt.u32.u16  %r2,%tid.z;  // zero-extend tid.z to %r2
</pre></div>
</div>
</section>
<section id="special-registers-ntid">
<span id="id563"></span><h2>
<span class="section-number">10.2. </span><a class="reference internal" href="#special-registers-ntid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%ntid</span></code></a><a class="headerlink" href="#special-registers-ntid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%ntid</span></code></p>
<p>Number of thread IDs per CTA.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %ntid;                   // CTA shape vector
.sreg .u32 %ntid.x, %ntid.y, %ntid.z;   // CTA dimensions
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the number of thread ids in each CTA
dimension. The <code class="docutils literal notranslate"><span class="pre">%ntid</span></code> special register contains a 3D CTA shape vector that holds the CTA
dimensions. CTA dimensions are non-zero; the fourth element is unused and always returns zero. The
total number of threads in a CTA is <code class="docutils literal notranslate"><span class="pre">(%ntid.x</span> <span class="pre">*</span> <span class="pre">%ntid.y</span> <span class="pre">*</span> <span class="pre">%ntid.z)</span></code>.</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>%ntid.y == %ntid.z == 1 in 1D CTAs.
%ntid.z ==1 in 2D CTAs.
</pre></div>
</div>
<p>Maximum values of %ntid.{x,y,z} are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 63%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.target architecture</p></th>
<th class="head"><p>%ntid.x</p></th>
<th class="head"><p>%ntid.y</p></th>
<th class="head"><p>%ntid.z</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code></p></td>
<td><p>512</p></td>
<td><p>512</p></td>
<td><p>64</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_5x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_7x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_8x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_9x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_10x</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_12x</span></code></p></td>
<td><p>1024</p></td>
<td><p>1024</p></td>
<td><p>64</p></td>
</tr>
</tbody>
</table>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0 with type <code class="docutils literal notranslate"><span class="pre">.v4.u16</span></code>.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.v4.u32</span></code> in PTX ISA version 2.0. For compatibility with legacy PTX code, 16-bit
<code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions may be used to read the lower 16-bits of each component of
<code class="docutils literal notranslate"><span class="pre">%ntid</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// compute unified thread id for 2D CTA
mov.u32  %r0,%tid.x;
mov.u32  %h1,%tid.y;
mov.u32  %h2,%ntid.x;
mad.u32  %r0,%h1,%h2,%r0;

mov.u16  %rh,%ntid.x;      // legacy code
</pre></div>
</div>
</section>
<section id="special-registers-laneid">
<span id="id564"></span><h2>
<span class="section-number">10.3. </span><a class="reference internal" href="#special-registers-laneid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%laneid</span></code></a><a class="headerlink" href="#special-registers-laneid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%laneid</span></code></p>
<p>Lane Identifier.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %laneid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register that returns the threadâ€™s lane within the warp. The lane
identifier ranges from zero to <code class="docutils literal notranslate"><span class="pre">WARP_SZ-1</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %laneid;
</pre></div>
</div>
</section>
<section id="special-registers-warpid">
<span id="id565"></span><h2>
<span class="section-number">10.4. </span><a class="reference internal" href="#special-registers-warpid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%warpid</span></code></a><a class="headerlink" href="#special-registers-warpid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%warpid</span></code></p>
<p>Warp identifier.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %warpid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register that returns the threadâ€™s warp identifier. The warp
identifier provides a unique warp number within a CTA but not across CTAs within a grid. The warp
identifier will be the same for all threads within a single warp.</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">%warpid</span></code> returns the location of a thread at the moment when read, but
its value may change during execution, e.g., due to rescheduling of threads following
preemption. For this reason, <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code> and <code class="docutils literal notranslate"><span class="pre">%tid</span></code> should be used to compute a virtual warp index
if such a value is needed in kernel code; <code class="docutils literal notranslate"><span class="pre">%warpid</span></code> is intended mainly to enable profiling and
diagnostic code to sample and log information such as work place mapping and load distribution.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %warpid;
</pre></div>
</div>
</section>
<section id="special-registers-nwarpid">
<span id="id566"></span><h2>
<span class="section-number">10.5. </span><a class="reference internal" href="#special-registers-nwarpid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code></a><a class="headerlink" href="#special-registers-nwarpid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code></p>
<p>Number of warp identifiers.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %nwarpid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register that returns the maximum number of warp identifiers.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %nwarpid;
</pre></div>
</div>
</section>
<section id="special-registers-ctaid">
<span id="id567"></span><h2>
<span class="section-number">10.6. </span><a class="reference internal" href="#special-registers-ctaid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code></a><a class="headerlink" href="#special-registers-ctaid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%ctaid</span></code></p>
<p>CTA identifier within a grid.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %ctaid;                      // CTA id vector
.sreg .u32 %ctaid.x, %ctaid.y, %ctaid.z;    // CTA id components
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the CTA identifier within the CTA
grid. The <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code> special register contains a 1D, 2D, or 3D vector, depending on the shape and
rank of the CTA grid. The fourth element is unused and always returns zero.</p>
<p>It is guaranteed that:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0  &lt;=  %ctaid.x &lt;  %nctaid.x
0  &lt;=  %ctaid.y &lt;  %nctaid.y
0  &lt;=  %ctaid.z &lt;  %nctaid.z
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0 with type <code class="docutils literal notranslate"><span class="pre">.v4.u16</span></code>.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.v4.u32</span></code> in PTX ISA version 2.0. For compatibility with legacy PTX code, 16-bit
<code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions may be used to read the lower 16-bits of each component of
<code class="docutils literal notranslate"><span class="pre">%ctaid</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r0,%ctaid.x;
mov.u16  %rh,%ctaid.y;   // legacy code
</pre></div>
</div>
</section>
<section id="special-registers-nctaid">
<span id="id568"></span><h2>
<span class="section-number">10.7. </span><a class="reference internal" href="#special-registers-nctaid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code></a><a class="headerlink" href="#special-registers-nctaid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%nctaid</span></code></p>
<p>Number of CTA ids per grid.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %nctaid                      // Grid shape vector
.sreg .u32 %nctaid.x,%nctaid.y,%nctaid.z;   // Grid dimensions
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the number of CTAs in each grid
dimension. The <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code> special register contains a 3D grid shape vector, with each element
having a value of at least <code class="docutils literal notranslate"><span class="pre">1</span></code>. The fourth element is unused and always returns zero.</p>
<p>Maximum values of %nctaid.{x,y,z} are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 54%">
<col style="width: 20%">
<col style="width: 13%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>.target architecture</p></th>
<th class="head"><p>%nctaid.x</p></th>
<th class="head"><p>%nctaid.y</p></th>
<th class="head"><p>%nctaid.z</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_1x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
<td><p>65535</p></td>
<td><p>65535</p></td>
<td><p>65535</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_5x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_7x</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_8x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_9x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_10x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_12x</span></code></p></td>
<td><p>2<sup>31</sup> -1</p></td>
<td><p>65535</p></td>
<td><p>65535</p></td>
</tr>
</tbody>
</table>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0 with type <code class="docutils literal notranslate"><span class="pre">.v4.u16</span></code>.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.v4.u32</span></code> in PTX ISA version 2.0. For compatibility with legacy PTX code, 16-bit
<code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions may be used to read the lower 16-bits of each component of
<code class="docutils literal notranslate"><span class="pre">%nctaid</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r0,%nctaid.x;
mov.u16  %rh,%nctaid.x;     // legacy code
</pre></div>
</div>
</section>
<section id="special-registers-smid">
<span id="id569"></span><h2>
<span class="section-number">10.8. </span><a class="reference internal" href="#special-registers-smid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%smid</span></code></a><a class="headerlink" href="#special-registers-smid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%smid</span></code></p>
<p>SM identifier.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %smid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register that returns the processor (SM) identifier on which a
particular thread is executing. The SM identifier ranges from <code class="docutils literal notranslate"><span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">%nsmid-1</span></code>. The SM
identifier numbering is not guaranteed to be contiguous.</p>
<p class="rubric">Notes</p>
<p>Note that <code class="docutils literal notranslate"><span class="pre">%smid</span></code> returns the location of a thread at the moment when read, but
its value may change during execution, e.g. due to rescheduling of threads following
preemption. <code class="docutils literal notranslate"><span class="pre">%smid</span></code> is intended mainly to enable profiling and diagnostic code to sample and log
information such as work place mapping and load distribution.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %smid;
</pre></div>
</div>
</section>
<section id="special-registers-nsmid">
<span id="id570"></span><h2>
<span class="section-number">10.9. </span><a class="reference internal" href="#special-registers-nsmid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%nsmid</span></code></a><a class="headerlink" href="#special-registers-nsmid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%nsmid</span></code></p>
<p>Number of SM identifiers.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %nsmid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register that returns the maximum number of SM identifiers. The SM
identifier numbering is not guaranteed to be contiguous, so <code class="docutils literal notranslate"><span class="pre">%nsmid</span></code> may be larger than the
physical number of SMs in the device.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%nsmid</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %nsmid;
</pre></div>
</div>
</section>
<section id="special-registers-gridid">
<span id="id571"></span><h2>
<span class="section-number">10.10. </span><a class="reference internal" href="#special-registers-gridid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%gridid</span></code></a><a class="headerlink" href="#special-registers-gridid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%gridid</span></code></p>
<p>Grid identifier.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u64 %gridid;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the per-grid temporal grid identifier. The
<code class="docutils literal notranslate"><span class="pre">%gridid</span></code> is used by debuggers to distinguish CTAs and clusters within concurrent (small) grids.</p>
<p>During execution, repeated launches of programs may occur, where each launch starts a
grid-of-CTAs. This variable provides the temporal grid launch number for this context.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets, <code class="docutils literal notranslate"><span class="pre">%gridid</span></code> is limited to the range [0..2<sup>16</sup>-1]. For <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>,
<code class="docutils literal notranslate"><span class="pre">%gridid</span></code> is limited to the range [0..2<sup>32</sup>-1]. <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> supports the entire 64-bit range.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0 as type <code class="docutils literal notranslate"><span class="pre">.u16</span></code>.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.u32</span></code> in PTX ISA version 1.3.</p>
<p>Redefined as type <code class="docutils literal notranslate"><span class="pre">.u64</span></code> in PTX ISA version 3.0.</p>
<p>For compatibility with legacy PTX code, 16-bit and 32-bit <code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instructions may be
used to read the lower 16-bits or 32-bits of each component of <code class="docutils literal notranslate"><span class="pre">%gridid</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u64  %s, %gridid;  // 64-bit read of %gridid
mov.u32  %r, %gridid;  // legacy code with 32-bit %gridid
</pre></div>
</div>
</section>
<section id="special-registers-is-explicit-cluster">
<span id="id572"></span><h2>
<span class="section-number">10.11. </span><a class="reference internal" href="#special-registers-is-explicit-cluster">Special Registers: <code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code></a><a class="headerlink" href="#special-registers-is-explicit-cluster" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code></p>
<p>Checks if user has explicitly specified cluster launch.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .pred %is_explicit_cluster;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the predicate value of whether the cluster
launch is explicitly specified by user.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .pred p;

mov.pred  p, %is_explicit_cluster;
</pre></div>
</div>
</section>
<section id="special-registers-clusterid">
<span id="id573"></span><h2>
<span class="section-number">10.12. </span><a class="reference internal" href="#special-registers-clusterid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%clusterid</span></code></a><a class="headerlink" href="#special-registers-clusterid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%clusterid</span></code></p>
<p>Cluster identifier within a grid.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %clusterid;
.sreg .u32 %clusterid.x, %clusterid.y, %clusterid.z;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the cluster identifier in a grid in each
dimension. Each cluster in a grid has a unique identifier.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">%clusterid</span></code> special register contains a 1D, 2D, or 3D vector, depending upon the shape and
rank of the cluster. The fourth element is unused and always returns zero.</p>
<p>It is guaranteed that:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0  &lt;=  %clusterid.x &lt;  %nclusterid.x
0  &lt;=  %clusterid.y &lt;  %nclusterid.y
0  &lt;=  %clusterid.z &lt;  %nclusterid.z
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r&lt;2&gt;;
.reg .v4 .b32 %rx;

mov.u32     %r0, %clusterid.x;
mov.u32     %r1, %clusterid.z;
mov.v4.u32  %rx, %clusterid;
</pre></div>
</div>
</section>
<section id="special-registers-nclusterid">
<span id="id574"></span><h2>
<span class="section-number">10.13. </span><a class="reference internal" href="#special-registers-nclusterid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code></a><a class="headerlink" href="#special-registers-nclusterid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code></p>
<p>Number of cluster identifiers per grid.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %nclusterid;
.sreg .u32 %nclusterid.x, %nclusterid.y, %nclusterid.z;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the number of clusters in each grid
dimension.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code> special register contains a 3D grid shape vector that holds the grid dimensions
in terms of clusters. The fourth element is unused and always returns zero.</p>
<p>Refer to the <em>Cuda Programming Guide</em> for details on the maximum values of <code class="docutils literal notranslate"><span class="pre">%nclusterid.{x,y,z}</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r&lt;2&gt;;
.reg .v4 .b32 %rx;

mov.u32     %r0, %nclusterid.x;
mov.u32     %r1, %nclusterid.z;
mov.v4.u32  %rx, %nclusterid;
</pre></div>
</div>
</section>
<section id="special-registers-cluster-ctaid">
<span id="id575"></span><h2>
<span class="section-number">10.14. </span><a class="reference internal" href="#special-registers-cluster-ctaid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code></a><a class="headerlink" href="#special-registers-cluster-ctaid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code></p>
<p>CTA identifier within a cluster.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %cluster_ctaid;
.sreg .u32 %cluster_ctaid.x, %cluster_ctaid.y, %cluster_ctaid.z;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the CTA identifier in a cluster in each
dimension. Each CTA in a cluster has a unique CTA identifier.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code> special register contains a 1D, 2D, or 3D vector, depending upon the shape of
the cluster. The fourth element is unused and always returns zero.</p>
<p>It is guaranteed that:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0  &lt;=  %cluster_ctaid.x &lt;  %cluster_nctaid.x
0  &lt;=  %cluster_ctaid.y &lt;  %cluster_nctaid.y
0  &lt;=  %cluster_ctaid.z &lt;  %cluster_nctaid.z
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r&lt;2&gt;;
.reg .v4 .b32 %rx;

mov.u32     %r0, %cluster_ctaid.x;
mov.u32     %r1, %cluster_ctaid.z;
mov.v4.u32  %rx, %cluster_ctaid;
</pre></div>
</div>
</section>
<section id="special-registers-cluster-nctaid">
<span id="id576"></span><h2>
<span class="section-number">10.15. </span><a class="reference internal" href="#special-registers-cluster-nctaid">Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code></a><a class="headerlink" href="#special-registers-cluster-nctaid" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code></p>
<p>Number of CTA identifiers per cluster.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .v4 .u32 %cluster_nctaid;
.sreg .u32 %cluster_nctaid.x, %cluster_nctaid.y, %cluster_nctaid.z;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the number of CTAs in a cluster in each
dimension.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code> special register contains a 3D grid shape vector that holds the cluster
dimensions in terms of CTAs. The fourth element is unused and always returns zero.</p>
<p>Refer to the <em>Cuda Programming Guide</em> for details on the maximum values of
<code class="docutils literal notranslate"><span class="pre">%cluster_nctaid.{x,y,z}</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r&lt;2&gt;;
.reg .v4 .b32 %rx;

mov.u32     %r0, %cluster_nctaid.x;
mov.u32     %r1, %cluster_nctaid.z;
mov.v4.u32  %rx, %cluster_nctaid;
</pre></div>
</div>
</section>
<section id="special-registers-cluster-ctarank">
<span id="id577"></span><h2>
<span class="section-number">10.16. </span><a class="reference internal" href="#special-registers-cluster-ctarank">Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code></a><a class="headerlink" href="#special-registers-cluster-ctarank" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code></p>
<p>CTA identifier in a cluster across all dimensions.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %cluster_ctarank;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the CTA rank within a cluster across all
dimensions.</p>
<p>It is guaranteed that:</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>0  &lt;=  %cluster_ctarank &lt;  %cluster_nctarank
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r;

mov.u32  %r, %cluster_ctarank;
</pre></div>
</div>
</section>
<section id="special-registers-cluster-nctarank">
<span id="id578"></span><h2>
<span class="section-number">10.17. </span><a class="reference internal" href="#special-registers-cluster-nctarank">Special Registers: <code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code></a><a class="headerlink" href="#special-registers-cluster-nctarank" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code></p>
<p>Number of CTA identifiers in a cluster across all dimensions.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %cluster_nctarank;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the nunber of CTAs within a cluster across
all dimensions.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %r;

mov.u32  %r, %cluster_nctarank;
</pre></div>
</div>
</section>
<section id="special-registers-lanemask-eq">
<span id="id579"></span><h2>
<span class="section-number">10.18. </span><a class="reference internal" href="#special-registers-lanemask-eq">Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code></a><a class="headerlink" href="#special-registers-lanemask-eq" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code></p>
<p>32-bit mask with bit set in position equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %lanemask_eq;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with a 32-bit mask with a bit set in the
position equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%lanemask_eq</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32     %r, %lanemask_eq;
</pre></div>
</div>
</section>
<section id="special-registers-lanemask-le">
<span id="id580"></span><h2>
<span class="section-number">10.19. </span><a class="reference internal" href="#special-registers-lanemask-le">Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code></a><a class="headerlink" href="#special-registers-lanemask-le" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code></p>
<p>32-bit mask with bits set in positions less than or equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %lanemask_le;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with a 32-bit mask with bits set in positions
less than or equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%lanemask_le</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32     %r, %lanemask_le
</pre></div>
</div>
</section>
<section id="special-registers-lanemask-lt">
<span id="id581"></span><h2>
<span class="section-number">10.20. </span><a class="reference internal" href="#special-registers-lanemask-lt">Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code></a><a class="headerlink" href="#special-registers-lanemask-lt" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code></p>
<p>32-bit mask with bits set in positions less than the threadâ€™s lane number in the warp.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %lanemask_lt;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with a 32-bit mask with bits set in positions
less than the threadâ€™s lane number in the warp.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%lanemask_lt</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32     %r, %lanemask_lt;
</pre></div>
</div>
</section>
<section id="special-registers-lanemask-ge">
<span id="id582"></span><h2>
<span class="section-number">10.21. </span><a class="reference internal" href="#special-registers-lanemask-ge">Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code></a><a class="headerlink" href="#special-registers-lanemask-ge" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code></p>
<p>32-bit mask with bits set in positions greater than or equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %lanemask_ge;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with a 32-bit mask with bits set in positions
greater than or equal to the threadâ€™s lane number in the warp.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%lanemask_ge</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32     %r, %lanemask_ge;
</pre></div>
</div>
</section>
<section id="special-registers-lanemask-gt">
<span id="id583"></span><h2>
<span class="section-number">10.22. </span><a class="reference internal" href="#special-registers-lanemask-gt">Special Registers: <code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code></a><a class="headerlink" href="#special-registers-lanemask-gt" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code></p>
<p>32-bit mask with bits set in positions greater than the threadâ€™s lane number in the warp.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %lanemask_gt;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with a 32-bit mask with bits set in positions
greater than the threadâ€™s lane number in the warp.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%lanemask_gt</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32     %r, %lanemask_gt;
</pre></div>
</div>
</section>
<section id="special-registers-clock">
<span id="id584"></span><h2>
<span class="section-number">10.23. </span><a class="reference internal" href="#special-registers-clock">Special Registers: <code class="docutils literal notranslate"><span class="pre">%clock</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code></a><a class="headerlink" href="#special-registers-clock" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%clock</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code></p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">%clock</span></code></dt>
<dd>
<p>A predefined, read-only 32-bit unsigned cycle counter.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code></dt>
<dd>
<p>The upper 32-bits of <code class="docutils literal notranslate"><span class="pre">%clock64</span></code> special register.</p>
</dd>
</dl>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %clock;
.sreg .u32 %clock_hi;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Special register <code class="docutils literal notranslate"><span class="pre">%clock</span></code> and <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code> are unsigned 32-bit read-only cycle counters that wrap
silently.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%clock</span></code> introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code> introduced in PTX ISA version 5.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%clock</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32 r1,%clock;
mov.u32 r2, %clock_hi;
</pre></div>
</div>
</section>
<section id="special-registers-clock64">
<span id="id585"></span><h2>
<span class="section-number">10.24. </span><a class="reference internal" href="#special-registers-clock64">Special Registers: <code class="docutils literal notranslate"><span class="pre">%clock64</span></code></a><a class="headerlink" href="#special-registers-clock64" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%clock64</span></code></p>
<p>A predefined, read-only 64-bit unsigned cycle counter.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u64 %clock64;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Special register <code class="docutils literal notranslate"><span class="pre">%clock64</span></code> is an unsigned 64-bit read-only cycle counter that wraps silently.</p>
<p class="rubric">Notes</p>
<p>The lower 32-bits of <code class="docutils literal notranslate"><span class="pre">%clock64</span></code> are identical to <code class="docutils literal notranslate"><span class="pre">%clock</span></code>.</p>
<p>The upper 32-bits of <code class="docutils literal notranslate"><span class="pre">%clock64</span></code> are identical to <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%clock64</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u64  r1,%clock64;
</pre></div>
</div>
</section>
<section id="special-registers-pm0-pm7">
<span id="id586"></span><h2>
<span class="section-number">10.25. </span><a class="reference internal" href="#special-registers-pm0-pm7">Special Registers: <code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code></a><a class="headerlink" href="#special-registers-pm0-pm7" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code></p>
<p>Performance monitoring counters.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %pm&lt;8&gt;;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Special registers <code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code> are unsigned 32-bit read-only performance monitor counters. Their
behavior is currently undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm3</span></code> introduced in PTX ISA version 1.3.</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm4</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code> introduced in PTX ISA version 3.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm3</span></code> supported on all target architectures.</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm4</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  r1,%pm0;
mov.u32  r1,%pm7;
</pre></div>
</div>
</section>
<section id="special-registers-pm0-64-pm7-64">
<span id="id587"></span><h2>
<span class="section-number">10.26. </span><a class="reference internal" href="#special-registers-pm0-64-pm7-64">Special Registers: <code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code></a><a class="headerlink" href="#special-registers-pm0-64-pm7-64" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code></p>
<p>64 bit Performance monitoring counters.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u64 %pm0_64;
.sreg .u64 %pm1_64;
.sreg .u64 %pm2_64;
.sreg .u64 %pm3_64;
.sreg .u64 %pm4_64;
.sreg .u64 %pm5_64;
.sreg .u64 %pm6_64;
.sreg .u64 %pm7_64;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Special registers <code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code> are unsigned 64-bit read-only performance monitor
counters. Their behavior is currently undefined.</p>
<p class="rubric">Notes</p>
<p>The lower 32bits of <code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code> are identical to <code class="docutils literal notranslate"><span class="pre">%pm0</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code> introduced in PTX ISA version 4.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">%pm0_64</span></code> â€¦ <code class="docutils literal notranslate"><span class="pre">%pm7_64</span></code> require <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  r1,%pm0_64;
mov.u32  r1,%pm7_64;
</pre></div>
</div>
</section>
<section id="special-registers-envreg-32">
<span id="id588"></span><h2>
<span class="section-number">10.27. </span><a class="reference internal" href="#special-registers-envreg-32">Special Registers: <code class="docutils literal notranslate"><span class="pre">%envreg&lt;32&gt;</span></code></a><a class="headerlink" href="#special-registers-envreg-32" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%envreg&lt;32&gt;</span></code></p>
<p>Driver-defined read-only registers.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .b32 %envreg&lt;32&gt;;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A set of 32 pre-defined read-only registers used to capture execution environment of PTX program
outside of PTX virtual machine. These registers are initialized by the driver prior to kernel launch
and can contain cta-wide or grid-wide values.</p>
<p>Precise semantics of these registers is defined in the driver documentation.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.b32      %r1,%envreg0;  // move envreg0 to %r1
</pre></div>
</div>
</section>
<section id="special-registers-globaltimer">
<span id="id589"></span><h2>
<span class="section-number">10.28. </span><a class="reference internal" href="#special-registers-globaltimer">Special Registers: <code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></a><a class="headerlink" href="#special-registers-globaltimer" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code>, <code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">%globaltimer</span></code></dt>
<dd>
<p>A predefined, 64-bit global nanosecond timer.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%globaltimer_lo</span></code></dt>
<dd>
<p>The lower 32-bits of %globaltimer.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%globaltimer_hi</span></code></dt>
<dd>
<p>The upper 32-bits of %globaltimer.</p>
</dd>
</dl>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u64 %globaltimer;
.sreg .u32 %globaltimer_lo, %globaltimer_hi;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Special registers intended for use by NVIDIA tools. The behavior is target-specific and may change
or be removed in future GPUs. When JIT-compiled to other targets, the value of these registers is
unspecified.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires target <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u64  r1,%globaltimer;
</pre></div>
</div>
</section>
<section id="special-registers-reserved-smem">
<span id="id590"></span><h2>
<span class="section-number">10.29. </span><a class="reference internal" href="#special-registers-reserved-smem">Special Registers: <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code>,
<code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_&lt;2&gt;</span></code></a><a class="headerlink" href="#special-registers-reserved-smem" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_&lt;2&gt;</span></code></p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code></dt>
<dd>
<p>Start of the reserved shared memory region.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code></dt>
<dd>
<p>End of the reserved shared memory region.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code></dt>
<dd>
<p>Total size of the reserved shared memory region.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_&lt;2&gt;</span></code></dt>
<dd>
<p>Offsets in the reserved shared memory region.</p>
</dd>
</dl>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .b32 %reserved_smem_offset_begin;
.sreg .b32 %reserved_smem_offset_end;
.sreg .b32 %reserved_smem_offset_cap;
.sreg .b32 %reserved_smem_offset_&lt;2&gt;;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>These are predefined, read-only special registers containing information about the shared memory
region which is reserved for the NVIDIA system software use. This region of shared memory is not
available to users, and accessing this region from user code results in undefined behavior. Refer to
<em>CUDA Programming Guide</em> for details.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.6.</p>
<p class="rubric">Target ISA Notes</p>
<p>Require <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reg .b32 %reg_begin, %reg_end, %reg_cap, %reg_offset0, %reg_offset1;

mov.b32 %reg_begin,   %reserved_smem_offset_begin;
mov.b32 %reg_end,     %reserved_smem_offset_end;
mov.b32 %reg_cap,     %reserved_smem_offset_cap;
mov.b32 %reg_offset0, %reserved_smem_offset_0;
mov.b32 %reg_offset1, %reserved_smem_offset_1;
</pre></div>
</div>
</section>
<section id="special-registers-total-smem-size">
<span id="id591"></span><h2>
<span class="section-number">10.30. </span><a class="reference internal" href="#special-registers-total-smem-size">Special Registers: <code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code></a><a class="headerlink" href="#special-registers-total-smem-size" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code></p>
<p>Total size of shared memory used by a CTA of a kernel.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %total_smem_size;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with total size of shared memory allocated
(statically and dynamically, excluding the shared memory reserved for the NVIDIA system software
use) for the CTA of a kernel at launch time.</p>
<p>Size is returned in multiples of shared memory allocation unit size supported by target
architecture.</p>
<p>Allocation unit values are as follows:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 55%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target architecture</p></th>
<th class="head"><p>Shared memory allocation unit size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_2x</span></code></p></td>
<td><p>128 bytes</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_3x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_5x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_7x</span></code></p></td>
<td><p>256 bytes</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_8x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_9x</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_10x</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_12x</span></code></p></td>
<td><p>128 bytes</p></td>
</tr>
</tbody>
</table>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %total_smem_size;
</pre></div>
</div>
</section>
<section id="special-registers-aggr-smem-size">
<span id="id592"></span><h2>
<span class="section-number">10.31. </span><a class="reference internal" href="#special-registers-aggr-smem-size">Special Registers: <code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code></a><a class="headerlink" href="#special-registers-aggr-smem-size" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code></p>
<p>Total size of shared memory used by a CTA of a kernel.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %aggr_smem_size;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with total aggregated size of shared memory
consisting of the size of user shared memory allocated (statically and dynamically) at launch time
and the size of shared memory region which is reserved for the NVIDIA system software use.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %aggr_smem_size;
</pre></div>
</div>
</section>
<section id="special-registers-dynamic-smem-size">
<span id="id593"></span><h2>
<span class="section-number">10.32. </span><a class="reference internal" href="#special-registers-dynamic-smem-size">Special Registers: <code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code></a><a class="headerlink" href="#special-registers-dynamic-smem-size" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code></p>
<p>Size of shared memory allocated dynamically at kernel launch.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u32 %dynamic_smem_size;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Size of shared memory allocated dynamically at kernel launch.</p>
<p>A predefined, read-only special register initialized with size of shared memory allocated dynamically for the CTA of a kernel at launch time.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 4.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u32  %r, %dynamic_smem_size;
</pre></div>
</div>
</section>
<section id="special-registers-current-graph-exec">
<span id="id594"></span><h2>
<span class="section-number">10.33. </span><a class="reference internal" href="#special-registers-current-graph-exec">Special Registers: <code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code></a><a class="headerlink" href="#special-registers-current-graph-exec" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code></p>
<p>An Identifier for currently executing CUDA device graph.</p>
<p class="rubric">Syntax (predefined)</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.sreg .u64 %current_graph_exec;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>A predefined, read-only special register initialized with the identifier referring to the CUDA
device graph being currently executed. This register is 0 if the executing kernel is not part of a
CUDA device graph.</p>
<p>Refer to the <em>CUDA Programming Guide</em> for more details on CUDA device graphs.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>mov.u64  r1, %current_graph_exec;
</pre></div>
</div>
</section>
</section>
<section id="directives">
<span id="id595"></span><h1>
<span class="section-number">11. </span><a class="reference internal" href="#directives">Directives</a><a class="headerlink" href="#directives" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="ptx-module-directives">
<span id="id596"></span><h2>
<span class="section-number">11.1. </span><a class="reference internal" href="#ptx-module-directives">PTX Module Directives</a><a class="headerlink" href="#ptx-module-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The following directives declare the PTX ISA version of the code in the module, the target
architecture for which the code was generated, and the size of addresses within the PTX module.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.version</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.target</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.address_size</span></code></p></li>
</ul>
<section id="ptx-module-directives-version">
<span id="id597"></span><h3>
<span class="section-number">11.1.1. </span><a class="reference internal" href="#ptx-module-directives-version">PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.version</span></code></a><a class="headerlink" href="#ptx-module-directives-version" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.version</span></code></p>
<p>PTX ISA version number.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.version  major.minor    // major, minor are integers
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Specifies the PTX language version number.</p>
<p>The <em>major</em> number is incremented when there are incompatible changes to the PTX language, such as
changes to the syntax or semantics. The version major number is used by the PTX compiler to ensure
correct execution of legacy PTX code.</p>
<p>The <em>minor</em> number is incremented when new features are added to PTX.</p>
<p class="rubric">Semantics</p>
<p>Indicates that this module must be compiled with tools that support an equal or greater version
number.</p>
<p>Each PTX module must begin with a <code class="docutils literal notranslate"><span class="pre">.version</span></code> directive, and no other <code class="docutils literal notranslate"><span class="pre">.version</span></code> directive is
allowed anywhere else within the module.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.version 3.1
.version 3.0
.version 2.3
</pre></div>
</div>
</section>
<section id="ptx-module-directives-target">
<span id="id598"></span><h3>
<span class="section-number">11.1.2. </span><a class="reference internal" href="#ptx-module-directives-target">PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.target</span></code></a><a class="headerlink" href="#ptx-module-directives-target" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.target</span></code></p>
<p>Architecture and Platform target.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.target stringlist         // comma separated list of target specifiers
string = { sm_120a, sm_120f, sm_120,          // sm_12x target architectures
           sm_121a, sm_121f, sm_121,          // sm_12x target architectures
           sm_110a, sm_110f, sm_110,          // sm_11x target architectures
           sm_100a, sm_100f, sm_100,          // sm_10x target architectures
           sm_101a, sm_101f, sm_101,          // sm_10x target architectures
           sm_103a, sm_103f, sm_103           // sm_10x target architectures
           sm_90a, sm_90,                     // sm_9x target architectures
           sm_80, sm_86, sm_87, sm_88, sm_89, // sm_8x target architectures
           sm_70, sm_72, sm_75,               // sm_7x target architectures
           sm_60, sm_61, sm_62,               // sm_6x target architectures
           sm_50, sm_52, sm_53,               // sm_5x target architectures
           sm_30, sm_32, sm_35, sm_37,        // sm_3x target architectures
           sm_20,                             // sm_2x target architectures
           sm_10, sm_11, sm_12, sm_13,        // sm_1x target architectures
           texmode_unified, texmode_independent,   // texturing mode
           debug,                                  // platform option
           map_f64_to_f32 };                       // platform option
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Specifies the set of features in the target architecture for which the current PTX code was
generated. In general, generations of SM architectures follow an <em>onion layer</em> model, where each
generation adds new features and retains all features of previous generations. The onion layer model
allows the PTX code generated for a given target to be run on later generation devices.</p>
<p>Target architectures with suffix â€œ<code class="docutils literal notranslate"><span class="pre">a</span></code>â€, such as <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>, include architecture-specific
features that are supported on the specified architecture only, hence such targets do not follow the
onion layer model. Therefore, PTX code generated for such targets cannot be run on later generation
devices. Architecture-specific features can only be used with targets that support these
features.</p>
<p>Target architectures with suffix â€œ<code class="docutils literal notranslate"><span class="pre">f</span></code>â€, such as <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, include family-specific features that
are supported only within the same architecture family. Therefore, PTX code generated for such
targets can run only on later generation devices in the same family. Family-specific features can be
used with f-targets as well as a-targets of later generation devices in the same family.</p>
<p><a class="reference internal" href="#architecture-family-definition"><span class="std std-numref">Table 58</span></a> defines the architecture families.</p>
<table class="table-no-stripes docutils align-default" id="architecture-family-definition">
<caption>
<span class="caption-number">Table 58 </span><span class="caption-text">Architecture Families</span><a class="headerlink" href="#architecture-family-definition" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 35%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Family</p></th>
<th class="head"><p>Target SM architectures included</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>sm_10x family</p></td>
<td><p>sm_100f, sm_103f, future targets
in sm_10x family</p></td>
</tr>
<tr class="row-odd">
<td><p>sm_11x family</p></td>
<td><p>sm_110f, sm_101f, future targets
in sm_11x family</p></td>
</tr>
<tr class="row-even">
<td><p>sm_12x family</p></td>
<td><p>sm_120f, sm_121f, future targets
in sm_12x family</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Semantics</p>
<p>Each PTX module must begin with a <code class="docutils literal notranslate"><span class="pre">.version</span></code> directive, immediately followed by a <code class="docutils literal notranslate"><span class="pre">.target</span></code>
directive containing a target architecture and optional platform options. A <code class="docutils literal notranslate"><span class="pre">.target</span></code> directive
specifies a single target architecture, but subsequent <code class="docutils literal notranslate"><span class="pre">.target</span></code> directives can be used to change
the set of target features allowed during parsing. A program with multiple <code class="docutils literal notranslate"><span class="pre">.target</span></code> directives
will compile and run only on devices that support all features of the highest-numbered architecture
listed in the program.</p>
<p>PTX features are checked against the specified target architecture, and an error is generated if an
unsupported feature is used. The following table summarizes the features in PTX that vary according
to target architecture.</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_120</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> family specific features.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> architecture-specific features.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_121</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_121</span></code> architecture.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_121f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_121f</span></code> family specific features.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code> architecture-specific features.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_110</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> family specific features.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> architecture-specific features.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> family specific features.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> architecture-specific features.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_101</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_101</span></code> architecture. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110</span></code>)</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> family specific features. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>)</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_101a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> architecture-specific features. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>)</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_103</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103f</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code> family specific features.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> architecture-specific features.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 88%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_90</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> architecture-specific features.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_80</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_86</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> modifier on <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> instructions.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_87</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_87</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_88</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_88</span></code> architecture.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_89</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> architecture.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 89%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_70</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_72</span></code></p></td>
<td>
<p>Adds support for integer multiplicand and accumulator matrices in <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions.</p>
<p>Adds support for <code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code> instruction.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_75</span></code></p></td>
<td>
<p>Adds support for sub-byte integer and single-bit multiplicant matrices in <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions.</p>
<p>Adds support for <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction.</p>
<p>Adds support for <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> instruction.</p>
<p>Adds support for <code class="docutils literal notranslate"><span class="pre">tanh</span></code> instruction.</p>
</td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 18%">
<col style="width: 82%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_60</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_60</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_61</span></code></p></td>
<td><p>Adds support for <code class="docutils literal notranslate"><span class="pre">dp2a</span></code> and <code class="docutils literal notranslate"><span class="pre">dp4a</span></code> instructions.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_62</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_61</span></code> architecture.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 11%">
<col style="width: 89%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_50</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_52</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> architecture.</p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_53</span></code></p></td>
<td><p>Adds support for arithmetic, comparsion and texture instructions for <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> types.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 17%">
<col style="width: 83%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_30</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> architecture.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_32</span></code></p></td>
<td>
<p>Adds 64-bit <code class="docutils literal notranslate"><span class="pre">{atom,red}.{and,or,xor,min,max}</span></code>
instructions.</p>
<p>Adds <code class="docutils literal notranslate"><span class="pre">shf</span></code> instruction.</p>
<p>Adds <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code> instruction.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_35</span></code></p></td>
<td><p>Adds support for CUDA Dynamic Parallelism.</p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_37</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_35</span></code> architecture.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 19%">
<col style="width: 81%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
<td><p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> architecture.</p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 14%">
<col style="width: 86%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Target</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_10</span></code></p></td>
<td>
<p>Baseline feature set for <code class="docutils literal notranslate"><span class="pre">sm_10</span></code> architecture.</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">map_f64_to_f32</span></code> if any <code class="docutils literal notranslate"><span class="pre">.f64</span></code> instructions used.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_11</span></code></p></td>
<td>
<p>Adds 64-bit <code class="docutils literal notranslate"><span class="pre">{atom,red}.{and,or,xor,min,max}</span></code> instructions.</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">map_f64_to_f32</span></code> if any <code class="docutils literal notranslate"><span class="pre">.f64</span></code> instructions used.</p>
</td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_12</span></code></p></td>
<td>
<p>Adds <code class="docutils literal notranslate"><span class="pre">{atom,red}.shared</span></code>, 64-bit <code class="docutils literal notranslate"><span class="pre">{atom,red}.global</span></code>, <code class="docutils literal notranslate"><span class="pre">vote</span></code>
instructions.</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">map_f64_to_f32</span></code> if any <code class="docutils literal notranslate"><span class="pre">.f64</span></code> instructions used.</p>
</td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">sm_13</span></code></p></td>
<td>
<p>Adds double-precision support, including expanded rounding modifiers.</p>
<p>Disallows use of <code class="docutils literal notranslate"><span class="pre">map_f64_to_f32</span></code>.</p>
</td>
</tr>
</tbody>
</table>
<p>The texturing mode is specified for an entire module and cannot be changed within the module.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.target</span></code> debug option declares that the PTX file contains DWARF debug information, and
subsequent compilation of PTX will retain information needed for source-level debugging. If the
debug option is declared, an error message is generated if no DWARF information is found in the
file. The debug option requires PTX ISA version 3.0 or later.</p>
<p><code class="docutils literal notranslate"><span class="pre">map_f64_to_f32</span></code> indicates that all double-precision instructions map to single-precision
regardless of the target architecture. This enables high-level language compilers to compile
programs containing type double to target device that do not support double-precision
operations. Note that <code class="docutils literal notranslate"><span class="pre">.f64</span></code> storage remains as 64-bits, with only half being used by instructions
converted from <code class="docutils literal notranslate"><span class="pre">.f64</span></code> to <code class="docutils literal notranslate"><span class="pre">.f32</span></code>.</p>
<p class="rubric">Notes</p>
<p>Targets of the form <code class="docutils literal notranslate"><span class="pre">compute_xx</span></code> are also accepted as synonyms for <code class="docutils literal notranslate"><span class="pre">sm_xx</span></code> targets.</p>
<p>Targets <code class="docutils literal notranslate"><span class="pre">sm_{101,101f,101a}</span></code> are renamed to targets <code class="docutils literal notranslate"><span class="pre">sm_{110,110f,110a}</span></code> from PTX ISA version 9.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Target strings <code class="docutils literal notranslate"><span class="pre">sm_10</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_11</span></code> introduced in PTX ISA version 1.0.</p>
<p>Target strings <code class="docutils literal notranslate"><span class="pre">sm_12</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_13</span></code> introduced in PTX ISA version 1.2.</p>
<p>Texturing mode introduced in PTX ISA version 1.5.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> introduced in PTX ISA version 2.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> introduced in PTX ISA version 3.0.</p>
<p>Platform option <code class="docutils literal notranslate"><span class="pre">debug</span></code> introduced in PTX ISA version 3.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_35</span></code> introduced in PTX ISA version 3.1.</p>
<p>Target strings <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> introduced in PTX ISA version 4.0.</p>
<p>Target strings <code class="docutils literal notranslate"><span class="pre">sm_37</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_52</span></code> introduced in PTX ISA version 4.1.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> introduced in PTX ISA version 4.2.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_60</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_61</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_62</span></code> introduced in PTX ISA version 5.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> introduced in PTX ISA version 6.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> introduced in PTX ISA version 6.1.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> introduced in PTX ISA version 6.3.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> introduced in PTX ISA version 7.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> introduced in PTX ISA version 7.1.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_87</span></code> introduced in PTX ISA version 7.4.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_88</span></code> introduced in PTX ISA version 9.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> introduced in PTX ISA version 7.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> introduced in PTX ISA version 7.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> introduced in PTX ISA version 8.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> introduced in PTX ISA version 8.6.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> introduced in PTX ISA version 8.6.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_101</span></code> introduced in PTX ISA version 8.6. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110</span></code>)</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code> introduced in PTX ISA version 8.8. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>)</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> introduced in PTX ISA version 8.6. (Renamed to <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>)</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_103</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_110</span></code> introduced in PTX ISA version 9.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> introduced in PTX ISA version 9.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> introduced in PTX ISA version 9.0.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_120</span></code> introduced in PTX ISA version 8.7.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> introduced in PTX ISA version 8.7.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_121</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_121f</span></code> introduced in PTX ISA version 8.8.</p>
<p>Target string <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code> introduced in PTX ISA version 8.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.target</span></code> directive is supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.target sm_10       // baseline target architecture
.target sm_13       // supports double-precision
.target sm_20, texmode_independent
.target sm_90       // baseline target architecture
.target sm_90a      // PTX using architecture-specific features
.target sm_100f     // PTX using family-specific features
</pre></div>
</div>
</section>
<section id="ptx-module-directives-address-size">
<span id="id599"></span><h3>
<span class="section-number">11.1.3. </span><a class="reference internal" href="#ptx-module-directives-address-size">PTX Module Directives: <code class="docutils literal notranslate"><span class="pre">.address_size</span></code></a><a class="headerlink" href="#ptx-module-directives-address-size" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.address_size</span></code></p>
<p>Address size used throughout PTX module.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.address_size  address-size
address-size = { 32, 64 };
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Specifies the address size assumed throughout the module by the PTX code and the binary DWARF
information in PTX.</p>
<p>Redefinition of this directive within a module is not allowed. In the presence of separate
compilation all modules must specify (or default to) the same address size.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.address_size</span></code> directive is optional, but it must immediately follow the <code class="docutils literal notranslate"><span class="pre">.target</span></code>directive if present within a module.</p>
<p class="rubric">Semantics</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">.address_size</span></code> directive is omitted, the address size defaults to 32.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>// example directives
   .address_size 32       // addresses are 32 bit
   .address_size 64       // addresses are 64 bit

// example of directive placement within a module
   .version 2.3
   .target sm_20
   .address_size 64
...
.entry foo () {
...
}
</pre></div>
</div>
</section>
</section>
<section id="specifying-kernel-entry-points-and-functions">
<span id="id600"></span><h2>
<span class="section-number">11.2. </span><a class="reference internal" href="#specifying-kernel-entry-points-and-functions">Specifying Kernel Entry Points and Functions</a><a class="headerlink" href="#specifying-kernel-entry-points-and-functions" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The following directives specify kernel entry points and functions.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.entry</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.func</span></code></p></li>
</ul>
<section id="kernel-and-function-directives-entry">
<span id="id601"></span><h3>
<span class="section-number">11.2.1. </span><a class="reference internal" href="#kernel-and-function-directives-entry">Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.entry</span></code></a><a class="headerlink" href="#kernel-and-function-directives-entry" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.entry</span></code></p>
<p>Kernel entry point and body, with optional parameters.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry kernel-name ( param-list )  kernel-body
.entry kernel-name  kernel-body
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Defines a kernel entry point name, parameters, and body for the kernel function.</p>
<p>Parameters are passed via <code class="docutils literal notranslate"><span class="pre">.param</span></code> space memory and are listed within an optional parenthesized
parameter list. Parameters may be referenced by name within the kernel body and loaded into
registers using <code class="docutils literal notranslate"><span class="pre">ld.param{::entry}</span></code> instructions.</p>
<p>In addition to normal parameters, opaque <code class="docutils literal notranslate"><span class="pre">.texref</span></code>, <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code>, and <code class="docutils literal notranslate"><span class="pre">.surfref</span></code> variables
may be passed as parameters. These parameters can only be referenced by name within texture and
surface load, store, and query instructions and cannot be accessed via <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> instructions.</p>
<p>The shape and size of the CTA executing the kernel are available in special registers.</p>
<p class="rubric">Semantics</p>
<p>Specify the entry point for a kernel program.</p>
<p>At kernel launch, the kernel dimensions and properties are established and made available via
special registers, e.g., <code class="docutils literal notranslate"><span class="pre">%ntid</span></code>, <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code>, etc.</p>
<p class="rubric">PTX ISA Notes</p>
<p>For PTX ISA version 1.4 and later, parameter variables are declared in the kernel parameter
list. For PTX ISA versions 1.0 through 1.3, parameter variables are declared in the kernel body.</p>
<p>The maximum memory size supported by PTX for normal (non-opaque type) parameters is 32764
bytes. Depending upon the PTX ISA version, the parameter size limit varies. The following table
shows the allowed parameter size for a PTX ISA version:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 48%">
<col style="width: 52%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>PTX ISA Version</p></th>
<th class="head"><p>Maximum parameter size (In bytes)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>PTX ISA version 8.1 and above</p></td>
<td><p>32764</p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA version 1.5 and above</p></td>
<td><p>4352</p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA version 1.4 and above</p></td>
<td><p>256</p></td>
</tr>
</tbody>
</table>
<p>The CUDA and OpenCL drivers support the following limits for parameter memory:</p>
<table class="table-no-stripes docutils align-default">
<colgroup>
<col style="width: 13%">
<col style="width: 88%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Driver</p></th>
<th class="head"><p>Parameter memory size</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>CUDA</p></td>
<td><p>256 bytes for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code>, 4096 bytes for <code class="docutils literal notranslate"><span class="pre">sm_2x</span> <span class="pre">and</span> <span class="pre">higher</span></code>,
32764 bytes fo <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and higher</p></td>
</tr>
<tr class="row-odd">
<td><p>OpenCL</p></td>
<td><p>32764 bytes for <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and higher, 4352 bytes on <code class="docutils literal notranslate"><span class="pre">sm_6x</span></code>
and lower</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry cta_fft
.entry filter ( .param .b32 x, .param .b32 y, .param .b32 z )
{
    .reg .b32 %r&lt;99&gt;;
    ld.param.b32  %r1, [x];
    ld.param.b32  %r2, [y];
    ld.param.b32  %r3, [z];
    ...
}

.entry prefix_sum ( .param .align 4 .s32 pitch[8000] )
{
    .reg .s32 %t;
    ld.param::entry.s32  %t, [pitch];
    ...
}
</pre></div>
</div>
</section>
<section id="kernel-and-function-directives-func">
<span id="id602"></span><h3>
<span class="section-number">11.2.2. </span><a class="reference internal" href="#kernel-and-function-directives-func">Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.func</span></code></a><a class="headerlink" href="#kernel-and-function-directives-func" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.func</span></code></p>
<p>Function definition.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func {.attribute(attr-list)} fname {.noreturn} {.abi_preserve N} {.abi_preserve_control N} function-body
.func {.attribute(attr-list)} fname (param-list) {.noreturn} {.abi_preserve N} {.abi_preserve_control N} function-body
.func {.attribute(attr-list)} (ret-param) fname (param-list) {.abi_preserve N} {.abi_preserve_control N} function-body
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Defines a function, including input and return parameters and optional function body.</p>
<p>An optional <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive indicates that the function does not return to the caller
function. <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive cannot be specified on functions which have return parameters. See
the description of <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive in <a class="reference internal" href="#performance-tuning-directives-noreturn"><span class="std std-ref">Performance-Tuning Directives: .noreturn</span></a>.</p>
<p>An optional <code class="docutils literal notranslate"><span class="pre">.attribute</span></code> directive specifies additional information associated with the
function. See the description of <a class="reference internal" href="#variable-and-function-attribute-directive-attribute"><span class="std std-ref">Variable and Function Attribute Directive: .attribute</span></a>
for allowed attributes.</p>
<p>Optional <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives are used to specify the number
of general purpose registers and control registers. See description of <a class="reference internal" href="#performance-tuning-directives-abi-preserve"><span class="std std-ref">Performance-Tuning Directives: .abi_preserve</span></a>
and <a class="reference internal" href="#performance-tuning-directives-abi-preserve-control"><span class="std std-ref">Performance-Tuning Directives: .abi_preserve_control</span></a> for more details.</p>
<p>Directives, if any specified, for a function, e.g. <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code>, must be specified consistently
between function declaration and definition.</p>
<p>A <code class="docutils literal notranslate"><span class="pre">.func</span></code> definition with no body provides a function prototype.</p>
<p>The parameter lists define locally-scoped variables in the function body. Parameters must be base
types in either the register or parameter state space. Parameters in register state space may be
referenced directly within instructions in the function body. Parameters in <code class="docutils literal notranslate"><span class="pre">.param</span></code> space are
accessed using <code class="docutils literal notranslate"><span class="pre">ld.param{::func}</span></code> and <code class="docutils literal notranslate"><span class="pre">st.param{::func}</span></code> instructions in the body. Parameter
passing is call-by-value.</p>
<p>The last parameter in the parameter list may be a <code class="docutils literal notranslate"><span class="pre">.param</span></code> array of type <code class="docutils literal notranslate"><span class="pre">.b8</span></code> with no size
specified. It is used to pass an arbitrary number of parameters to the function packed into a single
array object.</p>
<p>When calling a function with such an unsized last argument, the last argument may be omitted from
the <code class="docutils literal notranslate"><span class="pre">call</span></code> instruction if no parameter is passed through it. Accesses to this array parameter must
be within the bounds of the array. The result of an access is undefined if no array was passed, or
if the access was outside the bounds of the actual array being passed.</p>
<p class="rubric">Semantics</p>
<p>The PTX syntax hides all details of the underlying calling convention and ABI.</p>
<p>The implementation of parameter passing is left to the optimizing translator, which may use a
combination of registers and stack locations to pass parameters.</p>
<p class="rubric">Release Notes</p>
<p>For PTX ISA version 1.x code, parameters must be in the register state space, there is no stack, and
recursion is illegal.</p>
<p>PTX ISA versions 2.0 and later with target <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher allow parameters in the <code class="docutils literal notranslate"><span class="pre">.param</span></code>
state space, implements an ABI with stack, and supports recursion.</p>
<p>PTX ISA versions 2.0 and later with target <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher support at most one return value.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Support for unsized array parameter introduced in PTX ISA version 6.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive introduced in PTX ISA version 6.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.attribute</span></code> directive introduced in PTX ISA version 8.0.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Functions without unsized array parameter supported on all target architectures.</p>
<p>Unsized array parameter requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.attribute</span></code> directive requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives require <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func (.reg .b32 rval) foo (.reg .b32 N, .reg .f64 dbl)
{
.reg .b32 localVar;

... use N, dbl;
other code;

mov.b32 rval,result;
ret;
}

...
call (fooval), foo, (val0, val1);  // return value in fooval
...

.func foo (.reg .b32 N, .reg .f64 dbl) .noreturn
{
.reg .b32 localVar;
... use N, dbl;
other code;
mov.b32 rval, result;
ret;
}
...
call foo, (val0, val1);
...

.func (.param .u32 rval) bar(.param .u32 N, .param .align 4 .b8 numbers[])
{
    .reg .b32 input0, input1;
    ld.param.b32   input0, [numbers + 0];
    ld.param.b32   input1, [numbers + 4];
    ...
    other code;
    ret;
}
...

.param .u32 N;
.param .align 4 .b8 numbers[8];
st.param.u32    [N], 2;
st.param.b32    [numbers + 0], 5;
st.param.b32    [numbers + 4], 10;
call (rval), bar, (N, numbers);
...
</pre></div>
</div>
</section>
<section id="kernel-and-function-directives-alias">
<span id="id603"></span><h3>
<span class="section-number">11.2.3. </span><a class="reference internal" href="#kernel-and-function-directives-alias">Kernel and Function Directives: <code class="docutils literal notranslate"><span class="pre">.alias</span></code></a><a class="headerlink" href="#kernel-and-function-directives-alias" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.alias</span></code></p>
<p>Define an alias to existing function symbol.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.alias fAlias, fAliasee;
</pre></div>
</div>
<p class="rubric">Description</p>
<p><code class="docutils literal notranslate"><span class="pre">.alias</span></code> is a module scope directive that defines identifier <code class="docutils literal notranslate"><span class="pre">fAlias</span></code> to be an alias to function
specified by <code class="docutils literal notranslate"><span class="pre">fAliasee</span></code>.</p>
<p>Both <code class="docutils literal notranslate"><span class="pre">fAlias</span></code> and <code class="docutils literal notranslate"><span class="pre">fAliasee</span></code> are non-entry function symbols.</p>
<p>Identifier <code class="docutils literal notranslate"><span class="pre">fAlias</span></code> is a function declaration without body.</p>
<p>Identifier <code class="docutils literal notranslate"><span class="pre">fAliasee</span></code> is a function symbol which must be defined in the same module as <code class="docutils literal notranslate"><span class="pre">.alias</span></code>
declaration. Function <code class="docutils literal notranslate"><span class="pre">fAliasee</span></code> cannot have <code class="docutils literal notranslate"><span class="pre">.weak</span></code> linkage.</p>
<p>Prototype of <code class="docutils literal notranslate"><span class="pre">fAlias</span></code> and <code class="docutils literal notranslate"><span class="pre">fAliasee</span></code> must match.</p>
<p>Program can use either <code class="docutils literal notranslate"><span class="pre">fAlias</span></code> or <code class="docutils literal notranslate"><span class="pre">fAlisee</span></code> identifiers to reference function defined with
<code class="docutils literal notranslate"><span class="pre">fAliasee</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">.alias</span></code> directive introduced in PTX ISA 6.3.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">.alias</span></code> directive requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.visible .func foo(.param .u32 p) {
   ...
}
.visible .func bar(.param .u32 p);
.alias bar, foo;
.entry test()
{
      .param .u32 p;
      ...
      call foo, (p);       // call foo directly
       ...
       .param .u32 p;
       call bar, (p);        // call foo through alias
}
.entry filter ( .param .b32 x, .param .b32 y, .param .b32 z )
{
    .reg .b32 %r1, %r2, %r3;
    ld.param.b32  %r1, [x];
    ld.param.b32  %r2, [y];
    ld.param.b32  %r3, [z];
    ...
}
</pre></div>
</div>
</section>
</section>
<section id="control-flow-directives">
<span id="id604"></span><h2>
<span class="section-number">11.3. </span><a class="reference internal" href="#control-flow-directives">Control Flow Directives</a><a class="headerlink" href="#control-flow-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX provides directives for specifying potential targets for <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code> and <code class="docutils literal notranslate"><span class="pre">call</span></code>
instructions. See the descriptions of <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code> and <code class="docutils literal notranslate"><span class="pre">call</span></code> for more information.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.calltargets</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.callprototype</span></code></p></li>
</ul>
<section id="control-flow-directives-branchtargets">
<span id="id605"></span><h3>
<span class="section-number">11.3.1. </span><a class="reference internal" href="#control-flow-directives-branchtargets">Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code></a><a class="headerlink" href="#control-flow-directives-branchtargets" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code></p>
<p>Declare a list of potential branch targets.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Label:   .branchtargets  list-of-labels ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares a list of potential branch targets for a subsequent <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code>, and associates the list
with the label at the start of the line.</p>
<p>All control flow labels in the list must occur within the same function as the declaration.</p>
<p>The list of labels may use the compact, shorthand syntax for enumerating a range of labels having a
common prefix, similar to the syntax described in <a class="reference internal" href="#parameterized-variable-names"><span class="std std-ref">Parameterized Variable Names</span></a>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>  .function foo () {
      .reg .u32 %r0;
      ...
      L1:
      ...
      L2:
      ...
      L3:
      ...
      ts: .branchtargets L1, L2, L3;
      @p brx.idx %r0, ts;
      ...

.function bar() {
      .reg .u32 %r0;
      ...
      N0:
      ...
      N1:
      ...
      N2:
      ...
      N3:
      ...
      N4:
      ...
      ts: .branchtargets N&lt;5&gt;;
      @p brx.idx %r0, ts;
      ...
</pre></div>
</div>
</section>
<section id="control-flow-directives-calltargets">
<span id="id606"></span><h3>
<span class="section-number">11.3.2. </span><a class="reference internal" href="#control-flow-directives-calltargets">Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code></a><a class="headerlink" href="#control-flow-directives-calltargets" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.calltargets</span></code></p>
<p>Declare a list of potential call targets.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Label:   .calltargets  list-of-functions ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares a list of potential call targets for a subsequent indirect call, and associates the list
with the label at the start of the line.</p>
<p>All functions named in the list must be declared prior to the <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code> directive, and all
functions must have the same type signature.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>calltgt:  .calltargets  fastsin, fastcos;
...
@p   call  (%f1), %r0, (%x), calltgt;
...
</pre></div>
</div>
</section>
<section id="control-flow-directives-callprototype">
<span id="id607"></span><h3>
<span class="section-number">11.3.3. </span><a class="reference internal" href="#control-flow-directives-callprototype">Control Flow Directives: <code class="docutils literal notranslate"><span class="pre">.callprototype</span></code></a><a class="headerlink" href="#control-flow-directives-callprototype" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.callprototype</span></code></p>
<p>Declare a prototype for use in an indirect call.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span> // no input or return parameters
label: .callprototype _ .noreturn {.abi_preserve N} {.abi_preserve_control N};
// input params, no return params
label: .callprototype _ (param-list) .noreturn {.abi_preserve N} {.abi_preserve_control N};
// no input params, // return params
label: .callprototype (ret-param) _ {.abi_preserve N} {.abi_preserve_control N};
// input, return parameters
label: .callprototype (ret-param) _ (param-list) {.abi_preserve N} {.abi_preserve_control N};
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Defines a prototype with no specific function name, and associates the prototype with a label. The
prototype may then be used in indirect call instructions where there is incomplete knowledge of the
possible call targets.</p>
<p>Parameters may have either base types in the register or parameter state spaces, or array types in
parameter state space. The sink symbol <code class="docutils literal notranslate"><span class="pre">'_'</span></code> may be used to avoid dummy parameter names.</p>
<p>An optional <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive indicates that the function does not return to the caller
function. <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive cannot be specified on functions which have return parameters. See
the description of .noreturn directive in <a class="reference internal" href="#performance-tuning-directives-noreturn"><span class="std std-ref">Performance-Tuning Directives: .noreturn</span></a>.</p>
<p>Optional <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives are used to specify the number
of general purpose registers and control registers. See description of <a class="reference internal" href="#performance-tuning-directives-abi-preserve"><span class="std std-ref">Performance-Tuning Directives: .abi_preserve</span></a>
and <a class="reference internal" href="#performance-tuning-directives-abi-preserve-control"><span class="std std-ref">Performance-Tuning Directives: .abi_preserve_control</span></a> for more details.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.1.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive introduced in PTX ISA version 6.4.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p><code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directives require <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Fproto1: .callprototype  _ ;
Fproto2: .callprototype  _ (.param .f32 _);
Fproto3: .callprototype  (.param .u32 _) _ ;
Fproto4: .callprototype  (.param .u32 _) _ (.param .f32 _);
...
@p   call  (%val), %r0, (%f1), Fproto4;
...

// example of array parameter
Fproto5: .callprototype _ (.param .b8 _[12]);

Fproto6: .callprototype  _ (.param .f32 _) .noreturn;
...
@p   call  %r0, (%f1), Fproto6;
...

// example of .abi_preserve
Fproto7: .callprototype _ (.param .b32 _) .abi_preserve 10;
...
@p   call %r0, (%r1), Fproto7;
...
</pre></div>
</div>
</section>
</section>
<section id="performance-tuning-directives">
<span id="id608"></span><h2>
<span class="section-number">11.4. </span><a class="reference internal" href="#performance-tuning-directives">Performance-Tuning Directives</a><a class="headerlink" href="#performance-tuning-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>To provide a mechanism for low-level performance tuning, PTX supports the following directives,
which pass information to the optimizing backend compiler.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.maxntid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.reqntid</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> (deprecated)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.pragma</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code></p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code> directive specifies the maximum number of registers to be allocated to a single
thread;
the <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> directive specifies the maximum number of threads
in a thread block (CTA); the <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> directive specifies the required number of threads in a
thread block (CTA); and the <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> directive specifies a minimum number of thread blocks
to be scheduled on a single multiprocessor (SM). These can be used, for example, to throttle the
resource requirements (e.g., registers) to increase total thread count and provide a greater
opportunity to hide memory latency. The <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> directive can be used together with either
the <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> or <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> directive to trade-off registers-per-thread against multiprocessor
utilization without needed to directly specify a maximum number of registers. This may achieve better
performance when compiling PTX for multiple devices having different numbers of registers per SM.</p>
<p>Device function directives <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> specify number of data
and control registers from callee save registers that a function must preserve for its caller. This
can be considered to be the number of general purpose and control registers live in the caller when function
is called. Control registers refer to the number of divergent program points that happen in the calltree
leading to current function call.</p>
<p>Currently, the <code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code>,
<code class="docutils literal notranslate"><span class="pre">.maxntid</span></code>, <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code>, and <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code>
directives may be applied per-entry and must appear between an <code class="docutils literal notranslate"><span class="pre">.entry</span></code> directive and its body.
The directives take precedence over any module-level constraints passed to the optimizing backend.
A warning message is generated if the directivesâ€™ constraints are inconsistent or cannot be met for
the specified target device.</p>
<p>A general <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> directive is supported for passing information to the PTX backend. The
directive passes a list of strings to the backend, and the strings have no semantics within the PTX
virtual machine model. The interpretation of <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> values is determined by the backend
implementation and is beyond the scope of the PTX ISA. Note that <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> directives may appear
at module (file) scope, at entry-scope, or as statements within a kernel or device function body.</p>
<section id="performance-tuning-directives-maxnreg">
<span id="id609"></span><h3>
<span class="section-number">11.4.1. </span><a class="reference internal" href="#performance-tuning-directives-maxnreg">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code></a><a class="headerlink" href="#performance-tuning-directives-maxnreg" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.maxnreg</span></code></p>
<p>Maximum number of registers that can be allocated per thread.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.maxnreg n
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the maximum number of registers per thread in a CTA.</p>
<p class="rubric">Semantics</p>
<p>The compiler guarantees that this limit will not be exceeded. The actual number of registers used
may be less; for example, the backend may be able to compile to fewer registers, or the maximum
number of registers may be further constrained by <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> and <code class="docutils literal notranslate"><span class="pre">.maxctapersm</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .maxnreg 16 { ... }  // max regs per thread = 16
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-maxntid">
<span id="id610"></span><h3>
<span class="section-number">11.4.2. </span><a class="reference internal" href="#performance-tuning-directives-maxntid">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code></a><a class="headerlink" href="#performance-tuning-directives-maxntid" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.maxntid</span></code></p>
<p>Maximum number of threads in the thread block (CTA).</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.maxntid nx
.maxntid nx, ny
.maxntid nx, ny, nz
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the maximum number of threads in the thread block (CTA). This maximum is specified by giving
the maximum extent of each dimension of the 1D, 2D, or 3D CTA. The maximum number of threads is the
product of the maximum extent in each dimension.</p>
<p class="rubric">Semantics</p>
<p>The maximum number of threads in the thread block, computed as the product of the maximum extent
specified for each dimension, is guaranteed not to be exceeded in any invocation of the kernel in
which this directive appears. Exceeding the maximum number of threads results in a runtime error or
kernel launch failure.</p>
<p>Note that this directive guarantees that the <em>total</em> number of threads does not exceed the maximum,
but does not guarantee that the limit in any particular dimension is not exceeded.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .maxntid 256       { ... }  // max threads = 256
.entry bar .maxntid 16,16,4   { ... }  // max threads = 1024
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-reqntid">
<span id="id611"></span><h3>
<span class="section-number">11.4.3. </span><a class="reference internal" href="#performance-tuning-directives-reqntid">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code></a><a class="headerlink" href="#performance-tuning-directives-reqntid" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.reqntid</span></code></p>
<p>Number of threads in the thread block (CTA).</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reqntid nx
.reqntid nx, ny
.reqntid nx, ny, nz
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the number of threads in the thread block (CTA) by specifying the extent of each dimension
of the 1D, 2D, or 3D CTA. The total number of threads is the product of the number of threads in
each dimension.</p>
<p class="rubric">Semantics</p>
<p>The size of each CTA dimension specified in any invocation of the kernel is required to be equal to
that specified in this directive. Specifying a different CTA dimension at launch will result in a
runtime error or kernel launch failure.</p>
<p class="rubric">Notes</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> directive cannot be used in conjunction with the <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> directive.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .reqntid 256       { ... }  // num threads = 256
.entry bar .reqntid 16,16,4   { ... }  // num threads = 1024
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-minnctapersm">
<span id="id612"></span><h3>
<span class="section-number">11.4.4. </span><a class="reference internal" href="#performance-tuning-directives-minnctapersm">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code></a><a class="headerlink" href="#performance-tuning-directives-minnctapersm" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code></p>
<p>Minimum number of CTAs per SM.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.minnctapersm ncta
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the minimum number of CTAs from the kernelâ€™s grid to be mapped to a single multiprocessor
(SM).</p>
<p class="rubric">Notes</p>
<p>Optimizations based on <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> need either <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> or <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> to be specified as
well.</p>
<p>If the total number of threads on a single SM resulting from <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> and <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> /
<code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> exceed maximum number of threads supported by an SM then directive <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code>
will be ignored.</p>
<p>In PTX ISA version 2.1 or higher, a warning is generated if <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> is specified without
specifying either <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> or <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0 as a replacement for <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code>.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .maxntid 256 .minnctapersm 4 { ... }
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-maxnctapersm">
<span id="id613"></span><h3>
<span class="section-number">11.4.5. </span><a class="reference internal" href="#performance-tuning-directives-maxnctapersm">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> (deprecated)</a><a class="headerlink" href="#performance-tuning-directives-maxnctapersm" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code></p>
<p>Maximum number of CTAs per SM.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.maxnctapersm ncta
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the maximum number of CTAs from the kernelâ€™s grid that may be mapped to a single
multiprocessor (SM).</p>
<p class="rubric">Notes</p>
<p>Optimizations based on .maxnctapersm generally need <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> to be specified as well. The
optimizing backend compiler uses <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> and <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> to compute an upper-bound on
per-thread register usage so that the specified number of CTAs can be mapped to a single
multiprocessor. However, if the number of registers used by the backend is sufficiently lower than
this bound, additional CTAs may be mapped to a single multiprocessor. For this reason,
<code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> has been renamed to .minnctapersm in PTX ISA version 2.0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.3. Deprecated in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .maxntid 256 .maxnctapersm 4 { ... }
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-noreturn">
<span id="id614"></span><h3>
<span class="section-number">11.4.6. </span><a class="reference internal" href="#performance-tuning-directives-noreturn">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code></a><a class="headerlink" href="#performance-tuning-directives-noreturn" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.noreturn</span></code></p>
<p>Indicate that the function does not return to its caller function.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.noreturn
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Indicate that the function does not return to its caller function.</p>
<p class="rubric">Semantics</p>
<p>An optional <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive indicates that the function does not return to caller
function. <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive can only be specified on device functions and must appear between
a <code class="docutils literal notranslate"><span class="pre">.func</span></code> directive and its body.</p>
<p>The directive cannot be specified on functions which have return parameters.</p>
<p>If a function with <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive returns to the caller function at runtime, then the
behavior is undefined.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 6.4.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func foo .noreturn { ... }
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-pragma">
<span id="id615"></span><h3>
<span class="section-number">11.4.7. </span><a class="reference internal" href="#performance-tuning-directives-pragma">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.pragma</span></code></a><a class="headerlink" href="#performance-tuning-directives-pragma" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.pragma</span></code></p>
<p>Pass directives to PTX backend compiler.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma list-of-strings ;
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Pass module-scoped, entry-scoped, or statement-level directives to the PTX backend compiler.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> directive may occur at module-scope, at entry-scope, or at statement-level.</p>
<p class="rubric">Semantics</p>
<p>The interpretation of <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> directive strings is implementation-specific and has no impact on
PTX semantics. See <a class="reference internal" href="#descriptions-pragma-strings"><span class="std std-ref">Descriptions of .pragma Strings</span></a> for
descriptions of the pragma strings defined in <code class="docutils literal notranslate"><span class="pre">ptxas</span></code>.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "nounroll";    // disable unrolling in backend

// disable unrolling for current kernel
.entry foo .pragma "nounroll"; { ... }
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-abi-preserve">
<span id="id616"></span><h3>
<span class="section-number">11.4.8. </span><a class="reference internal" href="#performance-tuning-directives-abi-preserve">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code></a><a class="headerlink" href="#performance-tuning-directives-abi-preserve" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code></p>
<p>Specify number of general purpose registers that should be preserved by the callers of this function.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.abi_preserve N
</pre></div>
</div>
<p class="rubric">Description</p>
<p>It is an architecture agnostic value specifying actual number of general purpose registers.
Internally ABI defines some general purpose registers as preserved (callee save) registers.
Integer N specifies the actual number of general purpose registers that should be preserved by
the function.</p>
<p><code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> directive can only be specified on device functions and must appear between
a <code class="docutils literal notranslate"><span class="pre">.func</span></code> directive and its body.</p>
<p class="rubric">Semantics</p>
<p>When this directive is specified compiler backend modifies low level ABI components to ensure that
number of live data variables in the callers of this function that are stored in the callee save
registers are less than specified value.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func bar() .abi_preserve 8

// Indirect call via call prototype
.func (.param .b32 out[30]) foo (.param .b32 in[30]) .abi_preserve 10 { ... }
...
mov.b64 lpfoo, foo;
prot: .callprototype (.param .b32 out[30]) _ (.param .b32 in[30]) .abi_preserve 10;
call (out), lpfoo, (in), prot;
</pre></div>
</div>
</section>
<section id="performance-tuning-directives-abi-preserve-control">
<span id="id617"></span><h3>
<span class="section-number">11.4.9. </span><a class="reference internal" href="#performance-tuning-directives-abi-preserve-control">Performance-Tuning Directives: <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code></a><a class="headerlink" href="#performance-tuning-directives-abi-preserve-control" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code></p>
<p>Specify number of control registers that should be preserved by the callers of this function.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.abi_preserve_control N
</pre></div>
</div>
<p class="rubric">Description</p>
<p>It is an architecture agnostic value specifying the number of divergent program points that happen
in the calltree leading to current function call.
Internally ABI defines some control registers as preserved (callee save) registers.
Integer N specifies the actual number of control registers that should be preserved by the function.</p>
<p><code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code> directive can only be specified on device functions and must appear between
a <code class="docutils literal notranslate"><span class="pre">.func</span></code> directive and its body.</p>
<p class="rubric">Semantics</p>
<p>When this directive is specified compiler backend modifies low level ABI components to ensure that
number of live control variables in the callers of this function that are stored in the callee save
control registers are less than specified value.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.func foo() .abi_preserve_control 14

// Indirect call via call prototype
.func (.param .b32 out[30]) bar (.param .b32 in[30]) .abi_preserve_control 10 { ... }
...
mov.b64 lpbar, bar;
prot: .callprototype (.param .b32 out[30]) _ (.param .b32 in[30]) .abi_preserve_control 10;
call (out), lpbar, (in), prot;
</pre></div>
</div>
</section>
</section>
<section id="debugging-directives">
<span id="id618"></span><h2>
<span class="section-number">11.5. </span><a class="reference internal" href="#debugging-directives">Debugging Directives</a><a class="headerlink" href="#debugging-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>DWARF-format debug information is passed through PTX modules using the following directives:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">@@DWARF</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.section</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.file</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.loc</span></code></p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.section</span></code> directive was introduced in PTX ISA version 2.0 and replaces the <code class="docutils literal notranslate"><span class="pre">@@DWARF</span></code>
syntax. The <code class="docutils literal notranslate"><span class="pre">@@DWARF</span></code> syntax was deprecated in PTX ISA version 2.0 but is supported for legacy PTX
ISA version 1.x code.</p>
<p>Beginning with PTX ISA version 3.0, PTX files containing DWARF debug information should include the
<code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">debug</span></code> platform option. This forward declaration directs PTX compilation to retain
mappings for source-level debugging.</p>
<section id="debugging-directives-atatdwarf">
<span id="id619"></span><h3>
<span class="section-number">11.5.1. </span><a class="reference internal" href="#debugging-directives-atatdwarf">Debugging Directives: <code class="docutils literal notranslate"><span class="pre">@@dwarf</span></code></a><a class="headerlink" href="#debugging-directives-atatdwarf" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">@@dwarf</span></code></p>
<p>DWARF-format information.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@@DWARF dwarf-string

dwarf-string may have one of the
.byte   byte-list   // comma-separated hexadecimal byte values
.4byte  int32-list  // comma-separated hexadecimal integers in range [0..2^32-1]
.quad   int64-list  // comma-separated hexadecimal integers in range [0..2^64-1]
.4byte  label
.quad   label
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.2. Deprecated as of PTX ISA version 2.0, replaced by <code class="docutils literal notranslate"><span class="pre">.section</span></code>
directive.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>@@DWARF .section .debug_pubnames, "", @progbits
@@DWARF .byte   0x2b, 0x00, 0x00, 0x00, 0x02, 0x00
@@DWARF .4byte  .debug_info
@@DWARF .4byte  0x000006b5, 0x00000364, 0x61395a5f, 0x5f736f63
@@DWARF .4byte  0x6e69616d, 0x63613031, 0x6150736f, 0x736d6172
@@DWARF .byte   0x00, 0x00, 0x00, 0x00, 0x00
</pre></div>
</div>
</section>
<section id="debugging-directives-section">
<span id="id620"></span><h3>
<span class="section-number">11.5.2. </span><a class="reference internal" href="#debugging-directives-section">Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.section</span></code></a><a class="headerlink" href="#debugging-directives-section" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.section</span></code></p>
<p>PTX section definition.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.section section_name { dwarf-lines }

dwarf-lines have the following formats:
  .b8    byte-list       // comma-separated list of integers
                         // in range [-128..255]
  .b16   int16-list      // comma-separated list of integers
                         // in range [-2^15..2^16-1]
  .b32   int32-list      // comma-separated list of integers
                         // in range [-2^31..2^32-1]
  label:                 // Define label inside the debug section
  .b64   int64-list      // comma-separated list of integers
                         // in range [-2^63..2^64-1]
  .b32   label
  .b64   label
  .b32   label+imm       // a sum of label address plus a constant integer byte
                         // offset(signed, 32bit)
  .b64   label+imm       // a sum of label address plus a constant integer byte
                         // offset(signed, 64bit)
  .b32   label1-label2   // a difference in label addresses between labels in
                         // the same dwarf section (32bit)
  .b64   label3-label4   // a difference in label addresses between labels in
                         // the same dwarf section (64bit)
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0, replaces <code class="docutils literal notranslate"><span class="pre">@@DWARF</span></code> syntax.</p>
<p>label+imm expression introduced in PTX ISA version 3.2.</p>
<p>Support for <code class="docutils literal notranslate"><span class="pre">.b16</span></code> integers in dwarf-lines introduced in PTX ISA version 6.0.</p>
<p>Support for defining <code class="docutils literal notranslate"><span class="pre">label</span></code> inside the DWARF section is introduced in PTX ISA version 7.2.</p>
<p><code class="docutils literal notranslate"><span class="pre">label1-label2</span></code> expression introduced in PTX ISA version 7.5.</p>
<p>Negative numbers in dwarf lines introduced in PTX ISA version 7.5.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.section .debug_pubnames
{
    .b32    LpubNames_end0-LpubNames_begin0
  LpubNames_begin0:
    .b8     0x2b, 0x00, 0x00, 0x00, 0x02, 0x00
    .b32    .debug_info
  info_label1:
    .b32    0x000006b5, 0x00000364, 0x61395a5f, 0x5f736f63
    .b32    0x6e69616d, 0x63613031, 0x6150736f, 0x736d6172
    .b8     0x00, 0x00, 0x00, 0x00, 0x00
  LpubNames_end0:
}

.section .debug_info
{
    .b32 11430
    .b8 2, 0
    .b32 .debug_abbrev
    .b8 8, 1, 108, 103, 101, 110, 102, 101, 58, 32, 69, 68, 71, 32, 52, 46, 49
    .b8 0
    .b32 3, 37, 176, -99
    .b32 info_label1
    .b32 .debug_loc+0x4
    .b8 -11, 11, 112, 97
    .b32 info_label1+12
    .b64 -1
    .b16 -5, -65535
}
</pre></div>
</div>
</section>
<section id="debugging-directives-file">
<span id="id621"></span><h3>
<span class="section-number">11.5.3. </span><a class="reference internal" href="#debugging-directives-file">Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.file</span></code></a><a class="headerlink" href="#debugging-directives-file" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.file</span></code></p>
<p>Source file name.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.file file_index "filename" {, timestamp, file_size}
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Associates a source filename with an integer index. <code class="docutils literal notranslate"><span class="pre">.loc</span></code> directives reference source files by
index.</p>
<p><code class="docutils literal notranslate"><span class="pre">.file</span></code> directive allows optionally specifying an unsigned number representing time of last
modification and an unsigned integer representing size in bytes of source file. <code class="docutils literal notranslate"><span class="pre">timestamp</span></code> and
<code class="docutils literal notranslate"><span class="pre">file_size</span></code> value can be 0 to indicate this information is not available.</p>
<p><code class="docutils literal notranslate"><span class="pre">timestamp</span></code> value is in format of C and C++ data type <code class="docutils literal notranslate"><span class="pre">time_t</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">file_size</span></code> is an unsigned 64-bit integer.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.file</span></code> directive is allowed only in the outermost scope, i.e., at the same level as kernel
and device function declarations.</p>
<p class="rubric">Semantics</p>
<p>If timestamp and file size are not specified, they default to 0.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p>Timestamp and file size introduced in PTX ISA version 3.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.file 1 "example.cu"
.file 2 "kernel.cu"
.file 1 "kernel.cu", 1339013327, 64118
</pre></div>
</div>
</section>
<section id="debugging-directives-loc">
<span id="id622"></span><h3>
<span class="section-number">11.5.4. </span><a class="reference internal" href="#debugging-directives-loc">Debugging Directives: <code class="docutils literal notranslate"><span class="pre">.loc</span></code></a><a class="headerlink" href="#debugging-directives-loc" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.loc</span></code></p>
<p>Source file location.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.loc file_index line_number column_position
.loc file_index line_number column_position,function_name label {+ immediate }, inlined_at file_index2 line_number2 column_position2
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares the source file location (source file, line number, and column position) to be associated
with lexically subsequent PTX instructions. <code class="docutils literal notranslate"><span class="pre">.loc</span></code> refers to <code class="docutils literal notranslate"><span class="pre">file_index</span></code> which is defined by a
<code class="docutils literal notranslate"><span class="pre">.file</span></code> directive.</p>
<p>To indicate PTX instructions that are generated from a function that got inlined, additional
attribute <code class="docutils literal notranslate"><span class="pre">.inlined_at</span></code> can be specified as part of the <code class="docutils literal notranslate"><span class="pre">.loc</span></code> directive. <code class="docutils literal notranslate"><span class="pre">.inlined_at</span></code>
attribute specifies source location at which the specified function is inlined. <code class="docutils literal notranslate"><span class="pre">file_index2</span></code>,
<code class="docutils literal notranslate"><span class="pre">line_number2</span></code>, and <code class="docutils literal notranslate"><span class="pre">column_position2</span></code> specify the location at which function is inlined. Source
location specified as part of <code class="docutils literal notranslate"><span class="pre">.inlined_at</span></code> directive must lexically precede as source location in
<code class="docutils literal notranslate"><span class="pre">.loc</span></code> directive.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">function_name</span></code> attribute specifies an offset in the DWARF section named
<code class="docutils literal notranslate"><span class="pre">.debug_str</span></code>. Offset is specified as <code class="docutils literal notranslate"><span class="pre">label</span></code> expression or <code class="docutils literal notranslate"><span class="pre">label</span> <span class="pre">+</span> <span class="pre">immediate</span></code> expression
where <code class="docutils literal notranslate"><span class="pre">label</span></code> is defined in <code class="docutils literal notranslate"><span class="pre">.debug_str</span></code> section. DWARF section <code class="docutils literal notranslate"><span class="pre">.debug_str</span></code> contains ASCII
null-terminated strings that specify the name of the function that is inlined.</p>
<p>Note that a PTX instruction may have a single associated source location, determined by the nearest
lexically preceding .loc directive, or no associated source location if there is no preceding .loc
directive. Labels in PTX inherit the location of the closest lexically following instruction. A
label with no following PTX instruction has no associated source location.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p><code class="docutils literal notranslate"><span class="pre">function_name</span></code> and <code class="docutils literal notranslate"><span class="pre">inlined_at</span></code> attributes are introduced in PTX ISA version 7.2.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>    .loc 2 4237 0
L1:                        // line 4237, col 0 of file #2,
                           // inherited from mov
    mov.u32  %r1,%r2;      // line 4237, col 0 of file #2
    add.u32  %r2,%r1,%r3;  // line 4237, col 0 of file #2
...
L2:                        // line 4239, col 5 of file #2,
                           // inherited from sub
    .loc 2 4239 5
    sub.u32  %r2,%r1,%r3;  // line 4239, col 5 of file #2
    .loc 1 21 3
    .loc 1 9 3, function_name info_string0, inlined_at 1 21 3
    ld.global.u32   %r1, [gg]; // Function at line 9
    setp.lt.s32 %p1, %r1, 8;   // inlined at line 21
    .loc 1 27 3
    .loc 1 10 5, function_name info_string1, inlined_at 1 27 3
    .loc 1 15 3, function_name .debug_str+16, inlined_at 1 10 5
    setp.ne.s32 %p2, %r1, 18;
    @%p2 bra    BB2_3;

    .section .debug_str {
    info_string0:
     .b8 95  // _
     .b8 90  // z
     .b8 51  // 3
     .b8 102 // f
     .b8 111 // o
     .b8 111 // o
     .b8 118 // v
     .b8 0

    info_string1:
     .b8 95  // _
     .b8 90  // z
     .b8 51  // 3
     .b8 98  // b
     .b8 97  // a
     .b8 114 // r
     .b8 118 // v
     .b8 0
     .b8 95  // _
     .b8 90  // z
     .b8 51  // 3
     .b8 99  // c
     .b8 97  // a
     .b8 114 // r
     .b8 118 // v
     .b8 0
    }
</pre></div>
</div>
</section>
</section>
<section id="linking-directives">
<span id="id623"></span><h2>
<span class="section-number">11.6. </span><a class="reference internal" href="#linking-directives">Linking Directives</a><a class="headerlink" href="#linking-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.extern</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.visible</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.weak</span></code></p></li>
</ul>
<section id="linking-directives-extern">
<span id="id624"></span><h3>
<span class="section-number">11.6.1. </span><a class="reference internal" href="#linking-directives-extern">Linking Directives: <code class="docutils literal notranslate"><span class="pre">.extern</span></code></a><a class="headerlink" href="#linking-directives-extern" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.extern</span></code></p>
<p>External symbol declaration.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.extern identifier
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares identifier to be defined external to the current module. The module defining such
identifier must define it as <code class="docutils literal notranslate"><span class="pre">.weak</span></code> or <code class="docutils literal notranslate"><span class="pre">.visible</span></code> only once in a single object file. Extern
declaration of symbol may appear multiple times and references to that get resolved against the
single definition of that symbol.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.extern .global .b32 foo;  // foo is defined in another module
</pre></div>
</div>
</section>
<section id="linking-directives-visible">
<span id="id625"></span><h3>
<span class="section-number">11.6.2. </span><a class="reference internal" href="#linking-directives-visible">Linking Directives: <code class="docutils literal notranslate"><span class="pre">.visible</span></code></a><a class="headerlink" href="#linking-directives-visible" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.visible</span></code></p>
<p>Visible (externally) symbol declaration.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.visible identifier
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares identifier to be globally visible. Unlike C, where identifiers are globally visible unless
declared static, PTX identifiers are visible only within the current module unless declared
<code class="docutils literal notranslate"><span class="pre">.visible</span></code> outside the current.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 1.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.visible .global .b32 foo;  // foo will be externally visible
</pre></div>
</div>
</section>
<section id="linking-directives-weak">
<span id="id626"></span><h3>
<span class="section-number">11.6.3. </span><a class="reference internal" href="#linking-directives-weak">Linking Directives: <code class="docutils literal notranslate"><span class="pre">.weak</span></code></a><a class="headerlink" href="#linking-directives-weak" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.weak</span></code></p>
<p>Visible (externally) symbol declaration.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.weak identifier
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares identifier to be globally visible but <em>weak</em>. Weak symbols are similar to globally visible
symbols, except during linking, weak symbols are only chosen after globally visible symbols during
symbol resolution. Unlike globally visible symbols, multiple object files may declare the same weak
symbol, and references to a symbol get resolved against a weak symbol only if no global symbols have
the same name.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 3.1.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.weak .func (.reg .b32 val) foo;  // foo will be externally visible
</pre></div>
</div>
</section>
<section id="linking-directives-common">
<span id="id627"></span><h3>
<span class="section-number">11.6.4. </span><a class="reference internal" href="#linking-directives-common">Linking Directives: <code class="docutils literal notranslate"><span class="pre">.common</span></code></a><a class="headerlink" href="#linking-directives-common" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.common</span></code></p>
<p>Visible (externally) symbol declaration.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.common identifier
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares identifier to be globally visible but â€œcommonâ€.</p>
<p>Common symbols are similar to globally visible symbols. However multiple object files may declare
the same common symbol and they may have different types and sizes and references to a symbol get
resolved against a common symbol with the largest size.</p>
<p>Only one object file can initialize a common symbol and that must have the largest size among all
other definitions of that common symbol from different object files.</p>
<p><code class="docutils literal notranslate"><span class="pre">.common</span></code> linking directive can be used only on variables with <code class="docutils literal notranslate"><span class="pre">.global</span></code> storage. It cannot be
used on function symbols or on symbols with opaque type.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 5.0.</p>
<p class="rubric">Target ISA Notes</p>
<p><code class="docutils literal notranslate"><span class="pre">.common</span></code> directive requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.common .global .u32 gbl;
</pre></div>
</div>
</section>
</section>
<section id="cluster-dimension-directives">
<span id="id628"></span><h2>
<span class="section-number">11.7. </span><a class="reference internal" href="#cluster-dimension-directives">Cluster Dimension Directives</a><a class="headerlink" href="#cluster-dimension-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>The following directives specify information about clusters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code></p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code> directive specifies the number of CTAs in the cluster. The
<code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code> directive specifies that the kernel should be launched with explicit cluster
details. The <code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code> directive specifies the maximum number of CTAs in the cluster.</p>
<p>The cluster dimension directives can be applied only on kernel functions.</p>
<section id="cluster-dimension-directives-reqnctapercluster">
<span id="id629"></span><h3>
<span class="section-number">11.7.1. </span><a class="reference internal" href="#cluster-dimension-directives-reqnctapercluster">Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code></a><a class="headerlink" href="#cluster-dimension-directives-reqnctapercluster" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code></p>
<p>Declare the number of CTAs in the cluster.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.reqnctapercluster nx
.reqnctapercluster nx, ny
.reqnctapercluster nx, ny, nz
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Set the number of thread blocks (CTAs) in the cluster by specifying the extent of each dimension of
the 1D, 2D, or 3D cluster. The total number of CTAs is the product of the number of CTAs in each
dimension. For kernels with <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code> directive specified, runtime will use the
specified values for configuring the launch if the same are not specified at launch time.</p>
<p class="rubric">Semantics</p>
<p>If cluster dimension is explicitly specified at launch time, it should be equal to the values
specified in this directive. Specifying a different cluster dimension at launch will result in a
runtime error or kernel launch failure.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .reqnctapercluster 2         { . . . }
.entry bar .reqnctapercluster 2, 2, 1   { . . . }
.entry ker .reqnctapercluster 3, 2      { . . . }
</pre></div>
</div>
</section>
<section id="cluster-dimension-directives-explicitcluster">
<span id="id630"></span><h3>
<span class="section-number">11.7.2. </span><a class="reference internal" href="#cluster-dimension-directives-explicitcluster">Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code></a><a class="headerlink" href="#cluster-dimension-directives-explicitcluster" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code></p>
<p>Declare that Kernel must be launched with cluster dimensions explicitly specified.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.explicitcluster
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declares that this Kernel should be launched with cluster dimension explicitly specified.</p>
<p class="rubric">Semantics</p>
<p>Kernels with <code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code> directive must be launched with cluster dimension explicitly
specified (either at launch time or via <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code>), otherwise program will fail with
runtime error or kernel launch failure.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .explicitcluster         { . . . }
</pre></div>
</div>
</section>
<section id="cluster-dimension-directives-maxclusterrank">
<span id="id631"></span><h3>
<span class="section-number">11.7.3. </span><a class="reference internal" href="#cluster-dimension-directives-maxclusterrank">Cluster Dimension Directives: <code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code></a><a class="headerlink" href="#cluster-dimension-directives-maxclusterrank" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code></p>
<p>Declare the maximum number of CTAs that can be part of the cluster.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.maxclusterrank n
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Declare the maximum number of thread blocks (CTAs) allowed to be part of the cluster.</p>
<p class="rubric">Semantics</p>
<p>Product of the number of CTAs in each cluster dimension specified in any invocation of the kernel is
required to be less or equal to that specified in this directive. Otherwise invocation will result
in a runtime error or kernel launch failure.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code> directive cannot be used in conjunction with the <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code> directive.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 7.8.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo ..maxclusterrank 8         { . . . }
</pre></div>
</div>
</section>
</section>
<section id="miscellaneous-directives">
<span id="id632"></span><h2>
<span class="section-number">11.8. </span><a class="reference internal" href="#miscellaneous-directives">Miscellaneous Directives</a><a class="headerlink" href="#miscellaneous-directives" title="Permalink to this headline">ïƒ</a>
</h2>
<p>PTX provides the following miscellaneous directives:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code></p></li>
</ul>
<section id="miscellaneous-directives-blocksareclusters">
<span id="id633"></span><h3>
<span class="section-number">11.8.1. </span><a class="reference internal" href="#miscellaneous-directives-blocksareclusters">Miscellaneous Directives: <code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code></a><a class="headerlink" href="#miscellaneous-directives-blocksareclusters" title="Permalink to this headline">ïƒ</a>
</h3>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code></p>
<p>Specify that CUDA thread blocks are mapped to clusters.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.blocksareclusters
</pre></div>
</div>
<p class="rubric">Description</p>
<p>Default behavior of CUDA API is to specify the grid launch configuration by specifying the number of
thread blocks and the number of threads per block.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code> directive is specified, it implies that the grid launch configuration
for the corresponding <code class="docutils literal notranslate"><span class="pre">.entry</span></code> function is specifying the number of clusters, i.e. the launch
configuration is specifying number of clusters instead of the number of thread blocks. In this case,
the number of thread blocks per cluster is specified by <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code> directive and the
thread block size is specified with the <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> directive.</p>
<p><code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code> directive is only allowed for <code class="docutils literal notranslate"><span class="pre">.entry</span></code> functions and also needs
<code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> and <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code> directives to be specified.</p>
<p>Refer to <em>CUDA Programming Guide</em> for more details.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo .reqntid 32, 32, 1 .reqnctapercluster 32, 32, 1 .blocksareclusters { ... }
</pre></div>
</div>
</section>
</section>
</section>
<section id="descriptions-pragma-strings">
<span id="id634"></span><h1>
<span class="section-number">12. </span><a class="reference internal" href="#descriptions-pragma-strings">Descriptions of <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> Strings</a><a class="headerlink" href="#descriptions-pragma-strings" title="Permalink to this headline">ïƒ</a>
</h1>
<p>This section describes the <code class="docutils literal notranslate"><span class="pre">.pragma</span></code> strings defined by ptxas.</p>
<section id="pragma-strings-nounroll">
<span id="id635"></span><h2>
<span class="section-number">12.1. </span><a class="reference internal" href="#pragma-strings-nounroll">Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"nounroll"</span></code></a><a class="headerlink" href="#pragma-strings-nounroll" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">"nounroll"</span></code></p>
<p>Disable loop unrolling in optimizing the backend compiler.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "nounroll";
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"nounroll"</span> <span class="pre">pragma</span></code> is a directive to disable loop unrolling in the optimizing backend
compiler.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"nounroll"</span> <span class="pre">pragma</span></code> is allowed at module, entry-function, and statement levels, with the
following meanings:</p>
<dl class="simple">
<dt>module scope</dt>
<dd>
<p>disables unrolling for all loops in module, including loops preceding the <code class="docutils literal notranslate"><span class="pre">.pragma</span></code>.</p>
</dd>
<dt>entry-function scope</dt>
<dd>
<p>disables unrolling for all loops in the entry function body.</p>
</dd>
<dt>statement-level pragma</dt>
<dd>
<p>disables unrolling of the loop for which the current block is the loop header.</p>
</dd>
</dl>
<p>Note that in order to have the desired effect at statement level, the <code class="docutils literal notranslate"><span class="pre">"nounroll"</span></code> directive must
appear before any instruction statements in the loop header basic block for the desired loop. The
loop header block is defined as the block that dominates all blocks in the loop body and is the
target of the loop backedge. Statement-level <code class="docutils literal notranslate"><span class="pre">"nounroll"</span></code> directives appearing outside of loop
header blocks are silently ignored.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 2.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> or higher. Ignored for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo (...)
.pragma "nounroll";  // do not unroll any loop in this function
{
...
}

.func bar (...)
{
...
L1_head:
     .pragma "nounroll";  // do not unroll this loop
     ...
@p   bra L1_end;
L1_body:
     ...
L1_continue:
     bra L1_head;
L1_end:
     ...
}
</pre></div>
</div>
</section>
<section id="pragma-strings-used-bytes-mask">
<span id="id636"></span><h2>
<span class="section-number">12.2. </span><a class="reference internal" href="#pragma-strings-used-bytes-mask">Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"used_bytes_mask"</span></code></a><a class="headerlink" href="#pragma-strings-used-bytes-mask" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">"used_bytes_mask"</span></code></p>
<p>Mask for indicating used bytes in data of ld operation.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "used_bytes_mask mask";
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"used_bytes_mask"</span> <span class="pre">pragma</span></code> is a directive that specifies used bytes in a load
operation based on the mask provided.</p>
<p><code class="docutils literal notranslate"><span class="pre">"used_bytes_mask"</span> <span class="pre">pragma</span></code> needs to be specified prior to a load instruction for which
information about bytes used from the load operation is needed.
Pragma is ignored if instruction following it is not a load instruction.</p>
<p>For a load instruction without this pragma, all bytes from the load operation are assumed
to be used.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">mask</span></code> is a 32-bit integer with set bits indicating the used bytes in data of
load operation.</p>
<p class="rubric">Semantics</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>Each bit in mask operand corresponds to a byte data where each set bit represents the used byte.
Most-significant bit corresponds to most-significant byte of data.

// For 4 bytes load with only lower 3 bytes used
.pragma "used_bytes_mask 0x7";
ld.global.u32 %r0, [gbl];     // Higher 1 byte from %r0 is unused

// For vector load of 16 bytes with lower 12 bytes used
.pragma "used_bytes_mask 0xfff";
ld.global.v4.u32 {%r0, %r1, %r2, %r3}, [gbl];  // %r3 unused
</pre></div>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 8.3.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "used_bytes_mask 0xfff";
ld.global.v4.u32 {%r0, %r1, %r2, %r3}, [gbl]; // Only lower 12 bytes used
</pre></div>
</div>
</section>
<section id="pragma-strings-enable-smem-spilling">
<span id="id637"></span><h2>
<span class="section-number">12.3. </span><a class="reference internal" href="#pragma-strings-enable-smem-spilling">Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"enable_smem_spilling"</span></code></a><a class="headerlink" href="#pragma-strings-enable-smem-spilling" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">"enable_smem_spilling"</span></code></p>
<p>Enable shared memory spilling for CUDA kernels.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "enable_smem_spilling";
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"enable_smem_spilling"</span> <span class="pre">pragma</span></code> is a directive that enables register spilling into shared memory.
During the spilling process, registers are first spilled into shared memory, and once the allocated
shared memory is full, any additional spills are redirected to local memory. This can enhance
performance by reducing memory access latency since shared memory accesses are faster than local memory.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"enable_smem_spilling"</span> <span class="pre">pragma</span></code> is only allowed within the function scope. When applied, it enables
shared memory spilling for the specified function.</p>
<p>The usage of pragma is valid only in certain scenarios and specific compilation modes. The usage of
pragma is disallowed under following cases and may result in an error:</p>
<ul class="simple">
<li><p>Per-function compilation mode: e.g., Separate Compilation, Device-debug, Whole program with recursive
function calls, Extensible-whole-program</p></li>
<li><p>Kernels utilizing dynamically allocated shared memory</p></li>
<li><p>Kernels using <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If launch bounds are not explicitly specified, the compiler assumes the maximum possible number of
threads per CTA to estimate shared memory allocated per CTA and corresponding spill size. However,
if the kernel is launched with fewer threads per CTA than estimated, the shared memory allocated
per CTA may exceed the compiler estimated size, thereby potentially limiting the number of CTAs
that can be launched on an SM. Due to this, using the pragma without launch bounds may lead to
performance regressions. Hence it is recommended to use this pragma only when launch bounds are
explicitly specified.</p>
</div>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Requires <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> or higher.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo (...)
{
    ...
    .pragma "enable_smem_spilling";   // Enable shared memory spilling for this function
    ...
}
</pre></div>
</div>
</section>
<section id="pragma-strings-frequency">
<span id="id638"></span><h2>
<span class="section-number">12.4. </span><a class="reference internal" href="#pragma-strings-frequency">Pragma Strings: <code class="docutils literal notranslate"><span class="pre">"frequency"</span></code></a><a class="headerlink" href="#pragma-strings-frequency" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric"><code class="docutils literal notranslate"><span class="pre">"frequency"</span></code></p>
<p>Specify frequency for basic block execution.</p>
<p class="rubric">Syntax</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.pragma "frequency n";
</pre></div>
</div>
<p class="rubric">Description</p>
<p>The <code class="docutils literal notranslate"><span class="pre">"frequency"</span> <span class="pre">pragma</span></code> is a directive that specifies the number of times a basic block is
executed by an executing thread. The optimizing compiler backend treats this pragma as a hint
which will be used for optimizations.</p>
<p>Operand <code class="docutils literal notranslate"><span class="pre">n</span></code> is a 64-bit non-negative integer constant that specifies the execution frequency.</p>
<p>Note that in order to have the desired effect of this pragma, it should be specified at the start of
the basic block. Basic block is defined as a straight-line sequence of instructions with only one
entry point and one exit point.</p>
<p class="rubric">PTX ISA Notes</p>
<p>Introduced in PTX ISA version 9.0.</p>
<p class="rubric">Target ISA Notes</p>
<p>Supported on all target architectures.</p>
<p class="rubric">Examples</p>
<div class="highlight-text notranslate">
<div class="highlight"><pre><span></span>.entry foo (...)
{
    .pragma "frequency 32";
    ...
}
</pre></div>
</div>
</section>
</section>
<section id="release-notes">
<span id="id639"></span><h1>
<span class="section-number">13. </span><a class="reference internal" href="#release-notes">Release Notes</a><a class="headerlink" href="#release-notes" title="Permalink to this headline">ïƒ</a>
</h1>
<p>This section describes the history of change in the PTX ISA and implementation. The first section
describes ISA and implementation changes in the current release of PTX ISA version 9.1, and the
remaining sections provide a record of changes in previous releases of PTX ISA versions back to PTX
ISA version 2.0.</p>
<p><a class="reference internal" href="#release-notes-ptx-release-history"><span class="std std-numref">Table 59</span></a> shows the PTX release history.</p>
<table class="table-no-stripes docutils align-default" id="release-notes-ptx-release-history">
<caption>
<span class="caption-number">Table 59 </span><span class="caption-text">PTX Release History</span><a class="headerlink" href="#release-notes-ptx-release-history" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 14%">
<col style="width: 21%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>PTX ISA Version</p></th>
<th class="head"><p>CUDA Release</p></th>
<th class="head"><p>Supported Targets</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p>PTX ISA 1.0</p></td>
<td><p>CUDA 1.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 1.1</p></td>
<td><p>CUDA 1.1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 1.2</p></td>
<td><p>CUDA 2.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 1.3</p></td>
<td><p>CUDA 2.1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 1.4</p></td>
<td><p>CUDA 2.2</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 1.5</p></td>
<td><p>driver r190</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 2.0</p></td>
<td><p>CUDA 3.0, driver r195</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 2.1</p></td>
<td><p>CUDA 3.1, driver r256</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 2.2</p></td>
<td><p>CUDA 3.2, driver r260</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 2.3</p></td>
<td><p>CUDA 4.0, driver r270</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>PTX ISA 3.0</p></td>
<td><p>CUDA 4.1, driver r285</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>CUDA 4.2, driver r295</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_30</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 3.1</p></td>
<td><p>CUDA 5.0, driver r302</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,35}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 3.2</p></td>
<td><p>CUDA 5.5, driver r319</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,35}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 4.0</p></td>
<td><p>CUDA 6.0, driver r331</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_50</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 4.1</p></td>
<td><p>CUDA 6.5, driver r340</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 4.2</p></td>
<td><p>CUDA 7.0, driver r346</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 4.3</p></td>
<td><p>CUDA 7.5, driver r352</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 5.0</p></td>
<td><p>CUDA 8.0, driver r361</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 6.0</p></td>
<td><p>CUDA 9.0, driver r384</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 6.1</p></td>
<td><p>CUDA 9.1, driver r387</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_72</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 6.2</p></td>
<td><p>CUDA 9.2, driver r396</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_72</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 6.3</p></td>
<td><p>CUDA 10.0, driver r400</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_72</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_75</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 6.4</p></td>
<td><p>CUDA 10.1, driver r418</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_72</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_75</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 6.5</p></td>
<td><p>CUDA 10.2, driver r440</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_70</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_72</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_75</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 7.0</p></td>
<td><p>CUDA 11.0, driver r445</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_80</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 7.1</p></td>
<td><p>CUDA 11.1, driver r455</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 7.2</p></td>
<td><p>CUDA 11.2, driver r460</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 7.3</p></td>
<td><p>CUDA 11.3, driver r465</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 7.4</p></td>
<td><p>CUDA 11.4, driver r470</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 7.5</p></td>
<td><p>CUDA 11.5, driver r495</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 7.6</p></td>
<td><p>CUDA 11.6, driver r510</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 7.7</p></td>
<td><p>CUDA 11.7, driver r515</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 7.8</p></td>
<td><p>CUDA 11.8, driver r520</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_90</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 8.0</p></td>
<td><p>CUDA 12.0, driver r525</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 8.1</p></td>
<td><p>CUDA 12.1, driver r530</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 8.2</p></td>
<td><p>CUDA 12.2, driver r535</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 8.3</p></td>
<td><p>CUDA 12.3, driver r545</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 8.4</p></td>
<td><p>CUDA 12.4, driver r550</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>PTX ISA 8.5</p></td>
<td><p>CUDA 12.5, driver r555</p></td>
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>CUDA 12.6, driver r560</p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 8.6</p></td>
<td><p>CUDA 12.7, driver r565</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{100,100a,101,101a}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 8.7</p></td>
<td><p>CUDA 12.8, driver r570</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{100,100,101,101a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{120,120a}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 8.8</p></td>
<td><p>CUDA 12.9, driver r575</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,89}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{100,100f,100a,101,101f,101a,103,103f,103a}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{120,120f,120a,121,121f,121a}</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>PTX ISA 9.0</p></td>
<td><p>CUDA 13.0, driver r580</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,88,89}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{100,100f,100a,103,103f,103a}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{110,110f,110a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{120,120f,120a,121,121f,121a}</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>PTX ISA 9.1</p></td>
<td><p>CUDA 13.1, driver r590</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_{10,11,12,13}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{30,32,35,37}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{50,52,53}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{60,61,62}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{70,72,75}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{80,86,87,88,89}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{90,90a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{100,100f,100a,103,103f,103a}</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_{110,110f,110a}</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_{120,120f,120a,121,121f,121a}</span></code></p></td>
</tr>
</tbody>
</table>
<table class="table-no-stripes docutils align-default" id="release-notes-a-spec-f-spec-ptx-feature-release-history">
<caption>
<span class="caption-number">Table 60 </span><span class="caption-text">Arch-specific/ Family-specific PTX Features Release History</span><a class="headerlink" href="#release-notes-a-spec-f-spec-ptx-feature-release-history" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 26%">
<col style="width: 33%">
<col style="width: 13%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Instruction</p></th>
<th class="head"><p>Variant</p></th>
<th class="head"><p>PTX ISA Version</p></th>
<th class="head"><p>Supported Targets</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td rowspan="11"><p><code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></p></td>
<td rowspan="4"><p>Base variant</p></td>
<td><p>8.3</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">tensormap.replace.swizzle_atomicity</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.elemtype</span></code> for <code class="docutils literal notranslate"><span class="pre">.field3</span></code> with values
<code class="docutils literal notranslate"><span class="pre">13</span></code>, <code class="docutils literal notranslate"><span class="pre">14</span></code>, <code class="docutils literal notranslate"><span class="pre">15</span></code> for <code class="docutils literal notranslate"><span class="pre">new_val</span></code></p></td>
<td><p>8.7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.swizzle_mode</span></code> for <code class="docutils literal notranslate"><span class="pre">.field3</span></code> with value
<code class="docutils literal notranslate"><span class="pre">4</span></code> for <code class="docutils literal notranslate"><span class="pre">new_val</span></code></p></td>
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code>,
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async.sp</span></code>,
<code class="docutils literal notranslate"><span class="pre">wgmma.fence</span></code>,
<code class="docutils literal notranslate"><span class="pre">wgmma.commit_group</span></code>,
<code class="docutils literal notranslate"><span class="pre">wgmma.wait_group</span></code></p></td>
<td><p>Base variant</p></td>
<td><p>8.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="4"><p><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></p></td>
<td rowspan="4"><p>Base variant</p></td>
<td><p>8.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_90a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="6"><p><code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>,
<code class="docutils literal notranslate"><span class="pre">multimem.st</span></code>,
<code class="docutils literal notranslate"><span class="pre">multimem.red</span></code></p></td>
<td rowspan="3"><p>Types <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.acc::f16</span></code> qualifier</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="8"><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code></p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> for <code class="docutils literal notranslate"><span class="pre">.f32</span></code> to <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> AND
<code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code> to
<code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> AND
<code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> AND
<code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding mode</p></td>
<td><p>8.7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> type</p></td>
<td><p>9.1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> for <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code></p></td>
<td><p>9.1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> for <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> to <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code></p></td>
<td><p>9.1</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="9"><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code></p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> with
<code class="docutils literal notranslate"><span class="pre">.shared::cluster</span></code> as destination state
space</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.cta_group</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code></p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code>, <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code>,
<code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">redux.sync</span></code></p></td>
<td rowspan="2"><p>Type <code class="docutils literal notranslate"><span class="pre">.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code>, <code class="docutils literal notranslate"><span class="pre">.NaN</span></code>
qualifiers</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code></p></td>
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">.multicast::cluster::all</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code></p></td>
<td rowspan="3"><p>Shapes <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n16</span></code> AND
Type <code class="docutils literal notranslate"><span class="pre">.b8</span></code> AND
Qualifiers <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code>, <code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></p></td>
<td rowspan="3"><p>Shapes <code class="docutils literal notranslate"><span class="pre">.m16n8</span></code> AND
Type <code class="docutils literal notranslate"><span class="pre">.b8</span></code> AND</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.fence</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld.red</span></code></p></td>
<td rowspan="2"><p>Base variant</p></td>
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="10"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Kind <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.block16</span></code>, <code class="docutils literal notranslate"><span class="pre">.block32</span></code></p></td>
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>K shape value <code class="docutils literal notranslate"><span class="pre">96</span></code></p></td>
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="12"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Kind <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p>Kind <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_103a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="2"><p>Argument <code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec::2X</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Qualifiers <code class="docutils literal notranslate"><span class="pre">.block16</span></code>, <code class="docutils literal notranslate"><span class="pre">.block32</span></code></p></td>
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-even">
<td rowspan="5"><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code></p></td>
<td rowspan="3"><p>Base variant</p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p>Kind <code class="docutils literal notranslate"><span class="pre">.kind::i8</span></code></p></td>
<td><p>8.6</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>9.0</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_110a</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="2"><p><code class="docutils literal notranslate"><span class="pre">mma</span></code></p></td>
<td rowspan="2"><p>Types <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
AND Qualifiers <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code></p></td>
<td><p>8.7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td rowspan="3"><p><code class="docutils literal notranslate"><span class="pre">mma.sp</span></code></p></td>
<td rowspan="2"><p>Types <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code>
AND Qualifiers <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code></p></td>
<td><p>8.7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>8.8</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Kind <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code></p></td>
<td><p>8.7</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120a</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code></p></td>
</tr>
</tbody>
</table>
<section id="changes-in-ptx-isa-version-9-1">
<span id="id640"></span><h2>
<span class="section-number">13.1. </span><a class="reference internal" href="#changes-in-ptx-isa-version-9-1">Changes in PTX ISA Version 9.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-9-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 9.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.volatile</span></code> qualifier with <code class="docutils literal notranslate"><span class="pre">.local</span></code> state space for <code class="docutils literal notranslate"><span class="pre">ld</span></code> and
<code class="docutils literal notranslate"><span class="pre">st</span></code> instructions.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> source types for <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction
with destination types <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code> with <code class="docutils literal notranslate"><span class="pre">.ue8m0</span></code> as <code class="docutils literal notranslate"><span class="pre">.stype</span></code> with <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> for
<code class="docutils literal notranslate"><span class="pre">mma</span></code>/<code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instructions.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.s2f6x2</span></code> instruction type for <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">multimem.cp.async.bulk</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.cp.reduce.async.bulk</span></code> instructions.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-9-0">
<span id="id641"></span><h2>
<span class="section-number">13.2. </span><a class="reference internal" href="#changes-in-ptx-isa-version-9-0">Changes in PTX ISA Version 9.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-9-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 9.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_88</span></code> target architecture.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_110</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_110f</span></code> that supports family-specific features.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_110a</span></code> that supports architecture-specific features.</p></li>
<li><p>Adds support for pragma <code class="docutils literal notranslate"><span class="pre">enable_smem_spilling</span></code> that is used to enable shared
memory spilling for a function.</p></li>
<li><p>Adds support for pragma <code class="docutils literal notranslate"><span class="pre">frequency</span></code> that is used to specify the execution frequency of a basic
block.</p></li>
<li><p>Adds support for directive <code class="docutils literal notranslate"><span class="pre">.blocksareclusters</span></code> that is used to specify that CUDA thread blocks
are mapped to clusters.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">size</span></code> operand of <code class="docutils literal notranslate"><span class="pre">st.bulk</span></code> instruction to support 32-bit length.</p></li>
<li><p>Adds support for performance-tuning directives <code class="docutils literal notranslate"><span class="pre">.abi_preserve</span></code> and <code class="docutils literal notranslate"><span class="pre">.abi_preserve_control</span></code>
that are used to specify the number of data and control registers that should be preserved by the
callers of a function.</p></li>
</ul>
<p class="rubric">Notes</p>
<ul class="simple">
<li><p>Targets <code class="docutils literal notranslate"><span class="pre">sm_{101,101f,101a}</span></code> are renamed to targets <code class="docutils literal notranslate"><span class="pre">sm_{110,110f,110a}</span></code> from PTX ISA version 9.0.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>All <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> instructions(<code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws,</span> <span class="pre">tcgen05.mma.ws.sp</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code>) within a kernel must specify the same value for the <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> qualifier.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-8-8">
<span id="id642"></span><h2>
<span class="section-number">13.3. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-8">Changes in PTX ISA Version 8.8</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-8" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.8 introduces the following new features:</p>
<ul>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_103</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_103a</span></code> that supports architecture-specific features.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_121</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_121a</span></code> that supports architecture-specific features.</p></li>
<li><p>Introduces family-specific target architectures that are represented with â€œfâ€ suffix.
PTX for family-specific targets is compatible with all subsequent targets in same family.
Adds support for <code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_120f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_121f</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> instructions to support three input arguments.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> instruction to add support for new <code class="docutils literal notranslate"><span class="pre">scale_vectorsize</span></code>
qualifiers <code class="docutils literal notranslate"><span class="pre">.block16</span></code> and <code class="docutils literal notranslate"><span class="pre">.block32</span></code> and K dimension 96.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">.field3</span></code> of <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code> instruction to support 96B swizzle mode.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">tcgen05.ld.red</span></code> instruction.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> instructions to support 256b load/store operations.</p></li>
<li>
<p><a class="reference internal" href="#changes-in-ptx-isa-8-8-family-specific-features"><span class="std std-numref">Table 61</span></a> shows the list of features that are
supported on family-specific targets:</p>
<table class="table-no-stripes docutils align-default" id="changes-in-ptx-isa-8-8-family-specific-features">
<caption>
<span class="caption-number">Table 61 </span><span class="caption-text">List of features promoted to family-specific architecture</span><a class="headerlink" href="#changes-in-ptx-isa-8-8-family-specific-features" title="Permalink to this table">ïƒ</a>
</caption>
<colgroup>
<col style="width: 51%">
<col style="width: 49%">
</colgroup>
<thead>
<tr class="row-odd">
<th class="head"><p>Feature</p></th>
<th class="head"><p>Supported targets</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.m16n8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m8n16</span></code> shapes and <code class="docutils literal notranslate"><span class="pre">.b8</span></code>
type for <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code>/<code class="docutils literal notranslate"><span class="pre">stmatrix</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p>Shapes for <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> <code class="docutils literal notranslate"><span class="pre">.16x64b</span></code>
<code class="docutils literal notranslate"><span class="pre">.16x128b</span></code>, <code class="docutils literal notranslate"><span class="pre">.16x256b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.16x32bx2</span></code>, <code class="docutils literal notranslate"><span class="pre">.32x32b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.4x256b</span></code>, <code class="docutils literal notranslate"><span class="pre">.32x128b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.64x128b</span></code>, <code class="docutils literal notranslate"><span class="pre">.128x256b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.128x128b</span></code>, <code class="docutils literal notranslate"><span class="pre">.31x256b</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.cta_group</span></code> modifier</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">multimem</span></code> with <code class="docutils literal notranslate"><span class="pre">.acc::f16</span></code>
and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code> types</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld.red</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_103f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code>/<code class="docutils literal notranslate"><span class="pre">st</span></code>/<code class="docutils literal notranslate"><span class="pre">fence</span></code>/
<code class="docutils literal notranslate"><span class="pre">wait</span></code>/<code class="docutils literal notranslate"><span class="pre">commit</span></code>/<code class="docutils literal notranslate"><span class="pre">cp</span></code>/
<code class="docutils literal notranslate"><span class="pre">alloc</span></code>/<code class="docutils literal notranslate"><span class="pre">dealloc</span></code>/
<code class="docutils literal notranslate"><span class="pre">relinquish_alloc_permit</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">tcgen05.mma{.ws}{.sp}</span></code>
(except <code class="docutils literal notranslate"><span class="pre">kind::mxf4</span></code>/
<code class="docutils literal notranslate"><span class="pre">kind::mxf4nvf4</span></code> for <code class="docutils literal notranslate"><span class="pre">.sp</span></code>)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">tcgen05</span></code> <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::mxf4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::mxf8f6f4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.kind::tf32</span></code>,
<code class="docutils literal notranslate"><span class="pre">.kind::f8f6f4</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.ashift</span></code>, <code class="docutils literal notranslate"><span class="pre">.collector_usage</span></code>
modifiers for <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p>Modifiers <code class="docutils literal notranslate"><span class="pre">.b8x16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.b6x16_p32</span></code>, <code class="docutils literal notranslate"><span class="pre">.b4x16_p64</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.block_scale</span></code> modifier</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">mma{.sp}</span></code> with <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> types and
<code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>,
<code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code> modifiers
(except <code class="docutils literal notranslate"><span class="pre">.sp</span></code> with <code class="docutils literal notranslate"><span class="pre">mxf4</span></code>/
<code class="docutils literal notranslate"><span class="pre">mxf4nvf4</span></code>)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.scale_vec::1X</span></code>/<code class="docutils literal notranslate"><span class="pre">2X</span></code>/<code class="docutils literal notranslate"><span class="pre">4X</span></code>
modifiers</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">.block16</span></code>/<code class="docutils literal notranslate"><span class="pre">.block32</span></code>
modifiers (alias to
<code class="docutils literal notranslate"><span class="pre">scale_vec</span></code>)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.warpx2::02_13</span></code>,
<code class="docutils literal notranslate"><span class="pre">.warpx2::01_23</span></code>, <code class="docutils literal notranslate"><span class="pre">.warpx4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.pack::16b</span></code>,
<code class="docutils literal notranslate"><span class="pre">.unpack::16b</span></code> modifiers for
<code class="docutils literal notranslate"><span class="pre">tcgen05</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol.try_cancel</span></code>
<code class="docutils literal notranslate"><span class="pre">multicast::cluster::all</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code>,
<code class="docutils literal notranslate"><span class="pre">sm_120f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code>,
<code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code>,
<code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_101f</span></code></p></td>
</tr>
<tr class="row-even">
<td><p><code class="docutils literal notranslate"><span class="pre">redux.f32</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
<tr class="row-odd">
<td><p><code class="docutils literal notranslate"><span class="pre">scale-input-d</span></code> for <code class="docutils literal notranslate"><span class="pre">tcgen05</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">sm_100f</span></code></p></td>
</tr>
</tbody>
</table>
</li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Clarified the behavior of float-to-integer conversions for <code class="docutils literal notranslate"><span class="pre">NaN</span></code> input.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-8-7">
<span id="id643"></span><h2>
<span class="section-number">13.4. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-7">Changes in PTX ISA Version 8.7</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-7" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.7 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_120</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_120a</span></code> that supports architecture-specific features.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> instruction to add support for <code class="docutils literal notranslate"><span class="pre">.kind::mxf4nvf4</span></code> and <code class="docutils literal notranslate"><span class="pre">.scale_vec::4X</span></code>
qualifiers.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.f16</span></code> type accumulator and shape <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code> with
FP8 types <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction to add support for <code class="docutils literal notranslate"><span class="pre">.rs</span></code> rounding mode and destination types
<code class="docutils literal notranslate"><span class="pre">.e2m1x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e2m3x4</span></code>.</p></li>
<li><p>Extends support for <code class="docutils literal notranslate"><span class="pre">st.async</span></code> and <code class="docutils literal notranslate"><span class="pre">red.async</span></code> instructions to add support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code>, <code class="docutils literal notranslate"><span class="pre">.release</span></code>,
<code class="docutils literal notranslate"><span class="pre">.global</span></code> and <code class="docutils literal notranslate"><span class="pre">.scope</span></code> qualifiers.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code> instruction to add support for values <code class="docutils literal notranslate"><span class="pre">13</span></code> to <code class="docutils literal notranslate"><span class="pre">15</span></code> for
<code class="docutils literal notranslate"><span class="pre">.elemtype</span></code> qualifier.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> and <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> instructions to add support for types <code class="docutils literal notranslate"><span class="pre">.e3m2</span></code>/<code class="docutils literal notranslate"><span class="pre">.e2m3</span></code>/
<code class="docutils literal notranslate"><span class="pre">.e2m1</span></code> and qualifiers <code class="docutils literal notranslate"><span class="pre">.kind</span></code>, <code class="docutils literal notranslate"><span class="pre">.block_scale</span></code>, <code class="docutils literal notranslate"><span class="pre">.scale_vec_size</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Clarified that in <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code>, <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> modes, tensor coordinates need to be
specified as {col_idx, row_idx0, row_idx1, row_idx2, row_idx3} i.e. {x, y0, y1, y2, y3} instead
of {x0, x1, x2, x3, y}.</p></li>
<li><p>Updated <a class="reference internal" href="#tcgen05-instruction-descriptor"><span class="std std-ref">Instruction descriptor</span></a> of <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code> instruction
to clarify the bits that are reserved for future use.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-8-6">
<span id="id644"></span><h2>
<span class="section-number">13.5. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-6">Changes in PTX ISA Version 8.6</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-6" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.6 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_100</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_100a</span></code> that supports architecture-specific features.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_101</span></code> target architecture.</p></li>
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_101a</span></code> that supports architecture-specific features.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> instructions to add
<code class="docutils literal notranslate"><span class="pre">.shared::cta</span></code> as destination state space.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction to add support for <code class="docutils literal notranslate"><span class="pre">.acquire</span></code> and <code class="docutils literal notranslate"><span class="pre">.release</span></code> qualifiers.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">fence</span></code> and <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> instructions to add support for <code class="docutils literal notranslate"><span class="pre">.sync_restrict</span></code>
qualifier.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.m16n16</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n16</span></code> shapes and <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.src_fmt</span></code>, <code class="docutils literal notranslate"><span class="pre">.dst_fmt</span></code> qualifiers.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.m16n8</span></code> shape and <code class="docutils literal notranslate"><span class="pre">.b8</span></code> type.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">clusterlaunchcontrol</span></code> instruction.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code> and <code class="docutils literal notranslate"><span class="pre">fma</span></code> instructions to support mixed precision floating point
operations with <code class="docutils literal notranslate"><span class="pre">.f32</span></code> as destaination operand type and <code class="docutils literal notranslate"><span class="pre">.f16</span></code>/<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> as source operand
types.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">mul</span></code> and <code class="docutils literal notranslate"><span class="pre">fma</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.f32x2</span></code> type.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction with <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> type to support <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier
for <code class="docutils literal notranslate"><span class="pre">.rn</span></code>/<code class="docutils literal notranslate"><span class="pre">.rz</span></code> rounding modes.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.cp_mask</span></code> qualifier and <code class="docutils literal notranslate"><span class="pre">byteMask</span></code>
operand.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e5m2x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e5m2x4</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>, <code class="docutils literal notranslate"><span class="pre">.e4m3x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.e4m3x4</span></code> types.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction to support conversions to/from <code class="docutils literal notranslate"><span class="pre">.e2m1x2</span></code>, <code class="docutils literal notranslate"><span class="pre">.e3m2x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.e2m3x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.ue8m0x2</span></code> types.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code> instructions to
support new load_mode qualifiers <code class="docutils literal notranslate"><span class="pre">.tile::scatter4</span></code> and <code class="docutils literal notranslate"><span class="pre">.tile::gather4</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code> instruction to add support for new qualifier
<code class="docutils literal notranslate"><span class="pre">.swizzle_atomicity</span></code> for supporting new swizzle modes.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code>, <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code>, <code class="docutils literal notranslate"><span class="pre">.mbarrier.test_wait</span></code> and
<code class="docutils literal notranslate"><span class="pre">.mbarrier.try_wait</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.relaxed</span></code> qualifier.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.prefetch.tensor</span></code> instructions to
support new load_mode qualifiers <code class="docutils literal notranslate"><span class="pre">.im2col::w</span></code> and <code class="docutils literal notranslate"><span class="pre">.im2col::w::128</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> instruction to support new qualifier <code class="docutils literal notranslate"><span class="pre">.cta_group</span></code>.</p></li>
<li><p>Add support for <code class="docutils literal notranslate"><span class="pre">st.bulk</span></code> instruction.</p></li>
<li><p>Adds support for tcgen05 features and related instructions: <code class="docutils literal notranslate"><span class="pre">tcgen05.alloc</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.dealloc</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.relinquish_alloc_permit</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.ld</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.st</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.wait</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.cp</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.shift</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.sp</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws</span></code>,
<code class="docutils literal notranslate"><span class="pre">tcgen05.mma.ws.sp</span></code>, <code class="docutils literal notranslate"><span class="pre">tcgen05.fence</span></code> and <code class="docutils literal notranslate"><span class="pre">tcgen05.commit</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> instruction to add support for <code class="docutils literal notranslate"><span class="pre">.f32</span></code> type with qualifiers <code class="docutils literal notranslate"><span class="pre">.abs</span></code>
and <code class="docutils literal notranslate"><span class="pre">.NaN</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-8-5">
<span id="id645"></span><h2>
<span class="section-number">13.6. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-5">Changes in PTX ISA Version 8.5</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-5" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.5 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">mma.sp::ordered_metadata</span></code> instruction.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Values <code class="docutils literal notranslate"><span class="pre">0b0000</span></code>, <code class="docutils literal notranslate"><span class="pre">0b0101</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1010</span></code>, <code class="docutils literal notranslate"><span class="pre">0b1111</span></code> for sparsity metadata (operand <code class="docutils literal notranslate"><span class="pre">e</span></code>)
of instruction <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> are invalid and their usage results in undefined behavior.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-8-4">
<span id="id646"></span><h2>
<span class="section-number">13.7. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-4">Changes in PTX ISA Version 8.4</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-4" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.4 introduces the following new features:</p>
<ul class="simple">
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code> and <code class="docutils literal notranslate"><span class="pre">atom</span></code> instructions with <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type to support <code class="docutils literal notranslate"><span class="pre">.sys</span></code> scope.</p></li>
<li><p>Extends integer <code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.u8.s8</span></code> and <code class="docutils literal notranslate"><span class="pre">.s8.u8</span></code> as <code class="docutils literal notranslate"><span class="pre">.atype</span></code>
and <code class="docutils literal notranslate"><span class="pre">.btype</span></code> respectively.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code>, <code class="docutils literal notranslate"><span class="pre">mma.sp</span></code> instructions to support FP8 types <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-8-3">
<span id="id647"></span><h2>
<span class="section-number">13.8. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-3">Changes in PTX ISA Version 8.3</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-3" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.3 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for pragma <code class="docutils literal notranslate"><span class="pre">used_bytes_mask</span></code> that is used to specify mask for used bytes for a load operation.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">isspacep</span></code>, <code class="docutils literal notranslate"><span class="pre">cvta.to</span></code>, <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> instructions to accept <code class="docutils literal notranslate"><span class="pre">::entry</span></code> and <code class="docutils literal notranslate"><span class="pre">::func</span></code>
sub-qualifiers with <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space qualifier.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.b128</span></code> type on instructions <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code>, <code class="docutils literal notranslate"><span class="pre">ldu</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">mov</span></code> and <code class="docutils literal notranslate"><span class="pre">atom</span></code>.</p></li>
<li><p>Add support for instructions <code class="docutils literal notranslate"><span class="pre">tensormap.replace</span></code>, <code class="docutils literal notranslate"><span class="pre">tensormap.cp_fenceproxy</span></code> and support for qualifier
<code class="docutils literal notranslate"><span class="pre">.to_proxykind::from_proxykind</span></code> on instruction <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> to support modifying <code class="docutils literal notranslate"><span class="pre">tensor-map</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-8-2">
<span id="id648"></span><h2>
<span class="section-number">13.9. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-2">Changes in PTX ISA Version 8.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.2 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.mmio</span></code> qualifier on <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> instructions.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">lop3</span></code> instruction to allow predicate destination.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.acc::f32</span></code> qualifer to allow <code class="docutils literal notranslate"><span class="pre">.f32</span></code>
precision of the intermediate accumulation.</p></li>
<li><p>Extends the asynchronous warpgroup-level matrix multiply-and-accumulate operation
<code class="docutils literal notranslate"><span class="pre">wgmma.mma_async</span></code> to support <code class="docutils literal notranslate"><span class="pre">.sp</span></code> modifier that allows matrix multiply-accumulate operation
when input matrix A is sparse.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> qualifier on <code class="docutils literal notranslate"><span class="pre">cp.async.bulk</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async.bulk.tensor</span></code> instructions
is optimized for target architecture <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> and may have substantially reduced performance on
other targets and hence <code class="docutils literal notranslate"><span class="pre">.multicast::cluster</span></code> is advised to be used with <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code>.</p>
</section>
<section id="changes-in-ptx-isa-version-8-1">
<span id="id649"></span><h2>
<span class="section-number">13.10. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-1">Changes in PTX ISA Version 8.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">st.async</span></code> and <code class="docutils literal notranslate"><span class="pre">red.async</span></code> instructions for asynchronous store and
asynchronous reduction operations respectively on shared memory.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.oob</span></code> modifier on half-precision <code class="docutils literal notranslate"><span class="pre">fma</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> saturation modifer on <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction for <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16</span></code>
and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> formats.</p></li>
<li><p>Extends support for <code class="docutils literal notranslate"><span class="pre">cvt</span></code> with <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code>/<code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> to <code class="docutils literal notranslate"><span class="pre">sm_89</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">atom</span></code> and <code class="docutils literal notranslate"><span class="pre">red</span></code> instructions to support vector types.</p></li>
<li><p>Adds support for special register <code class="docutils literal notranslate"><span class="pre">%aggr_smem_size</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">sured</span></code> instruction with 64-bit <code class="docutils literal notranslate"><span class="pre">min</span></code>/<code class="docutils literal notranslate"><span class="pre">max</span></code> operations.</p></li>
<li><p>Adds support for increased kernel parameter size of 32764 bytes.</p></li>
<li><p>Adds support for multimem addresses in memory consistency model.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">multimem.ld_reduce</span></code>, <code class="docutils literal notranslate"><span class="pre">multimem.st</span></code> and <code class="docutils literal notranslate"><span class="pre">multimem.red</span></code> instructions to
perform memory operations on multimem addresses.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-8-0">
<span id="id650"></span><h2>
<span class="section-number">13.11. </span><a class="reference internal" href="#changes-in-ptx-isa-version-8-0">Changes in PTX ISA Version 8.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-8-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 8.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for target <code class="docutils literal notranslate"><span class="pre">sm_90a</span></code> that supports architecture-specific features.</p></li>
<li><p>Adds support for asynchronous warpgroup-level matrix multiply-and-accumulate operation <code class="docutils literal notranslate"><span class="pre">wgmma</span></code>.</p></li>
<li><p>Extends the asynchronous copy operations with bulk operations that operate on large data,
including tensor data.</p></li>
<li><p>Introduces packed integer types <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>.</p></li>
<li><p>Extends integer arithmetic instruction <code class="docutils literal notranslate"><span class="pre">add</span></code> to allow packed integer types <code class="docutils literal notranslate"><span class="pre">.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>.</p></li>
<li><p>Extends integer arithmetic instructions <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> to allow packed integer types
<code class="docutils literal notranslate"><span class="pre">.u16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code>, as well as saturation modifier <code class="docutils literal notranslate"><span class="pre">.relu</span></code> on <code class="docutils literal notranslate"><span class="pre">.s16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.s32</span></code>
types.</p></li>
<li><p>Adds support for special register <code class="docutils literal notranslate"><span class="pre">%current_graph_exec</span></code> that identifies the currently executing
CUDA device graph.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">elect.sync</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.unified</span></code> attribute on functions and variables.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">setmaxnreg</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.sem</span></code> qualifier on <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code> instruction.</p></li>
<li><p>Extends the <code class="docutils literal notranslate"><span class="pre">fence</span></code> instruction to allow opcode-specific synchronizaion using <code class="docutils literal notranslate"><span class="pre">op_restrict</span></code>
qualifier.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope on <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive</span></code>, <code class="docutils literal notranslate"><span class="pre">mbarrier.arrive_drop</span></code>,
<code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> and <code class="docutils literal notranslate"><span class="pre">mbarrier.try_wait</span></code> operations.</p></li>
<li><p>Adds support for transaction count operations on <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> objects, specified with
<code class="docutils literal notranslate"><span class="pre">.expect_tx</span></code> and <code class="docutils literal notranslate"><span class="pre">.complete_tx</span></code> qualifiers.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-8">
<span id="id651"></span><h2>
<span class="section-number">13.12. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-8">Changes in PTX ISA Version 7.8</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-8" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.8 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_89</span></code> target architecture.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">sm_90</span></code> target architecture.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">bar</span></code> and <code class="docutils literal notranslate"><span class="pre">barrier</span></code> instructions to accept optional scope qualifier <code class="docutils literal notranslate"><span class="pre">.cta</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space qualifier with optional sub-qualifier <code class="docutils literal notranslate"><span class="pre">::cta</span></code>.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">movmatrix</span></code> instruction which transposes a matrix in registers across a warp.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">stmatrix</span></code> instruction which stores one or more matrices to shared memory.</p></li>
<li><p>Extends the <code class="docutils literal notranslate"><span class="pre">.f64</span></code> floating point type <code class="docutils literal notranslate"><span class="pre">mma</span></code> operation with shapes <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>,
and <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, <code class="docutils literal notranslate"><span class="pre">mul</span></code>, <code class="docutils literal notranslate"><span class="pre">set</span></code>, <code class="docutils literal notranslate"><span class="pre">setp</span></code>, <code class="docutils literal notranslate"><span class="pre">cvt</span></code>, <code class="docutils literal notranslate"><span class="pre">tanh</span></code>, <code class="docutils literal notranslate"><span class="pre">ex2</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code> and
<code class="docutils literal notranslate"><span class="pre">red</span></code> instructions with <code class="docutils literal notranslate"><span class="pre">bf16</span></code> alternate floating point data format.</p></li>
<li><p>Adds support for new alternate floating-point data formats <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction to convert <code class="docutils literal notranslate"><span class="pre">.e4m3</span></code> and <code class="docutils literal notranslate"><span class="pre">.e5m2</span></code> alternate floating point data formats.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">griddepcontrol</span></code> instruction as a communication mechanism to control the
execution of dependent grids.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> instruction to allow a new phase completion check operation <em>try_wait</em>.</p></li>
<li><p>Adds support for new thread scope <code class="docutils literal notranslate"><span class="pre">.cluster</span></code> which is a set of Cooperative Thread Arrays (CTAs).</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">fence</span></code>/<code class="docutils literal notranslate"><span class="pre">membar</span></code>, <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code>, and <code class="docutils literal notranslate"><span class="pre">red</span></code> instructions to accept
<code class="docutils literal notranslate"><span class="pre">.cluster</span></code> scope.</p></li>
<li><p>Adds support for extended visibility of shared state space to all threads within a cluster.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space qualifier with <code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifier for cluster-level
visibility of shared memory.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">isspacep</span></code>, <code class="docutils literal notranslate"><span class="pre">cvta</span></code>, <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code>, and <code class="docutils literal notranslate"><span class="pre">red</span></code> instructions to accept
<code class="docutils literal notranslate"><span class="pre">::cluster</span></code> sub-qualifier with <code class="docutils literal notranslate"><span class="pre">.shared</span></code> state space qualifier.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">mapa</span></code> instruction to map a shared memory address to the corresponding address
in a different CTA within the cluster.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">getctarank</span></code> instruction to query the rank of the CTA that contains a given
address.</p></li>
<li><p>Adds support for new barrier synchronization instruction <code class="docutils literal notranslate"><span class="pre">barrier.cluster</span></code>.</p></li>
<li><p>Extends the memory consistency model to include the new cluster scope.</p></li>
<li><p>Adds support for special registers related to cluster information: <code class="docutils literal notranslate"><span class="pre">%is_explicit_cluster</span></code>,
<code class="docutils literal notranslate"><span class="pre">%clusterid</span></code>, <code class="docutils literal notranslate"><span class="pre">%nclusterid</span></code>, <code class="docutils literal notranslate"><span class="pre">%cluster_ctaid</span></code>, <code class="docutils literal notranslate"><span class="pre">%cluster_nctaid</span></code>, <code class="docutils literal notranslate"><span class="pre">%cluster_ctarank</span></code>,
<code class="docutils literal notranslate"><span class="pre">%cluster_nctarank</span></code>.</p></li>
<li><p>Adds support for cluster dimension directives <code class="docutils literal notranslate"><span class="pre">.reqnctapercluster</span></code>, <code class="docutils literal notranslate"><span class="pre">.explicitcluster</span></code>, and
<code class="docutils literal notranslate"><span class="pre">.maxclusterrank</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-7">
<span id="id652"></span><h2>
<span class="section-number">13.13. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-7">Changes in PTX ISA Version 7.7</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-7" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.7 introduces the following new features:</p>
<ul class="simple">
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">isspacep</span></code> and <code class="docutils literal notranslate"><span class="pre">cvta</span></code> instructions to include the <code class="docutils literal notranslate"><span class="pre">.param</span></code> state space for kernel
function parameters.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-6">
<span id="id653"></span><h2>
<span class="section-number">13.14. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-6">Changes in PTX ISA Version 7.6</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-6" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.6 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">szext</span></code> instruction which performs sign-extension or zero-extension on a specified
value.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">bmsk</span></code> instruction which creates a bitmask of the specified width starting at the
specified bit position.</p></li>
<li><p>Support for special registers <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_begin</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_end</span></code>,
<code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset_cap</span></code>, <code class="docutils literal notranslate"><span class="pre">%reserved_smem_offset&lt;2&gt;</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-5">
<span id="id654"></span><h2>
<span class="section-number">13.15. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-5">Changes in PTX ISA Version 7.5</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-5" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.5 introduces the following new features:</p>
<ul>
<li><p>Debug information enhancements to support label difference and negative values in the <code class="docutils literal notranslate"><span class="pre">.section</span></code>
debugging directive.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">ignore-src</span></code> operand on <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instruction.</p></li>
<li>
<p>Extensions to the memory consistency model to introduce the following new concepts:</p>
<blockquote>
<div>
<ul class="simple">
<li><p>A <em>memory proxy</em> as an abstract label for different methods of memory access.</p></li>
<li><p>Virtual aliases as distinct memory addresses accessing the same physical memory location.</p></li>
</ul>
</div>
</blockquote>
</li>
<li><p>Support for new <code class="docutils literal notranslate"><span class="pre">fence.proxy</span></code> and <code class="docutils literal notranslate"><span class="pre">membar.proxy</span></code> instructions to allow synchronization of
memory accesses performed via virtual aliases.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-4">
<span id="id655"></span><h2>
<span class="section-number">13.16. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-4">Changes in PTX ISA Version 7.4</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-4" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.4 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_87</span></code> target architecture.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.level::eviction_priority</span></code> qualifier which allows specifying cache eviction
priority hints on <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, and <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> instructions.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.level::prefetch_size</span></code> qualifier which allows specifying data prefetch hints on
<code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instructions.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">createpolicy</span></code> instruction which allows construction of different types of cache
eviction policies.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.level::cache_hint</span></code> qualifier which allows the use of cache eviction policies with
<code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code>, <code class="docutils literal notranslate"><span class="pre">red</span></code> and <code class="docutils literal notranslate"><span class="pre">cp.async</span></code> instructions.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">applypriority</span></code> and <code class="docutils literal notranslate"><span class="pre">discard</span></code> operations on cached data.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-3">
<span id="id656"></span><h2>
<span class="section-number">13.17. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-3">Changes in PTX ISA Version 7.3</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-3" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.3 introduces the following new features:</p>
<ul class="simple">
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mask()</span></code> operator used in initializers to also support integer constant expression.</p></li>
<li><p>Adds support for stack manpulation instructions that allow manipulating stack using <code class="docutils literal notranslate"><span class="pre">stacksave</span></code>
and <code class="docutils literal notranslate"><span class="pre">stackrestore</span></code> instructions and allocation of per-thread stack using <code class="docutils literal notranslate"><span class="pre">alloca</span></code>
instruction.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The unimplemented version of <code class="docutils literal notranslate"><span class="pre">alloca</span></code> from the older PTX ISA specification has been replaced with
new stack manipulation instructions in PTX ISA version 7.3.</p>
</section>
<section id="changes-in-ptx-isa-version-7-2">
<span id="id657"></span><h2>
<span class="section-number">13.18. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-2">Changes in PTX ISA Version 7.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.2 introduces the following new features:</p>
<ul class="simple">
<li><p>Enhances <code class="docutils literal notranslate"><span class="pre">.loc</span></code> directive to represent inline function information.</p></li>
<li><p>Adds support to define labels inside the debug sections.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.xorsign</span></code> and <code class="docutils literal notranslate"><span class="pre">.abs</span></code> modifiers.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-1">
<span id="id658"></span><h2>
<span class="section-number">13.19. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-1">Changes in PTX ISA Version 7.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_86</span></code> target architecture.</p></li>
<li><p>Adds a new operator, <code class="docutils literal notranslate"><span class="pre">mask()</span></code>, to extract a specific byte from variableâ€™s address used in
initializers.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tex</span></code> and <code class="docutils literal notranslate"><span class="pre">tld4</span></code> instructions to return an optional predicate that indicates if data
at specified coordinates is resident in memory.</p></li>
<li><p>Extends single-bit <code class="docutils literal notranslate"><span class="pre">wmma</span></code> and <code class="docutils literal notranslate"><span class="pre">mma</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.and</span></code> operation.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.sp</span></code> modifier that allows matrix multiply-accumulate
operation when input matrix A is sparse.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mbarrier.test_wait</span></code> instruction to test the completion of specific phase parity.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-7-0">
<span id="id659"></span><h2>
<span class="section-number">13.20. </span><a class="reference internal" href="#changes-in-ptx-isa-version-7-0">Changes in PTX ISA Version 7.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-7-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 7.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_80</span></code> target architecture.</p></li>
<li><p>Adds support for asynchronous copy instructions that allow copying of data asynchronously from one
state space to another.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">mbarrier</span></code> instructions that allow creation of <em>mbarrier objects</em> in memory and
use of these objects to synchronize threads and asynchronous copy operations initiated by threads.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">redux.sync</span></code> instruction which allows reduction operation across threads in a
warp.</p></li>
<li><p>Adds support for new alternate floating-point data formats <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type with shape <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> data format.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> data format with shape <code class="docutils literal notranslate"><span class="pre">.m16n16k8</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.f64</span></code> type with shape <code class="docutils literal notranslate"><span class="pre">.m8n8k4</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> data formats with shape
<code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction to support new shapes <code class="docutils literal notranslate"><span class="pre">.m8n8k128</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k4</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k16</span></code>,
<code class="docutils literal notranslate"><span class="pre">.m16n8k32</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k64</span></code>, <code class="docutils literal notranslate"><span class="pre">.m16n8k128</span></code> and <code class="docutils literal notranslate"><span class="pre">.m16n8k256</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">abs</span></code> and <code class="docutils literal notranslate"><span class="pre">neg</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> data formats.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">min</span></code> and <code class="docutils literal notranslate"><span class="pre">max</span></code> instructions to support <code class="docutils literal notranslate"><span class="pre">.NaN</span></code> modifier and <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> data formats.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">fma</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.relu</span></code> saturation mode and <code class="docutils literal notranslate"><span class="pre">.bf16</span></code> and <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code>
data formats.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.relu</span></code> saturation mode and <code class="docutils literal notranslate"><span class="pre">.f16</span></code>, <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code>,
<code class="docutils literal notranslate"><span class="pre">.bf16</span></code>, <code class="docutils literal notranslate"><span class="pre">.bf16x2</span></code> and <code class="docutils literal notranslate"><span class="pre">.tf32</span></code> destination formats.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">tanh</span></code> instruction that computes hyperbolic-tangent.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">ex2</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> types.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-6-5">
<span id="id660"></span><h2>
<span class="section-number">13.21. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-5">Changes in PTX ISA Version 6.5</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-5" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.5 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for integer destination types for half precision comparison instruction <code class="docutils literal notranslate"><span class="pre">set</span></code>.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">abs</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> types.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">cvt.pack</span></code> instruction which allows converting two integer values and packing
the results together.</p></li>
<li><p>Adds new shapes <code class="docutils literal notranslate"><span class="pre">.m16n8k8</span></code>, <code class="docutils literal notranslate"><span class="pre">.m8n8k16</span></code> and <code class="docutils literal notranslate"><span class="pre">.m8n8k32</span></code> on the <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">ldmatrix</span></code> instruction which loads one or more matrices from shared memory for
<code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction.</p></li>
</ul>
<p class="rubric">Removed Features</p>
<p>PTX ISA version 6.5 removes the following features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier on floating point <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction has been
removed. This support was deprecated since PTX ISA version 6.4.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-6-4">
<span id="id661"></span><h2>
<span class="section-number">13.22. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-4">Changes in PTX ISA Version 6.4</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-4" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.4 introduces the following new features:</p>
<ul class="simple">
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.noreturn</span></code> directive which can be used to indicate a function does not return
to itâ€™s caller function.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">mma</span></code> instruction which allows performing matrix multiply-and-accumulate
operation.</p></li>
</ul>
<p class="rubric">Deprecated Features</p>
<p>PTX ISA version 6.4 deprecates the following features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.satfinite</span></code> qualifier on floating point <code class="docutils literal notranslate"><span class="pre">wmma.mma</span></code> instruction.</p></li>
</ul>
<p class="rubric">Removed Features</p>
<p>PTX ISA version 6.4 removes the following features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">shfl</span></code> and <code class="docutils literal notranslate"><span class="pre">vote</span></code> instructions without the <code class="docutils literal notranslate"><span class="pre">.sync</span></code> qualifier has been removed
for <code class="docutils literal notranslate"><span class="pre">.target</span></code><code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and higher. This support was deprecated since PTX ISA version 6.0 as
documented in PTX ISA version 6.2.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Clarified that resolving references of a <code class="docutils literal notranslate"><span class="pre">.weak</span></code> symbol considers only <code class="docutils literal notranslate"><span class="pre">.weak</span></code> or <code class="docutils literal notranslate"><span class="pre">.visible</span></code>
symbols with the same name and does not consider local symbols with the same name.</p></li>
<li><p>Clarified that in <code class="docutils literal notranslate"><span class="pre">cvt</span></code> instruction, modifier <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> can only be specified when either
<code class="docutils literal notranslate"><span class="pre">.atype</span></code> or <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> is <code class="docutils literal notranslate"><span class="pre">.f32</span></code>.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-6-3">
<span id="id662"></span><h2>
<span class="section-number">13.23. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-3">Changes in PTX ISA Version 6.3</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-3" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.3 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_75</span></code> target architecture.</p></li>
<li><p>Adds support for a new instruction <code class="docutils literal notranslate"><span class="pre">nanosleep</span></code> that suspends a thread for a specified duration.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">.alias</span></code> directive which allows definining alias to function symbol.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">atom</span></code> instruction to perform <code class="docutils literal notranslate"><span class="pre">.f16</span></code> addition operation and <code class="docutils literal notranslate"><span class="pre">.cas.b16</span></code> operation.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">red</span></code> instruction to perform <code class="docutils literal notranslate"><span class="pre">.f16</span></code> addition operation.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions are extended to support multiplicand matrices of type <code class="docutils literal notranslate"><span class="pre">.s8</span></code>, <code class="docutils literal notranslate"><span class="pre">.u8</span></code>,
<code class="docutils literal notranslate"><span class="pre">.s4</span></code>, <code class="docutils literal notranslate"><span class="pre">.u4</span></code>, <code class="docutils literal notranslate"><span class="pre">.b1</span></code> and accumulator matrices of type <code class="docutils literal notranslate"><span class="pre">.s32</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Introduced the mandatory <code class="docutils literal notranslate"><span class="pre">.aligned</span></code> qualifier for all <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions.</p></li>
<li><p>Specified the alignment required for the base address and stride parameters passed to
<code class="docutils literal notranslate"><span class="pre">wmma.load</span></code> and <code class="docutils literal notranslate"><span class="pre">wmma.store</span></code>.</p></li>
<li><p>Clarified that layout of fragment returned by <code class="docutils literal notranslate"><span class="pre">wmma</span></code> operation is architecture dependent and
passing <code class="docutils literal notranslate"><span class="pre">wmma</span></code> fragments around functions compiled for different link compatible SM
architectures may not work as expected.</p></li>
<li><p>Clarified that atomicity for <code class="docutils literal notranslate"><span class="pre">{atom/red}.f16x2}</span></code> operations is guranteed separately for each of
the two <code class="docutils literal notranslate"><span class="pre">.f16</span></code> elements but not guranteed to be atomic as single 32-bit access.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-6-2">
<span id="id663"></span><h2>
<span class="section-number">13.24. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-2">Changes in PTX ISA Version 6.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.2 introduces the following new features:</p>
<ul class="simple">
<li><p>A new instruction <code class="docutils literal notranslate"><span class="pre">activemask</span></code> for querying active threads in a warp.</p></li>
<li><p>Extends atomic and reduction instructions to perform <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> addition operation with mandatory
<code class="docutils literal notranslate"><span class="pre">.noftz</span></code> qualifier.</p></li>
</ul>
<p class="rubric">Deprecated Features</p>
<p>PTX ISA version 6.2 deprecates the following features:</p>
<ul class="simple">
<li><p>The use of <code class="docutils literal notranslate"><span class="pre">shfl</span></code> and <code class="docutils literal notranslate"><span class="pre">vote</span></code> instructions without the <code class="docutils literal notranslate"><span class="pre">.sync</span></code> is deprecated retrospectively
from PTX ISA version 6.0, which introduced the <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> architecture that implements
<a class="reference internal" href="#independent-thread-scheduling"><span class="std std-ref">Independent Thread Scheduling</span></a>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Clarified that <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instructions can be used in conditionally executed code only if it is
known that all threads in the warp evaluate the condition identically, otherwise behavior is
undefined.</p></li>
<li><p>In the memory consistency model, the definition of <em>morally strong operations</em> was updated to
exclude fences from the requirement of <em>complete overlap</em> since fences do not access memory.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-6-1">
<span id="id664"></span><h2>
<span class="section-number">13.25. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-1">Changes in PTX ISA Version 6.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_72</span></code> target architecture.</p></li>
<li><p>Support for new matrix shapes <code class="docutils literal notranslate"><span class="pre">32x8x16</span></code> and <code class="docutils literal notranslate"><span class="pre">8x32x16</span></code> in <code class="docutils literal notranslate"><span class="pre">wmma</span></code> instruction.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-6-0">
<span id="id665"></span><h2>
<span class="section-number">13.26. </span><a class="reference internal" href="#changes-in-ptx-isa-version-6-0">Changes in PTX ISA Version 6.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-6-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 6.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> target architecture.</p></li>
<li><p>Specifies the memory consistency model for programs running on <code class="docutils literal notranslate"><span class="pre">sm_70</span></code> and later architectures.</p></li>
<li><p>Various extensions to memory instructions to specify memory synchronization semantics and scopes
at which such synchronization can be observed.</p></li>
<li><p>New instruction <code class="docutils literal notranslate"><span class="pre">wmma</span></code> for matrix operations which allows loading matrices from memory,
performing multiply-and-accumulate on them and storing result in memory.</p></li>
<li><p>Support for new <code class="docutils literal notranslate"><span class="pre">barrier</span></code> instruction.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">neg</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> types.</p></li>
<li><p>A new instruction <code class="docutils literal notranslate"><span class="pre">fns</span></code> which allows finding n-th set bit in integer.</p></li>
<li><p>A new instruction <code class="docutils literal notranslate"><span class="pre">bar.warp.sync</span></code> which allows synchronizing threads in warp.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">vote</span></code> and <code class="docutils literal notranslate"><span class="pre">shfl</span></code> instructions with <code class="docutils literal notranslate"><span class="pre">.sync</span></code> modifier which waits for specified
threads before executing the <code class="docutils literal notranslate"><span class="pre">vote</span></code> and <code class="docutils literal notranslate"><span class="pre">shfl</span></code> operation respectively.</p></li>
<li><p>A new instruction <code class="docutils literal notranslate"><span class="pre">match.sync</span></code> which allows broadcasting and comparing a value across threads in
warp.</p></li>
<li><p>A new instruction <code class="docutils literal notranslate"><span class="pre">brx.idx</span></code> which allows branching to a label indexed from list of potential
targets.</p></li>
<li><p>Support for unsized array parameter for <code class="docutils literal notranslate"><span class="pre">.func</span></code> which can be used to implement variadic
functions.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.b16</span></code> integer type in dwarf-lines.</p></li>
<li><p>Support for taking address of device function return parameters using <code class="docutils literal notranslate"><span class="pre">mov</span></code> instruction.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<ul class="simple">
<li><p>Semantics of <code class="docutils literal notranslate"><span class="pre">bar</span></code> instruction were updated to indicate that executing thread waits for other
non-exited threads from itâ€™s warp.</p></li>
<li><p>Support for indirect branch introduced in PTX 2.1 which was unimplemented has been removed from
the spec.</p></li>
<li><p>Support for taking address of labels, using labels in initializers which was unimplemented has
been removed from the spec.</p></li>
<li><p>Support for variadic functions which was unimplemented has been removed from the spec.</p></li>
</ul>
</section>
<section id="changes-in-ptx-isa-version-5-0">
<span id="id666"></span><h2>
<span class="section-number">13.27. </span><a class="reference internal" href="#changes-in-ptx-isa-version-5-0">Changes in PTX ISA Version 5.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-5-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 5.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_60</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_61</span></code>, <code class="docutils literal notranslate"><span class="pre">sm_62</span></code> target architecture.</p></li>
<li><p>Extends atomic and reduction instructions to perform double-precision add operation.</p></li>
<li><p>Extends atomic and reduction instructions to specify <code class="docutils literal notranslate"><span class="pre">scope</span></code> modifier.</p></li>
<li><p>A new <code class="docutils literal notranslate"><span class="pre">.common</span></code> directive to permit linking multiple object files containing declarations of the
same symbol with different size.</p></li>
<li><p>A new <code class="docutils literal notranslate"><span class="pre">dp4a</span></code> instruction which allows 4-way dot product with accumulate operation.</p></li>
<li><p>A new <code class="docutils literal notranslate"><span class="pre">dp2a</span></code> instruction which allows 2-way dot product with accumulate operation.</p></li>
<li><p>Support for special register <code class="docutils literal notranslate"><span class="pre">%clock_hi</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>Semantics of cache modifiers on <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> instructions were clarified to reflect cache
operations are treated as performance hint only and do not change memory consistency behavior of the
program.</p>
<p>Semantics of <code class="docutils literal notranslate"><span class="pre">volatile</span></code> operations on <code class="docutils literal notranslate"><span class="pre">ld</span></code> and <code class="docutils literal notranslate"><span class="pre">st</span></code> instructions were clarified to reflect how
<code class="docutils literal notranslate"><span class="pre">volatile</span></code> operations are handled by optimizing compiler.</p>
</section>
<section id="changes-in-ptx-isa-version-4-3">
<span id="id667"></span><h2>
<span class="section-number">13.28. </span><a class="reference internal" href="#changes-in-ptx-isa-version-4-3">Changes in PTX ISA Version 4.3</a><a class="headerlink" href="#changes-in-ptx-isa-version-4-3" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 4.3 introduces the following new features:</p>
<ul class="simple">
<li><p>A new <code class="docutils literal notranslate"><span class="pre">lop3</span></code> instruction which allows arbitrary logical operation on 3 inputs.</p></li>
<li><p>Adds support for 64-bit computations in extended precision arithmetic instructions.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tex.grad</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">cube</span></code> and <code class="docutils literal notranslate"><span class="pre">acube</span></code> geometries.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tld4</span></code> instruction to support <code class="docutils literal notranslate"><span class="pre">a2d</span></code>, <code class="docutils literal notranslate"><span class="pre">cube</span></code> and <code class="docutils literal notranslate"><span class="pre">acube</span></code> geometries.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">tex</span></code> and <code class="docutils literal notranslate"><span class="pre">tld4</span></code> instructions to support optional operands for offset vector and depth
compare.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">txq</span></code> instruction to support querying texture fields from specific LOD.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-4-2">
<span id="id668"></span><h2>
<span class="section-number">13.29. </span><a class="reference internal" href="#changes-in-ptx-isa-version-4-2">Changes in PTX ISA Version 4.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-4-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 4.2 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_53</span></code> target architecture.</p></li>
<li><p>Support for arithmetic, comparsion and texture instructions for <code class="docutils literal notranslate"><span class="pre">.f16</span></code> and <code class="docutils literal notranslate"><span class="pre">.f16x2</span></code> types.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">memory_layout</span></code> field for surfaces and <code class="docutils literal notranslate"><span class="pre">suq</span></code> instruction support for querying this
field.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>Semantics for parameter passing under ABI were updated to indicate <code class="docutils literal notranslate"><span class="pre">ld.param</span></code> and <code class="docutils literal notranslate"><span class="pre">st.param</span></code>
instructions used for argument passing cannot be predicated.</p>
<p>Semantics of <code class="docutils literal notranslate"><span class="pre">{atom/red}.add.f32</span></code> were updated to indicate subnormal inputs and results are
flushed to sign-preserving zero for atomic operations on global memory; whereas atomic operations on
shared memory preserve subnormal inputs and results and donâ€™t flush them to zero.</p>
</section>
<section id="changes-in-ptx-isa-version-4-1">
<span id="id669"></span><h2>
<span class="section-number">13.30. </span><a class="reference internal" href="#changes-in-ptx-isa-version-4-1">Changes in PTX ISA Version 4.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-4-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 4.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_37</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_52</span></code> target architectures.</p></li>
<li><p>Support for new fields <code class="docutils literal notranslate"><span class="pre">array_size</span></code>, <code class="docutils literal notranslate"><span class="pre">num_mipmap_levels</span></code> and <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> for Textures, and
the <code class="docutils literal notranslate"><span class="pre">txq</span></code> instruction support for querying these fields.</p></li>
<li><p>Support for new field <code class="docutils literal notranslate"><span class="pre">array_size</span></code> for Surfaces, and the <code class="docutils literal notranslate"><span class="pre">suq</span></code> instruction support for
querying this field.</p></li>
<li><p>Support for special registers <code class="docutils literal notranslate"><span class="pre">%total_smem_size</span></code> and <code class="docutils literal notranslate"><span class="pre">%dynamic_smem_size</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-4-0">
<span id="id670"></span><h2>
<span class="section-number">13.31. </span><a class="reference internal" href="#changes-in-ptx-isa-version-4-0">Changes in PTX ISA Version 4.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-4-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 4.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_32</span></code> and <code class="docutils literal notranslate"><span class="pre">sm_50</span></code> target architectures.</p></li>
<li><p>Support for 64bit performance counter special registers <code class="docutils literal notranslate"><span class="pre">%pm0_64,..,%pm7_64</span></code>.</p></li>
<li><p>A new <code class="docutils literal notranslate"><span class="pre">istypep</span></code> instruction.</p></li>
<li><p>A new instruction, <code class="docutils literal notranslate"><span class="pre">rsqrt.approx.ftz.f64</span></code> has been added to compute a fast approximation of the
square root reciprocal of a value.</p></li>
<li><p>Support for a new directive <code class="docutils literal notranslate"><span class="pre">.attribute</span></code> for specifying special attributes of a variable.</p></li>
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">.managed</span></code> variable attribute.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The <code class="docutils literal notranslate"><span class="pre">vote</span></code> instruction semantics were updated to clearly indicate that an inactive thread in a
warp contributes a 0 for its entry when participating in <code class="docutils literal notranslate"><span class="pre">vote.ballot.b32</span></code>.</p>
</section>
<section id="changes-in-ptx-isa-version-3-2">
<span id="id671"></span><h2>
<span class="section-number">13.32. </span><a class="reference internal" href="#changes-in-ptx-isa-version-3-2">Changes in PTX ISA Version 3.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-3-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 3.2 introduces the following new features:</p>
<ul class="simple">
<li><p>The texture instruction supports reads from multi-sample and multisample array textures.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">.section</span></code> debugging directive to include label + immediate expressions.</p></li>
<li><p>Extends <code class="docutils literal notranslate"><span class="pre">.file</span></code> directive to include timestamp and file size information.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The <code class="docutils literal notranslate"><span class="pre">vavrg2</span></code> and <code class="docutils literal notranslate"><span class="pre">vavrg4</span></code> instruction semantics were updated to indicate that instruction adds 1
only if Va[i] + Vb[i] is non-negative, and that the addition result is shifted by 1 (rather than
being divided by 2).</p>
</section>
<section id="changes-in-ptx-isa-version-3-1">
<span id="id672"></span><h2>
<span class="section-number">13.33. </span><a class="reference internal" href="#changes-in-ptx-isa-version-3-1">Changes in PTX ISA Version 3.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-3-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 3.1 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_35</span></code> target architecture.</p></li>
<li><p>Support for CUDA Dynamic Parallelism, which enables a kernel to create and synchronize new work.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ld.global.nc</span></code> for loading read-only global data though the non-coherent texture cache.</p></li>
<li><p>A new funnel shift instruction, <code class="docutils literal notranslate"><span class="pre">shf</span></code>.</p></li>
<li><p>Extends atomic and reduction instructions to perform 64-bit <code class="docutils literal notranslate"><span class="pre">{and,</span> <span class="pre">or,</span> <span class="pre">xor}</span></code> operations, and
64-bit integer <code class="docutils literal notranslate"><span class="pre">{min,</span> <span class="pre">max}</span></code> operations.</p></li>
<li><p>Adds support for <code class="docutils literal notranslate"><span class="pre">mipmaps</span></code>.</p></li>
<li><p>Adds support for indirect access to textures and surfaces.</p></li>
<li><p>Extends support for generic addressing to include the <code class="docutils literal notranslate"><span class="pre">.const</span></code> state space, and adds a new
operator, <code class="docutils literal notranslate"><span class="pre">generic()</span></code>, to form a generic address for <code class="docutils literal notranslate"><span class="pre">.global</span></code> or <code class="docutils literal notranslate"><span class="pre">.const</span></code> variables used in
initializers.</p></li>
<li><p>A new <code class="docutils literal notranslate"><span class="pre">.weak</span></code> directive to permit linking multiple object files containing declarations of the
same symbol.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>PTX 3.1 redefines the default addressing for global variables in initializers, from generic
addresses to offsets in the global state space. Legacy PTX code is treated as having an implicit
<code class="docutils literal notranslate"><span class="pre">generic()</span></code> operator for each global variable used in an initializer. PTX 3.1 code should either
include explicit <code class="docutils literal notranslate"><span class="pre">generic()</span></code> operators in initializers, use <code class="docutils literal notranslate"><span class="pre">cvta.global</span></code> to form generic
addresses at runtime, or load from the non-generic address using <code class="docutils literal notranslate"><span class="pre">ld.global</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> requires a rounding modifier for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> and higher targets. However for
PTX ISA version 3.0 and earlier, ptxas does not enforce this requirement and <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> silently
defaults to <code class="docutils literal notranslate"><span class="pre">mad.rn.f32</span></code>. For PTX ISA version 3.1, ptxas generates a warning and defaults to
<code class="docutils literal notranslate"><span class="pre">mad.rn.f32</span></code>, and in subsequent releases ptxas will enforce the requirement for PTX ISA version
3.2 and later.</p>
</section>
<section id="changes-in-ptx-isa-version-3-0">
<span id="id673"></span><h2>
<span class="section-number">13.34. </span><a class="reference internal" href="#changes-in-ptx-isa-version-3-0">Changes in PTX ISA Version 3.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-3-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX ISA version 3.0 introduces the following new features:</p>
<ul class="simple">
<li><p>Support for <code class="docutils literal notranslate"><span class="pre">sm_30</span></code> target architectures.</p></li>
<li><p>SIMD video instructions.</p></li>
<li><p>A new warp shuffle instruction.</p></li>
<li><p>Instructions <code class="docutils literal notranslate"><span class="pre">mad.cc</span></code> and <code class="docutils literal notranslate"><span class="pre">madc</span></code> for efficient, extended-precision integer multiplication.</p></li>
<li><p>Surface instructions with 3D and array geometries.</p></li>
<li><p>The texture instruction supports reads from cubemap and cubemap array textures.</p></li>
<li><p>Platform option <code class="docutils literal notranslate"><span class="pre">.target</span></code> debug to declare that a PTX module contains <code class="docutils literal notranslate"><span class="pre">DWARF</span></code> debug information.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pmevent.mask</span></code>, for triggering multiple performance monitor events.</p></li>
<li><p>Performance monitor counter special registers <code class="docutils literal notranslate"><span class="pre">%pm4..%pm7</span></code>.</p></li>
</ul>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>Special register <code class="docutils literal notranslate"><span class="pre">%gridid</span></code> has been extended from 32-bits to 64-bits.</p>
<p>PTX ISA version 3.0 deprecates module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code> and <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables when compiling to the
Application Binary Interface (ABI). When compiling without use of the ABI, module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code>
and <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables are supported as before. When compiling legacy PTX code (ISA versions prior
to 3.0) containing module-scoped <code class="docutils literal notranslate"><span class="pre">.reg</span></code> or <code class="docutils literal notranslate"><span class="pre">.local</span></code> variables, the compiler silently disables
use of the ABI.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">shfl</span></code> instruction semantics were updated to clearly indicate that value of source operand
<code class="docutils literal notranslate"><span class="pre">a</span></code> is unpredictable for inactive and predicated-off threads within the warp.</p>
<p>PTX modules no longer allow duplicate <code class="docutils literal notranslate"><span class="pre">.version</span></code> directives. This feature was unimplemented, so
there is no semantic change.</p>
<p>Unimplemented instructions <code class="docutils literal notranslate"><span class="pre">suld.p</span></code> and <code class="docutils literal notranslate"><span class="pre">sust.p.{u32,s32,f32}</span></code> have been removed.</p>
</section>
<section id="changes-in-ptx-isa-version-2-3">
<span id="id674"></span><h2>
<span class="section-number">13.35. </span><a class="reference internal" href="#changes-in-ptx-isa-version-2-3">Changes in PTX ISA Version 2.3</a><a class="headerlink" href="#changes-in-ptx-isa-version-2-3" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX 2.3 adds support for texture arrays. The texture array feature supports access to an array of 1D
or 2D textures, where an integer indexes into the array of textures, and then one or two
single-precision floating point coordinates are used to address within the selected 1D or 2D
texture.</p>
<p>PTX 2.3 adds a new directive, <code class="docutils literal notranslate"><span class="pre">.address_size</span></code>, for specifying the size of addresses.</p>
<p>Variables in <code class="docutils literal notranslate"><span class="pre">.const</span></code> and <code class="docutils literal notranslate"><span class="pre">.global</span></code> state spaces are initialized to zero by default.</p>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The semantics of the <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> directive have been updated to match the current
implementation. Specifically, <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code> only guarantees that the total number of threads in a
thread block does not exceed the maximum. Previously, the semantics indicated that the maximum was
enforced separately in each dimension, which is not the case.</p>
<p>Bit field extract and insert instructions BFE and BFI now indicate that the <code class="docutils literal notranslate"><span class="pre">len</span></code> and <code class="docutils literal notranslate"><span class="pre">pos</span></code>
operands are restricted to the value range <code class="docutils literal notranslate"><span class="pre">0..255</span></code>.</p>
<p>Unimplemented instructions <code class="docutils literal notranslate"><span class="pre">{atom,red}.{min,max}.f32</span></code> have been removed.</p>
</section>
<section id="changes-in-ptx-isa-version-2-2">
<span id="id675"></span><h2>
<span class="section-number">13.36. </span><a class="reference internal" href="#changes-in-ptx-isa-version-2-2">Changes in PTX ISA Version 2.2</a><a class="headerlink" href="#changes-in-ptx-isa-version-2-2" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>PTX 2.2 adds a new directive for specifying kernel parameter attributes; specifically, there is a
new directives for specifying that a kernel parameter is a pointer, for specifying to which state
space the parameter points, and for optionally specifying the alignment of the memory to which the
parameter points.</p>
<p>PTX 2.2 adds a new field named <code class="docutils literal notranslate"><span class="pre">force_unnormalized_coords</span></code> to the <code class="docutils literal notranslate"><span class="pre">.samplerref</span></code> opaque
type. This field is used in the independent texturing mode to override the <code class="docutils literal notranslate"><span class="pre">normalized_coords</span></code>
field in the texture header. This field is needed to support languages such as OpenCL, which
represent the property of normalized/unnormalized coordinates in the sampler header rather than in
the texture header.</p>
<p>PTX 2.2 deprecates explicit constant banks and supports a large, flat address space for the
<code class="docutils literal notranslate"><span class="pre">.const</span></code> state space. Legacy PTX that uses explicit constant banks is still supported.</p>
<p>PTX 2.2 adds a new <code class="docutils literal notranslate"><span class="pre">tld4</span></code> instruction for loading a component (<code class="docutils literal notranslate"><span class="pre">r</span></code>, <code class="docutils literal notranslate"><span class="pre">g</span></code>, <code class="docutils literal notranslate"><span class="pre">b</span></code>, or <code class="docutils literal notranslate"><span class="pre">a</span></code>) from
the four texels compising the bilinear interpolation footprint of a given texture location. This
instruction may be used to compute higher-precision bilerp results in software, or for performing
higher-bandwidth texture loads.</p>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>None.</p>
</section>
<section id="changes-in-ptx-isa-version-2-1">
<span id="id676"></span><h2>
<span class="section-number">13.37. </span><a class="reference internal" href="#changes-in-ptx-isa-version-2-1">Changes in PTX ISA Version 2.1</a><a class="headerlink" href="#changes-in-ptx-isa-version-2-1" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p>The underlying, stack-based ABI is supported in PTX ISA version 2.1 for <code class="docutils literal notranslate"><span class="pre">sm_2x</span></code> targets.</p>
<p>Support for indirect calls has been implemented for <code class="docutils literal notranslate"><span class="pre">sm_2x</span></code> targets.</p>
<p>New directives, <code class="docutils literal notranslate"><span class="pre">.branchtargets</span></code> and <code class="docutils literal notranslate"><span class="pre">.calltargets</span></code>, have been added for specifying potential
targets for indirect branches and indirect function calls. A <code class="docutils literal notranslate"><span class="pre">.callprototype</span></code> directive has been
added for declaring the type signatures for indirect function calls.</p>
<p>The names of <code class="docutils literal notranslate"><span class="pre">.global</span></code> and <code class="docutils literal notranslate"><span class="pre">.const</span></code> variables can now be specified in variable initializers to
represent their addresses.</p>
<p>A set of thirty-two driver-specific execution environment special registers has been added. These
are named <code class="docutils literal notranslate"><span class="pre">%envreg0..%envreg31</span></code>.</p>
<p>Textures and surfaces have new fields for channel data type and channel order, and the <code class="docutils literal notranslate"><span class="pre">txq</span></code> and
<code class="docutils literal notranslate"><span class="pre">suq</span></code> instructions support queries for these fields.</p>
<p>Directive <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> has replaced the <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> directive.</p>
<p>Directive <code class="docutils literal notranslate"><span class="pre">.reqntid</span></code> has been added to allow specification of exact CTA dimensions.</p>
<p>A new instruction, <code class="docutils literal notranslate"><span class="pre">rcp.approx.ftz.f64</span></code>, has been added to compute a fast, gross approximate
reciprocal.</p>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>A warning is emitted if <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> is specified without also specifying <code class="docutils literal notranslate"><span class="pre">.maxntid</span></code>.</p>
</section>
<section id="changes-in-ptx-isa-version-2-0">
<span id="id677"></span><h2>
<span class="section-number">13.38. </span><a class="reference internal" href="#changes-in-ptx-isa-version-2-0">Changes in PTX ISA Version 2.0</a><a class="headerlink" href="#changes-in-ptx-isa-version-2-0" title="Permalink to this headline">ïƒ</a>
</h2>
<p class="rubric">New Features</p>
<p class="rubric">Floating Point Extensions</p>
<p>This section describes the floating-point changes in PTX ISA version 2.0 for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> targets. The
goal is to achieve IEEE 754 compliance wherever possible, while maximizing backward compatibility
with legacy PTX ISA version 1.x code and <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets.</p>
<p>The changes from PTX ISA version 1.x are as follows:</p>
<ul class="simple">
<li><p>Single-precision instructions support subnormal numbers by default for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> targets. The
<code class="docutils literal notranslate"><span class="pre">.ftz</span></code> modifier may be used to enforce backward compatibility with <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code>.</p></li>
<li><p>Single-precision <code class="docutils literal notranslate"><span class="pre">add</span></code>, <code class="docutils literal notranslate"><span class="pre">sub</span></code>, and <code class="docutils literal notranslate"><span class="pre">mul</span></code> now support <code class="docutils literal notranslate"><span class="pre">.rm</span></code> and <code class="docutils literal notranslate"><span class="pre">.rp</span></code> rounding modifiers
for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> targets.</p></li>
<li><p>A single-precision fused multiply-add (fma) instruction has been added, with support for IEEE 754
compliant rounding modifiers and support for subnormal numbers. The <code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> instruction also
supports <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> and <code class="docutils literal notranslate"><span class="pre">.sat</span></code> modifiers. <code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> requires <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>. The <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code>
instruction has been extended with rounding modifiers so that itâ€™s synonymous with <code class="docutils literal notranslate"><span class="pre">fma.f32</span></code>
for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> targets. Both <code class="docutils literal notranslate"><span class="pre">fma.f32</span></code> and <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> require a rounding modifier for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>
targets.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code> instruction <em>without rounding</em> is retained so that compilers can generate code for
<code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> targets. When code compiled for <code class="docutils literal notranslate"><span class="pre">sm_1x</span></code> is executed on <code class="docutils literal notranslate"><span class="pre">sm_20</span></code> devices, <code class="docutils literal notranslate"><span class="pre">mad.f32</span></code>
maps to <code class="docutils literal notranslate"><span class="pre">fma.rn.f32</span></code>.</p></li>
<li><p>Single- and double-precision <code class="docutils literal notranslate"><span class="pre">div</span></code>, <code class="docutils literal notranslate"><span class="pre">rcp</span></code>, and <code class="docutils literal notranslate"><span class="pre">sqrt</span></code> with IEEE 754 compliant rounding have
been added. These are indicated by the use of a rounding modifier and require <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>.</p></li>
<li><p>Instructions <code class="docutils literal notranslate"><span class="pre">testp</span></code> and <code class="docutils literal notranslate"><span class="pre">copysign</span></code> have been added.</p></li>
</ul>
<p class="rubric">New Instructions</p>
<p>A <em>load uniform</em> instruction, <code class="docutils literal notranslate"><span class="pre">ldu</span></code>, has been added.</p>
<p>Surface instructions support additional <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> modifiers, <code class="docutils literal notranslate"><span class="pre">.clamp</span></code> and <code class="docutils literal notranslate"><span class="pre">.zero</span></code>.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">sust</span></code> now supports formatted surface stores.</p>
<p>A <em>count leading zeros</em> instruction, <code class="docutils literal notranslate"><span class="pre">clz</span></code>, has been added.</p>
<p>A <em>find leading non-sign bit instruction</em>, <code class="docutils literal notranslate"><span class="pre">bfind</span></code>, has been added.</p>
<p>A <em>bit reversal</em> instruction, <code class="docutils literal notranslate"><span class="pre">brev</span></code>, has been added.</p>
<p>Bit field extract and insert instructions, <code class="docutils literal notranslate"><span class="pre">bfe</span></code> and <code class="docutils literal notranslate"><span class="pre">bfi</span></code>, have been added.</p>
<p>A <em>population count</em> instruction, <code class="docutils literal notranslate"><span class="pre">popc</span></code>, has been added.</p>
<p>A <em>vote ballot</em> instruction, <code class="docutils literal notranslate"><span class="pre">vote.ballot.b32</span></code>, has been added.</p>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">{atom,red}.add.f32</span></code> have been implemented.</p>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">{atom,red}</span></code>.shared have been extended to handle 64-bit data types for <code class="docutils literal notranslate"><span class="pre">sm_20</span></code>
targets.</p>
<p>A system-level membar instruction, <code class="docutils literal notranslate"><span class="pre">membar.sys</span></code>, has been added.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">bar</span></code> instruction has been extended as follows:</p>
<ul class="simple">
<li><p>A <code class="docutils literal notranslate"><span class="pre">bar.arrive</span></code> instruction has been added.</p></li>
<li><p>Instructions <code class="docutils literal notranslate"><span class="pre">bar.red.popc.u32</span></code> and <code class="docutils literal notranslate"><span class="pre">bar.red.{and,or}.pred</span></code> have been added.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bar</span></code> now supports optional thread count and register operands.</p></li>
</ul>
<p>Scalar video instructions (includes <code class="docutils literal notranslate"><span class="pre">prmt</span></code>) have been added.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">isspacep</span></code> for querying whether a generic address falls within a specified state space
window has been added.</p>
<p>Instruction <code class="docutils literal notranslate"><span class="pre">cvta</span></code> for converting global, local, and shared addresses to generic address and
vice-versa has been added.</p>
<p class="rubric">Other New Features</p>
<p>Instructions <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">ldu</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetch</span></code>, <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code>, <code class="docutils literal notranslate"><span class="pre">isspacep</span></code>, <code class="docutils literal notranslate"><span class="pre">cvta</span></code>, <code class="docutils literal notranslate"><span class="pre">atom</span></code>,
and <code class="docutils literal notranslate"><span class="pre">red</span></code> now support generic addressing.</p>
<p>New special registers <code class="docutils literal notranslate"><span class="pre">%nwarpid</span></code>, <code class="docutils literal notranslate"><span class="pre">%nsmid</span></code>, <code class="docutils literal notranslate"><span class="pre">%clock64</span></code>, <code class="docutils literal notranslate"><span class="pre">%lanemask_{eq,le,lt,ge,gt}</span></code> have
been added.</p>
<p>Cache operations have been added to instructions <code class="docutils literal notranslate"><span class="pre">ld</span></code>, <code class="docutils literal notranslate"><span class="pre">st</span></code>, <code class="docutils literal notranslate"><span class="pre">suld</span></code>, and <code class="docutils literal notranslate"><span class="pre">sust</span></code>, e.g., for
<code class="docutils literal notranslate"><span class="pre">prefetching</span></code> to specified level of memory hierarchy. Instructions <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> and <code class="docutils literal notranslate"><span class="pre">prefetchu</span></code>
have also been added.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">.maxnctapersm</span></code> directive was deprecated and replaced with <code class="docutils literal notranslate"><span class="pre">.minnctapersm</span></code> to better match
its behavior and usage.</p>
<p>A new directive, <code class="docutils literal notranslate"><span class="pre">.section</span></code>, has been added to replace the <code class="docutils literal notranslate"><span class="pre">@@DWARF</span></code> syntax for passing
DWARF-format debugging information through PTX.</p>
<p>A new directive, <code class="docutils literal notranslate"><span class="pre">.pragma</span> <span class="pre">nounroll</span></code>, has been added to allow users to disable loop unrolling.</p>
<p class="rubric">Semantic Changes and Clarifications</p>
<p>The errata in <code class="docutils literal notranslate"><span class="pre">cvt.ftz</span></code> for PTX ISA versions 1.4 and earlier, where single-precision subnormal
inputs and results were not flushed to zero if either source or destination type size was 64-bits,
has been fixed. In PTX ISA version 1.5 and later, <code class="docutils literal notranslate"><span class="pre">cvt.ftz</span></code> (and <code class="docutils literal notranslate"><span class="pre">cvt</span></code> for <code class="docutils literal notranslate"><span class="pre">.target</span> <span class="pre">sm_1x</span></code>,
where <code class="docutils literal notranslate"><span class="pre">.ftz</span></code> is implied) instructions flush single-precision subnormal inputs and results to
sign-preserving zero for all combinations of floating-point instruction types. To maintain
compatibility with legacy PTX code, if .version is 1.4 or earlier, single-precision subnormal inputs
and results are flushed to sign-preserving zero only when neither source nor destination type size
is 64-bits.</p>
<p>Components of special registers <code class="docutils literal notranslate"><span class="pre">%tid</span></code>, <code class="docutils literal notranslate"><span class="pre">%ntid</span></code>, <code class="docutils literal notranslate"><span class="pre">%ctaid</span></code>, and <code class="docutils literal notranslate"><span class="pre">%nctaid</span></code> have been extended
from 16-bits to 32-bits. These registers now have type <code class="docutils literal notranslate"><span class="pre">.v4.u32</span></code>.</p>
<p>The number of samplers available in independent texturing mode was incorrectly listed as thirty-two
in PTX ISA version 1.5; the correct number is sixteen.</p>
</section>
</section>
<section id="notices">
<h1>
<span class="section-number">14. </span>Notices<a class="headerlink" href="#notices" title="Permalink to this headline">ïƒ</a>
</h1>
<section id="notice">
<h2>
<span class="section-number">14.1. </span>Notice<a class="headerlink" href="#notice" title="Permalink to this headline">ïƒ</a>
</h2>
<p>This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (â€œNVIDIAâ€) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.</p>
<p>NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice.</p>
<p>Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.</p>
<p>NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (â€œTerms of Saleâ€). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document.</p>
<p>NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customerâ€™s own risk.</p>
<p>NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customerâ€™s sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customerâ€™s product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs.</p>
<p>No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA.</p>
<p>Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.</p>
<p>THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, â€œMATERIALSâ€) ARE BEING PROVIDED â€œAS IS.â€ NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIAâ€™s aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product.</p>
</section>
<section id="opencl">
<h2>
<span class="section-number">14.2. </span>OpenCL<a class="headerlink" href="#opencl" title="Permalink to this headline">ïƒ</a>
</h2>
<p>OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc.</p>
</section>
<section id="trademarks">
<h2>
<span class="section-number">14.3. </span>Trademarks<a class="headerlink" href="#trademarks" title="Permalink to this headline">ïƒ</a>
</h2>
<p>NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr>

  <div role="contentinfo">
<img src="../_static/NVIDIA-LogoBlack.svg" class="only-light">
<img src="../_static/NVIDIA-LogoWhite.svg" class="only-dark">

<p class="notices">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank">Contact</a>
</p>

<p>
  Copyright Â© 2007-2026, NVIDIA Corporation &amp; affiliates. All rights reserved.
</p>

    <p>
      <span class="lastupdated">Last updated on Jan 08, 2026.
      </span></p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 



</body>
</html>
